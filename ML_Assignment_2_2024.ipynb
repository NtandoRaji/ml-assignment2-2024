{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(x):\n",
    "    labels = np.unique(x)\n",
    "    result = np.zeros(shape=(x.shape[0], labels.shape[0]))\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        result[i][x[i]] = 1.0\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_feature_cover(X, std_tol = 500):\n",
    "    x_mean = np.mean(X, axis = 0)\n",
    "    x_std = np.mean(X, axis = 0)\n",
    "    feature_cover = np.zeros(len(x_mean), dtype = bool)\n",
    "\n",
    "    for i in range(len(x_mean)):\n",
    "        if np.abs(x_std[i]) > std_tol:\n",
    "            feature_cover[i] = True    \n",
    "\n",
    "    return feature_cover\n",
    "\n",
    "\n",
    "def split_data(X, y, test_size=0.2, val_size=0.2, random_state=42):\n",
    "   \n",
    "    # Splitting the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Further splitting the training data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size / (1 - test_size),\n",
    "                                                      random_state=random_state)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [] # Features per class\n",
    "training_labels = [] # Labels\n",
    "testing_data = [] # Features per class\n",
    "testing_labels = [] # Labels\n",
    "N = 5250 # Amount of data we want to use max: 5250\n",
    "\n",
    "# Import the features\n",
    "with open(\"traindata.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        features = [float(i) for i in line.split(\",\")]\n",
    "        training_data.append(features)\n",
    "\n",
    "with open(\"testdata.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        features = [float(i) for i in line.split(\",\")]\n",
    "        testing_data.append(features)\n",
    "\n",
    "\n",
    "# Import the labels\n",
    "with open(\"trainlabels.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        label = float(line.rstrip())\n",
    "        training_labels.append(label)\n",
    "\n",
    "with open(\"targetlabels.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        label = float(line.rstrip())\n",
    "        testing_labels.append(label)\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "# X = np.array(training_data)\n",
    "# y = to_onehot(np.array(training_labels, dtype=np.int64))\n",
    "\n",
    "# feature_cover = generate_feature_cover(X, 1000)\n",
    "\n",
    "X_train = np.load(\"augmented_traindata.npy\")\n",
    "y_train = to_onehot(np.load(\"augmented_trainlabels.npy\"))\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(np.array(testing_data), to_onehot(np.array(testing_labels, dtype=np.int64)), test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the number of components to consider when performing pca\n",
    "def num_components(X, variance_tol = 0.8):\n",
    "    # Standardize each feature of the matrix\n",
    "    x_mean = np.mean(X, axis = 0)\n",
    "    x_std = np.std(X, axis = 0)\n",
    "    Z = (X - x_mean) / x_std\n",
    "\n",
    "    # Calculate covariance matrix\n",
    "    C = np.cov(Z, rowvar=False)\n",
    "    # Calculate eigenvalues and eigenvectors and sort by size\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(C)\n",
    "    index = eigenvalues.argsort()[:: -1]\n",
    "    eigenvalues = eigenvalues[index]\n",
    "    eigenvectors = eigenvectors[:, index]\n",
    "\n",
    "    # Calculate explained variance matrix \n",
    "    explained_var = np.cumsum(eigenvalues) / np.sum(eigenvalues)\n",
    "\n",
    "    # Select number of components responsible for variance_tol% of variance\n",
    "    n_components = np.argmax(explained_var >= variance_tol) + 1\n",
    "    return Z, x_mean, x_std, n_components\n",
    "\n",
    "# Parameters are trained components, trained mean, trained standard deviation and the new inputs X\n",
    "# Changes to the PCA basis\n",
    "def convert_to_pca(components, mean, std, X):\n",
    "    Z = (X - mean)/std\n",
    "    return Z @ components.transpose()\n",
    "\n",
    "Z, mean, std, n_components = num_components(X_train, 0.70)\n",
    "# Initialize prinicipal component analysis\n",
    "pca = PCA(n_components, random_state=453)\n",
    "pca.fit(Z)\n",
    "components = pca.components_\n",
    "X_train_PCA = pca.transform(Z)\n",
    "temp = pca.transform(X_test)\n",
    "X_test_PCA = convert_to_pca(components, mean, std, X_test)\n",
    "X_val_PCA = convert_to_pca(components, mean, std, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"pca_utils/pca_components\", components)\n",
    "np.save(\"pca_utils/X_mean\", mean)\n",
    "np.save(\"pca_utils/X_std\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5922, 63)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_PCA.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, p_dropout=0.20, save_dir=\"./models\"):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        activation = nn.ReLU()\n",
    "        dropout = nn.AlphaDropout(p=p_dropout)\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(in_features=n_inputs, out_features=1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            activation,\n",
    "            dropout,\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            activation,\n",
    "            dropout,\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            activation,\n",
    "            dropout,\n",
    "            nn.Linear(in_features=256, out_features=n_outputs),\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        logits = self.network(X)\n",
    "        return logits\n",
    "    \n",
    "    def save(self, name):\n",
    "        T.save(self.state_dict(), f\"{self.save_dir}/{name}.pth\")\n",
    "\n",
    "    def load(self, name):\n",
    "        self.load_state_dict(T.load(f\"{self.save_dir}/{name}.pth\"))\n",
    "\n",
    "n_inputs = X_train_PCA.shape[1] # 140 inputs\n",
    "n_outputs = 21 # 21 labels\n",
    "\n",
    "# Move a tensor to the GPU\n",
    "device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model\n",
    "model_1 = NeuralNetwork(n_inputs=n_inputs, n_outputs=n_outputs, p_dropout=0.3).to(device)\n",
    "model_2 = NeuralNetwork(n_inputs=n_inputs, n_outputs=n_outputs, p_dropout=0.3).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(y_pred, y_true, labels):\n",
    "    N = labels.shape[0]\n",
    "    matrix = [[0] * (N + 1) for _ in range(N + 1)]\n",
    "\n",
    "    matrix[0][0] = \" \"\n",
    "    for i in range(1, N):\n",
    "        matrix[i][0] = f\"{i}\"\n",
    "        matrix[0][i] = f\"{i}\"\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        matrix[round(y_pred[i]) + 1][y_true[i] + 1] += 1\n",
    "\n",
    "    for i in range(N):\n",
    "        print(\" \".join(map(str, matrix[i])))\n",
    "\n",
    "    return sum([matrix[i + 1][i + 1] for i in range(2)]) / len(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model1, model2, X_val, y_val, criterion):\n",
    "    size = len(y_val)\n",
    "\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "\n",
    "    with T.no_grad():\n",
    "        X = T.from_numpy(X_val).to(T.float32).to(device)\n",
    "        y_true = T.Tensor(y_val).to(T.float).to(device)\n",
    "\n",
    "        logits_1 = model1.forward(X)\n",
    "        logits_2 = model2.forward(X)\n",
    "\n",
    "        loss_1, loss_2 = criterion(logits_1, logits_2, y_true, 0.2)\n",
    "\n",
    "        correct_1 = (logits_1.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "        correct_2 = (logits_2.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "        \n",
    "        loss_1 /= size\n",
    "        loss_2 /= size\n",
    "        accuracy_1 = correct_1/size\n",
    "        accuracy_2 = correct_2/size\n",
    "        print(f\"Validation Error (Model 1): \\n Accuracy: {(100 * (accuracy_1)):>0.1f}%, Avg loss: {loss_1:>8f}\")\n",
    "        print(f\"Validation Error (Model 2): \\n Accuracy: {(100 * (accuracy_2)):>0.1f}%, Avg loss: {loss_2:>8f} \\n\")\n",
    "    \n",
    "    return accuracy_1, accuracy_2, loss_1, loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_1, model_2, X_train, y_train, criterion, optimizer_1, optimizer_2):\n",
    "    size = len(X_train)\n",
    "    batch_size = 141\n",
    "\n",
    "    #Prevents model from memorizing the position of data\n",
    "    indices = np.random.randint(0, size, size)\n",
    "\n",
    "    model_1.train()\n",
    "    model_2.train()\n",
    "\n",
    "    for i in range(size//batch_size):\n",
    "        start = batch_size * i\n",
    "        end = start + batch_size\n",
    "\n",
    "        X = T.from_numpy(X_train[indices[start:end]]).to(T.float32).to(device)\n",
    "        y_true = T.Tensor(y_train[indices[start:end]]).to(T.float).to(device)\n",
    "\n",
    "        logits_1 = model_1.forward(X)\n",
    "        logits_2 = model_2.forward(X)\n",
    "\n",
    "        loss_1, loss_2 = criterion(logits_1, logits_2, y_true, 0.2)\n",
    "\n",
    "        # Gradiant Descent using Adam optimizer for best performance\n",
    "        optimizer_1.zero_grad()\n",
    "        loss_1.backward()\n",
    "        optimizer_1.step()\n",
    "\n",
    "        optimizer_2.zero_grad()\n",
    "        loss_2.backward()\n",
    "        optimizer_2.step()\n",
    "\n",
    "        correct_1 = (logits_1.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "        correct_2 = (logits_2.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "\n",
    "        accuracy_1 = correct_1/batch_size\n",
    "        accuracy_2 = correct_2/batch_size\n",
    "\n",
    "        # if (i * batch_size) % 564 == 0:\n",
    "        #     loss_1, loss_2, current = loss_1.item(), loss_2.item(), (i + 1) * batch_size\n",
    "        #     print(f\"Accuracy_1: {(100 * (accuracy_1)):>0.1f}%, Loss_1: {loss_1:>7f}, \", end=\"\")\n",
    "        #     print(f\"Accuracy_2: {(100 * (accuracy_2)):>0.1f}% Loss_2: {loss_2:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Loss functions\n",
    "def loss_coteaching(y_1, y_2, t, forget_rate):\n",
    "    loss_1 = F.cross_entropy(y_1, t, reduction=\"none\")\n",
    "    ind_1_sorted = T.argsort(loss_1.data)\n",
    "    loss_1_sorted = loss_1[ind_1_sorted]\n",
    "\n",
    "    loss_2 = F.cross_entropy(y_2, t, reduction=\"none\")\n",
    "    ind_2_sorted = T.argsort(loss_2.data)\n",
    "    loss_2_sorted = loss_2[ind_2_sorted]\n",
    "\n",
    "    remember_rate = 1 - forget_rate\n",
    "    num_remember = int(remember_rate * len(loss_1_sorted))\n",
    "\n",
    "\n",
    "    ind_1_update=ind_1_sorted[:num_remember]\n",
    "    ind_2_update=ind_2_sorted[:num_remember]\n",
    "    # exchange\n",
    "    loss_1_update = F.cross_entropy(y_1[ind_2_update], t[ind_2_update])\n",
    "    loss_2_update = F.cross_entropy(y_2[ind_1_update], t[ind_1_update])\n",
    "\n",
    "    return T.sum(loss_1_update)/num_remember, T.sum(loss_2_update)/num_remember\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Accuracy_1: 3.5%, Loss_1: 0.029158, Accuracy_2: 7.8% Loss_2: 0.028289  [  141/ 5922]\n",
      "Accuracy_1: 8.5%, Loss_1: 0.027612, Accuracy_2: 7.8% Loss_2: 0.027972  [  705/ 5922]\n",
      "Accuracy_1: 7.8%, Loss_1: 0.027936, Accuracy_2: 8.5% Loss_2: 0.027984  [ 1269/ 5922]\n",
      "Accuracy_1: 5.7%, Loss_1: 0.027551, Accuracy_2: 9.2% Loss_2: 0.027756  [ 1833/ 5922]\n",
      "Accuracy_1: 8.5%, Loss_1: 0.028170, Accuracy_2: 7.8% Loss_2: 0.027212  [ 2397/ 5922]\n",
      "Accuracy_1: 7.1%, Loss_1: 0.027261, Accuracy_2: 4.3% Loss_2: 0.027137  [ 2961/ 5922]\n",
      "Accuracy_1: 5.7%, Loss_1: 0.027454, Accuracy_2: 6.4% Loss_2: 0.027612  [ 3525/ 5922]\n",
      "Accuracy_1: 7.8%, Loss_1: 0.026687, Accuracy_2: 5.0% Loss_2: 0.027160  [ 4089/ 5922]\n",
      "Accuracy_1: 9.2%, Loss_1: 0.026329, Accuracy_2: 6.4% Loss_2: 0.027401  [ 4653/ 5922]\n",
      "Accuracy_1: 15.6%, Loss_1: 0.025771, Accuracy_2: 11.3% Loss_2: 0.026317  [ 5217/ 5922]\n",
      "Accuracy_1: 12.8%, Loss_1: 0.025963, Accuracy_2: 9.2% Loss_2: 0.026026  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 18.7%, Avg loss: 0.000003\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 17.0%, Avg loss: 0.000003 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Accuracy_1: 13.5%, Loss_1: 0.026047, Accuracy_2: 11.3% Loss_2: 0.027045  [  141/ 5922]\n",
      "Accuracy_1: 8.5%, Loss_1: 0.026423, Accuracy_2: 11.3% Loss_2: 0.025724  [  705/ 5922]\n",
      "Accuracy_1: 14.9%, Loss_1: 0.024736, Accuracy_2: 10.6% Loss_2: 0.025648  [ 1269/ 5922]\n",
      "Accuracy_1: 13.5%, Loss_1: 0.024930, Accuracy_2: 14.2% Loss_2: 0.024770  [ 1833/ 5922]\n",
      "Accuracy_1: 10.6%, Loss_1: 0.024758, Accuracy_2: 13.5% Loss_2: 0.024872  [ 2397/ 5922]\n",
      "Accuracy_1: 12.8%, Loss_1: 0.025460, Accuracy_2: 12.1% Loss_2: 0.026261  [ 2961/ 5922]\n",
      "Accuracy_1: 12.1%, Loss_1: 0.024082, Accuracy_2: 19.9% Loss_2: 0.023874  [ 3525/ 5922]\n",
      "Accuracy_1: 15.6%, Loss_1: 0.023873, Accuracy_2: 15.6% Loss_2: 0.024190  [ 4089/ 5922]\n",
      "Accuracy_1: 17.7%, Loss_1: 0.023113, Accuracy_2: 14.9% Loss_2: 0.023767  [ 4653/ 5922]\n",
      "Accuracy_1: 18.4%, Loss_1: 0.023032, Accuracy_2: 18.4% Loss_2: 0.023826  [ 5217/ 5922]\n",
      "Accuracy_1: 12.8%, Loss_1: 0.023782, Accuracy_2: 17.7% Loss_2: 0.023003  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 19.7%, Avg loss: 0.000003\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 19.0%, Avg loss: 0.000003 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Accuracy_1: 18.4%, Loss_1: 0.023434, Accuracy_2: 14.2% Loss_2: 0.023749  [  141/ 5922]\n",
      "Accuracy_1: 19.9%, Loss_1: 0.022480, Accuracy_2: 19.1% Loss_2: 0.022435  [  705/ 5922]\n",
      "Accuracy_1: 12.1%, Loss_1: 0.022961, Accuracy_2: 17.0% Loss_2: 0.022142  [ 1269/ 5922]\n",
      "Accuracy_1: 19.1%, Loss_1: 0.021829, Accuracy_2: 20.6% Loss_2: 0.021672  [ 1833/ 5922]\n",
      "Accuracy_1: 13.5%, Loss_1: 0.022877, Accuracy_2: 16.3% Loss_2: 0.022719  [ 2397/ 5922]\n",
      "Accuracy_1: 13.5%, Loss_1: 0.022524, Accuracy_2: 19.1% Loss_2: 0.021917  [ 2961/ 5922]\n",
      "Accuracy_1: 16.3%, Loss_1: 0.021806, Accuracy_2: 15.6% Loss_2: 0.022203  [ 3525/ 5922]\n",
      "Accuracy_1: 15.6%, Loss_1: 0.021797, Accuracy_2: 19.9% Loss_2: 0.021286  [ 4089/ 5922]\n",
      "Accuracy_1: 19.9%, Loss_1: 0.021727, Accuracy_2: 22.0% Loss_2: 0.021792  [ 4653/ 5922]\n",
      "Accuracy_1: 13.5%, Loss_1: 0.021973, Accuracy_2: 20.6% Loss_2: 0.021172  [ 5217/ 5922]\n",
      "Accuracy_1: 17.0%, Loss_1: 0.022494, Accuracy_2: 16.3% Loss_2: 0.021779  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 21.3%, Avg loss: 0.000003\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 22.5%, Avg loss: 0.000003 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Accuracy_1: 19.1%, Loss_1: 0.021495, Accuracy_2: 18.4% Loss_2: 0.021823  [  141/ 5922]\n",
      "Accuracy_1: 16.3%, Loss_1: 0.021741, Accuracy_2: 19.9% Loss_2: 0.021602  [  705/ 5922]\n",
      "Accuracy_1: 19.9%, Loss_1: 0.020878, Accuracy_2: 23.4% Loss_2: 0.020595  [ 1269/ 5922]\n",
      "Accuracy_1: 17.0%, Loss_1: 0.021015, Accuracy_2: 21.3% Loss_2: 0.020608  [ 1833/ 5922]\n",
      "Accuracy_1: 15.6%, Loss_1: 0.021495, Accuracy_2: 15.6% Loss_2: 0.021795  [ 2397/ 5922]\n",
      "Accuracy_1: 22.0%, Loss_1: 0.020184, Accuracy_2: 24.1% Loss_2: 0.020156  [ 2961/ 5922]\n",
      "Accuracy_1: 19.9%, Loss_1: 0.019810, Accuracy_2: 23.4% Loss_2: 0.020154  [ 3525/ 5922]\n",
      "Accuracy_1: 19.1%, Loss_1: 0.020177, Accuracy_2: 23.4% Loss_2: 0.020242  [ 4089/ 5922]\n",
      "Accuracy_1: 21.3%, Loss_1: 0.019690, Accuracy_2: 22.0% Loss_2: 0.020057  [ 4653/ 5922]\n",
      "Accuracy_1: 28.4%, Loss_1: 0.019608, Accuracy_2: 26.2% Loss_2: 0.018956  [ 5217/ 5922]\n",
      "Accuracy_1: 27.7%, Loss_1: 0.019398, Accuracy_2: 29.8% Loss_2: 0.018827  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 26.9%, Avg loss: 0.000003\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 28.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Accuracy_1: 26.2%, Loss_1: 0.018047, Accuracy_2: 28.4% Loss_2: 0.018323  [  141/ 5922]\n",
      "Accuracy_1: 27.0%, Loss_1: 0.018486, Accuracy_2: 36.2% Loss_2: 0.017561  [  705/ 5922]\n",
      "Accuracy_1: 30.5%, Loss_1: 0.018107, Accuracy_2: 23.4% Loss_2: 0.019204  [ 1269/ 5922]\n",
      "Accuracy_1: 28.4%, Loss_1: 0.018891, Accuracy_2: 30.5% Loss_2: 0.018172  [ 1833/ 5922]\n",
      "Accuracy_1: 25.5%, Loss_1: 0.018797, Accuracy_2: 29.1% Loss_2: 0.017808  [ 2397/ 5922]\n",
      "Accuracy_1: 31.2%, Loss_1: 0.019374, Accuracy_2: 22.7% Loss_2: 0.019607  [ 2961/ 5922]\n",
      "Accuracy_1: 31.2%, Loss_1: 0.017623, Accuracy_2: 31.9% Loss_2: 0.017929  [ 3525/ 5922]\n",
      "Accuracy_1: 28.4%, Loss_1: 0.019029, Accuracy_2: 19.9% Loss_2: 0.019580  [ 4089/ 5922]\n",
      "Accuracy_1: 22.0%, Loss_1: 0.018662, Accuracy_2: 32.6% Loss_2: 0.017869  [ 4653/ 5922]\n",
      "Accuracy_1: 25.5%, Loss_1: 0.018267, Accuracy_2: 36.2% Loss_2: 0.017211  [ 5217/ 5922]\n",
      "Accuracy_1: 29.1%, Loss_1: 0.018341, Accuracy_2: 28.4% Loss_2: 0.018348  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 31.8%, Avg loss: 0.000003\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 33.2%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Accuracy_1: 33.3%, Loss_1: 0.018049, Accuracy_2: 34.0% Loss_2: 0.017168  [  141/ 5922]\n",
      "Accuracy_1: 35.5%, Loss_1: 0.016847, Accuracy_2: 29.8% Loss_2: 0.016918  [  705/ 5922]\n",
      "Accuracy_1: 31.2%, Loss_1: 0.018062, Accuracy_2: 32.6% Loss_2: 0.016901  [ 1269/ 5922]\n",
      "Accuracy_1: 29.1%, Loss_1: 0.017624, Accuracy_2: 28.4% Loss_2: 0.018531  [ 1833/ 5922]\n",
      "Accuracy_1: 29.8%, Loss_1: 0.017985, Accuracy_2: 29.8% Loss_2: 0.017439  [ 2397/ 5922]\n",
      "Accuracy_1: 32.6%, Loss_1: 0.017062, Accuracy_2: 32.6% Loss_2: 0.016381  [ 2961/ 5922]\n",
      "Accuracy_1: 29.8%, Loss_1: 0.017428, Accuracy_2: 27.7% Loss_2: 0.017818  [ 3525/ 5922]\n",
      "Accuracy_1: 32.6%, Loss_1: 0.017332, Accuracy_2: 31.2% Loss_2: 0.016718  [ 4089/ 5922]\n",
      "Accuracy_1: 31.9%, Loss_1: 0.016994, Accuracy_2: 36.2% Loss_2: 0.016075  [ 4653/ 5922]\n",
      "Accuracy_1: 25.5%, Loss_1: 0.017746, Accuracy_2: 34.8% Loss_2: 0.016443  [ 5217/ 5922]\n",
      "Accuracy_1: 32.6%, Loss_1: 0.015811, Accuracy_2: 35.5% Loss_2: 0.014923  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 35.2%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 35.2%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Accuracy_1: 30.5%, Loss_1: 0.016886, Accuracy_2: 24.8% Loss_2: 0.017668  [  141/ 5922]\n",
      "Accuracy_1: 31.2%, Loss_1: 0.017180, Accuracy_2: 31.9% Loss_2: 0.017724  [  705/ 5922]\n",
      "Accuracy_1: 24.8%, Loss_1: 0.017963, Accuracy_2: 30.5% Loss_2: 0.016820  [ 1269/ 5922]\n",
      "Accuracy_1: 38.3%, Loss_1: 0.015236, Accuracy_2: 41.8% Loss_2: 0.014853  [ 1833/ 5922]\n",
      "Accuracy_1: 34.8%, Loss_1: 0.015664, Accuracy_2: 35.5% Loss_2: 0.015833  [ 2397/ 5922]\n",
      "Accuracy_1: 26.2%, Loss_1: 0.016119, Accuracy_2: 31.9% Loss_2: 0.016837  [ 2961/ 5922]\n",
      "Accuracy_1: 35.5%, Loss_1: 0.014548, Accuracy_2: 36.2% Loss_2: 0.015026  [ 3525/ 5922]\n",
      "Accuracy_1: 28.4%, Loss_1: 0.016287, Accuracy_2: 36.2% Loss_2: 0.015351  [ 4089/ 5922]\n",
      "Accuracy_1: 33.3%, Loss_1: 0.016795, Accuracy_2: 29.1% Loss_2: 0.016925  [ 4653/ 5922]\n",
      "Accuracy_1: 28.4%, Loss_1: 0.017263, Accuracy_2: 29.1% Loss_2: 0.016243  [ 5217/ 5922]\n",
      "Accuracy_1: 37.6%, Loss_1: 0.014089, Accuracy_2: 36.2% Loss_2: 0.013987  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 36.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 38.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Accuracy_1: 34.0%, Loss_1: 0.017199, Accuracy_2: 30.5% Loss_2: 0.016744  [  141/ 5922]\n",
      "Accuracy_1: 27.7%, Loss_1: 0.016950, Accuracy_2: 28.4% Loss_2: 0.017743  [  705/ 5922]\n",
      "Accuracy_1: 34.0%, Loss_1: 0.015864, Accuracy_2: 30.5% Loss_2: 0.015231  [ 1269/ 5922]\n",
      "Accuracy_1: 36.2%, Loss_1: 0.015460, Accuracy_2: 40.4% Loss_2: 0.015183  [ 1833/ 5922]\n",
      "Accuracy_1: 31.9%, Loss_1: 0.015986, Accuracy_2: 29.1% Loss_2: 0.016211  [ 2397/ 5922]\n",
      "Accuracy_1: 38.3%, Loss_1: 0.014482, Accuracy_2: 36.9% Loss_2: 0.014957  [ 2961/ 5922]\n",
      "Accuracy_1: 41.8%, Loss_1: 0.013289, Accuracy_2: 34.8% Loss_2: 0.014660  [ 3525/ 5922]\n",
      "Accuracy_1: 35.5%, Loss_1: 0.014019, Accuracy_2: 36.9% Loss_2: 0.014152  [ 4089/ 5922]\n",
      "Accuracy_1: 36.9%, Loss_1: 0.013706, Accuracy_2: 36.2% Loss_2: 0.014757  [ 4653/ 5922]\n",
      "Accuracy_1: 43.3%, Loss_1: 0.014678, Accuracy_2: 37.6% Loss_2: 0.014351  [ 5217/ 5922]\n",
      "Accuracy_1: 38.3%, Loss_1: 0.014128, Accuracy_2: 36.2% Loss_2: 0.014273  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 40.2%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 41.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Accuracy_1: 35.5%, Loss_1: 0.014673, Accuracy_2: 35.5% Loss_2: 0.015286  [  141/ 5922]\n",
      "Accuracy_1: 37.6%, Loss_1: 0.014956, Accuracy_2: 35.5% Loss_2: 0.014641  [  705/ 5922]\n",
      "Accuracy_1: 41.8%, Loss_1: 0.014296, Accuracy_2: 40.4% Loss_2: 0.013997  [ 1269/ 5922]\n",
      "Accuracy_1: 36.2%, Loss_1: 0.014277, Accuracy_2: 46.1% Loss_2: 0.013296  [ 1833/ 5922]\n",
      "Accuracy_1: 31.9%, Loss_1: 0.014992, Accuracy_2: 34.0% Loss_2: 0.013915  [ 2397/ 5922]\n",
      "Accuracy_1: 40.4%, Loss_1: 0.014658, Accuracy_2: 36.9% Loss_2: 0.014492  [ 2961/ 5922]\n",
      "Accuracy_1: 45.4%, Loss_1: 0.013713, Accuracy_2: 41.8% Loss_2: 0.013886  [ 3525/ 5922]\n",
      "Accuracy_1: 43.3%, Loss_1: 0.013604, Accuracy_2: 39.7% Loss_2: 0.013616  [ 4089/ 5922]\n",
      "Accuracy_1: 41.8%, Loss_1: 0.013416, Accuracy_2: 37.6% Loss_2: 0.013845  [ 4653/ 5922]\n",
      "Accuracy_1: 44.7%, Loss_1: 0.013002, Accuracy_2: 36.2% Loss_2: 0.013994  [ 5217/ 5922]\n",
      "Accuracy_1: 39.0%, Loss_1: 0.014520, Accuracy_2: 31.2% Loss_2: 0.015551  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 41.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 42.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Accuracy_1: 34.8%, Loss_1: 0.015642, Accuracy_2: 36.2% Loss_2: 0.015140  [  141/ 5922]\n",
      "Accuracy_1: 41.1%, Loss_1: 0.014541, Accuracy_2: 44.0% Loss_2: 0.013234  [  705/ 5922]\n",
      "Accuracy_1: 42.6%, Loss_1: 0.013695, Accuracy_2: 46.1% Loss_2: 0.012291  [ 1269/ 5922]\n",
      "Accuracy_1: 36.9%, Loss_1: 0.013890, Accuracy_2: 38.3% Loss_2: 0.014313  [ 1833/ 5922]\n",
      "Accuracy_1: 34.8%, Loss_1: 0.014600, Accuracy_2: 37.6% Loss_2: 0.014722  [ 2397/ 5922]\n",
      "Accuracy_1: 39.7%, Loss_1: 0.014283, Accuracy_2: 36.2% Loss_2: 0.014435  [ 2961/ 5922]\n",
      "Accuracy_1: 44.7%, Loss_1: 0.013539, Accuracy_2: 40.4% Loss_2: 0.014104  [ 3525/ 5922]\n",
      "Accuracy_1: 44.0%, Loss_1: 0.012724, Accuracy_2: 45.4% Loss_2: 0.013060  [ 4089/ 5922]\n",
      "Accuracy_1: 52.5%, Loss_1: 0.011527, Accuracy_2: 52.5% Loss_2: 0.011202  [ 4653/ 5922]\n",
      "Accuracy_1: 41.8%, Loss_1: 0.013201, Accuracy_2: 42.6% Loss_2: 0.013190  [ 5217/ 5922]\n",
      "Accuracy_1: 44.0%, Loss_1: 0.014362, Accuracy_2: 44.0% Loss_2: 0.013630  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 44.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 43.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Accuracy_1: 41.8%, Loss_1: 0.013331, Accuracy_2: 37.6% Loss_2: 0.013989  [  141/ 5922]\n",
      "Accuracy_1: 39.7%, Loss_1: 0.013856, Accuracy_2: 38.3% Loss_2: 0.014245  [  705/ 5922]\n",
      "Accuracy_1: 41.1%, Loss_1: 0.014046, Accuracy_2: 39.0% Loss_2: 0.013862  [ 1269/ 5922]\n",
      "Accuracy_1: 35.5%, Loss_1: 0.015025, Accuracy_2: 38.3% Loss_2: 0.013906  [ 1833/ 5922]\n",
      "Accuracy_1: 45.4%, Loss_1: 0.012772, Accuracy_2: 39.0% Loss_2: 0.012490  [ 2397/ 5922]\n",
      "Accuracy_1: 39.0%, Loss_1: 0.013605, Accuracy_2: 41.1% Loss_2: 0.012797  [ 2961/ 5922]\n",
      "Accuracy_1: 36.9%, Loss_1: 0.013970, Accuracy_2: 38.3% Loss_2: 0.013763  [ 3525/ 5922]\n",
      "Accuracy_1: 42.6%, Loss_1: 0.012665, Accuracy_2: 40.4% Loss_2: 0.013682  [ 4089/ 5922]\n",
      "Accuracy_1: 52.5%, Loss_1: 0.011272, Accuracy_2: 48.2% Loss_2: 0.010854  [ 4653/ 5922]\n",
      "Accuracy_1: 36.9%, Loss_1: 0.014059, Accuracy_2: 41.8% Loss_2: 0.014264  [ 5217/ 5922]\n",
      "Accuracy_1: 45.4%, Loss_1: 0.013735, Accuracy_2: 41.8% Loss_2: 0.013103  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 44.1%, Avg loss: 0.000003\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 44.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Accuracy_1: 36.9%, Loss_1: 0.014150, Accuracy_2: 41.8% Loss_2: 0.014402  [  141/ 5922]\n",
      "Accuracy_1: 44.7%, Loss_1: 0.012985, Accuracy_2: 48.2% Loss_2: 0.011444  [  705/ 5922]\n",
      "Accuracy_1: 41.1%, Loss_1: 0.014430, Accuracy_2: 39.7% Loss_2: 0.014786  [ 1269/ 5922]\n",
      "Accuracy_1: 46.1%, Loss_1: 0.012526, Accuracy_2: 41.1% Loss_2: 0.013468  [ 1833/ 5922]\n",
      "Accuracy_1: 41.1%, Loss_1: 0.014537, Accuracy_2: 42.6% Loss_2: 0.014199  [ 2397/ 5922]\n",
      "Accuracy_1: 44.0%, Loss_1: 0.013198, Accuracy_2: 34.8% Loss_2: 0.014884  [ 2961/ 5922]\n",
      "Accuracy_1: 39.0%, Loss_1: 0.014881, Accuracy_2: 43.3% Loss_2: 0.013284  [ 3525/ 5922]\n",
      "Accuracy_1: 39.0%, Loss_1: 0.013970, Accuracy_2: 43.3% Loss_2: 0.013992  [ 4089/ 5922]\n",
      "Accuracy_1: 40.4%, Loss_1: 0.013324, Accuracy_2: 47.5% Loss_2: 0.012763  [ 4653/ 5922]\n",
      "Accuracy_1: 35.5%, Loss_1: 0.015283, Accuracy_2: 42.6% Loss_2: 0.014843  [ 5217/ 5922]\n",
      "Accuracy_1: 46.8%, Loss_1: 0.013211, Accuracy_2: 44.7% Loss_2: 0.013965  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 44.4%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 44.8%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Accuracy_1: 46.1%, Loss_1: 0.011383, Accuracy_2: 41.1% Loss_2: 0.013783  [  141/ 5922]\n",
      "Accuracy_1: 43.3%, Loss_1: 0.012713, Accuracy_2: 46.1% Loss_2: 0.011989  [  705/ 5922]\n",
      "Accuracy_1: 36.2%, Loss_1: 0.015061, Accuracy_2: 39.7% Loss_2: 0.013846  [ 1269/ 5922]\n",
      "Accuracy_1: 39.0%, Loss_1: 0.013425, Accuracy_2: 41.1% Loss_2: 0.012949  [ 1833/ 5922]\n",
      "Accuracy_1: 42.6%, Loss_1: 0.012411, Accuracy_2: 45.4% Loss_2: 0.012071  [ 2397/ 5922]\n",
      "Accuracy_1: 43.3%, Loss_1: 0.011416, Accuracy_2: 53.9% Loss_2: 0.010652  [ 2961/ 5922]\n",
      "Accuracy_1: 53.9%, Loss_1: 0.010496, Accuracy_2: 54.6% Loss_2: 0.010097  [ 3525/ 5922]\n",
      "Accuracy_1: 44.7%, Loss_1: 0.013024, Accuracy_2: 37.6% Loss_2: 0.014504  [ 4089/ 5922]\n",
      "Accuracy_1: 36.9%, Loss_1: 0.013615, Accuracy_2: 43.3% Loss_2: 0.013754  [ 4653/ 5922]\n",
      "Accuracy_1: 44.0%, Loss_1: 0.013214, Accuracy_2: 44.7% Loss_2: 0.012513  [ 5217/ 5922]\n",
      "Accuracy_1: 44.7%, Loss_1: 0.012539, Accuracy_2: 38.3% Loss_2: 0.013143  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 45.5%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 46.8%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Accuracy_1: 44.0%, Loss_1: 0.012300, Accuracy_2: 44.0% Loss_2: 0.012686  [  141/ 5922]\n",
      "Accuracy_1: 39.0%, Loss_1: 0.013202, Accuracy_2: 41.1% Loss_2: 0.013327  [  705/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.011916, Accuracy_2: 39.7% Loss_2: 0.012509  [ 1269/ 5922]\n",
      "Accuracy_1: 38.3%, Loss_1: 0.014399, Accuracy_2: 40.4% Loss_2: 0.014596  [ 1833/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.012095, Accuracy_2: 46.8% Loss_2: 0.012673  [ 2397/ 5922]\n",
      "Accuracy_1: 46.1%, Loss_1: 0.011973, Accuracy_2: 43.3% Loss_2: 0.012045  [ 2961/ 5922]\n",
      "Accuracy_1: 44.7%, Loss_1: 0.010690, Accuracy_2: 48.2% Loss_2: 0.011465  [ 3525/ 5922]\n",
      "Accuracy_1: 39.7%, Loss_1: 0.013051, Accuracy_2: 46.8% Loss_2: 0.013341  [ 4089/ 5922]\n",
      "Accuracy_1: 46.1%, Loss_1: 0.012247, Accuracy_2: 46.8% Loss_2: 0.012364  [ 4653/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.013001, Accuracy_2: 48.2% Loss_2: 0.011902  [ 5217/ 5922]\n",
      "Accuracy_1: 42.6%, Loss_1: 0.011955, Accuracy_2: 42.6% Loss_2: 0.012060  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 46.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 47.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Accuracy_1: 45.4%, Loss_1: 0.010634, Accuracy_2: 42.6% Loss_2: 0.010946  [  141/ 5922]\n",
      "Accuracy_1: 44.7%, Loss_1: 0.011670, Accuracy_2: 51.8% Loss_2: 0.011772  [  705/ 5922]\n",
      "Accuracy_1: 48.9%, Loss_1: 0.011274, Accuracy_2: 45.4% Loss_2: 0.011368  [ 1269/ 5922]\n",
      "Accuracy_1: 46.1%, Loss_1: 0.010892, Accuracy_2: 52.5% Loss_2: 0.011127  [ 1833/ 5922]\n",
      "Accuracy_1: 41.8%, Loss_1: 0.013108, Accuracy_2: 42.6% Loss_2: 0.012380  [ 2397/ 5922]\n",
      "Accuracy_1: 45.4%, Loss_1: 0.012361, Accuracy_2: 39.7% Loss_2: 0.013716  [ 2961/ 5922]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.011497, Accuracy_2: 46.8% Loss_2: 0.012543  [ 3525/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.012459, Accuracy_2: 42.6% Loss_2: 0.011875  [ 4089/ 5922]\n",
      "Accuracy_1: 52.5%, Loss_1: 0.012171, Accuracy_2: 41.8% Loss_2: 0.013186  [ 4653/ 5922]\n",
      "Accuracy_1: 46.1%, Loss_1: 0.012172, Accuracy_2: 46.1% Loss_2: 0.012011  [ 5217/ 5922]\n",
      "Accuracy_1: 48.9%, Loss_1: 0.012329, Accuracy_2: 46.8% Loss_2: 0.012068  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 48.2%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 47.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Accuracy_1: 39.7%, Loss_1: 0.013332, Accuracy_2: 44.0% Loss_2: 0.013763  [  141/ 5922]\n",
      "Accuracy_1: 41.1%, Loss_1: 0.014542, Accuracy_2: 41.1% Loss_2: 0.013383  [  705/ 5922]\n",
      "Accuracy_1: 41.1%, Loss_1: 0.012493, Accuracy_2: 45.4% Loss_2: 0.011164  [ 1269/ 5922]\n",
      "Accuracy_1: 45.4%, Loss_1: 0.013014, Accuracy_2: 46.8% Loss_2: 0.012793  [ 1833/ 5922]\n",
      "Accuracy_1: 45.4%, Loss_1: 0.011655, Accuracy_2: 43.3% Loss_2: 0.011797  [ 2397/ 5922]\n",
      "Accuracy_1: 44.7%, Loss_1: 0.011506, Accuracy_2: 55.3% Loss_2: 0.010088  [ 2961/ 5922]\n",
      "Accuracy_1: 49.6%, Loss_1: 0.010885, Accuracy_2: 41.8% Loss_2: 0.011483  [ 3525/ 5922]\n",
      "Accuracy_1: 46.8%, Loss_1: 0.011667, Accuracy_2: 44.7% Loss_2: 0.011758  [ 4089/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.010851, Accuracy_2: 45.4% Loss_2: 0.011291  [ 4653/ 5922]\n",
      "Accuracy_1: 45.4%, Loss_1: 0.011577, Accuracy_2: 45.4% Loss_2: 0.011028  [ 5217/ 5922]\n",
      "Accuracy_1: 42.6%, Loss_1: 0.011974, Accuracy_2: 42.6% Loss_2: 0.012153  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 48.6%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 48.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Accuracy_1: 47.5%, Loss_1: 0.010840, Accuracy_2: 55.3% Loss_2: 0.009543  [  141/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.010709, Accuracy_2: 46.8% Loss_2: 0.011852  [  705/ 5922]\n",
      "Accuracy_1: 43.3%, Loss_1: 0.012773, Accuracy_2: 51.8% Loss_2: 0.010037  [ 1269/ 5922]\n",
      "Accuracy_1: 52.5%, Loss_1: 0.010295, Accuracy_2: 52.5% Loss_2: 0.010450  [ 1833/ 5922]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.010479, Accuracy_2: 51.8% Loss_2: 0.010907  [ 2397/ 5922]\n",
      "Accuracy_1: 42.6%, Loss_1: 0.013676, Accuracy_2: 43.3% Loss_2: 0.012142  [ 2961/ 5922]\n",
      "Accuracy_1: 44.7%, Loss_1: 0.011418, Accuracy_2: 48.9% Loss_2: 0.011211  [ 3525/ 5922]\n",
      "Accuracy_1: 56.0%, Loss_1: 0.010508, Accuracy_2: 56.0% Loss_2: 0.010706  [ 4089/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.011894, Accuracy_2: 51.8% Loss_2: 0.013131  [ 4653/ 5922]\n",
      "Accuracy_1: 46.1%, Loss_1: 0.011446, Accuracy_2: 55.3% Loss_2: 0.012130  [ 5217/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.010764, Accuracy_2: 56.7% Loss_2: 0.010397  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 48.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 48.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Accuracy_1: 53.9%, Loss_1: 0.011513, Accuracy_2: 48.2% Loss_2: 0.011281  [  141/ 5922]\n",
      "Accuracy_1: 45.4%, Loss_1: 0.011224, Accuracy_2: 48.2% Loss_2: 0.011553  [  705/ 5922]\n",
      "Accuracy_1: 48.9%, Loss_1: 0.010137, Accuracy_2: 49.6% Loss_2: 0.010780  [ 1269/ 5922]\n",
      "Accuracy_1: 44.7%, Loss_1: 0.012000, Accuracy_2: 42.6% Loss_2: 0.011235  [ 1833/ 5922]\n",
      "Accuracy_1: 46.8%, Loss_1: 0.012312, Accuracy_2: 41.8% Loss_2: 0.012562  [ 2397/ 5922]\n",
      "Accuracy_1: 52.5%, Loss_1: 0.010944, Accuracy_2: 46.8% Loss_2: 0.012641  [ 2961/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.012231, Accuracy_2: 47.5% Loss_2: 0.011257  [ 3525/ 5922]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.010496, Accuracy_2: 51.8% Loss_2: 0.010353  [ 4089/ 5922]\n",
      "Accuracy_1: 41.1%, Loss_1: 0.014240, Accuracy_2: 44.7% Loss_2: 0.013157  [ 4653/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.012150, Accuracy_2: 46.8% Loss_2: 0.011957  [ 5217/ 5922]\n",
      "Accuracy_1: 46.8%, Loss_1: 0.011830, Accuracy_2: 44.7% Loss_2: 0.011686  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 48.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 49.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Accuracy_1: 45.4%, Loss_1: 0.012895, Accuracy_2: 48.9% Loss_2: 0.011589  [  141/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.010347, Accuracy_2: 46.8% Loss_2: 0.010253  [  705/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.010644, Accuracy_2: 44.7% Loss_2: 0.011379  [ 1269/ 5922]\n",
      "Accuracy_1: 46.8%, Loss_1: 0.010572, Accuracy_2: 44.7% Loss_2: 0.011784  [ 1833/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.011278, Accuracy_2: 48.2% Loss_2: 0.012298  [ 2397/ 5922]\n",
      "Accuracy_1: 48.9%, Loss_1: 0.011225, Accuracy_2: 43.3% Loss_2: 0.011733  [ 2961/ 5922]\n",
      "Accuracy_1: 47.5%, Loss_1: 0.011154, Accuracy_2: 48.2% Loss_2: 0.011664  [ 3525/ 5922]\n",
      "Accuracy_1: 49.6%, Loss_1: 0.011779, Accuracy_2: 50.4% Loss_2: 0.011311  [ 4089/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.010746, Accuracy_2: 51.8% Loss_2: 0.010688  [ 4653/ 5922]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.010661, Accuracy_2: 49.6% Loss_2: 0.011630  [ 5217/ 5922]\n",
      "Accuracy_1: 46.1%, Loss_1: 0.011987, Accuracy_2: 41.1% Loss_2: 0.012652  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 49.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 50.2%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Accuracy_1: 45.4%, Loss_1: 0.012826, Accuracy_2: 49.6% Loss_2: 0.012425  [  141/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.009815, Accuracy_2: 52.5% Loss_2: 0.009875  [  705/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.009675, Accuracy_2: 53.2% Loss_2: 0.010347  [ 1269/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.009737, Accuracy_2: 55.3% Loss_2: 0.009055  [ 1833/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.009921, Accuracy_2: 53.9% Loss_2: 0.010249  [ 2397/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.010526, Accuracy_2: 52.5% Loss_2: 0.010896  [ 2961/ 5922]\n",
      "Accuracy_1: 47.5%, Loss_1: 0.012205, Accuracy_2: 49.6% Loss_2: 0.012025  [ 3525/ 5922]\n",
      "Accuracy_1: 44.0%, Loss_1: 0.012165, Accuracy_2: 49.6% Loss_2: 0.010899  [ 4089/ 5922]\n",
      "Accuracy_1: 44.7%, Loss_1: 0.012628, Accuracy_2: 51.8% Loss_2: 0.010414  [ 4653/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.009669, Accuracy_2: 52.5% Loss_2: 0.009812  [ 5217/ 5922]\n",
      "Accuracy_1: 56.0%, Loss_1: 0.008806, Accuracy_2: 56.7% Loss_2: 0.009284  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 49.3%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 49.2%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Accuracy_1: 50.4%, Loss_1: 0.010962, Accuracy_2: 51.1% Loss_2: 0.011086  [  141/ 5922]\n",
      "Accuracy_1: 47.5%, Loss_1: 0.011928, Accuracy_2: 43.3% Loss_2: 0.011304  [  705/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.012358, Accuracy_2: 45.4% Loss_2: 0.012018  [ 1269/ 5922]\n",
      "Accuracy_1: 53.9%, Loss_1: 0.010340, Accuracy_2: 51.8% Loss_2: 0.010334  [ 1833/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.011732, Accuracy_2: 51.1% Loss_2: 0.011664  [ 2397/ 5922]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.010391, Accuracy_2: 46.8% Loss_2: 0.010972  [ 2961/ 5922]\n",
      "Accuracy_1: 52.5%, Loss_1: 0.011426, Accuracy_2: 52.5% Loss_2: 0.010374  [ 3525/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.007776, Accuracy_2: 60.3% Loss_2: 0.008461  [ 4089/ 5922]\n",
      "Accuracy_1: 46.1%, Loss_1: 0.010962, Accuracy_2: 48.2% Loss_2: 0.011270  [ 4653/ 5922]\n",
      "Accuracy_1: 58.2%, Loss_1: 0.009959, Accuracy_2: 52.5% Loss_2: 0.010390  [ 5217/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.010556, Accuracy_2: 49.6% Loss_2: 0.010429  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 50.2%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 48.8%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Accuracy_1: 44.0%, Loss_1: 0.012109, Accuracy_2: 47.5% Loss_2: 0.012297  [  141/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.011599, Accuracy_2: 44.0% Loss_2: 0.012322  [  705/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.009548, Accuracy_2: 47.5% Loss_2: 0.010965  [ 1269/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.009052, Accuracy_2: 56.0% Loss_2: 0.008859  [ 1833/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.011265, Accuracy_2: 44.0% Loss_2: 0.011704  [ 2397/ 5922]\n",
      "Accuracy_1: 48.9%, Loss_1: 0.010471, Accuracy_2: 53.2% Loss_2: 0.010474  [ 2961/ 5922]\n",
      "Accuracy_1: 44.0%, Loss_1: 0.012608, Accuracy_2: 50.4% Loss_2: 0.012302  [ 3525/ 5922]\n",
      "Accuracy_1: 52.5%, Loss_1: 0.010805, Accuracy_2: 50.4% Loss_2: 0.012066  [ 4089/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.008985, Accuracy_2: 50.4% Loss_2: 0.009662  [ 4653/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.010117, Accuracy_2: 51.1% Loss_2: 0.010755  [ 5217/ 5922]\n",
      "Accuracy_1: 52.5%, Loss_1: 0.008983, Accuracy_2: 53.2% Loss_2: 0.008706  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 49.6%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 50.2%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Accuracy_1: 50.4%, Loss_1: 0.011044, Accuracy_2: 48.2% Loss_2: 0.011193  [  141/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.009823, Accuracy_2: 58.2% Loss_2: 0.008744  [  705/ 5922]\n",
      "Accuracy_1: 47.5%, Loss_1: 0.010701, Accuracy_2: 49.6% Loss_2: 0.011764  [ 1269/ 5922]\n",
      "Accuracy_1: 52.5%, Loss_1: 0.010062, Accuracy_2: 53.2% Loss_2: 0.009603  [ 1833/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.011091, Accuracy_2: 44.7% Loss_2: 0.011852  [ 2397/ 5922]\n",
      "Accuracy_1: 48.9%, Loss_1: 0.011968, Accuracy_2: 52.5% Loss_2: 0.012374  [ 2961/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.011621, Accuracy_2: 44.0% Loss_2: 0.013351  [ 3525/ 5922]\n",
      "Accuracy_1: 57.4%, Loss_1: 0.009350, Accuracy_2: 52.5% Loss_2: 0.009789  [ 4089/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.011123, Accuracy_2: 51.1% Loss_2: 0.010304  [ 4653/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.009696, Accuracy_2: 52.5% Loss_2: 0.009535  [ 5217/ 5922]\n",
      "Accuracy_1: 53.9%, Loss_1: 0.009404, Accuracy_2: 55.3% Loss_2: 0.008652  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 49.6%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 50.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Accuracy_1: 54.6%, Loss_1: 0.009032, Accuracy_2: 49.6% Loss_2: 0.009358  [  141/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.011611, Accuracy_2: 44.7% Loss_2: 0.011682  [  705/ 5922]\n",
      "Accuracy_1: 47.5%, Loss_1: 0.012024, Accuracy_2: 46.8% Loss_2: 0.013184  [ 1269/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.009658, Accuracy_2: 48.9% Loss_2: 0.010226  [ 1833/ 5922]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.010541, Accuracy_2: 53.9% Loss_2: 0.010332  [ 2397/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.010141, Accuracy_2: 53.9% Loss_2: 0.010707  [ 2961/ 5922]\n",
      "Accuracy_1: 48.9%, Loss_1: 0.010614, Accuracy_2: 52.5% Loss_2: 0.009500  [ 3525/ 5922]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.010211, Accuracy_2: 52.5% Loss_2: 0.009112  [ 4089/ 5922]\n",
      "Accuracy_1: 48.9%, Loss_1: 0.010501, Accuracy_2: 50.4% Loss_2: 0.012041  [ 4653/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.012048, Accuracy_2: 51.1% Loss_2: 0.011052  [ 5217/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.010229, Accuracy_2: 47.5% Loss_2: 0.010616  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 51.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 50.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Accuracy_1: 51.1%, Loss_1: 0.008870, Accuracy_2: 46.1% Loss_2: 0.010781  [  141/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.009626, Accuracy_2: 55.3% Loss_2: 0.009268  [  705/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.010248, Accuracy_2: 53.2% Loss_2: 0.010397  [ 1269/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.007692, Accuracy_2: 58.2% Loss_2: 0.008162  [ 1833/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.011191, Accuracy_2: 51.8% Loss_2: 0.009812  [ 2397/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.009595, Accuracy_2: 49.6% Loss_2: 0.010794  [ 2961/ 5922]\n",
      "Accuracy_1: 58.2%, Loss_1: 0.007892, Accuracy_2: 61.7% Loss_2: 0.007170  [ 3525/ 5922]\n",
      "Accuracy_1: 61.0%, Loss_1: 0.008204, Accuracy_2: 56.0% Loss_2: 0.008331  [ 4089/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.010413, Accuracy_2: 49.6% Loss_2: 0.010187  [ 4653/ 5922]\n",
      "Accuracy_1: 57.4%, Loss_1: 0.009366, Accuracy_2: 49.6% Loss_2: 0.011029  [ 5217/ 5922]\n",
      "Accuracy_1: 48.9%, Loss_1: 0.010693, Accuracy_2: 48.2% Loss_2: 0.011882  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 51.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 51.2%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Accuracy_1: 58.2%, Loss_1: 0.009378, Accuracy_2: 50.4% Loss_2: 0.009387  [  141/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.010140, Accuracy_2: 51.1% Loss_2: 0.010372  [  705/ 5922]\n",
      "Accuracy_1: 46.1%, Loss_1: 0.011851, Accuracy_2: 55.3% Loss_2: 0.011215  [ 1269/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.011336, Accuracy_2: 52.5% Loss_2: 0.011268  [ 1833/ 5922]\n",
      "Accuracy_1: 61.0%, Loss_1: 0.008405, Accuracy_2: 55.3% Loss_2: 0.009689  [ 2397/ 5922]\n",
      "Accuracy_1: 53.9%, Loss_1: 0.008529, Accuracy_2: 53.2% Loss_2: 0.009653  [ 2961/ 5922]\n",
      "Accuracy_1: 46.8%, Loss_1: 0.011757, Accuracy_2: 47.5% Loss_2: 0.012855  [ 3525/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.010315, Accuracy_2: 54.6% Loss_2: 0.010359  [ 4089/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.009547, Accuracy_2: 56.0% Loss_2: 0.010251  [ 4653/ 5922]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.009817, Accuracy_2: 52.5% Loss_2: 0.009682  [ 5217/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.009623, Accuracy_2: 53.2% Loss_2: 0.009945  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 51.2%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 50.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Accuracy_1: 53.9%, Loss_1: 0.009749, Accuracy_2: 52.5% Loss_2: 0.010250  [  141/ 5922]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.009720, Accuracy_2: 55.3% Loss_2: 0.009598  [  705/ 5922]\n",
      "Accuracy_1: 52.5%, Loss_1: 0.010398, Accuracy_2: 50.4% Loss_2: 0.010381  [ 1269/ 5922]\n",
      "Accuracy_1: 66.7%, Loss_1: 0.006549, Accuracy_2: 59.6% Loss_2: 0.007317  [ 1833/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.009675, Accuracy_2: 55.3% Loss_2: 0.010024  [ 2397/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.009743, Accuracy_2: 51.1% Loss_2: 0.009932  [ 2961/ 5922]\n",
      "Accuracy_1: 58.9%, Loss_1: 0.008322, Accuracy_2: 48.9% Loss_2: 0.010403  [ 3525/ 5922]\n",
      "Accuracy_1: 52.5%, Loss_1: 0.011543, Accuracy_2: 48.9% Loss_2: 0.010904  [ 4089/ 5922]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.010627, Accuracy_2: 48.2% Loss_2: 0.009968  [ 4653/ 5922]\n",
      "Accuracy_1: 46.8%, Loss_1: 0.012091, Accuracy_2: 52.5% Loss_2: 0.011879  [ 5217/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.010355, Accuracy_2: 52.5% Loss_2: 0.010807  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 51.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 52.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Accuracy_1: 52.5%, Loss_1: 0.008677, Accuracy_2: 50.4% Loss_2: 0.008877  [  141/ 5922]\n",
      "Accuracy_1: 57.4%, Loss_1: 0.010423, Accuracy_2: 50.4% Loss_2: 0.011011  [  705/ 5922]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.010460, Accuracy_2: 53.9% Loss_2: 0.009659  [ 1269/ 5922]\n",
      "Accuracy_1: 49.6%, Loss_1: 0.010091, Accuracy_2: 63.1% Loss_2: 0.008360  [ 1833/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.011069, Accuracy_2: 44.0% Loss_2: 0.013996  [ 2397/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.008367, Accuracy_2: 58.2% Loss_2: 0.009057  [ 2961/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.008215, Accuracy_2: 54.6% Loss_2: 0.008716  [ 3525/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.009422, Accuracy_2: 52.5% Loss_2: 0.009560  [ 4089/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.008023, Accuracy_2: 54.6% Loss_2: 0.008941  [ 4653/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.010179, Accuracy_2: 53.9% Loss_2: 0.009405  [ 5217/ 5922]\n",
      "Accuracy_1: 44.0%, Loss_1: 0.013197, Accuracy_2: 44.7% Loss_2: 0.011328  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 51.2%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 51.8%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Accuracy_1: 51.1%, Loss_1: 0.008739, Accuracy_2: 56.0% Loss_2: 0.008359  [  141/ 5922]\n",
      "Accuracy_1: 43.3%, Loss_1: 0.013863, Accuracy_2: 48.2% Loss_2: 0.011590  [  705/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.009583, Accuracy_2: 48.9% Loss_2: 0.011312  [ 1269/ 5922]\n",
      "Accuracy_1: 49.6%, Loss_1: 0.011488, Accuracy_2: 51.8% Loss_2: 0.010135  [ 1833/ 5922]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.010656, Accuracy_2: 51.1% Loss_2: 0.010560  [ 2397/ 5922]\n",
      "Accuracy_1: 47.5%, Loss_1: 0.012326, Accuracy_2: 52.5% Loss_2: 0.011609  [ 2961/ 5922]\n",
      "Accuracy_1: 48.9%, Loss_1: 0.010149, Accuracy_2: 54.6% Loss_2: 0.009290  [ 3525/ 5922]\n",
      "Accuracy_1: 58.2%, Loss_1: 0.008657, Accuracy_2: 57.4% Loss_2: 0.008401  [ 4089/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.009528, Accuracy_2: 50.4% Loss_2: 0.011056  [ 4653/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.008913, Accuracy_2: 57.4% Loss_2: 0.009940  [ 5217/ 5922]\n",
      "Accuracy_1: 46.8%, Loss_1: 0.011797, Accuracy_2: 54.6% Loss_2: 0.010542  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 51.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 52.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Accuracy_1: 51.1%, Loss_1: 0.009519, Accuracy_2: 58.2% Loss_2: 0.007380  [  141/ 5922]\n",
      "Accuracy_1: 49.6%, Loss_1: 0.009864, Accuracy_2: 53.9% Loss_2: 0.009957  [  705/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.010483, Accuracy_2: 56.0% Loss_2: 0.009223  [ 1269/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.008581, Accuracy_2: 63.8% Loss_2: 0.008744  [ 1833/ 5922]\n",
      "Accuracy_1: 62.4%, Loss_1: 0.007777, Accuracy_2: 61.7% Loss_2: 0.008154  [ 2397/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.011998, Accuracy_2: 51.1% Loss_2: 0.012378  [ 2961/ 5922]\n",
      "Accuracy_1: 59.6%, Loss_1: 0.008271, Accuracy_2: 55.3% Loss_2: 0.009801  [ 3525/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.010965, Accuracy_2: 46.8% Loss_2: 0.011649  [ 4089/ 5922]\n",
      "Accuracy_1: 53.9%, Loss_1: 0.010064, Accuracy_2: 55.3% Loss_2: 0.009425  [ 4653/ 5922]\n",
      "Accuracy_1: 58.2%, Loss_1: 0.009623, Accuracy_2: 52.5% Loss_2: 0.008805  [ 5217/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.008968, Accuracy_2: 57.4% Loss_2: 0.008407  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 52.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 52.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Accuracy_1: 61.0%, Loss_1: 0.007671, Accuracy_2: 62.4% Loss_2: 0.007840  [  141/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.009486, Accuracy_2: 49.6% Loss_2: 0.010261  [  705/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.008971, Accuracy_2: 56.0% Loss_2: 0.008868  [ 1269/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.009055, Accuracy_2: 56.7% Loss_2: 0.008608  [ 1833/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.009344, Accuracy_2: 53.2% Loss_2: 0.010180  [ 2397/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.010091, Accuracy_2: 56.0% Loss_2: 0.008686  [ 2961/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.009782, Accuracy_2: 54.6% Loss_2: 0.008688  [ 3525/ 5922]\n",
      "Accuracy_1: 47.5%, Loss_1: 0.010755, Accuracy_2: 51.8% Loss_2: 0.010535  [ 4089/ 5922]\n",
      "Accuracy_1: 53.9%, Loss_1: 0.010695, Accuracy_2: 58.9% Loss_2: 0.009901  [ 4653/ 5922]\n",
      "Accuracy_1: 49.6%, Loss_1: 0.010665, Accuracy_2: 54.6% Loss_2: 0.010451  [ 5217/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.009598, Accuracy_2: 58.2% Loss_2: 0.009781  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 53.2%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 51.9%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Accuracy_1: 56.0%, Loss_1: 0.009676, Accuracy_2: 48.9% Loss_2: 0.011191  [  141/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.010469, Accuracy_2: 52.5% Loss_2: 0.009552  [  705/ 5922]\n",
      "Accuracy_1: 49.6%, Loss_1: 0.009790, Accuracy_2: 55.3% Loss_2: 0.010034  [ 1269/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.008826, Accuracy_2: 58.2% Loss_2: 0.009727  [ 1833/ 5922]\n",
      "Accuracy_1: 63.8%, Loss_1: 0.007116, Accuracy_2: 60.3% Loss_2: 0.007978  [ 2397/ 5922]\n",
      "Accuracy_1: 57.4%, Loss_1: 0.009249, Accuracy_2: 52.5% Loss_2: 0.008838  [ 2961/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.008596, Accuracy_2: 60.3% Loss_2: 0.007832  [ 3525/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.009534, Accuracy_2: 53.2% Loss_2: 0.010140  [ 4089/ 5922]\n",
      "Accuracy_1: 64.5%, Loss_1: 0.007589, Accuracy_2: 61.0% Loss_2: 0.006572  [ 4653/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.009539, Accuracy_2: 55.3% Loss_2: 0.008437  [ 5217/ 5922]\n",
      "Accuracy_1: 57.4%, Loss_1: 0.007896, Accuracy_2: 57.4% Loss_2: 0.008703  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 53.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 53.1%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Accuracy_1: 50.4%, Loss_1: 0.011790, Accuracy_2: 47.5% Loss_2: 0.012218  [  141/ 5922]\n",
      "Accuracy_1: 56.0%, Loss_1: 0.008498, Accuracy_2: 51.8% Loss_2: 0.010213  [  705/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.009419, Accuracy_2: 55.3% Loss_2: 0.010469  [ 1269/ 5922]\n",
      "Accuracy_1: 52.5%, Loss_1: 0.009888, Accuracy_2: 55.3% Loss_2: 0.009025  [ 1833/ 5922]\n",
      "Accuracy_1: 60.3%, Loss_1: 0.009002, Accuracy_2: 55.3% Loss_2: 0.009370  [ 2397/ 5922]\n",
      "Accuracy_1: 57.4%, Loss_1: 0.009032, Accuracy_2: 56.0% Loss_2: 0.010580  [ 2961/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.010133, Accuracy_2: 60.3% Loss_2: 0.009860  [ 3525/ 5922]\n",
      "Accuracy_1: 62.4%, Loss_1: 0.007386, Accuracy_2: 56.7% Loss_2: 0.008595  [ 4089/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.009374, Accuracy_2: 52.5% Loss_2: 0.009678  [ 4653/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.008495, Accuracy_2: 57.4% Loss_2: 0.007667  [ 5217/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.009116, Accuracy_2: 51.1% Loss_2: 0.010154  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 53.6%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 53.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Accuracy_1: 52.5%, Loss_1: 0.009722, Accuracy_2: 55.3% Loss_2: 0.010218  [  141/ 5922]\n",
      "Accuracy_1: 58.9%, Loss_1: 0.006916, Accuracy_2: 63.8% Loss_2: 0.006483  [  705/ 5922]\n",
      "Accuracy_1: 57.4%, Loss_1: 0.010157, Accuracy_2: 55.3% Loss_2: 0.009819  [ 1269/ 5922]\n",
      "Accuracy_1: 57.4%, Loss_1: 0.008476, Accuracy_2: 56.0% Loss_2: 0.009821  [ 1833/ 5922]\n",
      "Accuracy_1: 59.6%, Loss_1: 0.007961, Accuracy_2: 52.5% Loss_2: 0.009544  [ 2397/ 5922]\n",
      "Accuracy_1: 59.6%, Loss_1: 0.008240, Accuracy_2: 61.0% Loss_2: 0.008300  [ 2961/ 5922]\n",
      "Accuracy_1: 53.9%, Loss_1: 0.010316, Accuracy_2: 52.5% Loss_2: 0.009273  [ 3525/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.008736, Accuracy_2: 58.2% Loss_2: 0.008757  [ 4089/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.008793, Accuracy_2: 61.7% Loss_2: 0.008850  [ 4653/ 5922]\n",
      "Accuracy_1: 60.3%, Loss_1: 0.008202, Accuracy_2: 56.7% Loss_2: 0.009618  [ 5217/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.009153, Accuracy_2: 52.5% Loss_2: 0.008395  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 53.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 52.2%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Accuracy_1: 58.2%, Loss_1: 0.007654, Accuracy_2: 56.7% Loss_2: 0.009900  [  141/ 5922]\n",
      "Accuracy_1: 60.3%, Loss_1: 0.008305, Accuracy_2: 55.3% Loss_2: 0.008244  [  705/ 5922]\n",
      "Accuracy_1: 49.6%, Loss_1: 0.010357, Accuracy_2: 47.5% Loss_2: 0.010537  [ 1269/ 5922]\n",
      "Accuracy_1: 56.0%, Loss_1: 0.009226, Accuracy_2: 55.3% Loss_2: 0.009575  [ 1833/ 5922]\n",
      "Accuracy_1: 56.0%, Loss_1: 0.010677, Accuracy_2: 48.9% Loss_2: 0.011336  [ 2397/ 5922]\n",
      "Accuracy_1: 53.9%, Loss_1: 0.008579, Accuracy_2: 57.4% Loss_2: 0.008235  [ 2961/ 5922]\n",
      "Accuracy_1: 49.6%, Loss_1: 0.009791, Accuracy_2: 54.6% Loss_2: 0.009097  [ 3525/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.009388, Accuracy_2: 50.4% Loss_2: 0.009738  [ 4089/ 5922]\n",
      "Accuracy_1: 56.0%, Loss_1: 0.009381, Accuracy_2: 53.9% Loss_2: 0.009536  [ 4653/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.009228, Accuracy_2: 46.8% Loss_2: 0.010077  [ 5217/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.010003, Accuracy_2: 49.6% Loss_2: 0.009508  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 53.1%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 52.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Accuracy_1: 61.0%, Loss_1: 0.007618, Accuracy_2: 53.9% Loss_2: 0.010493  [  141/ 5922]\n",
      "Accuracy_1: 57.4%, Loss_1: 0.008199, Accuracy_2: 58.9% Loss_2: 0.008227  [  705/ 5922]\n",
      "Accuracy_1: 58.9%, Loss_1: 0.007348, Accuracy_2: 61.0% Loss_2: 0.006911  [ 1269/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.010402, Accuracy_2: 46.1% Loss_2: 0.012503  [ 1833/ 5922]\n",
      "Accuracy_1: 52.5%, Loss_1: 0.009229, Accuracy_2: 52.5% Loss_2: 0.011397  [ 2397/ 5922]\n",
      "Accuracy_1: 48.9%, Loss_1: 0.010516, Accuracy_2: 51.1% Loss_2: 0.010518  [ 2961/ 5922]\n",
      "Accuracy_1: 52.5%, Loss_1: 0.010232, Accuracy_2: 53.2% Loss_2: 0.009561  [ 3525/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.010280, Accuracy_2: 53.9% Loss_2: 0.011579  [ 4089/ 5922]\n",
      "Accuracy_1: 63.1%, Loss_1: 0.007157, Accuracy_2: 61.7% Loss_2: 0.006619  [ 4653/ 5922]\n",
      "Accuracy_1: 46.8%, Loss_1: 0.010967, Accuracy_2: 50.4% Loss_2: 0.010595  [ 5217/ 5922]\n",
      "Accuracy_1: 53.9%, Loss_1: 0.009892, Accuracy_2: 59.6% Loss_2: 0.007775  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 52.6%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 52.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Accuracy_1: 54.6%, Loss_1: 0.009510, Accuracy_2: 57.4% Loss_2: 0.008621  [  141/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.010626, Accuracy_2: 53.9% Loss_2: 0.009014  [  705/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.008311, Accuracy_2: 56.0% Loss_2: 0.008653  [ 1269/ 5922]\n",
      "Accuracy_1: 59.6%, Loss_1: 0.008495, Accuracy_2: 61.7% Loss_2: 0.008166  [ 1833/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.010479, Accuracy_2: 57.4% Loss_2: 0.008376  [ 2397/ 5922]\n",
      "Accuracy_1: 59.6%, Loss_1: 0.007204, Accuracy_2: 61.7% Loss_2: 0.007164  [ 2961/ 5922]\n",
      "Accuracy_1: 56.0%, Loss_1: 0.008085, Accuracy_2: 62.4% Loss_2: 0.007027  [ 3525/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.010259, Accuracy_2: 56.7% Loss_2: 0.008322  [ 4089/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.009164, Accuracy_2: 56.0% Loss_2: 0.008572  [ 4653/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.008687, Accuracy_2: 51.8% Loss_2: 0.009801  [ 5217/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.008167, Accuracy_2: 58.9% Loss_2: 0.007640  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 53.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 52.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Accuracy_1: 63.1%, Loss_1: 0.007366, Accuracy_2: 61.7% Loss_2: 0.007462  [  141/ 5922]\n",
      "Accuracy_1: 56.0%, Loss_1: 0.008788, Accuracy_2: 60.3% Loss_2: 0.007859  [  705/ 5922]\n",
      "Accuracy_1: 61.0%, Loss_1: 0.008783, Accuracy_2: 52.5% Loss_2: 0.009928  [ 1269/ 5922]\n",
      "Accuracy_1: 46.8%, Loss_1: 0.010327, Accuracy_2: 49.6% Loss_2: 0.010742  [ 1833/ 5922]\n",
      "Accuracy_1: 64.5%, Loss_1: 0.007393, Accuracy_2: 60.3% Loss_2: 0.008423  [ 2397/ 5922]\n",
      "Accuracy_1: 58.2%, Loss_1: 0.007764, Accuracy_2: 57.4% Loss_2: 0.007928  [ 2961/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.008568, Accuracy_2: 54.6% Loss_2: 0.008791  [ 3525/ 5922]\n",
      "Accuracy_1: 56.0%, Loss_1: 0.008159, Accuracy_2: 55.3% Loss_2: 0.008545  [ 4089/ 5922]\n",
      "Accuracy_1: 58.2%, Loss_1: 0.008036, Accuracy_2: 58.9% Loss_2: 0.008595  [ 4653/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.009187, Accuracy_2: 61.0% Loss_2: 0.008194  [ 5217/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.009185, Accuracy_2: 55.3% Loss_2: 0.010366  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 54.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 53.5%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Accuracy_1: 59.6%, Loss_1: 0.007886, Accuracy_2: 65.2% Loss_2: 0.006587  [  141/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.010193, Accuracy_2: 54.6% Loss_2: 0.010304  [  705/ 5922]\n",
      "Accuracy_1: 58.9%, Loss_1: 0.008216, Accuracy_2: 55.3% Loss_2: 0.009262  [ 1269/ 5922]\n",
      "Accuracy_1: 56.0%, Loss_1: 0.008668, Accuracy_2: 58.9% Loss_2: 0.009651  [ 1833/ 5922]\n",
      "Accuracy_1: 59.6%, Loss_1: 0.008616, Accuracy_2: 57.4% Loss_2: 0.007817  [ 2397/ 5922]\n",
      "Accuracy_1: 53.9%, Loss_1: 0.010361, Accuracy_2: 58.9% Loss_2: 0.010578  [ 2961/ 5922]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.010300, Accuracy_2: 53.2% Loss_2: 0.009992  [ 3525/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.009638, Accuracy_2: 62.4% Loss_2: 0.008321  [ 4089/ 5922]\n",
      "Accuracy_1: 61.7%, Loss_1: 0.007029, Accuracy_2: 61.0% Loss_2: 0.008735  [ 4653/ 5922]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.008315, Accuracy_2: 61.0% Loss_2: 0.008966  [ 5217/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.007385, Accuracy_2: 60.3% Loss_2: 0.007421  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 54.3%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 54.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Accuracy_1: 66.7%, Loss_1: 0.007190, Accuracy_2: 62.4% Loss_2: 0.006932  [  141/ 5922]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.010276, Accuracy_2: 58.2% Loss_2: 0.009282  [  705/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.009917, Accuracy_2: 50.4% Loss_2: 0.009971  [ 1269/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.007834, Accuracy_2: 55.3% Loss_2: 0.007784  [ 1833/ 5922]\n",
      "Accuracy_1: 53.9%, Loss_1: 0.009239, Accuracy_2: 51.1% Loss_2: 0.010596  [ 2397/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.008773, Accuracy_2: 54.6% Loss_2: 0.008494  [ 2961/ 5922]\n",
      "Accuracy_1: 60.3%, Loss_1: 0.007391, Accuracy_2: 58.9% Loss_2: 0.007509  [ 3525/ 5922]\n",
      "Accuracy_1: 59.6%, Loss_1: 0.007172, Accuracy_2: 59.6% Loss_2: 0.006606  [ 4089/ 5922]\n",
      "Accuracy_1: 58.9%, Loss_1: 0.009455, Accuracy_2: 56.7% Loss_2: 0.008625  [ 4653/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.008889, Accuracy_2: 49.6% Loss_2: 0.010405  [ 5217/ 5922]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.010986, Accuracy_2: 51.8% Loss_2: 0.010102  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 54.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 54.9%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Accuracy_1: 59.6%, Loss_1: 0.008551, Accuracy_2: 60.3% Loss_2: 0.007636  [  141/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.011206, Accuracy_2: 60.3% Loss_2: 0.009327  [  705/ 5922]\n",
      "Accuracy_1: 56.0%, Loss_1: 0.008845, Accuracy_2: 53.9% Loss_2: 0.009459  [ 1269/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.009076, Accuracy_2: 55.3% Loss_2: 0.009221  [ 1833/ 5922]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.007799, Accuracy_2: 60.3% Loss_2: 0.007653  [ 2397/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.010266, Accuracy_2: 52.5% Loss_2: 0.010443  [ 2961/ 5922]\n",
      "Accuracy_1: 49.6%, Loss_1: 0.010965, Accuracy_2: 60.3% Loss_2: 0.010051  [ 3525/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.009610, Accuracy_2: 58.9% Loss_2: 0.008103  [ 4089/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.009224, Accuracy_2: 53.9% Loss_2: 0.009108  [ 4653/ 5922]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.010022, Accuracy_2: 48.9% Loss_2: 0.011303  [ 5217/ 5922]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.009957, Accuracy_2: 53.2% Loss_2: 0.010397  [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 55.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 54.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Accuracy_1: 58.9%, Loss_1: 0.007006, Accuracy_2: 55.3% Loss_2: 0.008356  [  141/ 5922]\n",
      "Accuracy_1: 66.0%, Loss_1: 0.007001, Accuracy_2: 60.3% Loss_2: 0.008013  [  705/ 5922]\n",
      "Accuracy_1: 56.0%, Loss_1: 0.008779, Accuracy_2: 54.6% Loss_2: 0.009631  [ 1269/ 5922]\n",
      "Accuracy_1: 59.6%, Loss_1: 0.008356, Accuracy_2: 56.7% Loss_2: 0.008556  [ 1833/ 5922]\n",
      "Accuracy_1: 58.2%, Loss_1: 0.007930, Accuracy_2: 61.0% Loss_2: 0.007560  [ 2397/ 5922]\n",
      "Accuracy_1: 60.3%, Loss_1: 0.007276, Accuracy_2: 56.0% Loss_2: 0.008651  [ 2961/ 5922]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.009479, Accuracy_2: 48.2% Loss_2: 0.009482  [ 3525/ 5922]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_PCA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m     accuracy_1, accuracy_2, loss_1, loss_2 \u001b[38;5;241m=\u001b[39m validate_model(model_1, model_2, X_val_PCA, y_val, criterion)\n",
      "Cell \u001b[0;32mIn[24], line 18\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model_1, model_2, X_train, y_train, criterion, optimizer_1, optimizer_2)\u001b[0m\n\u001b[1;32m     15\u001b[0m X \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mfrom_numpy(X_train[indices[start:end]])\u001b[38;5;241m.\u001b[39mto(T\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     16\u001b[0m y_true \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mTensor(y_train[indices[start:end]])\u001b[38;5;241m.\u001b[39mto(T\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 18\u001b[0m logits_1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m logits_2 \u001b[38;5;241m=\u001b[39m model_2\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[1;32m     21\u001b[0m loss_1, loss_2 \u001b[38;5;241m=\u001b[39m criterion(logits_1, logits_2, y_true, \u001b[38;5;241m0.2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 30\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m---> 30\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Global Variables\n",
    "epochs = 5_000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Load Pre-Trained Models\n",
    "# model_1.load(\"NeuralNetwork-1_acc-50.29_loss-0.000003\")\n",
    "# model_2.load(\"NeuralNetwork-2_acc-50.38_loss-0.000003\")\n",
    "\n",
    "criterion = loss_coteaching # Co-teaching loss function\n",
    "optimizer_1 = optim.Adam(model_1.parameters(), lr=learning_rate)\n",
    "optimizer_2 = optim.Adam(model_2.parameters(), lr=learning_rate)\n",
    "\n",
    "best_accuracy = 0.60 # ???\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "\n",
    "    train_model(model_1, model_2, X_train_PCA, y_train, criterion, optimizer_1, optimizer_2)\n",
    "    print('Finished training')\n",
    "    \n",
    "    accuracy_1, accuracy_2, loss_1, loss_2 = validate_model(model_1, model_2, X_val_PCA, y_val, criterion)\n",
    "\n",
    "    if max(accuracy_1, accuracy_2) > best_accuracy:\n",
    "        print(f\"[+] Saving Model...\")\n",
    "\n",
    "        model_1.save(f\"NeuralNetwork-1_acc-{accuracy_1 * 100:.2f}_loss-{loss_1:>8f}\")\n",
    "        model_2.save(f\"NeuralNetwork-2_acc-{accuracy_2 * 100:.2f}_loss-{loss_2:>8f}\")\n",
    "        best_accuracy = max(accuracy_1, accuracy_2)\n",
    "\n",
    "        print(f\"[!] Models Saved.\")\n",
    "\n",
    "    epoch += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = loss_coteaching\n",
    "\n",
    "def test_model(model_1, model_2, X_test, y_test, criterion):\n",
    "    size = len(y_test)\n",
    "\n",
    "    model_1.eval()\n",
    "    model_2.eval()\n",
    "    with T.no_grad():\n",
    "        X = T.from_numpy(X_test).to(T.float32).to(device)\n",
    "        y_true = T.Tensor(y_test).to(T.float).to(device)\n",
    "\n",
    "        logits_1 = model_1.forward(X)\n",
    "        logits_2 = model_2.forward(X)\n",
    "\n",
    "        loss_1, loss_2 = criterion(logits_1, logits_2, y_true, 0.2)\n",
    "\n",
    "        correct_1 = (logits_1.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "        correct_2 = (logits_2.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "        \n",
    "        loss_1 /= size\n",
    "        loss_2 /= size\n",
    "        accuracy_1 = correct_1/size\n",
    "        accuracy_2 = correct_2/size\n",
    "        \n",
    "        print(f\"Test Error (Model 1): \\n Accuracy: {(100 * (accuracy_1)):>0.1f}%, Avg loss: {loss_1:>8f}\")\n",
    "        print(f\"Test Error (Model 2): \\n Accuracy: {(100 * (accuracy_2)):>0.1f}%, Avg loss: {loss_2:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error (Model 1): \n",
      " Accuracy: 62.4%, Avg loss: 0.000009\n",
      "Test Error (Model 2): \n",
      " Accuracy: 61.6%, Avg loss: 0.000004 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1.load(\"NeuralNetwork-1_acc-61.81_loss-0.000009\")\n",
    "model_2.load(\"NeuralNetwork-2_acc-61.62_loss-0.000004\")\n",
    "test_model(model_1, model_2, X_test_PCA, y_test, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
