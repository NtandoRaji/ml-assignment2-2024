{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(x):\n",
    "    labels = np.unique(x)\n",
    "    result = np.zeros(shape=(x.shape[0], labels.shape[0]))\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        result[i][x[i]] = 1.0\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = [] # Features per class\n",
    "y = [] # Labels\n",
    "N = 5250 # Amount of data we want to use max: 5250\n",
    "\n",
    "# Import the features\n",
    "with open(\"traindata.txt\", \"r\") as file:\n",
    "    for line in file.readlines()[:N]:\n",
    "        features = [float(i) for i in line.split(\",\")]\n",
    "        X.append(features)\n",
    "\n",
    "# Import the labels\n",
    "with open(\"trainlabels.txt\", \"r\") as file:\n",
    "    for line in file.readlines()[:N]:\n",
    "        label = float(line.rstrip())\n",
    "        y.append(label)\n",
    "    \n",
    "# Convert data to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y, dtype=np.int32)\n",
    "y_onehot = to_onehot(y)\n",
    "\n",
    "def split_data(X, y, test_size=0.2, val_size=0.2, random_state=42):\n",
    "   \n",
    "    # Splitting the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Further splitting the training data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size / (1 - test_size),\n",
    "                                                      random_state=random_state)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3150, 1041)\n"
     ]
    }
   ],
   "source": [
    "# Calculates the number of components to consider when performing pca\n",
    "def num_components(X, variance_tol = 0.8):\n",
    "    # Standardize each feature of the matrix\n",
    "    x_mean = np.mean(X, axis = 0)\n",
    "    x_std = np.std(X, axis = 0)\n",
    "    Z = (X - x_mean) / x_std\n",
    "\n",
    "    # Calculate covariance matrix\n",
    "    C = np.cov(Z, rowvar=False)\n",
    "    # Calculate eigenvalues and eigenvectors and sort by size\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(C)\n",
    "    index = eigenvalues.argsort()[:: -1]\n",
    "    eigenvalues = eigenvalues[index]\n",
    "    eigenvectors = eigenvectors[:, index]\n",
    "\n",
    "    # Calculate explained variance matrix \n",
    "    explained_var = np.cumsum(eigenvalues) / np.sum(eigenvalues)\n",
    "\n",
    "    # Select number of components responsible for variance_tol% of variance\n",
    "    n_components = np.argmax(explained_var >= variance_tol) + 1\n",
    "    return Z, x_mean, x_std, n_components\n",
    "\n",
    "# Parameters are trained components, trained mean, trained standard deviation and the new inputs X\n",
    "# Changes to the PCA basis\n",
    "def convert_to_pca(components, mean, std, X):\n",
    "    Z = (X - mean)/std\n",
    "    return np.transpose(np.matmul(components, np.transpose(Z)))\n",
    "\n",
    "Z, mean, std, n_components = num_components(X_train, 0.8)\n",
    "# Initialize prinicipal component analysis\n",
    "pca = PCA(n_components)\n",
    "pca.fit(Z)\n",
    "components = pca.components_\n",
    "X_train = pca.transform(Z)\n",
    "temp = pca.transform(X_test)\n",
    "X_test = convert_to_pca(components, mean, std, X_test)\n",
    "X_val = convert_to_pca(components, mean, std, X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Build Model\n",
    "def build_model(n_inputs, n_outputs, h1_dims=512, h2_dims=256):\n",
    "    model =  nn.Sequential(\n",
    "        nn.Linear(n_inputs, h1_dims),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(h1_dims, h2_dims),\n",
    "        nn.ReLU(),                              \n",
    "        nn.Linear(h2_dims, n_outputs),\n",
    "        nn.Softmax(dim=-1)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, h1_dims=512, h2_dims=256, name=\"NeuralNetwork\", save_dir=\"/trained_models\"):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.name = name\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.model = build_model(n_inputs, n_outputs, h1_dims, h2_dims)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.model(X)\n",
    "        return X\n",
    "    \n",
    "    def save_model(self):\n",
    "        T.save(self.state_dict, f\"{self.save_dir}/{self.name}.pth\")\n",
    "\n",
    "    def load_model(self, name):\n",
    "        self.load_state_dict(T.load(f\"{self.save_dir}/{name}.pth\"))\n",
    "\n",
    "\n",
    "\n",
    "labels = np.unique(y) # Labels of our data (0 - 20)\n",
    "\n",
    "n_inputs = X_train.shape[1]\n",
    "h1_dims = 2 * n_inputs # Number of nodes for the 1st hidden layer\n",
    "h2_dims = n_inputs # Number of nodes for the 2nd hidden layer\n",
    "n_outputs = labels.shape[0] # 21 labels\n",
    "\n",
    "# Initialize the model\n",
    "net = NeuralNetwork(n_inputs=n_inputs, n_outputs=n_outputs, h1_dims=h1_dims, h2_dims=h2_dims, name=\"NN-v1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.045372  [   50/ 3150]\n",
      "loss: 0.045574  [  300/ 3150]\n",
      "loss: 0.045313  [  550/ 3150]\n",
      "loss: 0.045334  [  800/ 3150]\n",
      "loss: 0.045585  [ 1050/ 3150]\n",
      "loss: 0.045630  [ 1300/ 3150]\n",
      "loss: 0.045541  [ 1550/ 3150]\n",
      "loss: 0.045348  [ 1800/ 3150]\n",
      "loss: 0.045090  [ 2050/ 3150]\n",
      "loss: 0.045493  [ 2300/ 3150]\n",
      "loss: 0.045317  [ 2550/ 3150]\n",
      "loss: 0.045475  [ 2800/ 3150]\n",
      "loss: 0.045251  [ 3050/ 3150]\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 33.8%, Avg loss: 0.000334 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.045265  [   50/ 3150]\n",
      "loss: 0.045510  [  300/ 3150]\n",
      "loss: 0.045261  [  550/ 3150]\n",
      "loss: 0.045264  [  800/ 3150]\n",
      "loss: 0.045506  [ 1050/ 3150]\n",
      "loss: 0.045578  [ 1300/ 3150]\n",
      "loss: 0.045483  [ 1550/ 3150]\n",
      "loss: 0.045296  [ 1800/ 3150]\n",
      "loss: 0.045012  [ 2050/ 3150]\n",
      "loss: 0.045436  [ 2300/ 3150]\n",
      "loss: 0.045257  [ 2550/ 3150]\n",
      "loss: 0.045414  [ 2800/ 3150]\n",
      "loss: 0.045214  [ 3050/ 3150]\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 37.5%, Avg loss: 0.000333 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.045187  [   50/ 3150]\n",
      "loss: 0.045455  [  300/ 3150]\n",
      "loss: 0.045210  [  550/ 3150]\n",
      "loss: 0.045200  [  800/ 3150]\n",
      "loss: 0.045431  [ 1050/ 3150]\n",
      "loss: 0.045531  [ 1300/ 3150]\n",
      "loss: 0.045430  [ 1550/ 3150]\n",
      "loss: 0.045245  [ 1800/ 3150]\n",
      "loss: 0.044940  [ 2050/ 3150]\n",
      "loss: 0.045381  [ 2300/ 3150]\n",
      "loss: 0.045200  [ 2550/ 3150]\n",
      "loss: 0.045357  [ 2800/ 3150]\n",
      "loss: 0.045176  [ 3050/ 3150]\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 0.000333 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.045112  [   50/ 3150]\n",
      "loss: 0.045401  [  300/ 3150]\n",
      "loss: 0.045159  [  550/ 3150]\n",
      "loss: 0.045141  [  800/ 3150]\n",
      "loss: 0.045358  [ 1050/ 3150]\n",
      "loss: 0.045486  [ 1300/ 3150]\n",
      "loss: 0.045378  [ 1550/ 3150]\n",
      "loss: 0.045195  [ 1800/ 3150]\n",
      "loss: 0.044873  [ 2050/ 3150]\n",
      "loss: 0.045328  [ 2300/ 3150]\n",
      "loss: 0.045147  [ 2550/ 3150]\n",
      "loss: 0.045302  [ 2800/ 3150]\n",
      "loss: 0.045138  [ 3050/ 3150]\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 0.000333 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.045039  [   50/ 3150]\n",
      "loss: 0.045348  [  300/ 3150]\n",
      "loss: 0.045108  [  550/ 3150]\n",
      "loss: 0.045081  [  800/ 3150]\n",
      "loss: 0.045288  [ 1050/ 3150]\n",
      "loss: 0.045441  [ 1300/ 3150]\n",
      "loss: 0.045328  [ 1550/ 3150]\n",
      "loss: 0.045146  [ 1800/ 3150]\n",
      "loss: 0.044807  [ 2050/ 3150]\n",
      "loss: 0.045276  [ 2300/ 3150]\n",
      "loss: 0.045094  [ 2550/ 3150]\n",
      "loss: 0.045248  [ 2800/ 3150]\n",
      "loss: 0.045099  [ 3050/ 3150]\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 0.000333 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.044969  [   50/ 3150]\n",
      "loss: 0.045296  [  300/ 3150]\n",
      "loss: 0.045056  [  550/ 3150]\n",
      "loss: 0.045022  [  800/ 3150]\n",
      "loss: 0.045219  [ 1050/ 3150]\n",
      "loss: 0.045398  [ 1300/ 3150]\n",
      "loss: 0.045279  [ 1550/ 3150]\n",
      "loss: 0.045097  [ 1800/ 3150]\n",
      "loss: 0.044743  [ 2050/ 3150]\n",
      "loss: 0.045224  [ 2300/ 3150]\n",
      "loss: 0.045042  [ 2550/ 3150]\n",
      "loss: 0.045195  [ 2800/ 3150]\n",
      "loss: 0.045061  [ 3050/ 3150]\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.000332 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.044900  [   50/ 3150]\n",
      "loss: 0.045244  [  300/ 3150]\n",
      "loss: 0.045002  [  550/ 3150]\n",
      "loss: 0.044963  [  800/ 3150]\n",
      "loss: 0.045149  [ 1050/ 3150]\n",
      "loss: 0.045354  [ 1300/ 3150]\n",
      "loss: 0.045231  [ 1550/ 3150]\n",
      "loss: 0.045047  [ 1800/ 3150]\n",
      "loss: 0.044680  [ 2050/ 3150]\n",
      "loss: 0.045170  [ 2300/ 3150]\n",
      "loss: 0.044991  [ 2550/ 3150]\n",
      "loss: 0.045143  [ 2800/ 3150]\n",
      "loss: 0.045021  [ 3050/ 3150]\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.000332 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.044832  [   50/ 3150]\n",
      "loss: 0.045192  [  300/ 3150]\n",
      "loss: 0.044947  [  550/ 3150]\n",
      "loss: 0.044905  [  800/ 3150]\n",
      "loss: 0.045078  [ 1050/ 3150]\n",
      "loss: 0.045309  [ 1300/ 3150]\n",
      "loss: 0.045184  [ 1550/ 3150]\n",
      "loss: 0.044996  [ 1800/ 3150]\n",
      "loss: 0.044618  [ 2050/ 3150]\n",
      "loss: 0.045115  [ 2300/ 3150]\n",
      "loss: 0.044939  [ 2550/ 3150]\n",
      "loss: 0.045092  [ 2800/ 3150]\n",
      "loss: 0.044979  [ 3050/ 3150]\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.000332 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.044763  [   50/ 3150]\n",
      "loss: 0.045139  [  300/ 3150]\n",
      "loss: 0.044890  [  550/ 3150]\n",
      "loss: 0.044847  [  800/ 3150]\n",
      "loss: 0.045005  [ 1050/ 3150]\n",
      "loss: 0.045265  [ 1300/ 3150]\n",
      "loss: 0.045135  [ 1550/ 3150]\n",
      "loss: 0.044946  [ 1800/ 3150]\n",
      "loss: 0.044557  [ 2050/ 3150]\n",
      "loss: 0.045058  [ 2300/ 3150]\n",
      "loss: 0.044886  [ 2550/ 3150]\n",
      "loss: 0.045040  [ 2800/ 3150]\n",
      "loss: 0.044936  [ 3050/ 3150]\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.000332 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.044694  [   50/ 3150]\n",
      "loss: 0.045086  [  300/ 3150]\n",
      "loss: 0.044831  [  550/ 3150]\n",
      "loss: 0.044788  [  800/ 3150]\n",
      "loss: 0.044930  [ 1050/ 3150]\n",
      "loss: 0.045219  [ 1300/ 3150]\n",
      "loss: 0.045086  [ 1550/ 3150]\n",
      "loss: 0.044894  [ 1800/ 3150]\n",
      "loss: 0.044497  [ 2050/ 3150]\n",
      "loss: 0.044997  [ 2300/ 3150]\n",
      "loss: 0.044833  [ 2550/ 3150]\n",
      "loss: 0.044987  [ 2800/ 3150]\n",
      "loss: 0.044893  [ 3050/ 3150]\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.000331 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Global Variables\n",
    "epochs = 10\n",
    "learning_rate = 1e-5\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def test_model(model, X_test, y_test, loss_func):\n",
    "    size = X_test.shape[1]\n",
    "\n",
    "    model.eval()\n",
    "    with T.no_grad():\n",
    "        X = T.from_numpy(X_test).to(T.float32)\n",
    "        y_tensor = T.Tensor(y_test).to(T.float)\n",
    "\n",
    "        y_pred = model.forward(X)\n",
    "\n",
    "        test_loss = loss_func(y_pred, y_tensor)\n",
    "\n",
    "        correct = (y_pred.argmax(1) == y_tensor.argmax(1)).type(T.float).sum().item()\n",
    "        \n",
    "        test_loss /= size\n",
    "        correct /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, loss_func, optimizer):\n",
    "    size = len(X_train)\n",
    "    batch_size = 50\n",
    "\n",
    "    for i in range(size//batch_size):\n",
    "        start = batch_size * i\n",
    "        end = start + batch_size\n",
    "        X = T.from_numpy(X_train[start:end]).to(T.float32)\n",
    "        y_true = T.Tensor(y_train[start:end]).to(T.float)\n",
    "\n",
    "        y_pred = model(X)\n",
    "        loss = loss_func(y_pred, y_true)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i * batch_size) % 250 == 0:\n",
    "            loss, current = loss.item(), (i + 1) * batch_size\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i+1}\\n-------------------------------\")\n",
    "\n",
    "    train_model(net, X_train, y_train, loss_func, optimizer)\n",
    "    print('Finished training')\n",
    "    test_model(net, X_test, y_test, loss_func)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
