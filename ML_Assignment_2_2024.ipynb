{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(x):\n",
    "    labels = np.unique(x)\n",
    "    result = np.zeros(shape=(x.shape[0], labels.shape[0]))\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        result[i][x[i]] = 1.0\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = [] # Features per class\n",
    "y = [] # Labels\n",
    "N = 5250 # Amount of data we want to use max: 5250\n",
    "\n",
    "# Import the features\n",
    "with open(\"traindata.txt\", \"r\") as file:\n",
    "    for line in file.readlines()[:N]:\n",
    "        features = [float(i) for i in line.split(\",\")]\n",
    "        X.append(features)\n",
    "\n",
    "# Import the labels\n",
    "with open(\"trainlabels.txt\", \"r\") as file:\n",
    "    for line in file.readlines()[:N]:\n",
    "        label = float(line.rstrip())\n",
    "        y.append(label)\n",
    "    \n",
    "# Convert data to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y, dtype=np.int32)\n",
    "y_onehot = to_onehot(y)\n",
    "\n",
    "def split_data(X, y, test_size=0.2, val_size=0.2, random_state=42):\n",
    "   \n",
    "    # Splitting the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Further splitting the training data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size / (1 - test_size),\n",
    "                                                      random_state=random_state)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the number of components to consider when performing pca\n",
    "def num_components(X, variance_tol = 0.8):\n",
    "    # Standardize each feature of the matrix\n",
    "    x_mean = np.mean(X, axis = 0)\n",
    "    x_std = np.std(X, axis = 0)\n",
    "    Z = (X - x_mean) / x_std\n",
    "\n",
    "    # Calculate covariance matrix\n",
    "    C = np.cov(Z, rowvar=False)\n",
    "    # Calculate eigenvalues and eigenvectors and sort by size\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(C)\n",
    "    index = eigenvalues.argsort()[:: -1]\n",
    "    eigenvalues = eigenvalues[index]\n",
    "    eigenvectors = eigenvectors[:, index]\n",
    "\n",
    "    # Calculate explained variance matrix \n",
    "    explained_var = np.cumsum(eigenvalues) / np.sum(eigenvalues)\n",
    "\n",
    "    # Select number of components responsible for variance_tol% of variance\n",
    "    n_components = np.argmax(explained_var >= variance_tol) + 1\n",
    "    return Z, x_mean, x_std, n_components\n",
    "\n",
    "# Parameters are trained components, trained mean, trained standard deviation and the new inputs X\n",
    "# Changes to the PCA basis\n",
    "def convert_to_pca(components, mean, std, X):\n",
    "    Z = (X - mean)/std\n",
    "    return np.transpose(np.matmul(components, np.transpose(Z)))\n",
    "\n",
    "Z, mean, std, n_components = num_components(X_train, 0.80)\n",
    "# Initialize prinicipal component analysis\n",
    "pca = PCA(n_components)\n",
    "pca.fit(Z)\n",
    "components = pca.components_\n",
    "X_train = pca.transform(Z)\n",
    "temp = pca.transform(X_test)\n",
    "X_test = convert_to_pca(components, mean, std, X_test)\n",
    "X_val = convert_to_pca(components, mean, std, X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Build Model\n",
    "def build_model(n_inputs, n_outputs, h1_dims=512, h2_dims=256):\n",
    "    model =  nn.Sequential(\n",
    "        nn.Linear(n_inputs, h1_dims),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(h1_dims, h2_dims),\n",
    "        nn.ReLU(),                              \n",
    "        nn.Linear(h2_dims, n_outputs),\n",
    "        nn.Softmax(dim=-1)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, h1_dims=512, h2_dims=256, name=\"NeuralNetwork\", save_dir=\"/trained_models\"):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.name = name\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.model = build_model(n_inputs, n_outputs, h1_dims, h2_dims)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.model(X)\n",
    "        return X\n",
    "    \n",
    "    def save_model(self):\n",
    "        T.save(self.state_dict, f\"{self.save_dir}/{self.name}.pth\")\n",
    "\n",
    "    def load_model(self, name):\n",
    "        self.load_state_dict(T.load(f\"{self.save_dir}/{name}.pth\"))\n",
    "\n",
    "\n",
    "\n",
    "labels = np.unique(y) # Labels of our data (0 - 20)\n",
    "\n",
    "n_inputs = X_train.shape[1]\n",
    "h1_dims = 2 * n_inputs # Number of nodes for the 1st hidden layer\n",
    "h2_dims = n_inputs # Number of nodes for the 2nd hidden layer\n",
    "n_outputs = labels.shape[0] # 21 labels\n",
    "\n",
    "# Initialize the model\n",
    "net = NeuralNetwork(n_inputs=n_inputs, n_outputs=n_outputs, h1_dims=h1_dims, h2_dims=h2_dims, name=\"NN-v1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 10.3%, Avg loss: 0.000043 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 14.7%, Avg loss: 0.000042 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 16.1%, Avg loss: 0.000042 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 20.1%, Avg loss: 0.000041 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 23.6%, Avg loss: 0.000040 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 26.5%, Avg loss: 0.000039 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 30.0%, Avg loss: 0.000038 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 32.2%, Avg loss: 0.000037 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 34.3%, Avg loss: 0.000036 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 36.2%, Avg loss: 0.000036 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 37.5%, Avg loss: 0.000035 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 38.4%, Avg loss: 0.000035 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 39.1%, Avg loss: 0.000034 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 39.9%, Avg loss: 0.000034 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 0.000034 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 41.0%, Avg loss: 0.000033 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 42.1%, Avg loss: 0.000033 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 42.7%, Avg loss: 0.000033 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 43.0%, Avg loss: 0.000033 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 44.6%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 44.6%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.3%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.1%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.6%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.8%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.8%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.000030 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.8%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.7%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.1%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.1%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.3%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.3%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.3%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.6%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.8%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.000031 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.1%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.1%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 49.1%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.8%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.3%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 0.000032 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 0.000032 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Global Variables\n",
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def test_model(model, X_test, y_test, loss_func):\n",
    "    size = len(y_test)\n",
    "\n",
    "    model.eval()\n",
    "    with T.no_grad():\n",
    "        X = T.from_numpy(X_test).to(T.float32)\n",
    "        y_tensor = T.Tensor(y_test).to(T.float)\n",
    "\n",
    "        y_pred = model.forward(X)\n",
    "\n",
    "        test_loss = loss_func(y_pred, y_tensor)\n",
    "\n",
    "        correct = (y_pred.argmax(1) == y_tensor.argmax(1)).type(T.float).sum().item()\n",
    "        \n",
    "        test_loss /= size\n",
    "        correct /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, loss_func, optimizer):\n",
    "    size = len(X_train)\n",
    "    batch_size = 50\n",
    "\n",
    "    for i in range(size//batch_size):\n",
    "        start = batch_size * i\n",
    "        end = start + batch_size\n",
    "        X = T.from_numpy(X_train[start:end]).to(T.float32)\n",
    "        y_true = T.Tensor(y_train[start:end]).to(T.float)\n",
    "\n",
    "        y_pred = model(X)\n",
    "        loss = loss_func(y_pred, y_true)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if (i * batch_size) % 500 == 0:\n",
    "        #     loss, current = loss.item(), (i + 1) * batch_size\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i+1}\\n-------------------------------\")\n",
    "\n",
    "    train_model(net, X_train, y_train, loss_func, optimizer)\n",
    "    print('Finished training')\n",
    "    test_model(net, X_test, y_test, loss_func)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
