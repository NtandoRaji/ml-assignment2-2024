{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(x):\n",
    "    labels = np.unique(x)\n",
    "    result = np.zeros(shape=(x.shape[0], labels.shape[0]))\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        result[i][x[i]] = 1.0\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = [] # Features per class\n",
    "y = [] # Labels\n",
    "N = 5250 # Amount of data we want to use max: 5250\n",
    "\n",
    "# Import the features\n",
    "with open(\"sample_data/training_data_onehot.pkl\", \"rb\") as f:\n",
    "\tX_train, y_train = pickle.load(f)\n",
    "\n",
    "with open(\"sample_data/test_data_onehot.pkl\", \"rb\") as f:\n",
    "\tX_test, y_test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the number of components to consider when performing pca\n",
    "def num_components(X, variance_tol = 0.8):\n",
    "    # Standardize each feature of the matrix\n",
    "    x_mean = np.mean(X, axis = 0)\n",
    "    x_std = np.std(X, axis = 0)\n",
    "    Z = (X - x_mean) / x_std\n",
    "\n",
    "    # Calculate covariance matrix\n",
    "    C = np.cov(Z, rowvar=False)\n",
    "    # Calculate eigenvalues and eigenvectors and sort by size\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(C)\n",
    "    index = eigenvalues.argsort()[:: -1]\n",
    "    eigenvalues = eigenvalues[index]\n",
    "    eigenvectors = eigenvectors[:, index]\n",
    "\n",
    "    # Calculate explained variance matrix \n",
    "    explained_var = np.cumsum(eigenvalues) / np.sum(eigenvalues)\n",
    "\n",
    "    # Select number of components responsible for variance_tol% of variance\n",
    "    n_components = np.argmax(explained_var >= variance_tol) + 1\n",
    "    return Z, x_mean, x_std, n_components\n",
    "\n",
    "# Parameters are trained components, trained mean, trained standard deviation and the new inputs X\n",
    "# Changes to the PCA basis\n",
    "def convert_to_pca(components, mean, std, X):\n",
    "    Z = (X - mean)/std\n",
    "    return np.matmul(components, Z)\n",
    "\n",
    "Z, mean, std, n_components = num_components(X_train)\n",
    "# Initialize prinicipal component analysis\n",
    "pca = PCA(n_components)\n",
    "pca.fit(Z)\n",
    "components = pca.components_\n",
    "x_pca = pca.transform(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Build Model\n",
    "def build_model(n_inputs, n_outputs, h1_dims=512, h2_dims=256):\n",
    "    model =  nn.Sequential(\n",
    "        nn.Linear(n_inputs, h1_dims),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(h1_dims, h2_dims),\n",
    "        nn.ReLU(),                              \n",
    "        nn.Linear(h2_dims, n_outputs),\n",
    "        nn.Softmax(dim=-1)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, h1_dims=512, h2_dims=256, name=\"NeuralNetwork\", save_dir=\"/trained_models\"):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.name = name\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.model = build_model(n_inputs, n_outputs, h1_dims, h2_dims)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.flatten(X)\n",
    "        X = self.model(X)\n",
    "        return X\n",
    "    \n",
    "    def save_model(self):\n",
    "        T.save(self.state_dict, f\"{self.save_dir}/{self.name}.pth\")\n",
    "\n",
    "    def load_model(self, name):\n",
    "        self.load_state_dict(T.load(f\"{self.save_dir}/{name}.pth\"))\n",
    "\n",
    "\n",
    "\n",
    "labels = np.unique(y_train) # Labels of our data (0 - 20)\n",
    "\n",
    "n_inputs = len(np.reshape(X_train[0], -1))\n",
    "h1_dims = 2 * n_inputs # Number of nodes for the 1st hidden layer\n",
    "h2_dims = n_inputs # Number of nodes for the 2nd hidden layer\n",
    "n_outputs = 10 # 21 labels\n",
    "\n",
    "# Initialize the model\n",
    "net = NeuralNetwork(n_inputs=n_inputs, n_outputs=n_outputs, h1_dims=h1_dims, h2_dims=h2_dims, name=\"NN-v1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.002534  [   50/35700]\n",
      "loss: 0.006014  [ 2550/35700]\n",
      "loss: 0.002144  [ 5050/35700]\n",
      "loss: 0.005779  [ 7550/35700]\n",
      "loss: 0.001126  [10050/35700]\n",
      "loss: 0.004376  [12550/35700]\n",
      "loss: 0.004941  [15050/35700]\n",
      "loss: 0.000882  [17550/35700]\n",
      "loss: 0.005417  [20050/35700]\n",
      "loss: 0.000394  [22550/35700]\n",
      "loss: 0.005584  [25050/35700]\n",
      "loss: 0.009057  [27550/35700]\n",
      "loss: 0.011634  [30050/35700]\n",
      "loss: 0.001576  [32550/35700]\n",
      "loss: 0.000797  [35050/35700]\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.001613  [   50/35700]\n",
      "loss: 0.005542  [ 2550/35700]\n",
      "loss: 0.001630  [ 5050/35700]\n",
      "loss: 0.006163  [ 7550/35700]\n",
      "loss: 0.000919  [10050/35700]\n",
      "loss: 0.003915  [12550/35700]\n",
      "loss: 0.004621  [15050/35700]\n",
      "loss: 0.000731  [17550/35700]\n",
      "loss: 0.005036  [20050/35700]\n",
      "loss: 0.000341  [22550/35700]\n",
      "loss: 0.005205  [25050/35700]\n",
      "loss: 0.008866  [27550/35700]\n",
      "loss: 0.011167  [30050/35700]\n",
      "loss: 0.001301  [32550/35700]\n",
      "loss: 0.001002  [35050/35700]\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.001188  [   50/35700]\n",
      "loss: 0.005652  [ 2550/35700]\n",
      "loss: 0.001597  [ 5050/35700]\n",
      "loss: 0.006005  [ 7550/35700]\n",
      "loss: 0.000793  [10050/35700]\n",
      "loss: 0.003732  [12550/35700]\n",
      "loss: 0.004534  [15050/35700]\n",
      "loss: 0.000756  [17550/35700]\n",
      "loss: 0.004771  [20050/35700]\n",
      "loss: 0.000310  [22550/35700]\n",
      "loss: 0.005108  [25050/35700]\n",
      "loss: 0.008554  [27550/35700]\n",
      "loss: 0.010878  [30050/35700]\n",
      "loss: 0.001145  [32550/35700]\n",
      "loss: 0.001135  [35050/35700]\n",
      "Finished training\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.000001 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Global Variables\n",
    "epochs = 3\n",
    "learning_rate = 1e-5\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def test_model(model, X_test, y_test, loss_func):\n",
    "    size = len(y_test)\n",
    "\n",
    "    model.eval()\n",
    "    with T.no_grad():\n",
    "        \n",
    "        X = T.from_numpy(X_test).to(T.float32)\n",
    "        y_tensor = T.Tensor(y_test).to(T.float)\n",
    "\n",
    "        y_pred = model.forward(X)\n",
    "\n",
    "        test_loss = loss_func(y_pred, y_tensor)\n",
    "\n",
    "        correct = (y_pred.argmax(1) == y_tensor.argmax(1)).type(T.float).sum().item()\n",
    "        \n",
    "        test_loss /= size\n",
    "        correct /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, loss_func, optimizer):\n",
    "    size = len(X_train)\n",
    "    batch_size = 50\n",
    "\n",
    "    for i in range(size//batch_size):\n",
    "        start = batch_size * i\n",
    "        end = start + batch_size\n",
    "        X = T.from_numpy(X_train[start:end]).to(T.float32)\n",
    "        y_true = T.Tensor(y_train[start:end]).to(T.float)\n",
    "\n",
    "        y_pred = model(X)\n",
    "        loss = loss_func(y_pred, y_true)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i * batch_size) % 2500 == 0:\n",
    "            loss, current = loss.item(), (i + 1) * batch_size\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i+1}\\n-------------------------------\")\n",
    "\n",
    "    train_model(net, X_train, y_train, loss_func, optimizer)\n",
    "    print('Finished training')\n",
    "    test_model(net, X_test, y_test, loss_func)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
