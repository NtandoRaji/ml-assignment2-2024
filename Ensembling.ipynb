{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [] # Features per class\n",
    "training_labels = [] # Labels\n",
    "testing_data = [] # Features per class\n",
    "testing_labels = [] # Labels\n",
    "N = 5250 # Amount of data we want to use max: 5250\n",
    "\n",
    "# Import the features\n",
    "with open(\"traindata.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        features = [float(i) for i in line.split(\",\")]\n",
    "        training_data.append(features)\n",
    "\n",
    "with open(\"testdata.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        features = [float(i) for i in line.split(\",\")]\n",
    "        testing_data.append(features)\n",
    "\n",
    "\n",
    "# Import the labels\n",
    "with open(\"trainlabels.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        label = float(line.rstrip())\n",
    "        training_labels.append(label)\n",
    "\n",
    "with open(\"targetlabels.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        label = float(line.rstrip())\n",
    "        testing_labels.append(label)\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "training_data = np.array(training_data)\n",
    "training_labels = np.array(training_labels, dtype=np.int64)\n",
    "\n",
    "testing_data = np.array(testing_data)\n",
    "testing_labels = np.array(testing_labels, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:  (5250, 1041) (5250,)\n",
      "Testing Data:  (2100, 1041) (2100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data: \", training_data.shape, training_labels.shape)\n",
    "print(\"Testing Data: \", testing_data.shape, testing_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(x):\n",
    "    labels = np.unique(x)\n",
    "    result = np.zeros(shape=(x.shape[0], labels.shape[0]))\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        result[i][x[i]] = 1.0\n",
    "\n",
    "    return result\n",
    "\n",
    "def rotate_image(image, orientation):\n",
    "    angle = 90 * orientation\n",
    "    \n",
    "    if angle == 0:\n",
    "        return image\n",
    "    elif angle == 90:\n",
    "        return np.fliplr(np.transpose(image))  # Rotate 90 degrees clockwise\n",
    "    elif angle == 180:\n",
    "        return np.flipud(np.fliplr(image))  # Rotate 180 degrees\n",
    "    elif angle == 270:\n",
    "        return np.transpose(np.fliplr(image))  # Rotate 270 degrees clockwise\n",
    "\n",
    "def preprocess_data(X):\n",
    "    x = X[:-1]\n",
    "    orientation = X[-1] # 4 orientations: 0, 1, 2, 3\n",
    "\n",
    "    filtered_x = x[x >= 0] # Filter out negative values\n",
    "    filtered_x = np.minimum(filtered_x, 255.0) # cap values greater than 255 to 255\n",
    "    image = filtered_x.reshape([32, 32]) # reshape to an image\n",
    "\n",
    "    normalized_image = MinMaxScaler().fit_transform(image) # Normalize Image\n",
    "\n",
    "    rotated_image = rotate_image(normalized_image, orientation) #Rotate Image\n",
    "    return rotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_training_data = []\n",
    "preprocess_testing_data = []\n",
    "\n",
    "for X in training_data:\n",
    "    preprocess_X = preprocess_data(X)\n",
    "    preprocess_training_data.append(preprocess_X)\n",
    "\n",
    "for X in testing_data:\n",
    "    preprocess_X = preprocess_data(X)\n",
    "    preprocess_testing_data.append(preprocess_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, val_size=0.2, random_state=42):\n",
    "   \n",
    "    # Splitting the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Further splitting the training data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size / (1 - test_size),\n",
    "                                                      random_state=random_state)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "X_train = np.array(preprocess_training_data)\n",
    "y_train = to_onehot(training_labels)\n",
    "X_test, X_val, y_test, y_val = train_test_split(np.array(preprocess_testing_data), to_onehot(testing_labels), test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5250, 1, 32, 32) (1050, 1, 32, 32) (1050, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "new_shape = [-1, 1, 32, 32]\n",
    "X_train = np.reshape(X_train, new_shape)\n",
    "X_test = np.reshape(X_test, new_shape)\n",
    "X_val = np.reshape(X_val, new_shape)\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(image, title):\n",
    "    plt.imshow(image.reshape([32, 32]), cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4oklEQVR4nO3de1iU5bo/8O+AMIDAKKAcFBRPeD6RBzTPLpVWauluq7mvpeXSrWEus1Yr2520taOsZVZL7bBb2ok0M/XKDpamqAmaKIvUJDFUVEBBAQXk+Pz+6GJ+jqA+N4IP4PdzXXMlM1/ued55Z7ibmXfusSilFIiIiG4zJ9MLICKiOxMbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxAZd+LECVgsFqxevdp+3gsvvACLxaL1+xaLBS+88EKNrmno0KEYOnRojdY0wWKxYO7cuTVWr6p9RVRdbEAkMm7cOHh4eODSpUvXzUydOhWurq7Izs6+jSuTO3LkCF544QWcOHHC9FLsduzYAYvFgs8//9z0UmpFeno6nnrqKQwbNgxeXl6wWCzYsWNHldny8nK8/fbb6NmzJzw9PeHv74/IyEjs2bPn9i6aag0bEIlMnToVhYWF2LBhQ5WXFxQUYNOmTRgzZgx8fX2rfT3PPPMMCgsLq/37Oo4cOYJFixZV2YC+++47fPfdd7V6/Xei5ORkvPLKKzhz5gy6det2w+xf//pXzJkzB926dcPSpUvx+OOP49dff8WQIUOwb9++27Riqk1sQCQybtw4eHl5ISYmpsrLN23ahPz8fEydOvWWrqdRo0Zwc3O7pRq3wtXVFa6ursauv6EKDw9HdnY2fv31VyxYsOC6udLSUqxcuRL/8R//gY8++gizZs3Ck08+ia1bt6K0tBSffPLJbVw11RY2IBJxd3fHhAkTsG3bNpw7d67S5TExMfDy8sK4ceNw4cIFPPHEE+jWrRs8PT3h7e2NyMhI/Pvf/77p9VT1HlBRUREee+wxNGvWzH4dp0+frvS7J0+exCOPPIKwsDC4u7vD19cXDzzwgMMzndWrV+OBBx4AAAwbNgwWi8Xh5aCq3gM6d+4cZsyYAX9/f7i5uaFHjx744IMPHDIV75G89tprePfdd9G2bVtYrVb06dMHP/300023W9drr72GAQMGwNfXF+7u7ggPD7/hy3affPIJwsLC4ObmhvDwcOzcubNS5syZM3j44Yfh7+8Pq9WKLl264F//+tdN11JSUoKjR48iPT39plkvLy/4+Pho1SwsLIS/v7/D+c2bN4eTkxPc3d1vWoPqvkamF0D1z9SpU/HBBx/gs88+c3iD+8KFC9iyZQumTJkCd3d3HD58GBs3bsQDDzyA0NBQZGZm4p133sGQIUNw5MgRBAUFia73z3/+Mz7++GM8+OCDGDBgAH744Qf88Y9/rJT76aefsGfPHkyePBktW7bEiRMnsHLlSgwdOhRHjhyBh4cHBg8ejHnz5uHNN9/E008/jU6dOgGA/b/XKiwsxNChQ5GSkoK5c+ciNDQU69atw/Tp05GTk4O//OUvDvmYmBhcunQJ//3f/w2LxYIlS5ZgwoQJ+O233+Di4iLa7qq88cYbGDduHKZOnYri4mKsWbMGDzzwADZv3lzpNomNjcXatWsxb948WK1WrFixAmPGjMG+ffvQtWtXAEBmZib69+9vP2ihWbNm+OabbzBjxgzk5eVh/vz5113LmTNn0KlTJ0ybNq3GDk5wd3dHv379sHr1akRERGDQoEHIycnBiy++iKZNm2LWrFk1cj1kmCISKi0tVYGBgSoiIsLh/LffflsBUFu2bFFKKXXlyhVVVlbmkElNTVVWq1UtXrzY4TwAatWqVfbznn/+eXX13TMxMVEBUI888ohDvQcffFABUM8//7z9vIKCgkprjouLUwDUhx9+aD9v3bp1CoDavn17pfyQIUPUkCFD7D8vW7ZMAVAff/yx/bzi4mIVERGhPD09VV5ensO2+Pr6qgsXLtizmzZtUgDUl19+Wem6rrZ9+3YFQK1bt+6GuWu3sbi4WHXt2lUNHz7c4XwACoDav3+//byTJ08qNzc3df/999vPmzFjhgoMDFRZWVkOvz958mRls9ns11fVvqo4b9q0aTdc87VudPsrpdSxY8dU79697dsAQLVp00YdPXpUdD1Ud/ElOBJzdnbG5MmTERcX5/CyVkxMDPz9/TFixAgAgNVqhZPT73exsrIyZGdnw9PTE2FhYThw4IDoOr/++msAwLx58xzOr+r/zK9+eaakpATZ2dlo164dmjRpIr7eq68/ICAAU6ZMsZ/n4uKCefPm4fLly4iNjXXIT5o0CU2bNrX/PGjQIADAb7/9Vq3rv9bV23jx4kXk5uZi0KBBVW5fREQEwsPD7T+HhIRg/Pjx2LJlC8rKyqCUwvr16zF27FgopZCVlWU/jR49Grm5uTe83Vq3bg2lVI0fmu3l5YUuXbogKioKX3zxBVasWIHS0lLcd999yMrKqtHrIjPYgKhaKg4yqDgY4fTp09i1axcmT54MZ2dnAL8fRvv666+jffv2sFqt8PPzQ7NmzZCUlITc3FzR9Z08eRJOTk5o27atw/lhYWGVsoWFhXjuuecQHBzscL05OTni6736+tu3b29vqBUqXrI7efKkw/khISEOP1c0o4sXL1br+q+1efNm9O/fH25ubvDx8UGzZs2wcuXKKrevffv2lc7r0KEDCgoKcP78eZw/fx45OTl499130axZM4fTQw89BABVvt9Xm0pLSzFy5EjYbDb885//xP333485c+Zg69atOH78OF599dXbuh6qHXwPiKolPDwcHTt2xKeffoqnn34an376KZRSDke/vfTSS3j22Wfx8MMP48UXX4SPjw+cnJwwf/58lJeX19raHn30UaxatQrz589HREQEbDYbLBYLJk+eXKvXe7WKJnwtpdQt1961axfGjRuHwYMHY8WKFQgMDISLiwtWrVp13aMTb6TiNvmv//ovTJs2rcpM9+7db2nNUjt37sShQ4ewdOlSh/Pbt2+PTp064ccff7yt66HawQZE1TZ16lQ8++yzSEpKQkxMDNq3b48+ffrYL//8888xbNgwvP/++w6/l5OTAz8/P9F1tWrVCuXl5Th+/LjDs57k5ORK2c8//xzTpk3DP/7xD/t5V65cQU5OjkNOd9JCxfUnJSWhvLzc4VnQ0aNH7ZffLuvXr4ebmxu2bNkCq9VqP3/VqlVV5o8dO1bpvF9//RUeHh5o1qwZgN9f7iorK8PIkSNrZ9FCmZmZAH5/6fZaJSUlKC0tvd1LolrAl+Co2iqe7Tz33HNITEys9NkfZ2fnSv/Hv27dOpw5c0Z8XZGRkQCAN9980+H8ZcuWVcpWdb1vvfVWpT9mjRs3BoBKjakq99xzDzIyMrB27Vr7eaWlpXjrrbfg6emJIUOG6GxGjXB2dobFYnHYnhMnTmDjxo1V5uPi4hzew0lLS8OmTZswatQoODs7w9nZGRMnTsT69etx6NChSr9//vz5G65Hchi2rg4dOgAA1qxZ43D+gQMHkJycjF69etXYdZE5fAZE1RYaGooBAwZg06ZNAFCpAd17771YvHgxHnroIQwYMAA///wzPvnkE7Rp00Z8XT179sSUKVOwYsUK5ObmYsCAAdi2bRtSUlIqZe+991589NFHsNls6Ny5M+Li4rB169ZKkxl69uwJZ2dnvPLKK8jNzYXVasXw4cPRvHnzSjVnzZqFd955B9OnT0dCQgJat26Nzz//HD/++COWLVsGLy8v8TbdyPr16+3Prq42bdo0/PGPf8TSpUsxZswYPPjggzh37hyWL1+Odu3aISkpqdLvdO3aFaNHj3Y4DBsAFi1aZM+8/PLL2L59O/r164eZM2eic+fOuHDhAg4cOICtW7fiwoUL112r9DDsv//97wCAw4cPAwA++ugj7N69G8DvEzCA31/i/cMf/oAPPvgAeXl5GDVqFNLT0/HWW2/B3d39hoeFUz1i8Ag8agCWL1+uAKi+fftWuuzKlSvq8ccfV4GBgcrd3V0NHDhQxcXFVTrEWecwbKWUKiwsVPPmzVO+vr6qcePGauzYsSotLa3SYdgXL15UDz30kPLz81Oenp5q9OjR6ujRo6pVq1aVDhV+7733VJs2bZSzs7PDIcHXrlEppTIzM+11XV1dVbdu3RzWfPW2vPrqq5Vuj2vXWZWKw7Cvd9q1a5dSSqn3339ftW/fXlmtVtWxY0e1atWqKm8zACoqKkp9/PHH9nyvXr2qPPQ5MzNTRUVFqeDgYOXi4qICAgLUiBEj1Lvvvltp+27lMOwbbd/VCgoK1OLFi1Xnzp2Vu7u7stls6t5771UHDx7Uuh6q+yxK1cC7okREREJ8D4iIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI+rcB1HLy8tx9uxZ+/fFExFR/aKUwqVLlxAUFFRpgO/V6lwDOnv2LIKDg00vg4iIblFaWhpatmx53cvrXAOqGGnSq1ev604Uvtb+/fu16x85ckS0ns2bN2tnpZ/p3bZtm3b26u9z0dG/f3/t7LVfPX0zVY33v5Hx48drZ1955RVR7X379mlni4uLRbWv9+2oVbl24OrNXD1TTseoUaO0sxUjbnQ9+eST2lmbzSaqHRcXp5399ddfRbWr+jbc67nZPLtrBQQEiPJVjW+6no8++khU++pvHb6Z+Ph4UW3JXEbJV4kUFRVhxYoVNx1RVWsNaPny5Xj11VeRkZGBHj164K233kLfvn1v+nsVL7s5OzujUaOaX550Zpfku+elo/4lX83s5uYmql0xaFOHt7e3qPaNnlJXxdXVtdbWItlO6VdhS+4rV0+l1iG9DSX1pY8byW3o6ekpqi2530ruJ4Bs3ZcvX6612oDsdpHeVyT3Qw8PD1Ftyf6Rrhu4+cT5WjkIYe3atViwYAGef/55HDhwAD169MDo0aNv+5daERFR3VUrDWjp0qWYOXMmHnroIXTu3Blvv/02PDw88K9//atStqioCHl5eQ4nIiJq+Gq8ARUXFyMhIcHhi62cnJwwcuTIKl8Pjo6Ohs1ms594AAIR0Z2hxhtQVlYWysrK4O/v73C+v78/MjIyKuUXLlyI3Nxc+yktLa2ml0RERHWQ8aPgrFZrtd7cIiKi+q3GnwH5+fnB2dnZ/p3uFTIzM8WHNhIRUcNV4w3I1dUV4eHhDp9xKS8vx7Zt2xAREVHTV0dERPVUrbwEt2DBAkybNg133XUX+vbti2XLliE/Px8PPfRQbVwdERHVQ7X2ldz//Oc/7R9E7dmzJ958803069fvpr+Xl5cHm82G8PBw7UkIiYmJ2usqKirSzgKodDDFjfj4+Ihqh4aGamd/++03Ue0mTZpoZ/fu3SuqLSW5XQoKCmqtdllZmai2ZBLCoUOHRLVbtWolyks+sV5YWCiqLfkAqPSzfJLb8JdffhHVHj58uHY2KSlJVFv6ofIWLVpoZyV/UwDZZAtfX19R7ZSUFO1sWFiYdrasrAyHDx9Gbm7uDT9cXmsHIcydO1c0QoKIiO4s/DoGIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMsL41zFcz5kzZ+DkpNcfJWNnTp8+LVrHtVO9GyLpiBrpyJSXXnpJO5udnS2qLZkktWvXLlHtnJwc7WyHDh1EtXNzc0V5yRgUd3d3UW3J2Jl7771XVPt//ud/RHmJH374odZq1yVHjx7Vzk6ZMkVUWzKa7OTJk9pZ3cclnwEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZUWdnwfn5+cHZ2Vkr++9//1u77nvvvSdax7x587Szvr6+otp1he7tXCE+Pl6U37hxo3bWw8NDVDsrK0s727p1a1Ftycy74OBgUW3JnDkAOHz4sHZWMjcOABo3bqyd9ff3F9UOCAgQ5amyf/zjH9rZ9PR0Ue0uXbpoZyUzI8vKypCXl3fTHJ8BERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZESdHcWTn58PJye9/igZD7Jo0SLROnbv3q2dvfvuu0W166uff/5ZlC8sLNTOFhQUiGpLxs6cOHFCVDsoKEg726iR7KEkHVFTUlKinQ0NDRXV3rp1q3Z2+PDhotocxVPZa6+9JsqfOXNGOxsYGCiqLRljJhnZpZTSyvEZEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRF1dhacxWKBxWLRyvbt21e7bnh4uGgds2fP1s7eKbPgzp49K8pHRkZqZ3v16iWq/euvv2pn/fz8RLXLy8u1s9JZcJIZdgBw6NAh7ax0nt6AAQO0s9L94+npKcrXV1u2bNHOvvfee6Lakvthdna2qHbv3r21s2VlZaKszsxIPgMiIiIjarwBvfDCC/ZnLxWnjh071vTVEBFRPVcrL8F16dLFYcS79OUJIiJq+GqlMzRq1IjfA0JERDdUK+8BHTt2DEFBQWjTpg2mTp2KU6dOXTdbVFSEvLw8hxMRETV8Nd6A+vXrh9WrV+Pbb7/FypUrkZqaikGDBuHSpUtV5qOjo2Gz2eyn4ODgml4SERHVQTXegCIjI/HAAw+ge/fuGD16NL7++mvk5OTgs88+qzK/cOFC5Obm2k9paWk1vSQiIqqDav3ogCZNmqBDhw5ISUmp8nKr1Qqr1VrbyyAiojqm1j8HdPnyZRw/fhyBgYG1fVVERFSP1HgDeuKJJxAbG4sTJ05gz549uP/+++Hs7IwpU6bU9FUREVE9VuMvwZ0+fRpTpkxBdnY2mjVrhrvvvhvx8fFo1qyZqE5qaqr2KJ7Q0FDtupKxFgCwe/du7ezMmTNFtesKyYgNABgzZowo/+qrr2pn8/PzRbVbtGihnW3ZsqWo9sGDB7WzOTk5oto2m02Ul7hy5YooL3lMnDt3TlS7VatWorxEaWmpdra2P4u4YsUK7ayXl5eodlJSknZ26NChotrp6enaWckRyrr3qRrfK2vWrKnpkkRE1ABxFhwRERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERG1PrXMVSXv78/nJz0+qNkJpRkvhcATJ48WTu7f/9+Ue277rpLlK8tzs7OonxISIgoL5k117hxY1Ht5ORk7azkfgIA3bt3185KZwwePXpUlPfw8NDOurq6imp36tRJOztv3jxRbd15jtVRm/PdYmJiRPnt27drZ4uKikS1w8LCtLP79u0T1ZY89iUzBpVSWjk+AyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMiIOjuKp1WrVtqjNiRjMKTjO/70pz9pZ729vUW16yubzSbK9+nTRzv7zTffiGp37txZO5uSkiKqXVhYqJ11cXER1W7Tpo0oP3z4cO3sli1bRLXnzp2rne3atauotoR0nJHuqC4ASE9PF9WWjtXq0aOHdlZ6P0xLS9POtm7dWlS7adOm2tndu3drZzmKh4iI6jQ2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIyos7PgLly4AGdnZ61sly5dtOvm5uaK1vHVV19pZ318fES1X3vtNVG+rujbt68on5WVVUsrAYqLi7WzvXv3FtVu3LixdrakpERU+8qVK6L85s2btbMXLlwQ1ZbchrWpNmfBZWdni2qvXLlSlO/Zs6d2tnnz5qLakvuKdM5cr169tLOlpaWi2jr4DIiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMiIOjsLzsfHB40a6S0vMzNTu+758+dF65DMeGrWrJmo9p1Cdz8CQE5Ojqi2ZK7WL7/8IqotmZHm5uYmqq0757BCu3bttLPDhw8X1e7UqZMoX1sk9xMAuHjxonb2u+++E9Xu0KGDKC+930q4urpqZ//zP/9TVDsmJkY7O3jwYO1saWkp9uzZc9McnwEREZER4ga0c+dOjB07FkFBQbBYLNi4caPD5UopPPfccwgMDIS7uztGjhyJY8eO1dR6iYiogRA3oPz8fPTo0QPLly+v8vIlS5bgzTffxNtvv429e/eicePGGD16tHj8PBERNWzi94AiIyMRGRlZ5WVKKSxbtgzPPPMMxo8fDwD48MMP4e/vj40bN2Ly5Mm3tloiImowavQ9oNTUVGRkZGDkyJH282w2G/r164e4uLgqf6eoqAh5eXkOJyIiavhqtAFlZGQAAPz9/R3O9/f3t192rejoaNhsNvspODi4JpdERER1lPGj4BYuXIjc3Fz7KS0tzfSSiIjoNqjRBhQQEACg8udyMjMz7Zddy2q1wtvb2+FEREQNX402oNDQUAQEBGDbtm328/Ly8rB3715ERETU5FUREVE9Jz4K7vLly0hJSbH/nJqaisTERPj4+CAkJATz58/H3//+d7Rv3x6hoaF49tlnERQUhPvuu68m101ERPWcuAHt378fw4YNs/+8YMECAMC0adOwevVqPPnkk8jPz8esWbOQk5ODu+++G99++614VElRURFKS0u1slc3xJu5++67Reu43sETVUlPTxfVlnw2Snr7ScbISEZ9VMeIESO0s4cPHxbVdnLSfxIvGWcDyMaruLi4iGrn5+eL8omJidrZP//5z6LaHTt2FOXriqKiIu2sZOQMAO2/PRUKCgq0sy1bthTVPnHihHZW+qH/aw8YuxHJ36uysjKtnLgBDR06FEqp615usViwePFiLF68WFqaiIjuIMaPgiMiojsTGxARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZIR7Fc7tIZl9J53BJnD9/XjsbHx8vqi2d7yZR2/PdJKxWq3b2RmOeqnLy5EntrKenp6h29+7dtbNHjx4V1ZbOpZPM4ZoxY4aodn31+uuva2eTk5NFta/39THXExISIspLSGbeOTs7i2pL/nY2btxYO6s7S4/PgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKizo7iCQoKgpOTXn+UjM24dOmSaB1lZWXaWW9vb1Ht2NhY7eyQIUNEteuSyMhI7ez69etFtc+dOyddjrYzZ85oZ6WjdaRjgZ544gntbGFhoai2u7u7KF9biouLRfmMjAztrM1mE9WWjsnavXu3drZjx46i2llZWdrZ0NBQUW1fX19RvqbxGRARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERdXYWXFFRkfYsOAkXFxdRXjKfKj4+XlR769at2tmBAweKajdqVHd27bFjx7SzPXv2FNV2dnaulXUAQOPGjbWz+/fvF9WWzgMLCwvTztaV2W4AUF5erp1dvHixqPYzzzyjnU1OThbVlswBBICuXbtqZ4OCgkS1JftTcp8FgBMnTmhnBwwYoJ0tLS3VyvEZEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREbUnXkt1/Dw8NAexXPu3DntugUFBaJ1SMZP7N27V1Q7ISFBO1uXRutIjRkzRjv74YcfimoXFRVpZ6UjUH755RftbLt27US1IyIiRPnx48eL8nWFZJyW5PEAAF999ZV2NiMjQ1S7bdu2ovzFixe1s7m5uaLarq6u2tmAgABRbcnoq23btolq6+AzICIiMoINiIiIjBA3oJ07d2Ls2LEICgqCxWLBxo0bHS6fPn06LBaLw0nyEgwREd0ZxA0oPz8fPXr0wPLly6+bGTNmDNLT0+2nTz/99JYWSUREDY/4ne3IyEhERkbeMGO1WsVvhhER0Z2lVt4D2rFjB5o3b46wsDDMmTMH2dnZ180WFRUhLy/P4URERA1fjTegMWPG4MMPP8S2bdvwyiuvIDY2FpGRkSgrK6syHx0dDZvNZj8FBwfX9JKIiKgOqvEPl0yePNn+727duqF79+5o27YtduzYgREjRlTKL1y4EAsWLLD/nJeXxyZERHQHqPXDsNu0aQM/Pz+kpKRUebnVaoW3t7fDiYiIGr5ab0CnT59GdnY2AgMDa/uqiIioHhG/BHf58mWHZzOpqalITEyEj48PfHx8sGjRIkycOBEBAQE4fvw4nnzySbRr1w6jR4+u0YUTEVH9Jm5A+/fvx7Bhw+w/V7x/M23aNKxcuRJJSUn44IMPkJOTg6CgIIwaNQovvvgirFar6HrS0tJgsVi0suHh4dp1k5OTRetwdnbWzvbo0UNU+9ixY9rZrKwsUW0/Pz9Rvq6QzlQ7cOCAdvbChQui2vn5+dpZFxcXUe36un+kdu7cqZ1NTU0V1ZY8lqWvwEgfb++88452dsiQIaLa7du3185K/85K5ruNHDlSO1taWoodO3bcNCduQEOHDoVS6rqXb9myRVqSiIjuQJwFR0RERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRE1/n1ANelGI3+uJpnxFRYWJlpDenq6dvbkyZOi2qGhodrZO2V22Lhx40T5pUuXamcHDBggqi2ZNXbPPfeIag8ePFiUrysKCwtF+WeffbbWattsNu3s+fPnRbXbtm0ryj/zzDPa2V27dolqS0hmIwLAXXfdpZ0tKSnRzpaWlmrl+AyIiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI+rsKB4XFxdYLBatrGRMzb59+0TrkIxMyczMFNXOy8vTziYmJopq9+zZU5SvK4qLi0V5Z2dn7ezFixdFtSWjlZ588klR7WHDhonydcXevXtF+YMHD2pnJY8HABg4cKB2VjomSzq658SJE9pZFxcXUW3JCJyQkBBRbcnoHskoq7KyMq0cnwEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZUWdnwbVr1057zperq6t23WbNmonW4e3trZ0NCAgQ1b58+bJ2Ni0tTVS7vs6Ca9GihSg/YsQI7eyGDRtEtSX786WXXhLVrksk98P4+HhR7bvuuks7K933RUVF2lnp4z4rK0uUb9mypXZWMjcOADw8PLSznp6eotpNmjTRzkrm+imltHJ8BkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERdXYUT1ZWFpyc9PqjZJSIdCRHcXGxdvbIkSOi2rqjhgAgNTVVVFuSDw0NFdWuTa1atRLl+/fvr53dv3+/qPbs2bO1s1OmTBHVrkskI4o+/vhjUe3c3FztrLu7u6h2t27dtLPffvutqLZktA4A+Pv7a2fbtGkjqv39999rZyWjdQCgffv22lnJ44ejeIiIqE5jAyIiIiNEDSg6Ohp9+vSBl5cXmjdvjvvuuw/JyckOmStXriAqKgq+vr7w9PTExIkTkZmZWaOLJiKi+k/UgGJjYxEVFYX4+Hh8//33KCkpwahRo5Cfn2/PPPbYY/jyyy+xbt06xMbG4uzZs5gwYUKNL5yIiOo30UEI176Rt3r1ajRv3hwJCQkYPHgwcnNz8f777yMmJgbDhw8HAKxatQqdOnVCfHx8lW8YFxUVOXyvR15eXnW2g4iI6plbeg+o4ggXHx8fAEBCQgJKSkowcuRIe6Zjx44ICQlBXFxclTWio6Nhs9nsp+Dg4FtZEhER1RPVbkDl5eWYP38+Bg4ciK5duwIAMjIy4OrqWulQQH9/f2RkZFRZZ+HChcjNzbWfpN/8SURE9VO1PwcUFRWFQ4cOYffu3be0AKvVCqvVeks1iIio/qnWM6C5c+di8+bN2L59u8MHtgICAlBcXIycnByHfGZmJgICAm5poURE1LCIGpBSCnPnzsWGDRvwww8/VPoEfXh4OFxcXLBt2zb7ecnJyTh16hQiIiJqZsVERNQgiF6Ci4qKQkxMDDZt2gQvLy/7+zo2mw3u7u6w2WyYMWMGFixYAB8fH3h7e+PRRx9FRESEaGQKERE1fKIGtHLlSgDA0KFDHc5ftWoVpk+fDgB4/fXX4eTkhIkTJ6KoqAijR4/GihUrxAvz8/PTnpWWnZ2tXVcy202a79Wrl6j22bNntbPr168X1a44DL6ha9q0qXZWdz5VhXHjxmlnpXPM6pILFy5oZyW3NwB4eXlpZ693pOz1SB5v0hmQFotFlO/UqZN2duvWraLa7dq1085KZtIBEB30Jf3bqUPUgHQewG5ubli+fDmWL19e7UUREVHDx1lwRERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZES1v46htnl4eGiP4vH19dWue73vJboeyRRv6agXybiPzMxMUe2CggJRvr7q0qWLdlY6ELc2Ro/cDocOHRLlT5w4oZ2Vfv1Ko0b6f2Kk46POnDmjnZXuyz59+ojyycnJ2lnp189UfOGnjj179ohqS/5mSdahlMLFixdvmuMzICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPq7Cy48vJy7VlpKSkp2nUl86MAIDg4WDtbUlIiqi2ZT3X+/HlR7b59+4ry9ZWLi4t2VjLXDwB69+4tXU6dkJSUJMp//fXX2tmOHTuKajdu3Fg7Gx8fL6rt5uamnc3NzRXVHjRokCh/7Ngx7Wx2draodn5+vna2ZcuWotr+/v7aWS8vL+1saWkpdu3addMcnwEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkhEUppUwv4mp5eXmw2WxwdXXVHsXTokUL7fq6NStIxuX4+vqKal+5ckU7m56eLqo9adIk7ew777wjql1fJScni/JhYWG1tBI5ycN0zpw5otpr167Vzubk5IhqSx6brVu3FtW+ePGidra0tFRU28/PT5SXjPhydnYW1fb29tbOJiYmimp7eHhoZyUjgSr+jufm5t5w/XwGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZEQj0wu4nt69e6NRI73l/fzzz9p1JfPXAMBms2ln09LSRLUls8Yk86AA4LffftPOnj59WlS7ZcuWonxdUZdmu0m98sor2tnc3FxR7Xbt2mlnu3TpIqp98OBB7WxKSoqotpeXl3ZWOttN+liWzGqUzqXr2bOndnbw4MGi2m5ubtrZ/v37a2d1t5HPgIiIyAhRA4qOjkafPn3g5eWF5s2b47777qs0YXjo0KGwWCwOp9mzZ9fooomIqP4TNaDY2FhERUUhPj4e33//PUpKSjBq1KhKY7pnzpyJ9PR0+2nJkiU1umgiIqr/RO8Bffvttw4/r169Gs2bN0dCQoLDa48eHh4ICAiomRUSEVGDdEvvAVW82enj4+Nw/ieffAI/Pz907doVCxcuREFBwXVrFBUVIS8vz+FEREQNX7WPgisvL8f8+fMxcOBAdO3a1X7+gw8+iFatWiEoKAhJSUn429/+huTkZHzxxRdV1omOjsaiRYuquwwiIqqnqt2AoqKicOjQIezevdvh/FmzZtn/3a1bNwQGBmLEiBE4fvw42rZtW6nOwoULsWDBAvvPeXl5CA4Oru6yiIionqhWA5o7dy42b96MnTt33vQzIf369QPw+zH+VTUgq9UKq9VanWUQEVE9JmpASik8+uij2LBhA3bs2IHQ0NCb/k5iYiIAIDAwsFoLJCKihknUgKKiohATE4NNmzbBy8sLGRkZAH6fFuDu7o7jx48jJiYG99xzD3x9fZGUlITHHnsMgwcPRvfu3WtlA4iIqH4SNaCVK1cC+P3DpldbtWoVpk+fDldXV2zduhXLli1Dfn4+goODMXHiRDzzzDM1tmAiImoYxC/B3UhwcDBiY2NvaUEVUlJS4OSkd5R4+/bttev+9NNPonVIaksPIbdYLNrZxo0bi2pL1p2UlCSqXV9nwdUlktlhAPDNN99oZytemdB15swZ7eyRI0dEtfv06aOd1Z39WOHChQu1VjskJESULy8v185K59JVvI2hw9nZWVRbMtvv7Nmz2lnd24Oz4IiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICDYgIiIygg2IiIiMYAMiIiIj2ICIiMgINiAiIjKi2t8HVNvc3d21R/HcbETQ1cLDw0XryMrK0s76+vqKap8+fVo7e+7cOVHtJk2aaGf37Nkjqn3PPfeI8lRZSkqKKH/s2DHtrM6U+qtJRqxIRrcAsjE/0ttkwIAB2lnJ2B7g/3+NjK4ff/xRO5uZmSmqLRnDJd33v/32m3bW09NTO8tRPEREVKexARERkRFsQEREZAQbEBERGcEGRERERrABERGREWxARERkBBsQEREZwQZERERGsAEREZERbEBERGREnZ0Fl5OTA4vFopV1dnbWrhsUFCRah2QmVHZ2tqi2ZE6WZBsB4Ouvv9bO5ufni2rTrfvqq69E+aZNm2pnpfuzuLhYO7tv3z5R7RYtWmhnpXPm8vLytLMeHh6i2hs3bhTlvb29tbPSeW2FhYXaWavVKqqtO7MNkM3T053PyWdARERkBBsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGVFnR/F06tQJjRrpLU8yTiItLU20Dnd3d+2sZB0A0Lx5c+3sxYsXRbVHjhypnc3NzRXVpsp2794tyq9du1aUl4xBCQ8PF9XWfZwBQN++fUW1jx07pp2VjhDq2LGjdvbSpUui2h06dBDlJaN+SkpKRLUlt0tCQoKots1m0866ublpZ5VSWn+z+AyIiIiMYAMiIiIj2ICIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjIiDo7C85iscBisWhli4uLteueOHFCtI6hQ4dqZzMyMkS1i4qKtLNDhgwR1S4rK9POJiYmimr36tVLlM/MzNTO5uXliWq3a9dOO3v69GlR7aysLO3spEmTRLVdXV1FeWdnZ+3srl27RLUbN26snfXy8hLVlux76W1y+fJl7WxpaamotuR+Bcgey5LHJgAcP35cOyuZ6wfIZl3GxMRoZ/Pz8zF27Nib5vgMiIiIjBA1oJUrV6J79+7w9vaGt7c3IiIi8M0339gvv3LlCqKiouDr6wtPT09MnDhR9H9ARER05xA1oJYtW+Lll19GQkIC9u/fj+HDh2P8+PE4fPgwAOCxxx7Dl19+iXXr1iE2NhZnz57FhAkTamXhRERUv4leMLz2Nb3//d//xcqVKxEfH4+WLVvi/fffR0xMDIYPHw4AWLVqFTp16oT4+Hj079+/5lZNRET1XrXfAyorK8OaNWuQn5+PiIgIJCQkoKSkxOGL0Dp27IiQkBDExcVdt05RURHy8vIcTkRE1PCJG9DPP/8MT09PWK1WzJ49Gxs2bEDnzp2RkZEBV1dXNGnSxCHv7+9/w6PDoqOjYbPZ7Kfg4GDxRhARUf0jbkBhYWFITEzE3r17MWfOHEybNg1Hjhyp9gIWLlyI3Nxc+0n6ldlERFQ/iT8H5Orqaj9GPjw8HD/99BPeeOMNTJo0CcXFxcjJyXF4FpSZmYmAgIDr1rNarbBarfKVExFRvXbLnwMqLy9HUVERwsPD4eLigm3bttkvS05OxqlTpxAREXGrV0NERA2M6BnQwoULERkZiZCQEFy6dAkxMTHYsWMHtmzZApvNhhkzZmDBggXw8fGBt7c3Hn30UURERPAIOCIiqkTUgM6dO4c//elPSE9Ph81mQ/fu3bFlyxb84Q9/AAC8/vrrcHJywsSJE1FUVITRo0djxYoV1VpYfn6+9viRQ4cOaddt3769aB3Hjh3Tzl57AMbNNG3aVDu7Z88eUW3J6Jbw8HBR7YSEBFE+KChIOyu5TQDZaKVOnTqJao8ePVo7261bN1Htb7/9VpQPDQ3VzjZv3lxUuzZHJUnG60hvQwnJ4xgATp48Kcr7+vpqZ6X7x8/PTzvr7+8vqi3527lkyRLtrO7oI1EDev/99294uZubG5YvX47ly5dLyhIR0R2Is+CIiMgINiAiIjKCDYiIiIxgAyIiIiPYgIiIyAg2ICIiMoINiIiIjGADIiIiI9iAiIjICPE07NqmlALw+xfeSX9HR3l5uWg9ktEjknVI1yKtLcnrjs2o7lok+9JisdTaWqTbKclL1y0daSO5r0hub6Du3Fek666tdQDyvxOStUtvw9rc9xKSdVdkb3a7W5R0z9Sy06dP80vpiIgagLS0NLRs2fK6l9e5BlReXo6zZ8/Cy8vL4f8q8/LyEBwcjLS0NHh7extcYe3idjYcd8I2AtzOhqYmtlMphUuXLiEoKAhOTtd/p6fOvQTn5OR0w47p7e3doHd+BW5nw3EnbCPA7WxobnU7bTbbTTM8CIGIiIxgAyIiIiPqTQOyWq14/vnnYbVaTS+lVnE7G447YRsBbmdDczu3s84dhEBERHeGevMMiIiIGhY2ICIiMoINiIiIjGADIiIiI9iAiIjIiHrTgJYvX47WrVvDzc0N/fr1w759+0wvqUa98MILsFgsDqeOHTuaXtYt2blzJ8aOHYugoCBYLBZs3LjR4XKlFJ577jkEBgbC3d0dI0eOxLFjx8ws9hbcbDunT59ead+OGTPGzGKrKTo6Gn369IGXlxeaN2+O++67D8nJyQ6ZK1euICoqCr6+vvD09MTEiRORmZlpaMXVo7OdQ4cOrbQ/Z8+ebWjF1bNy5Up0797dPu0gIiIC33zzjf3y27Uv60UDWrt2LRYsWIDnn38eBw4cQI8ePTB69GicO3fO9NJqVJcuXZCenm4/7d692/SSbkl+fj569OiB5cuXV3n5kiVL8Oabb+Ltt9/G3r170bhxY4wePRpXrly5zSu9NTfbTgAYM2aMw7799NNPb+MKb11sbCyioqIQHx+P77//HiUlJRg1ahTy8/Ptmcceewxffvkl1q1bh9jYWJw9exYTJkwwuGo5ne0EgJkzZzrszyVLlhhacfW0bNkSL7/8MhISErB//34MHz4c48ePx+HDhwHcxn2p6oG+ffuqqKgo+89lZWUqKChIRUdHG1xVzXr++edVjx49TC+j1gBQGzZssP9cXl6uAgIC1Kuvvmo/LycnR1mtVvXpp58aWGHNuHY7lVJq2rRpavz48UbWU1vOnTunAKjY2Fil1O/7zsXFRa1bt86e+eWXXxQAFRcXZ2qZt+za7VRKqSFDhqi//OUv5hZVS5o2bar+7//+77buyzr/DKi4uBgJCQkYOXKk/TwnJyeMHDkScXFxBldW844dO4agoCC0adMGU6dOxalTp0wvqdakpqYiIyPDYb/abDb069evwe1XANixYweaN2+OsLAwzJkzB9nZ2aaXdEtyc3MBAD4+PgCAhIQElJSUOOzPjh07IiQkpF7vz2u3s8Inn3wCPz8/dO3aFQsXLkRBQYGJ5dWIsrIyrFmzBvn5+YiIiLit+7LOTcO+VlZWFsrKyuDv7+9wvr+/P44ePWpoVTWvX79+WL16NcLCwpCeno5FixZh0KBBOHToELy8vEwvr8ZlZGQAQJX7teKyhmLMmDGYMGECQkNDcfz4cTz99NOIjIxEXFwcnJ2dTS9PrLy8HPPnz8fAgQPRtWtXAL/vT1dXVzRp0sQhW5/3Z1XbCQAPPvggWrVqhaCgICQlJeFvf/sbkpOT8cUXXxhcrdzPP/+MiIgIXLlyBZ6entiwYQM6d+6MxMTE27Yv63wDulNERkba/929e3f069cPrVq1wmeffYYZM2YYXBndqsmTJ9v/3a1bN3Tv3h1t27bFjh07MGLECIMrq56oqCgcOnSo3r9HeTPX285Zs2bZ/92tWzcEBgZixIgROH78ONq2bXu7l1ltYWFhSExMRG5uLj7//HNMmzYNsbGxt3UNdf4lOD8/Pzg7O1c6AiMzMxMBAQGGVlX7mjRpgg4dOiAlJcX0UmpFxb670/YrALRp0wZ+fn71ct/OnTsXmzdvxvbt2x2+tysgIADFxcXIyclxyNfX/Xm97axKv379AKDe7U9XV1e0a9cO4eHhiI6ORo8ePfDGG2/c1n1Z5xuQq6srwsPDsW3bNvt55eXl2LZtGyIiIgyurHZdvnwZx48fR2BgoOml1IrQ0FAEBAQ47Ne8vDzs3bu3Qe9X4Pevnc/Ozq5X+1Yphblz52LDhg344YcfEBoa6nB5eHg4XFxcHPZncnIyTp06Va/25822syqJiYkAUK/2Z1XKy8tRVFR0e/dljR7SUEvWrFmjrFarWr16tTpy5IiaNWuWatKkicrIyDC9tBrz+OOPqx07dqjU1FT1448/qpEjRyo/Pz917tw500urtkuXLqmDBw+qgwcPKgBq6dKl6uDBg+rkyZNKKaVefvll1aRJE7Vp0yaVlJSkxo8fr0JDQ1VhYaHhlcvcaDsvXbqknnjiCRUXF6dSU1PV1q1bVe/evVX79u3VlStXTC9d25w5c5TNZlM7duxQ6enp9lNBQYE9M3v2bBUSEqJ++OEHtX//fhUREaEiIiIMrlruZtuZkpKiFi9erPbv369SU1PVpk2bVJs2bdTgwYMNr1zmqaeeUrGxsSo1NVUlJSWpp556SlksFvXdd98ppW7fvqwXDUgppd566y0VEhKiXF1dVd++fVV8fLzpJdWoSZMmqcDAQOXq6qpatGihJk2apFJSUkwv65Zs375dAah0mjZtmlLq90Oxn332WeXv76+sVqsaMWKESk5ONrvoarjRdhYUFKhRo0apZs2aKRcXF9WqVSs1c+bMevc/T1VtHwC1atUqe6awsFA98sgjqmnTpsrDw0Pdf//9Kj093dyiq+Fm23nq1Ck1ePBg5ePjo6xWq2rXrp3661//qnJzc80uXOjhhx9WrVq1Uq6urqpZs2ZqxIgR9uaj1O3bl/w+ICIiMqLOvwdEREQNExsQEREZwQZERERGsAEREZERbEBERGQEGxARERnBBkREREawARERkRFsQEREZAQbEBERGcEGRERERvw/Uh96JU04npoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_point = 14\n",
    "plot_images(X_train[data_point], f\"Training Label: {np.argmax(y_train[data_point])}\")\n",
    "plot_images(X_test[data_point], f\"Testing Label: {np.argmax(y_test[data_point])}\")\n",
    "plot_images(X_val[data_point], f\"Validation Label: {np.argmax(y_val[data_point])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1977e-01, -4.6321e-01, -1.1619e-01, -3.5213e-01,  2.9254e-01,\n",
      "         -1.1731e-01,  1.6064e-01, -1.9959e-01,  4.3162e-01, -3.1179e-01,\n",
      "          1.0710e-01, -2.9522e-01,  1.6489e-02,  5.9222e-01, -1.3422e-02,\n",
      "          2.5963e-01, -5.0496e-01,  3.1828e-04,  7.9348e-01,  3.3878e-01,\n",
      "         -2.1540e-01]], device='cuda:0', grad_fn=<AddmmBackward0>) tensor([[-1.0081, -0.5935,  0.4110,  0.4287, -0.5451,  0.4829,  0.5080,  0.1244,\n",
      "         -0.9110, -1.1962, -0.0795, -0.1815, -0.0031, -0.4172,  0.9496,  0.4046,\n",
      "          0.7607,  0.4041,  0.0348,  0.2260, -0.3511]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dims, n_outputs, p_dropout=0.20, save_dir=\"./models\"):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        activation = nn.ReLU()\n",
    "        dropout = nn.AlphaDropout(p=p_dropout)\n",
    "\n",
    "        # Define layers with expected sizes\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, input_dims[0], kernel_size=3, padding=1),  # Input shape: (1, 32, 32)\n",
    "            activation,\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output shape: (32, 16, 16)\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # Output shape: (64, 16, 16)\n",
    "            activation,\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output shape: (64, 8, 8)\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=64 * 8 * 8, out_features=1024),\n",
    "            activation,\n",
    "            dropout,\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            activation,\n",
    "            dropout,\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            activation,\n",
    "            dropout,\n",
    "            nn.Linear(in_features=256, out_features=n_outputs),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        logits = self.network(X)\n",
    "        return logits\n",
    "\n",
    "    def save(self, name):\n",
    "        T.save(self.state_dict(), f\"{self.save_dir}/{name}.pth\")\n",
    "\n",
    "    def load(self, name):\n",
    "        self.load_state_dict(T.load(f\"{self.save_dir}/{name}.pth\"))\n",
    "\n",
    "\n",
    "# Adjust dimensions for input and output\n",
    "n_inputs = [32, 32]  # Width and height of the input image\n",
    "n_outputs = 21  # Number of output classes\n",
    "\n",
    "# Move a tensor to the GPU\n",
    "device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model\n",
    "model_1 = NeuralNetwork(input_dims=n_inputs, n_outputs=n_outputs, p_dropout=0.2).to(device)\n",
    "model_2 = NeuralNetwork(input_dims=n_inputs, n_outputs=n_outputs, p_dropout=0.2).to(device)\n",
    "\n",
    "dummy_image = T.rand(size=[1, 1, n_inputs[0], n_inputs[1]]).to(device)  # Dummy image tensor\n",
    "pred_1 = model_1(dummy_image)\n",
    "pred_2 = model_2(dummy_image)\n",
    "\n",
    "print(pred_1, pred_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(nn.Module):\n",
    "    def __init__(self, model_1, model_2, n_inputs, n_outputs, save_dir=\"./models\"):\n",
    "        super(Ensemble, self).__init__()\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.model_1 = model_1\n",
    "        self.model_2 = model_2\n",
    "\n",
    "        activation = nn.ReLU()\n",
    "        dropout = nn.Dropout(p=0.4)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            activation,\n",
    "            nn.Linear(in_features=n_inputs, out_features=256),\n",
    "            activation,\n",
    "            dropout,\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            activation,\n",
    "            dropout,\n",
    "            nn.Linear(in_features=128, out_features=n_outputs)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_1 = self.model_1(x.clone())\n",
    "        x_2 = self.model_2(x.clone())\n",
    "\n",
    "        x = T.cat([x_1, x_2], dim=1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "    \n",
    "    def save(self, name):\n",
    "        T.save(self.state_dict(), f\"{self.save_dir}/{name}.pth\")\n",
    "\n",
    "    def load(self, name):\n",
    "        self.load_state_dict(T.load(f\"{self.save_dir}/{name}.pth\"))\n",
    "\n",
    "\n",
    "model_1.save_dir = \"./models\"\n",
    "model_2.save_dir = \"./models\"\n",
    "\n",
    "#Freeze these models \n",
    "model_1.load(\"Conv-NeuralNetwork-Image Dataset-1_acc-80.00_loss-0.000001\")\n",
    "for param in model_1.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "model_2.load(\"Conv-NeuralNetwork-Image Dataset-2_acc-80.19_loss-0.000001\")\n",
    "for param in model_2.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "model = Ensemble(model_1, model_2, 42, 21).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, cohen_kappa_score\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, X_val, y_val, criterion):\n",
    "    size = len(y_val)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with T.no_grad():\n",
    "        X = T.from_numpy(X_val).to(T.float32).to(device)\n",
    "        y_true = T.Tensor(y_val).to(T.float).to(device)\n",
    "\n",
    "        logits = model.forward(X)\n",
    "\n",
    "        loss = criterion(logits, y_true)\n",
    "\n",
    "        y_pred = logits.argmax(1).cpu().numpy()\n",
    "        y_true = y_true.argmax(1).cpu().numpy()\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, average='macro')\n",
    "        recall = recall_score(y_true, y_pred, average='macro')\n",
    "        roc_auc = roc_auc_score(y_true, F.softmax(logits, dim=1).cpu().numpy(), multi_class='ovo')\n",
    "        cohen_kappa = cohen_kappa_score(y_true, y_pred)\n",
    "        \n",
    "        loss /= size\n",
    "        \n",
    "        print(f\"Validation Metrics: \\n Accuracy: {100 * accuracy:>0.2f}%, Precision: {precision:>0.4f}, Recall: {recall:>0.4f}, ROC AUC: {roc_auc:>0.4f}, Cohen Kappa: {cohen_kappa:>0.4f}, Avg loss: {loss:>8f}\")\n",
    "    \n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, criterion, optimizer):\n",
    "    size = len(X_train)\n",
    "    batch_size = 141\n",
    "\n",
    "    #Prevents model from memorizing the position of data\n",
    "    indices = np.random.randint(0, size, size)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i in range(size//batch_size):\n",
    "        start = batch_size * i\n",
    "        end = start + batch_size\n",
    "\n",
    "        X = T.from_numpy(X_train[indices[start:end]]).to(T.float32).to(device)\n",
    "        y_true = T.Tensor(y_train[indices[start:end]]).to(T.float).to(device)\n",
    "\n",
    "        logits = model.forward(X)\n",
    "        \n",
    "        loss = criterion(logits, y_true)\n",
    "\n",
    "        # Gradiant Descent using Adam optimizer for best performance\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = (logits.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "        accuracy = correct/batch_size\n",
    "\n",
    "        if (i * batch_size) % 564 == 0:\n",
    "            loss, current = loss.item(), (i + 1) * batch_size\n",
    "            print(f\"Accuracy: {(100 * (accuracy)):>0.1f}%, Loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Accuracy: 7.1%, Loss: 4.143784 [  141/ 5250]\n",
      "Accuracy: 3.5%, Loss: 4.099166 [  705/ 5250]\n",
      "Accuracy: 5.0%, Loss: 4.145131 [ 1269/ 5250]\n",
      "Accuracy: 5.7%, Loss: 3.792129 [ 1833/ 5250]\n",
      "Accuracy: 11.3%, Loss: 3.389846 [ 2397/ 5250]\n",
      "Accuracy: 14.9%, Loss: 3.211211 [ 2961/ 5250]\n",
      "Accuracy: 12.8%, Loss: 3.066962 [ 3525/ 5250]\n",
      "Accuracy: 14.9%, Loss: 2.948876 [ 4089/ 5250]\n",
      "Accuracy: 17.7%, Loss: 2.764198 [ 4653/ 5250]\n",
      "Accuracy: 22.7%, Loss: 2.734777 [ 5217/ 5250]\n",
      "Finished training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics: \n",
      " Accuracy: 55.33%, Precision: 0.5681, Recall: 0.5489, ROC AUC: 0.9263,  Avg loss: 0.001564\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Accuracy: 21.3%, Loss: 2.783886 [  141/ 5250]\n",
      "Accuracy: 24.8%, Loss: 2.628974 [  705/ 5250]\n",
      "Accuracy: 27.7%, Loss: 2.381369 [ 1269/ 5250]\n",
      "Accuracy: 34.8%, Loss: 2.318147 [ 1833/ 5250]\n",
      "Accuracy: 39.7%, Loss: 2.161101 [ 2397/ 5250]\n",
      "Accuracy: 33.3%, Loss: 2.211359 [ 2961/ 5250]\n",
      "Accuracy: 41.8%, Loss: 2.127930 [ 3525/ 5250]\n",
      "Accuracy: 39.0%, Loss: 2.113221 [ 4089/ 5250]\n",
      "Accuracy: 51.8%, Loss: 1.820678 [ 4653/ 5250]\n",
      "Accuracy: 55.3%, Loss: 1.701710 [ 5217/ 5250]\n",
      "Finished training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics: \n",
      " Accuracy: 75.81%, Precision: 0.7358, Recall: 0.7579, ROC AUC: 0.9634,  Avg loss: 0.000958\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Accuracy: 47.5%, Loss: 1.805533 [  141/ 5250]\n",
      "Accuracy: 58.2%, Loss: 1.687569 [  705/ 5250]\n",
      "Accuracy: 55.3%, Loss: 1.723815 [ 1269/ 5250]\n",
      "Accuracy: 58.2%, Loss: 1.574065 [ 1833/ 5250]\n",
      "Accuracy: 68.1%, Loss: 1.422697 [ 2397/ 5250]\n",
      "Accuracy: 63.8%, Loss: 1.459132 [ 2961/ 5250]\n",
      "Accuracy: 66.0%, Loss: 1.490637 [ 3525/ 5250]\n",
      "Accuracy: 70.2%, Loss: 1.474634 [ 4089/ 5250]\n",
      "Accuracy: 68.8%, Loss: 1.459722 [ 4653/ 5250]\n",
      "Accuracy: 72.3%, Loss: 1.257228 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7951, Recall: 0.7941, ROC AUC: 0.9665,  Avg loss: 0.000943\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Accuracy: 67.4%, Loss: 1.396408 [  141/ 5250]\n",
      "Accuracy: 73.0%, Loss: 1.150602 [  705/ 5250]\n",
      "Accuracy: 72.3%, Loss: 1.267125 [ 1269/ 5250]\n",
      "Accuracy: 72.3%, Loss: 1.279743 [ 1833/ 5250]\n",
      "Accuracy: 78.0%, Loss: 1.050426 [ 2397/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.973150 [ 2961/ 5250]\n",
      "Accuracy: 78.7%, Loss: 1.150021 [ 3525/ 5250]\n",
      "Accuracy: 79.4%, Loss: 1.011589 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.826461 [ 4653/ 5250]\n",
      "Accuracy: 74.5%, Loss: 1.140053 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7975, Recall: 0.7959, ROC AUC: 0.9678,  Avg loss: 0.001047\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss: 0.956240 [  141/ 5250]\n",
      "Accuracy: 80.1%, Loss: 1.044953 [  705/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.933729 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.851704 [ 1833/ 5250]\n",
      "Accuracy: 80.1%, Loss: 0.988651 [ 2397/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.962669 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.657323 [ 3525/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.903225 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.811405 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.764903 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8048, Recall: 0.8016, ROC AUC: 0.9684,  Avg loss: 0.001172\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss: 1.004885 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.772128 [  705/ 5250]\n",
      "Accuracy: 80.1%, Loss: 0.886434 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.744430 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.828683 [ 2397/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.890731 [ 2961/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.867231 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.869081 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.619872 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.769798 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8017, Recall: 0.7987, ROC AUC: 0.9687,  Avg loss: 0.001281\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.693617 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.711339 [  705/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.892317 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.649707 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.696148 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.716336 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.798547 [ 3525/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.952803 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.627233 [ 4653/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.772088 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8028, Recall: 0.7996, ROC AUC: 0.9691,  Avg loss: 0.001368\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.660459 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.720567 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.737040 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.780434 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.768086 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.599724 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.738211 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.760890 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.713179 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.603851 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8035, Recall: 0.8005, ROC AUC: 0.9691,  Avg loss: 0.001439\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.788536 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.726229 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.555468 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.590308 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.717279 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.471387 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.644142 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.594899 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.580801 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.490695 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8049, Recall: 0.8016, ROC AUC: 0.9693,  Avg loss: 0.001491\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.694597 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.794315 [  705/ 5250]\n",
      "Accuracy: 79.4%, Loss: 0.899667 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.695549 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.563078 [ 2397/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.870113 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.679699 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.800382 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.616480 [ 4653/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.834474 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8059, Recall: 0.8025, ROC AUC: 0.9694,  Avg loss: 0.001538\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.619303 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.569663 [  705/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.916071 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.698050 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.640543 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.745583 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.639051 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.694669 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.563398 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.626532 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8066, Recall: 0.8035, ROC AUC: 0.9695,  Avg loss: 0.001571\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.559237 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.763076 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.487977 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.768181 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.643726 [ 2397/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.905305 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.560369 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.543278 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.774845 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.552451 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8065, Recall: 0.8035, ROC AUC: 0.9696,  Avg loss: 0.001600\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss: 0.793650 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.755501 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.382785 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.475551 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.736677 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.632893 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.507976 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.699300 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.599546 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.640894 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8044, Recall: 0.8014, ROC AUC: 0.9697,  Avg loss: 0.001621\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.722811 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.429886 [  705/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.741291 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.746047 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.883768 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.681517 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.705861 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.502680 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.540959 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.578113 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8059, Recall: 0.8026, ROC AUC: 0.9698,  Avg loss: 0.001642\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss: 0.760848 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.736972 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.691795 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.585772 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.729239 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.509181 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.680848 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.766212 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.627445 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.410154 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8056, Recall: 0.8023, ROC AUC: 0.9697,  Avg loss: 0.001645\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.592770 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.630521 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.540986 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.593280 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.810131 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.647726 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.492945 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.692078 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.432156 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.525422 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8035, Recall: 0.8002, ROC AUC: 0.9697,  Avg loss: 0.001658\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.399851 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.728528 [  705/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.830135 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.538924 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.669297 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.600474 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.699299 [ 3525/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.815293 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.485172 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.616707 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8033, Recall: 0.8003, ROC AUC: 0.9697,  Avg loss: 0.001671\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.542295 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.527231 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.626787 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.588211 [ 1833/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.814470 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.423233 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.566952 [ 3525/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.787524 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.636756 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.645285 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8045, Recall: 0.8013, ROC AUC: 0.9698,  Avg loss: 0.001682\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.468852 [  141/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.347744 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.678375 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.624536 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.638097 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.620144 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.656260 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.632746 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.379246 [ 4653/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.791193 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8044, Recall: 0.8013, ROC AUC: 0.9699,  Avg loss: 0.001679\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.433207 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.510078 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.535774 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.475056 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.483845 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.577191 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.573218 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.460065 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.592081 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.528250 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8034, Recall: 0.8002, ROC AUC: 0.9699,  Avg loss: 0.001689\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.619568 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.565114 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.599873 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.419192 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.457851 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.639900 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.702261 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.490608 [ 4089/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.888495 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.526238 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8049, Recall: 0.8022, ROC AUC: 0.9700,  Avg loss: 0.001704\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.668437 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.539267 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.482750 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.590310 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.432716 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.479669 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.478089 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.554980 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.439262 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.762500 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8024, Recall: 0.7996, ROC AUC: 0.9701,  Avg loss: 0.001703\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.605246 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.704548 [  705/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.713235 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.535557 [ 1833/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.919380 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.476711 [ 2961/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.835743 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.616740 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.698210 [ 4653/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.677211 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8031, Recall: 0.8003, ROC AUC: 0.9699,  Avg loss: 0.001699\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.603798 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.641205 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.678750 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.751167 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.475033 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.604673 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.531372 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.545025 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.831867 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.585582 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8012, Recall: 0.7985, ROC AUC: 0.9700,  Avg loss: 0.001689\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.622816 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.499531 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.536413 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.433058 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.565875 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.636168 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.391217 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.482368 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.403448 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.471727 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8013, Recall: 0.7985, ROC AUC: 0.9699,  Avg loss: 0.001687\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.695534 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.601318 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.502322 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.475915 [ 1833/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.809123 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.491270 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.477159 [ 3525/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.300773 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.703202 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.591887 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8055, Recall: 0.8023, ROC AUC: 0.9700,  Avg loss: 0.001699\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.607154 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.657189 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.586661 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.717862 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.684430 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.483520 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.453717 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.534782 [ 4089/ 5250]\n",
      "Accuracy: 79.4%, Loss: 1.000924 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.527847 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8049, Recall: 0.8013, ROC AUC: 0.9701,  Avg loss: 0.001696\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.371431 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.558337 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.534819 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.672017 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.538227 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.495908 [ 2961/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.343911 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.599507 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.601735 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.529414 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8050, Recall: 0.8011, ROC AUC: 0.9700,  Avg loss: 0.001690\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.485268 [  141/ 5250]\n",
      "Accuracy: 80.1%, Loss: 0.937043 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.532210 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.518266 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.553873 [ 2397/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.693591 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.445170 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.699592 [ 4089/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.881647 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.477677 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8052, Recall: 0.8013, ROC AUC: 0.9702,  Avg loss: 0.001692\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.490866 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.524959 [  705/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.774127 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.505316 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.579195 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.363537 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.605670 [ 3525/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.779987 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.593971 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.547129 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8062, Recall: 0.8023, ROC AUC: 0.9702,  Avg loss: 0.001690\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.389005 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.339835 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.509947 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.584756 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.413451 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.391235 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.579858 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.581350 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.384737 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.593179 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8060, Recall: 0.8024, ROC AUC: 0.9703,  Avg loss: 0.001682\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.578734 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.678495 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.608436 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.544270 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.617452 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.453699 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.671175 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.543092 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.476655 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.415594 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8069, Recall: 0.8033, ROC AUC: 0.9704,  Avg loss: 0.001685\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.660574 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.687110 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.522587 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.760560 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.626269 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.641891 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.465244 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.391273 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.418216 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.303715 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8057, Recall: 0.8024, ROC AUC: 0.9704,  Avg loss: 0.001679\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss: 0.759013 [  141/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.775350 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.500417 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.623914 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.701809 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.492342 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.525064 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.710943 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.578075 [ 4653/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.872353 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8057, Recall: 0.8030, ROC AUC: 0.9705,  Avg loss: 0.001675\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss: 0.812236 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.581731 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.615270 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.792117 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.657284 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.551360 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.703688 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.571532 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.504453 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.719061 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8064, Recall: 0.8031, ROC AUC: 0.9705,  Avg loss: 0.001658\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss: 0.865208 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.552254 [  705/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.841831 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.563212 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.655026 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.281601 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.487789 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.599937 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.476796 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.609268 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8081, Recall: 0.8041, ROC AUC: 0.9704,  Avg loss: 0.001654\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.588543 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.660168 [  705/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.269697 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.583915 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.533661 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.435391 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.527463 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.504857 [ 4089/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.401337 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.664301 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8043, Recall: 0.8012, ROC AUC: 0.9704,  Avg loss: 0.001674\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.475919 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.481434 [  705/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.753085 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.490998 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.367074 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.465113 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.460486 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.442930 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.485107 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.608011 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8039, Recall: 0.8005, ROC AUC: 0.9704,  Avg loss: 0.001689\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.486063 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.596025 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.578444 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.443476 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.449349 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.615923 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.601195 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.469194 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.681590 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.754358 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8024, Recall: 0.7995, ROC AUC: 0.9705,  Avg loss: 0.001667\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.600548 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.334256 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.597027 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.586545 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.548595 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.618387 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.590364 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.653215 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.682064 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.347792 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8029, Recall: 0.8003, ROC AUC: 0.9706,  Avg loss: 0.001641\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.681536 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.481302 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.514470 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.545977 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.589270 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.612254 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.577536 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.423398 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.485930 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.472534 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8037, Recall: 0.8012, ROC AUC: 0.9706,  Avg loss: 0.001647\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.683961 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.605135 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.568131 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.375911 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.463037 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.475955 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.523508 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.673402 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.412540 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.423670 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8043, Recall: 0.8013, ROC AUC: 0.9707,  Avg loss: 0.001650\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.374383 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.466400 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.399809 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.530948 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.735407 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.624225 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.404095 [ 3525/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.321523 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.614652 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.533456 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8041, Recall: 0.8013, ROC AUC: 0.9707,  Avg loss: 0.001646\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.466861 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.591927 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.615861 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.604876 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.425621 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.521144 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.526753 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.424476 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.616852 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.621199 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8061, Recall: 0.8032, ROC AUC: 0.9707,  Avg loss: 0.001651\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.496266 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.506108 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.705517 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.518744 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.512111 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.499019 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.446864 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.530936 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.378373 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.535585 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8065, Recall: 0.8033, ROC AUC: 0.9707,  Avg loss: 0.001635\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.561004 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.631865 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.419161 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.683814 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.528529 [ 2397/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.700573 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.521497 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.395052 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.407993 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.580152 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8042, Recall: 0.8012, ROC AUC: 0.9708,  Avg loss: 0.001626\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.449698 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.633417 [  705/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.772876 [ 1269/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.880014 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.535214 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.596933 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.430087 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.622187 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.539892 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.607273 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8052, Recall: 0.8022, ROC AUC: 0.9708,  Avg loss: 0.001639\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.458596 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.550188 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.436269 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.545369 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.697797 [ 2397/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.758928 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.493223 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.529685 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.608684 [ 4653/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.679467 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8046, Recall: 0.8022, ROC AUC: 0.9708,  Avg loss: 0.001640\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.401723 [  141/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.857359 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.562762 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.545754 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.534607 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.520281 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.599769 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.691820 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.346295 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.414486 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8048, Recall: 0.8022, ROC AUC: 0.9709,  Avg loss: 0.001621\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.566801 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.593828 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.690352 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.551999 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.391850 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.569591 [ 2961/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.772339 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.711641 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.628341 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.696207 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8028, Recall: 0.8004, ROC AUC: 0.9710,  Avg loss: 0.001616\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Accuracy: 94.3%, Loss: 0.335075 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.712606 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.530301 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.562106 [ 1833/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.717307 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.558586 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.559372 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.507325 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.455108 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.578777 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8049, Recall: 0.8023, ROC AUC: 0.9709,  Avg loss: 0.001619\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.496134 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.650415 [  705/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.310837 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.690119 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.602321 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.385190 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.350322 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.600688 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.436473 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.536211 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8054, Recall: 0.8024, ROC AUC: 0.9708,  Avg loss: 0.001632\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.480656 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.527214 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.634061 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.377231 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.435697 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.580799 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.496642 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.616496 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.537780 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.468666 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8074, Recall: 0.8040, ROC AUC: 0.9709,  Avg loss: 0.001637\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.476375 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.526757 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.686481 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.569973 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.510477 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.363079 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.409107 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.781373 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.339783 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.618875 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.57%, Precision: 0.8084, Recall: 0.8050, ROC AUC: 0.9709,  Avg loss: 0.001659\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.483025 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.553579 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.428045 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.406606 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.560923 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.485671 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.416200 [ 3525/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.634192 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.675065 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.633910 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8078, Recall: 0.8042, ROC AUC: 0.9708,  Avg loss: 0.001660\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.439241 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.494947 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.761784 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.706664 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.593756 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.580240 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.720799 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.410678 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.541633 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.788940 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8064, Recall: 0.8032, ROC AUC: 0.9708,  Avg loss: 0.001629\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.700962 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.443507 [  705/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.301096 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.501259 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.434441 [ 2397/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.698495 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.500517 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.542500 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.534823 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.490661 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8061, Recall: 0.8032, ROC AUC: 0.9709,  Avg loss: 0.001639\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.508680 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.537576 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.520728 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.395435 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.483242 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.490549 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.649832 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.498218 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.402438 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.557894 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8048, Recall: 0.8023, ROC AUC: 0.9710,  Avg loss: 0.001640\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.573359 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.394432 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.543387 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.565485 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.781851 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.465100 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.534670 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.568937 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.606732 [ 4653/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.750549 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8058, Recall: 0.8032, ROC AUC: 0.9710,  Avg loss: 0.001624\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.632306 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.640110 [  705/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.709957 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.412602 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.559777 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.654048 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.526477 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.380183 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.534861 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.559053 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8056, Recall: 0.8031, ROC AUC: 0.9710,  Avg loss: 0.001615\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.432297 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.398803 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.677458 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.566772 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.574435 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.554838 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.490170 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.528485 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.581476 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.472782 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.57%, Precision: 0.8076, Recall: 0.8049, ROC AUC: 0.9709,  Avg loss: 0.001635\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.509718 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.519108 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.433347 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.367744 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.552596 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.654948 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.447327 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.639306 [ 4089/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.685651 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.621669 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8046, Recall: 0.8023, ROC AUC: 0.9710,  Avg loss: 0.001630\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.553931 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.445014 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.385539 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.638900 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.577747 [ 2397/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.819258 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.654088 [ 3525/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.763045 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.574350 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.676196 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8050, Recall: 0.8021, ROC AUC: 0.9711,  Avg loss: 0.001621\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.657735 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.375584 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.418245 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.522247 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.514736 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.380528 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.682986 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.583835 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.379345 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.521293 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8060, Recall: 0.8031, ROC AUC: 0.9709,  Avg loss: 0.001642\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.514317 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.431586 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.423295 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.547004 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.306146 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.489710 [ 2961/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.681445 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.428839 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.356312 [ 4653/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.800378 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8074, Recall: 0.8042, ROC AUC: 0.9709,  Avg loss: 0.001655\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss: 0.722721 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.703618 [  705/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.772178 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.583789 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.535291 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.598778 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.492412 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.689536 [ 4089/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.338247 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.470006 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8067, Recall: 0.8041, ROC AUC: 0.9710,  Avg loss: 0.001652\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.267347 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.507969 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.518924 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.444014 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.650393 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.497356 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.555867 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.570833 [ 4089/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.303484 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.663205 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.57%, Precision: 0.8076, Recall: 0.8049, ROC AUC: 0.9710,  Avg loss: 0.001639\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.432365 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.634467 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.605539 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.546687 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.431465 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.529639 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.596629 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.358715 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.441082 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.715489 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8056, Recall: 0.8031, ROC AUC: 0.9710,  Avg loss: 0.001623\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.722382 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.398090 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.448551 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.508587 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.584696 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.521103 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.364824 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.504395 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.423814 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.444560 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8067, Recall: 0.8040, ROC AUC: 0.9710,  Avg loss: 0.001630\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.431680 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.518329 [  705/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.699447 [ 1269/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.730350 [ 1833/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.301558 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.511076 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.460171 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.427733 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.426053 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.445919 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8064, Recall: 0.8042, ROC AUC: 0.9711,  Avg loss: 0.001632\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.583593 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.610338 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.475529 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.648476 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.577176 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.538371 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.479144 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.604828 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.511620 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.524253 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8065, Recall: 0.8040, ROC AUC: 0.9710,  Avg loss: 0.001606\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.341252 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.530679 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.541662 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.511889 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.508283 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.562363 [ 2961/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.660278 [ 3525/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.706477 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.322657 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.537789 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8069, Recall: 0.8042, ROC AUC: 0.9711,  Avg loss: 0.001614\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.521355 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.386363 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.581639 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.498221 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.682019 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.519632 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.549811 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.550691 [ 4089/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.753870 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.471652 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.57%, Precision: 0.8073, Recall: 0.8049, ROC AUC: 0.9710,  Avg loss: 0.001600\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss: 0.692961 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.721531 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.313587 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.679500 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.549806 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.534303 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.557395 [ 3525/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.740383 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.519789 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.554499 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.67%, Precision: 0.8086, Recall: 0.8060, ROC AUC: 0.9710,  Avg loss: 0.001625\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.365650 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.402713 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.505714 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.448897 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.531420 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.274288 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.393228 [ 3525/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.835801 [ 4089/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.242749 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.406239 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8067, Recall: 0.8041, ROC AUC: 0.9710,  Avg loss: 0.001653\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.503285 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.514297 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.566671 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.681929 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.428762 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.493263 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.611530 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.512893 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.717073 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.611305 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8068, Recall: 0.8041, ROC AUC: 0.9710,  Avg loss: 0.001641\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.550445 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.610281 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.498224 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.554603 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.644454 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.687603 [ 2961/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.604610 [ 3525/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.718971 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.613959 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.513522 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8068, Recall: 0.8041, ROC AUC: 0.9711,  Avg loss: 0.001622\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.586073 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.462199 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.529053 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.688996 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.347049 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.475926 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.430316 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.578778 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.554809 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.580738 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8058, Recall: 0.8030, ROC AUC: 0.9711,  Avg loss: 0.001613\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.445093 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.559776 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.497701 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.475208 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.357398 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.518943 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.545095 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.360675 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.449247 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.495576 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.57%, Precision: 0.8079, Recall: 0.8052, ROC AUC: 0.9713,  Avg loss: 0.001610\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.496239 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.554098 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.414918 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.644188 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.385353 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.371517 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.498551 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.571543 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.543838 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.418710 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8069, Recall: 0.8042, ROC AUC: 0.9713,  Avg loss: 0.001609\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.416136 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.707088 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.463764 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.497475 [ 1833/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.682037 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.507234 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.587445 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.514023 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.364875 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.461873 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8070, Recall: 0.8042, ROC AUC: 0.9712,  Avg loss: 0.001599\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.419951 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.451804 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.523542 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.551606 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.439021 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.509956 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.370768 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.603218 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.597991 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.570808 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8048, Recall: 0.8022, ROC AUC: 0.9713,  Avg loss: 0.001596\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.523986 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.618543 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.457711 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.554402 [ 1833/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.727344 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.602402 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.533397 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.388307 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.331982 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.456115 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8073, Recall: 0.8041, ROC AUC: 0.9713,  Avg loss: 0.001610\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.617137 [  141/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.713419 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.518703 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.621063 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.452531 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.501884 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.501639 [ 3525/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.628440 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.541219 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.542394 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8071, Recall: 0.8041, ROC AUC: 0.9713,  Avg loss: 0.001632\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.478720 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.370584 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.657368 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.514729 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.413402 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.434275 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.410755 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.549164 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.536598 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.369005 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8071, Recall: 0.8041, ROC AUC: 0.9713,  Avg loss: 0.001633\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.690308 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.439916 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.550490 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.530637 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.509174 [ 2397/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.619283 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.506139 [ 3525/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.740270 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.557560 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.396270 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8072, Recall: 0.8041, ROC AUC: 0.9711,  Avg loss: 0.001624\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.594689 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.564608 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.487317 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.584985 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.518698 [ 2397/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.714523 [ 2961/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.805082 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.462893 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.492088 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.467709 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.57%, Precision: 0.8079, Recall: 0.8050, ROC AUC: 0.9710,  Avg loss: 0.001637\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.473350 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.359895 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.473683 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.415909 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.596582 [ 2397/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.755943 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.555687 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.629137 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.331219 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.311711 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8071, Recall: 0.8041, ROC AUC: 0.9710,  Avg loss: 0.001641\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.355223 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.553250 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.361381 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.515556 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.722199 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.420421 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.486886 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.449846 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.388309 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.799601 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.57%, Precision: 0.8080, Recall: 0.8052, ROC AUC: 0.9711,  Avg loss: 0.001650\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.585445 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.630958 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.613647 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.557929 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.503857 [ 2397/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.657436 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.273925 [ 3525/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.698323 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.679718 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.560636 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.57%, Precision: 0.8083, Recall: 0.8052, ROC AUC: 0.9711,  Avg loss: 0.001634\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.530360 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.498451 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.543326 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.501921 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.512716 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.389649 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.480753 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.457188 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.376718 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.470552 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8048, Recall: 0.8022, ROC AUC: 0.9712,  Avg loss: 0.001623\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.475290 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.461305 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.522328 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.565004 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.405100 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.434011 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.543725 [ 3525/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.289209 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.606977 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.478091 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8070, Recall: 0.8042, ROC AUC: 0.9712,  Avg loss: 0.001600\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.484450 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.335171 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.610842 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.319242 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.427272 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.471770 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.446988 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.523288 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.539622 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.465613 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.57%, Precision: 0.8081, Recall: 0.8052, ROC AUC: 0.9711,  Avg loss: 0.001613\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.414988 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.459732 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.469422 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.366812 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.685134 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.595348 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.368477 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.572544 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.455244 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.387839 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8072, Recall: 0.8042, ROC AUC: 0.9711,  Avg loss: 0.001632\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.554975 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.351074 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.570689 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.547755 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.544655 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.621068 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.550997 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.557439 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.560098 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.301931 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8070, Recall: 0.8042, ROC AUC: 0.9711,  Avg loss: 0.001633\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.562329 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.606583 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.540004 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.596932 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.421326 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.451296 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.269276 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.529291 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.474327 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.622179 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8057, Recall: 0.8031, ROC AUC: 0.9712,  Avg loss: 0.001636\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.526789 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.452771 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.495474 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.489317 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.499583 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.492792 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.334539 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.563299 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.494053 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.636573 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8056, Recall: 0.8031, ROC AUC: 0.9712,  Avg loss: 0.001630\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.655360 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.478301 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.406603 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.623628 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.628330 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.360765 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.684483 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.486926 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.372371 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.491536 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.57%, Precision: 0.8080, Recall: 0.8050, ROC AUC: 0.9712,  Avg loss: 0.001631\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.389657 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.388853 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.434197 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.490706 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.437049 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.400580 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.424929 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.459055 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.399285 [ 4653/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.846660 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8070, Recall: 0.8041, ROC AUC: 0.9711,  Avg loss: 0.001650\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.471852 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.347392 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.593812 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.398834 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.649655 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.410959 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.537274 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.476305 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.416952 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.451845 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8060, Recall: 0.8031, ROC AUC: 0.9711,  Avg loss: 0.001622\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.558818 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.434657 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.463239 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.571665 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.715054 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.351925 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.329586 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.588813 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.446855 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.520059 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8049, Recall: 0.8022, ROC AUC: 0.9711,  Avg loss: 0.001638\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss: 0.646972 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.497630 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.542744 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.381141 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.458639 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.609289 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.578620 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.554915 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.347370 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.619154 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8067, Recall: 0.8042, ROC AUC: 0.9712,  Avg loss: 0.001608\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.515083 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.495034 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.525678 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.536856 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.529039 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.568537 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.606838 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.515972 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.527750 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.392557 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8056, Recall: 0.8031, ROC AUC: 0.9712,  Avg loss: 0.001611\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.556376 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.468831 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.552568 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.361417 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.509977 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.490898 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.589150 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.481475 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.414203 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.541828 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8048, Recall: 0.8016, ROC AUC: 0.9713,  Avg loss: 0.001620\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.298410 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.498496 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.392605 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.481886 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.473644 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.503585 [ 2961/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.332351 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.470947 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.492471 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.445413 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8065, Recall: 0.8042, ROC AUC: 0.9714,  Avg loss: 0.001613\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.503491 [  141/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.707822 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.574992 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.584987 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.443391 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.593546 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.603312 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.339600 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.526272 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.476118 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8068, Recall: 0.8042, ROC AUC: 0.9713,  Avg loss: 0.001607\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.667598 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.437841 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.344077 [ 1269/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.597793 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.547959 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.693600 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.340780 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.436382 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.514181 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.557950 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8072, Recall: 0.8042, ROC AUC: 0.9713,  Avg loss: 0.001618\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.384567 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.476984 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.414157 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.645841 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.516491 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.531822 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.468711 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.527300 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.388276 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.383180 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8073, Recall: 0.8041, ROC AUC: 0.9713,  Avg loss: 0.001619\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.496540 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.570731 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.662795 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.570798 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.587627 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.697177 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.447412 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.490107 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.533790 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.605567 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8049, Recall: 0.8015, ROC AUC: 0.9712,  Avg loss: 0.001606\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.752210 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.639731 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.372448 [ 1269/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.706395 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.541521 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.640221 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.461680 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.463524 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.524125 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.454844 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8061, Recall: 0.8026, ROC AUC: 0.9713,  Avg loss: 0.001613\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.593468 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.721400 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.515649 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.477332 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.549260 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.509759 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.562180 [ 3525/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.611213 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.471702 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.595654 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8061, Recall: 0.8026, ROC AUC: 0.9712,  Avg loss: 0.001602\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.598890 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.421437 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.517321 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.538497 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.383700 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.353844 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.659567 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.498672 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.600785 [ 4653/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.206627 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8048, Recall: 0.8015, ROC AUC: 0.9713,  Avg loss: 0.001594\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.530665 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.509336 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.305042 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.433793 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.362331 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.561350 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.513380 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.431736 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.683203 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.491349 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8063, Recall: 0.8031, ROC AUC: 0.9712,  Avg loss: 0.001609\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.591368 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.410351 [  705/ 5250]\n",
      "Accuracy: 78.7%, Loss: 0.873711 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.652001 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.444634 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.575938 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.470910 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.412918 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.486445 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.730364 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8061, Recall: 0.8028, ROC AUC: 0.9712,  Avg loss: 0.001597\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.584287 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.455899 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.566311 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.301799 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.442833 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.549279 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.497372 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.505982 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.326308 [ 4653/ 5250]\n",
      "Accuracy: 96.5%, Loss: 0.254135 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8039, Recall: 0.8007, ROC AUC: 0.9712,  Avg loss: 0.001604\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.503892 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.547920 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.499965 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.512486 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.450510 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.454990 [ 2961/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.272620 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.377158 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.658022 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.275471 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8048, Recall: 0.8021, ROC AUC: 0.9713,  Avg loss: 0.001627\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.383883 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.536939 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.472427 [ 1269/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.704609 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.485835 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.546430 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.514226 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.542753 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.389042 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.595459 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8070, Recall: 0.8042, ROC AUC: 0.9713,  Avg loss: 0.001619\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.384500 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.526070 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.452330 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.611599 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.552021 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.393797 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.541519 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.425532 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.390662 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.532015 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.57%, Precision: 0.8076, Recall: 0.8051, ROC AUC: 0.9713,  Avg loss: 0.001610\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.460681 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.400575 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.323349 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.627758 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.350623 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.658441 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.701235 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.412408 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.394494 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.446127 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.57%, Precision: 0.8076, Recall: 0.8051, ROC AUC: 0.9713,  Avg loss: 0.001633\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.584031 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.590351 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.615615 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.381507 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.397013 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.551833 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.512321 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.486471 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.467867 [ 4653/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.610349 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8063, Recall: 0.8029, ROC AUC: 0.9712,  Avg loss: 0.001631\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.560023 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.568027 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.385670 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.419368 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.505779 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.548520 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.479891 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.568353 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.565447 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.439643 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8056, Recall: 0.8015, ROC AUC: 0.9712,  Avg loss: 0.001612\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss: 0.687700 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.442692 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.542214 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.311664 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.540198 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.610234 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.514395 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.643144 [ 4089/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.801819 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.550487 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8061, Recall: 0.8025, ROC AUC: 0.9713,  Avg loss: 0.001613\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.532970 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.574912 [  705/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.646442 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.557060 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.371910 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.563348 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.588775 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.512019 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.625727 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.404516 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8061, Recall: 0.8025, ROC AUC: 0.9713,  Avg loss: 0.001613\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "Accuracy: 95.7%, Loss: 0.216218 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.350129 [  705/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.716624 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.615668 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.548996 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.464199 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.446811 [ 3525/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.689154 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.357303 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.444757 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8052, Recall: 0.8014, ROC AUC: 0.9713,  Avg loss: 0.001625\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.580809 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.683757 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.351673 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.487736 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.325925 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.599319 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.503631 [ 3525/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.195324 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.441634 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.536574 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8035, Recall: 0.8006, ROC AUC: 0.9714,  Avg loss: 0.001633\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.513221 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.483565 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.484804 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.392274 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.459333 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.601014 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.545673 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.480720 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.481128 [ 4653/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.751924 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8044, Recall: 0.8006, ROC AUC: 0.9713,  Avg loss: 0.001621\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.427541 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.477125 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.402733 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.543595 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.433133 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.522401 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.512813 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.595221 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.433692 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.555064 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8054, Recall: 0.8017, ROC AUC: 0.9713,  Avg loss: 0.001608\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.401223 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.521259 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.321743 [ 1269/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.617773 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.490187 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.483865 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.595495 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.699660 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.564424 [ 4653/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.666197 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8062, Recall: 0.8026, ROC AUC: 0.9712,  Avg loss: 0.001607\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.448201 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.428978 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.470233 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.560652 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.571154 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.450018 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.517887 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.408037 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.494868 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.576012 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8030, Recall: 0.7997, ROC AUC: 0.9713,  Avg loss: 0.001602\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.448691 [  141/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.592869 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.572849 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.494384 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.465507 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.637085 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.591481 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.495994 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.579818 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.353882 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8064, Recall: 0.8031, ROC AUC: 0.9713,  Avg loss: 0.001606\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.521055 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.383289 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.565785 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.473941 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.343822 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.397860 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.397620 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.525506 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.552445 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.506991 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.57%, Precision: 0.8084, Recall: 0.8049, ROC AUC: 0.9712,  Avg loss: 0.001616\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.572269 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.616601 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.618212 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.585903 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.436047 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.597411 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.474244 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.481619 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.302650 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.497095 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8073, Recall: 0.8036, ROC AUC: 0.9712,  Avg loss: 0.001608\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.334978 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.477877 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.520783 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.297288 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.358904 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.472295 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.412771 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.521910 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.440598 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.556124 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8074, Recall: 0.8036, ROC AUC: 0.9711,  Avg loss: 0.001640\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.464531 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.310518 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.448859 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.500179 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.397522 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.433496 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.473000 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.396388 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.434573 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.435702 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8074, Recall: 0.8036, ROC AUC: 0.9712,  Avg loss: 0.001622\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.356240 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.475248 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.484670 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.402599 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.485817 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.464696 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.568128 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.373405 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.365494 [ 4653/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.653334 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8041, Recall: 0.8006, ROC AUC: 0.9713,  Avg loss: 0.001612\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.529247 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.474892 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.535496 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.559356 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.520684 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.551472 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.491377 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.379213 [ 4089/ 5250]\n",
      "Accuracy: 78.7%, Loss: 0.825603 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.437516 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8024, Recall: 0.7985, ROC AUC: 0.9713,  Avg loss: 0.001601\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.442851 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.448646 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.525093 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.509409 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.547579 [ 2397/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.670121 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.451806 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.384486 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.378786 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.458543 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8023, Recall: 0.7987, ROC AUC: 0.9713,  Avg loss: 0.001612\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.454887 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.513274 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.566122 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.503685 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.424091 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.548512 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.493069 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.560528 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.519357 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.344730 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8016, Recall: 0.7976, ROC AUC: 0.9713,  Avg loss: 0.001618\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.372085 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.405478 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.332138 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.576655 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.466197 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.552642 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.440104 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.642759 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.481804 [ 4653/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.758938 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8026, Recall: 0.7985, ROC AUC: 0.9714,  Avg loss: 0.001634\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.405039 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.547578 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.350244 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.476962 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.329721 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.466453 [ 2961/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.628995 [ 3525/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.281616 [ 4089/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.591397 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.486267 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8045, Recall: 0.8005, ROC AUC: 0.9713,  Avg loss: 0.001643\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "Accuracy: 95.0%, Loss: 0.278228 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.399413 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.511508 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.359680 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.414424 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.567145 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.484798 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.454622 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.329882 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.295596 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8039, Recall: 0.7995, ROC AUC: 0.9713,  Avg loss: 0.001644\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.577241 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.374258 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.516358 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.618326 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.480624 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.471576 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.373544 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.509415 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.335484 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.527712 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8043, Recall: 0.8004, ROC AUC: 0.9712,  Avg loss: 0.001637\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.471409 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.423352 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.575249 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.698895 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.520941 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.559036 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.466352 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.391252 [ 4089/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.738770 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.332810 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8033, Recall: 0.7996, ROC AUC: 0.9710,  Avg loss: 0.001634\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.402581 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.443810 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.479475 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.547266 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.593721 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.336947 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.420382 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.592053 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.529762 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.333595 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8041, Recall: 0.7997, ROC AUC: 0.9711,  Avg loss: 0.001646\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.447571 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.336422 [  705/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.253811 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.493437 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.519608 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.563021 [ 2961/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.631701 [ 3525/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.729545 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.393493 [ 4653/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.316426 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8022, Recall: 0.7986, ROC AUC: 0.9712,  Avg loss: 0.001668\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.593186 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.361049 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.396276 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.460313 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.476368 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.389090 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.336054 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.356369 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.375358 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.487162 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8032, Recall: 0.7998, ROC AUC: 0.9713,  Avg loss: 0.001664\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.491280 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.518137 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.342920 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.387157 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.675533 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.495019 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.594667 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.554218 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.551763 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.410978 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8044, Recall: 0.8009, ROC AUC: 0.9713,  Avg loss: 0.001650\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.497142 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.473914 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.332904 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.457677 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.595986 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.502993 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.532178 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.494953 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.454481 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.259154 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8023, Recall: 0.7988, ROC AUC: 0.9713,  Avg loss: 0.001646\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.487147 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.433848 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.531902 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.393400 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.605052 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.325750 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.388610 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.496818 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.318995 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.370985 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8006, Recall: 0.7976, ROC AUC: 0.9711,  Avg loss: 0.001631\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.531541 [  141/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.618824 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.428781 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.650167 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.365399 [ 2397/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.711041 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.526416 [ 3525/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.553226 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.508382 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.537306 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8047, Recall: 0.8013, ROC AUC: 0.9710,  Avg loss: 0.001644\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.494439 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.629015 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.529739 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.470291 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.601865 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.363541 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.498873 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.513353 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.279652 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.347598 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8059, Recall: 0.8036, ROC AUC: 0.9710,  Avg loss: 0.001655\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.632555 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.500069 [  705/ 5250]\n",
      "Accuracy: 80.1%, Loss: 0.811627 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.518736 [ 1833/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.638496 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.497924 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.532491 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.444109 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.462790 [ 4653/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.621609 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8025, Recall: 0.7996, ROC AUC: 0.9711,  Avg loss: 0.001649\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.360687 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.560085 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.436740 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.399101 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.482767 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.473319 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.453338 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.415757 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.450084 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.351578 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8027, Recall: 0.7996, ROC AUC: 0.9712,  Avg loss: 0.001659\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.562396 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.509050 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.523197 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.413699 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.492938 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.407763 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.330440 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.475076 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.529686 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.390784 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8042, Recall: 0.8014, ROC AUC: 0.9712,  Avg loss: 0.001655\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.372396 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.543259 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.442208 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.396682 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.517944 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.568792 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.349334 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.522931 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.487867 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.487865 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8056, Recall: 0.8022, ROC AUC: 0.9712,  Avg loss: 0.001636\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.468132 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.500401 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.541835 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.398281 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.428718 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.532393 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.484474 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.452743 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.397073 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.467924 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8034, Recall: 0.8003, ROC AUC: 0.9712,  Avg loss: 0.001637\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.520761 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.390288 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.528089 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.614018 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.446093 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.469840 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.510686 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.422078 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.538827 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.463919 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8016, Recall: 0.7986, ROC AUC: 0.9711,  Avg loss: 0.001670\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.470293 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.481768 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.390138 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.574009 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.588984 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.460737 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.382909 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.390213 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.378159 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.355045 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8033, Recall: 0.8004, ROC AUC: 0.9711,  Avg loss: 0.001686\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.514690 [  141/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.653327 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.507380 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.588548 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.469244 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.448755 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.459481 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.454711 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.432145 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.447469 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8053, Recall: 0.8022, ROC AUC: 0.9711,  Avg loss: 0.001672\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.517090 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.561178 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.350588 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.391573 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.483363 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.627496 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.537675 [ 3525/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.270385 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.464635 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.498652 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8046, Recall: 0.8013, ROC AUC: 0.9711,  Avg loss: 0.001658\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.506889 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.349484 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.542806 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.570104 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.433544 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.389236 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.596816 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.487623 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.508705 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.361961 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8026, Recall: 0.7994, ROC AUC: 0.9710,  Avg loss: 0.001650\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.327080 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.410779 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.454884 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.412522 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.461577 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.544720 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.396603 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.522763 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.577046 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.470641 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8012, Recall: 0.7975, ROC AUC: 0.9710,  Avg loss: 0.001652\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.348625 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.479068 [  705/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.580300 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.363034 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.506920 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.401668 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.527780 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.587596 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.543870 [ 4653/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.679394 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8030, Recall: 0.7996, ROC AUC: 0.9710,  Avg loss: 0.001663\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.580974 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.615489 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.427632 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.461359 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.452137 [ 2397/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.664835 [ 2961/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.679137 [ 3525/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.633551 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.459427 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.541949 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8051, Recall: 0.8014, ROC AUC: 0.9709,  Avg loss: 0.001643\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.559921 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.350049 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.447250 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.436065 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.356822 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.464017 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.378678 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.418710 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.494049 [ 4653/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.736093 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8074, Recall: 0.8035, ROC AUC: 0.9710,  Avg loss: 0.001658\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.483891 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.561977 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.517380 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.633669 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.530067 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.441412 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.526272 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.624787 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.403383 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.544454 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8036, Recall: 0.7994, ROC AUC: 0.9709,  Avg loss: 0.001649\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.346508 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.530521 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.385916 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.548849 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.518326 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.585373 [ 2961/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.686670 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.467255 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.603047 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.278770 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8022, Recall: 0.7984, ROC AUC: 0.9709,  Avg loss: 0.001639\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.562696 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.426164 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.387292 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.527874 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.456327 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.549850 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.403490 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.483171 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.379763 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.442567 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8021, Recall: 0.7994, ROC AUC: 0.9709,  Avg loss: 0.001642\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.608822 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.542294 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.520192 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.409726 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.385413 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.512489 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.331539 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.422168 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.451545 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.410196 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8033, Recall: 0.7995, ROC AUC: 0.9707,  Avg loss: 0.001662\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss: 0.690702 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.411725 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.533927 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.435518 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.476198 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.475498 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.585231 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.482750 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.467832 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.571160 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8028, Recall: 0.7995, ROC AUC: 0.9707,  Avg loss: 0.001678\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.519159 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.480498 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.428179 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.442194 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.607087 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.266495 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.518889 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.547380 [ 4089/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.514588 [ 4653/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.593093 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.48%, Precision: 0.8065, Recall: 0.8036, ROC AUC: 0.9708,  Avg loss: 0.001684\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.663996 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.628312 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.227562 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.491630 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.412827 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.625934 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.610918 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.417521 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.390512 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.547369 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8064, Recall: 0.8029, ROC AUC: 0.9709,  Avg loss: 0.001656\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.558381 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.533096 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.444444 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.570272 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.409277 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.513487 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.586367 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.397381 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.564342 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.402008 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.8007, Recall: 0.7969, ROC AUC: 0.9710,  Avg loss: 0.001630\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.405238 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.633938 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.620053 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.358885 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.315410 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.440514 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.413950 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.433622 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.522636 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.412145 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8055, Recall: 0.8019, ROC AUC: 0.9710,  Avg loss: 0.001654\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.503840 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.401315 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.355587 [ 1269/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.279179 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.413588 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.452254 [ 2961/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.602095 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.427421 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.453391 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.474504 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8056, Recall: 0.8019, ROC AUC: 0.9710,  Avg loss: 0.001662\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.560679 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.484361 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.464076 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.478006 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.418411 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.313205 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.539567 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.528139 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.472483 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.576083 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8063, Recall: 0.8027, ROC AUC: 0.9710,  Avg loss: 0.001674\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.488547 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.609969 [  705/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.611789 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.289575 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.424980 [ 2397/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.273909 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.400141 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.511616 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.561423 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.571389 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8070, Recall: 0.8028, ROC AUC: 0.9711,  Avg loss: 0.001676\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.439527 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.442156 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.346265 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.464189 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.466514 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.301270 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.565180 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.416651 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.473607 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.393593 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8054, Recall: 0.8019, ROC AUC: 0.9711,  Avg loss: 0.001681\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.496468 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.524994 [  705/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.695459 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.466501 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.425940 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.254310 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.382523 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.545530 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.439877 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.420580 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8067, Recall: 0.8029, ROC AUC: 0.9711,  Avg loss: 0.001660\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.596835 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.530975 [  705/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.623774 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.582923 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.376845 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.504442 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.411766 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.524224 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.432667 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.437609 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.38%, Precision: 0.8066, Recall: 0.8028, ROC AUC: 0.9710,  Avg loss: 0.001656\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.504078 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.544784 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.371918 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.610155 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.408675 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.474740 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.537979 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.396632 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.399461 [ 4653/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.699606 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8046, Recall: 0.8019, ROC AUC: 0.9711,  Avg loss: 0.001652\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.434599 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.401820 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.340857 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.271569 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.446318 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.336628 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.485983 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.343905 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.340565 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.516386 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8028, Recall: 0.7997, ROC AUC: 0.9713,  Avg loss: 0.001661\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.615173 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.411192 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.447338 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.598653 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.470897 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.490113 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.560588 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.482292 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.450766 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.337284 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8008, Recall: 0.7979, ROC AUC: 0.9713,  Avg loss: 0.001656\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.428951 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.532910 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.387063 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.383551 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.335237 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.493884 [ 2961/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.277763 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.334663 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.446842 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.440291 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8008, Recall: 0.7979, ROC AUC: 0.9713,  Avg loss: 0.001670\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.497060 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.423113 [  705/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.601508 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.490825 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.356060 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.421896 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.428305 [ 3525/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.593894 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.420774 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.485940 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8064, Recall: 0.8019, ROC AUC: 0.9711,  Avg loss: 0.001669\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.410506 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.467270 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.519422 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.480375 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.467604 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.605183 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.507405 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.514033 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.414736 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.358967 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8042, Recall: 0.7997, ROC AUC: 0.9711,  Avg loss: 0.001660\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.525316 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.585368 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.423484 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.404790 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.513026 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.352599 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.361149 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.492982 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.415617 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.396278 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.8006, Recall: 0.7968, ROC AUC: 0.9713,  Avg loss: 0.001663\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.459367 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.638089 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.507153 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.300523 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.393983 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.362534 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.515312 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.458239 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.405055 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.380691 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8013, Recall: 0.7981, ROC AUC: 0.9714,  Avg loss: 0.001657\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.483239 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.398051 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.518894 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.520778 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.507184 [ 2397/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.616688 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.297949 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.375051 [ 4089/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.564360 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.377764 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7979, Recall: 0.7942, ROC AUC: 0.9712,  Avg loss: 0.001678\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.424369 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.342133 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.499601 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.403023 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.552435 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.400910 [ 2961/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.331179 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.412964 [ 4089/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.692958 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.499519 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7993, Recall: 0.7959, ROC AUC: 0.9713,  Avg loss: 0.001660\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.408188 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.621949 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.377974 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.572610 [ 1833/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.564911 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.426807 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.488183 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.449948 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.402848 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.456991 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8026, Recall: 0.7987, ROC AUC: 0.9712,  Avg loss: 0.001657\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.551566 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.616077 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.529090 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.451663 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.412948 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.417570 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.473650 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.518757 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.350393 [ 4653/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.638747 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.8013, Recall: 0.7968, ROC AUC: 0.9712,  Avg loss: 0.001672\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.612267 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.437838 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.513281 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.448881 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.416775 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.411177 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.440480 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.597170 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.337214 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.592944 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8039, Recall: 0.7997, ROC AUC: 0.9711,  Avg loss: 0.001692\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.519725 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.438127 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.524962 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.412331 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.290676 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.477223 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.448531 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.333384 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.527472 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.354609 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.8012, Recall: 0.7968, ROC AUC: 0.9712,  Avg loss: 0.001690\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.407629 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.613866 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.483108 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.346756 [ 1833/ 5250]\n",
      "Accuracy: 96.5%, Loss: 0.196481 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.526648 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.545601 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.391406 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.476997 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.415944 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8024, Recall: 0.7987, ROC AUC: 0.9713,  Avg loss: 0.001667\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.511334 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.454973 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.390972 [ 1269/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.717651 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.511511 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.386512 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.552037 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.432819 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.440553 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.411017 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8007, Recall: 0.7977, ROC AUC: 0.9713,  Avg loss: 0.001656\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.383778 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.341756 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.283578 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.460074 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.537924 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.384947 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.459897 [ 3525/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.619938 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.589013 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.403395 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.8000, Recall: 0.7968, ROC AUC: 0.9712,  Avg loss: 0.001657\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.390478 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.469380 [  705/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.547661 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.570099 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.381755 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.450982 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.336620 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.407698 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.514114 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.384440 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7993, Recall: 0.7959, ROC AUC: 0.9712,  Avg loss: 0.001664\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.461763 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.549881 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.534382 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.387150 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.558160 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.497965 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.464478 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.408362 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.725533 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.484114 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.7999, Recall: 0.7969, ROC AUC: 0.9710,  Avg loss: 0.001663\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.559975 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.644994 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.494522 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.250819 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.378681 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.451399 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.615983 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.531715 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.449713 [ 4653/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.757117 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8015, Recall: 0.7994, ROC AUC: 0.9712,  Avg loss: 0.001664\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.589879 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.397671 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.434983 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.551992 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.478736 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.358279 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.605032 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.415201 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.437493 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.550393 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8011, Recall: 0.7979, ROC AUC: 0.9712,  Avg loss: 0.001672\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.490234 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.400253 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.387694 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.485447 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.395123 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.507612 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.556610 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.481203 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.544412 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.348210 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8018, Recall: 0.7987, ROC AUC: 0.9712,  Avg loss: 0.001662\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.365746 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.496571 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.522781 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.421048 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.584145 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.464984 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.530818 [ 3525/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.288900 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.484046 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.535506 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8024, Recall: 0.7995, ROC AUC: 0.9713,  Avg loss: 0.001658\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.358824 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.461856 [  705/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.666497 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.583894 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.433199 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.326038 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.637735 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.413305 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.466583 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.520827 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8014, Recall: 0.7986, ROC AUC: 0.9714,  Avg loss: 0.001648\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.560250 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.460535 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.536336 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.414261 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.495264 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.708463 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.404953 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.517392 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.341422 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.484669 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8025, Recall: 0.7995, ROC AUC: 0.9712,  Avg loss: 0.001650\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.443930 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.384955 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.470625 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.285635 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.399504 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.465507 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.420854 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.545199 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.407093 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.321256 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8037, Recall: 0.8004, ROC AUC: 0.9712,  Avg loss: 0.001682\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.377157 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.328379 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.434654 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.444399 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.493701 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.688058 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.450866 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.410899 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.442984 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.452300 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8031, Recall: 0.7996, ROC AUC: 0.9712,  Avg loss: 0.001672\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.413819 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.472739 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.427061 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.360940 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.551390 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.537966 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.529549 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.565988 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.430401 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.624651 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8047, Recall: 0.8006, ROC AUC: 0.9712,  Avg loss: 0.001684\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.297967 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.364577 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.546271 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.416296 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.415698 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.418189 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.431846 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.568386 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.407682 [ 4653/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.689888 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8045, Recall: 0.8006, ROC AUC: 0.9711,  Avg loss: 0.001684\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss: 0.650254 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.429235 [  705/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.231888 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.493952 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.531474 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.406407 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.386025 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.283491 [ 4089/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.630426 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.326794 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.29%, Precision: 0.8061, Recall: 0.8016, ROC AUC: 0.9712,  Avg loss: 0.001683\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.510986 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.491925 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.569938 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.370518 [ 1833/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.737449 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.420857 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.469404 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.460371 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.422995 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.562056 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.19%, Precision: 0.8045, Recall: 0.8007, ROC AUC: 0.9712,  Avg loss: 0.001691\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.366391 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.427472 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.535270 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.388370 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.391909 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.377519 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.388395 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.438262 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.413230 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.597329 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.8000, Recall: 0.7968, ROC AUC: 0.9713,  Avg loss: 0.001701\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.633848 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.369406 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.316798 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.421352 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.625915 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.342700 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.429607 [ 3525/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.706884 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.269687 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.551189 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8008, Recall: 0.7987, ROC AUC: 0.9714,  Avg loss: 0.001665\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.451113 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.357703 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.506501 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.337561 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.341412 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.388315 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.456288 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.515694 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.430885 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.369310 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8026, Recall: 0.7999, ROC AUC: 0.9712,  Avg loss: 0.001670\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.362060 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.445520 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.385710 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.515421 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.445109 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.284871 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.424519 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.337749 [ 4089/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.645113 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.461512 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8016, Recall: 0.7991, ROC AUC: 0.9712,  Avg loss: 0.001685\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.482033 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.490734 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.554038 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.398633 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.435915 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.389362 [ 2961/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.686865 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.345438 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.368812 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.560416 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8031, Recall: 0.7999, ROC AUC: 0.9714,  Avg loss: 0.001691\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.345854 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.454751 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.323526 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.379893 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.355515 [ 2397/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.297676 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.340750 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.377864 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.437516 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.403372 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8015, Recall: 0.7990, ROC AUC: 0.9713,  Avg loss: 0.001689\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.445968 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.460004 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.461336 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.318522 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.378402 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.452727 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.550415 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.636019 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.325915 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.543578 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8019, Recall: 0.7990, ROC AUC: 0.9714,  Avg loss: 0.001675\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.522870 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.397445 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.438382 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.330044 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.313115 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.482688 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.459714 [ 3525/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.629102 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.396039 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.295579 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8031, Recall: 0.7999, ROC AUC: 0.9712,  Avg loss: 0.001693\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.322607 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.290519 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.379010 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.351585 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.361038 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.386847 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.298074 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.393660 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.491169 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.383482 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8015, Recall: 0.7985, ROC AUC: 0.9712,  Avg loss: 0.001713\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.392401 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.506746 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.424313 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.362413 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.517478 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.589153 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.428365 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.407676 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.513943 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.344157 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8012, Recall: 0.7985, ROC AUC: 0.9712,  Avg loss: 0.001701\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.472961 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.468840 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.480005 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.577840 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.440659 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.562508 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.375456 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.508982 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.464529 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.398519 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8011, Recall: 0.7987, ROC AUC: 0.9712,  Avg loss: 0.001699\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.609077 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.357663 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.459570 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.273817 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.605960 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.591336 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.427641 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.517618 [ 4089/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.573944 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.447838 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8023, Recall: 0.7991, ROC AUC: 0.9711,  Avg loss: 0.001683\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.341282 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.433303 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.298076 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.441508 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.642627 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.510942 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.361044 [ 3525/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.291407 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.399755 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.431680 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8012, Recall: 0.7980, ROC AUC: 0.9712,  Avg loss: 0.001701\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.298056 [  141/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.266817 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.289385 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.496634 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.286895 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.399134 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.527938 [ 3525/ 5250]\n",
      "Accuracy: 96.5%, Loss: 0.245486 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.494333 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.312171 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8040, Recall: 0.8000, ROC AUC: 0.9712,  Avg loss: 0.001724\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.431156 [  141/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.680063 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.483120 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.432890 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.302581 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.215257 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.402703 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.361508 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.628874 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.472808 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8015, Recall: 0.7990, ROC AUC: 0.9712,  Avg loss: 0.001686\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.546812 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.544571 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.447271 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.358667 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.581469 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.505474 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.309234 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.492448 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.373231 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.505288 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.10%, Precision: 0.8021, Recall: 0.8001, ROC AUC: 0.9713,  Avg loss: 0.001656\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.526478 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.515260 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.464680 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.263908 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.426964 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.310773 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.474327 [ 3525/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.591556 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.366539 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.423695 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7985, Recall: 0.7960, ROC AUC: 0.9713,  Avg loss: 0.001679\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.444624 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.498316 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.449886 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.314511 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.448581 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.458636 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.341252 [ 3525/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.601849 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.463385 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.330436 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.7996, Recall: 0.7967, ROC AUC: 0.9713,  Avg loss: 0.001702\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.470952 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.464615 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.478728 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.391099 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.433792 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.513331 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.376208 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.515500 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.348496 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.465697 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.8001, Recall: 0.7969, ROC AUC: 0.9712,  Avg loss: 0.001695\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.439562 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.462598 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.435631 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.467972 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.363138 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.547255 [ 2961/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.621186 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.359327 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.419986 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.675058 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7974, Recall: 0.7953, ROC AUC: 0.9712,  Avg loss: 0.001696\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss: 0.710561 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.533943 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.450434 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.377586 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.492372 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.511107 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.413389 [ 3525/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.771234 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.439179 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.535278 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.7995, Recall: 0.7972, ROC AUC: 0.9712,  Avg loss: 0.001679\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.561895 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.512728 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.325945 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.506260 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.515541 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.472734 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.423831 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.595376 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.301336 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.473315 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7979, Recall: 0.7958, ROC AUC: 0.9711,  Avg loss: 0.001693\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.420034 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.351516 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.570030 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.403430 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.427936 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.359289 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.512116 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.620030 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.420829 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.605964 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7973, Recall: 0.7950, ROC AUC: 0.9712,  Avg loss: 0.001690\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.559726 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.393949 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.482878 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.478467 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.435812 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.457676 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.412121 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.397336 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.328928 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.410558 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7979, Recall: 0.7958, ROC AUC: 0.9713,  Avg loss: 0.001691\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.438956 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.418539 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.576854 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.525240 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.429077 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.263506 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.369397 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.520393 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.342172 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.422095 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7974, Recall: 0.7954, ROC AUC: 0.9713,  Avg loss: 0.001697\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.444745 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.493865 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.411547 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.532491 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.461655 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.537571 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.371559 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.504795 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.467770 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.384961 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 80.00%, Precision: 0.8016, Recall: 0.7990, ROC AUC: 0.9711,  Avg loss: 0.001685\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.438598 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.514409 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.373209 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.456574 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.664366 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.433938 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.548969 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.372741 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.623848 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.264958 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7988, Recall: 0.7959, ROC AUC: 0.9711,  Avg loss: 0.001679\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.623817 [  141/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.655901 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.544937 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.459067 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.341770 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.287584 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.468491 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.400795 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.451750 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.438021 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.7990, Recall: 0.7971, ROC AUC: 0.9710,  Avg loss: 0.001697\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.317856 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.557714 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.417079 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.628637 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.384364 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.287783 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.493569 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.477425 [ 4089/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.316484 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.423273 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7978, Recall: 0.7962, ROC AUC: 0.9710,  Avg loss: 0.001717\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.422272 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.713742 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.430028 [ 1269/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.659427 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.490775 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.517173 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.395987 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.317066 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.350267 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.296073 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7980, Recall: 0.7959, ROC AUC: 0.9710,  Avg loss: 0.001722\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.470645 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.289939 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.505781 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.465090 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.484206 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.415103 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.444850 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.310087 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.297684 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.385908 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7988, Recall: 0.7959, ROC AUC: 0.9709,  Avg loss: 0.001731\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss: 0.680946 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.426068 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.413585 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.363865 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.514341 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.510802 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.391260 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.375176 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.344621 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.414679 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.7995, Recall: 0.7968, ROC AUC: 0.9710,  Avg loss: 0.001729\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.393660 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.445585 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.564830 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.539665 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.379079 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.311044 [ 2961/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.634132 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.577664 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.489652 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.453404 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.7991, Recall: 0.7968, ROC AUC: 0.9711,  Avg loss: 0.001719\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.330367 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.606386 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.429319 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.376010 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.417775 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.402553 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.416165 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.445776 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.332660 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.512008 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7987, Recall: 0.7961, ROC AUC: 0.9710,  Avg loss: 0.001714\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.460278 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.393634 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.407399 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.354431 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.483043 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.474394 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.410456 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.534532 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.293605 [ 4653/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.175927 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.8000, Recall: 0.7961, ROC AUC: 0.9708,  Avg loss: 0.001712\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.497873 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.416654 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.345386 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.350000 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.514743 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.393127 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.486234 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.393340 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.318235 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.385598 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7982, Recall: 0.7960, ROC AUC: 0.9709,  Avg loss: 0.001717\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.531657 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.449484 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.555912 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.482260 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.445225 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.431480 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.428076 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.461408 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.480577 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.540046 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7972, Recall: 0.7951, ROC AUC: 0.9709,  Avg loss: 0.001725\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.365657 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.289890 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.500905 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.667212 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.529440 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.370981 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.389441 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.645166 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.511366 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.546925 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8002, Recall: 0.7980, ROC AUC: 0.9710,  Avg loss: 0.001725\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.414019 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.296729 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.444812 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.445005 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.378820 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.394340 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.520571 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.538192 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.470468 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.410637 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8005, Recall: 0.7980, ROC AUC: 0.9710,  Avg loss: 0.001738\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.481857 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.552276 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.374841 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.344924 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.451804 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.501110 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.496280 [ 3525/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.522820 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.367790 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.449092 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7980, Recall: 0.7954, ROC AUC: 0.9710,  Avg loss: 0.001729\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.566566 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.399246 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.407261 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.430564 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.477629 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.478789 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.518818 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.528485 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.327609 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.441782 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.7997, Recall: 0.7972, ROC AUC: 0.9710,  Avg loss: 0.001733\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.466839 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.476699 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.440711 [ 1269/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.726601 [ 1833/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.617187 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.368757 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.495545 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.255504 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.507466 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.409643 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.7992, Recall: 0.7971, ROC AUC: 0.9709,  Avg loss: 0.001730\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.548951 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.427232 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.407430 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.477509 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.375655 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.531785 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.321274 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.526686 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.490944 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.462655 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7982, Recall: 0.7962, ROC AUC: 0.9709,  Avg loss: 0.001746\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.382329 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.524498 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.298901 [ 1269/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.584081 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.367837 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.312702 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.373974 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.423979 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.582923 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.410437 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7974, Recall: 0.7953, ROC AUC: 0.9710,  Avg loss: 0.001742\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.455955 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.520945 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.446311 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.406685 [ 1833/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.628750 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.471126 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.613980 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.362116 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.429943 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.529729 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.7996, Recall: 0.7971, ROC AUC: 0.9710,  Avg loss: 0.001738\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.515568 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.397530 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.490307 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.226414 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.380363 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.462911 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.585309 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.447844 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.612848 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.450593 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7987, Recall: 0.7962, ROC AUC: 0.9709,  Avg loss: 0.001738\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.365604 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.519929 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.275998 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.426286 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.440191 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.402059 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.450642 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.586208 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.540479 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.451414 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7969, Recall: 0.7941, ROC AUC: 0.9708,  Avg loss: 0.001727\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.413930 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.454151 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.446523 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.427863 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.474885 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.345099 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.579933 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.471042 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.452336 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.386503 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7987, Recall: 0.7959, ROC AUC: 0.9710,  Avg loss: 0.001711\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.463529 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.503615 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.432393 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.448372 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.311831 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.572531 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.418765 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.380851 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.361380 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.456484 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7977, Recall: 0.7949, ROC AUC: 0.9710,  Avg loss: 0.001728\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.453123 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.408773 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.432172 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.731190 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.440477 [ 2397/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.503441 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.431564 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.379951 [ 4089/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.556216 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.374259 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7959, Recall: 0.7932, ROC AUC: 0.9711,  Avg loss: 0.001715\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss: 0.596702 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.577460 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.458233 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.453668 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.379816 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.376047 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.524858 [ 3525/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.702260 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.344736 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.441951 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7966, Recall: 0.7941, ROC AUC: 0.9712,  Avg loss: 0.001716\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.356633 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.503364 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.293713 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.490468 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.458228 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.465086 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.275133 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.538620 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.501101 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.587532 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7993, Recall: 0.7959, ROC AUC: 0.9711,  Avg loss: 0.001725\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.451041 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.531826 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.475362 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.468084 [ 1833/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.271780 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.438855 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.578725 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.392080 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.426774 [ 4653/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.250012 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8006, Recall: 0.7977, ROC AUC: 0.9712,  Avg loss: 0.001704\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.530707 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.278162 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.375556 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.404333 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.572065 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.443083 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.586651 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.500255 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.408765 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.393406 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7986, Recall: 0.7959, ROC AUC: 0.9712,  Avg loss: 0.001707\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.392072 [  141/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.613135 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.267072 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.555646 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.525681 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.485242 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.323398 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.569290 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.443105 [ 4653/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.623467 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.8003, Recall: 0.7967, ROC AUC: 0.9712,  Avg loss: 0.001721\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.346220 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.341854 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.442456 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.245072 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.331480 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.336378 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.449519 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.317124 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.344613 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.566488 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.8001, Recall: 0.7968, ROC AUC: 0.9711,  Avg loss: 0.001732\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.482913 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.321070 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.398477 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.418955 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.389892 [ 2397/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.625288 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.481653 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.630547 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.436993 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.372473 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.8006, Recall: 0.7966, ROC AUC: 0.9709,  Avg loss: 0.001740\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.345795 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.451911 [  705/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.637043 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.394616 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.661898 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.426350 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.453331 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.397326 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.333276 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.482847 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.81%, Precision: 0.8006, Recall: 0.7967, ROC AUC: 0.9708,  Avg loss: 0.001738\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.425791 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.440195 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.456266 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.250185 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.435291 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.451384 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.418620 [ 3525/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.250981 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.466085 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.502683 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7990, Recall: 0.7962, ROC AUC: 0.9708,  Avg loss: 0.001745\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.385459 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.530543 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.325442 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.608094 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.491835 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.330322 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.390192 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.360665 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.482139 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.406641 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8012, Recall: 0.7977, ROC AUC: 0.9708,  Avg loss: 0.001754\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.281137 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.575488 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.535535 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.577879 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.439921 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.397270 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.253600 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.481570 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.487949 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.398186 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.90%, Precision: 0.8012, Recall: 0.7975, ROC AUC: 0.9708,  Avg loss: 0.001762\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.446148 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.332900 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.412630 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.495249 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.584006 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.507057 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.475834 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.461182 [ 4089/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.266505 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.433014 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7992, Recall: 0.7958, ROC AUC: 0.9706,  Avg loss: 0.001768\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.441512 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.487163 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.395403 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.347218 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.585858 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.358165 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.319712 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.435910 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.325356 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.433580 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7982, Recall: 0.7951, ROC AUC: 0.9705,  Avg loss: 0.001753\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.326150 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.286169 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.550052 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.373481 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.287565 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.356545 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.484641 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.388079 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.401575 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.351606 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7967, Recall: 0.7931, ROC AUC: 0.9706,  Avg loss: 0.001761\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.596183 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.383466 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.440562 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.493489 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.480922 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.371095 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.520434 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.275570 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.367864 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.530219 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7978, Recall: 0.7940, ROC AUC: 0.9706,  Avg loss: 0.001765\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.506876 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.293324 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.477335 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.328809 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.494593 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.562167 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.429821 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.424369 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.377235 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.465187 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7976, Recall: 0.7940, ROC AUC: 0.9706,  Avg loss: 0.001740\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.367356 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.467419 [  705/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.285994 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.467780 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.595365 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.525336 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.421988 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.427139 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.441074 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.461696 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7958, Recall: 0.7931, ROC AUC: 0.9707,  Avg loss: 0.001737\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.498272 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.459026 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.346882 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.611765 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.386832 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.389011 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.529956 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.613118 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.437658 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.608436 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7941, Recall: 0.7913, ROC AUC: 0.9708,  Avg loss: 0.001735\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.347482 [  141/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.697225 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.489666 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.450972 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.442769 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.346938 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.435760 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.346552 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.338971 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.467814 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7983, Recall: 0.7949, ROC AUC: 0.9709,  Avg loss: 0.001724\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.513075 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.411493 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.473167 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.281008 [ 1833/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.669592 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.408525 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.569675 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.488213 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.415529 [ 4653/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.323252 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7943, Recall: 0.7921, ROC AUC: 0.9707,  Avg loss: 0.001738\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "Accuracy: 94.3%, Loss: 0.278462 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.438833 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.649781 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.392851 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.570816 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.378662 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.556890 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.362288 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.412736 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.446735 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7945, Recall: 0.7921, ROC AUC: 0.9708,  Avg loss: 0.001737\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.396814 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.404769 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.334502 [ 1269/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.690870 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.340426 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.503840 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.326374 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.552210 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.406790 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.276508 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7966, Recall: 0.7939, ROC AUC: 0.9707,  Avg loss: 0.001745\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.495870 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.406705 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.422063 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.525937 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.539343 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.625871 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.471009 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.410518 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.567167 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.370320 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7970, Recall: 0.7939, ROC AUC: 0.9708,  Avg loss: 0.001741\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss: 0.581326 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.514545 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.443083 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.473063 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.412769 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.400118 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.295034 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.277598 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.369136 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.423533 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7951, Recall: 0.7922, ROC AUC: 0.9708,  Avg loss: 0.001728\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.438289 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.356694 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.443809 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.488606 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.332631 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.523490 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.320048 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.378448 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.341999 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.453610 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7943, Recall: 0.7913, ROC AUC: 0.9708,  Avg loss: 0.001746\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.645284 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.467466 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.401637 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.639622 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.499904 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.548595 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.469666 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.401789 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.370228 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.395164 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.71%, Precision: 0.7995, Recall: 0.7958, ROC AUC: 0.9709,  Avg loss: 0.001747\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.372108 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.630977 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.315317 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.480999 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.430670 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.378381 [ 2961/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.582986 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.379920 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.460289 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.259178 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7966, Recall: 0.7940, ROC AUC: 0.9708,  Avg loss: 0.001725\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss: 0.612547 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.370668 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.438244 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.317666 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.501129 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.255882 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.547443 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.361855 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.576267 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.285095 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7925, Recall: 0.7904, ROC AUC: 0.9709,  Avg loss: 0.001730\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.497609 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.572378 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.413177 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.427864 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.426343 [ 2397/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.497151 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.324330 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.353878 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.371180 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.431441 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7937, Recall: 0.7913, ROC AUC: 0.9709,  Avg loss: 0.001735\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.445691 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.295570 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.549768 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.420666 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.370885 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.283403 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.384072 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.353699 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.470181 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.494295 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7938, Recall: 0.7913, ROC AUC: 0.9709,  Avg loss: 0.001739\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.475616 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.548526 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.500801 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.306892 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.403103 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.540235 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.362843 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.503706 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.312814 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.442741 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7946, Recall: 0.7924, ROC AUC: 0.9709,  Avg loss: 0.001753\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.441468 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.473288 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.333282 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.514786 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.432220 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.387290 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.493934 [ 3525/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.674058 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.483050 [ 4653/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.225318 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7956, Recall: 0.7932, ROC AUC: 0.9709,  Avg loss: 0.001746\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.457665 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.477632 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.385822 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.411147 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.217283 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.477730 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.522328 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.471565 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.479485 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.454398 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7945, Recall: 0.7924, ROC AUC: 0.9708,  Avg loss: 0.001758\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.518925 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.436263 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.340035 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.301049 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.459297 [ 2397/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.218480 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.393769 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.504267 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.407619 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.461071 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7952, Recall: 0.7924, ROC AUC: 0.9708,  Avg loss: 0.001760\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss: 0.752930 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.416677 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.469483 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.459038 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.428058 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.510567 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.425598 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.511869 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.395319 [ 4653/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.593608 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7949, Recall: 0.7924, ROC AUC: 0.9708,  Avg loss: 0.001749\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.438371 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.410069 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.416068 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.404181 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.252305 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.362757 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.396428 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.588144 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.577193 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.344306 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7967, Recall: 0.7942, ROC AUC: 0.9708,  Avg loss: 0.001748\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.514239 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.342279 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.475886 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.362354 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.537730 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.628302 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.355812 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.397021 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.462092 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.557114 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7948, Recall: 0.7924, ROC AUC: 0.9708,  Avg loss: 0.001743\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.470704 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.322348 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.396291 [ 1269/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.591619 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.384843 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.525460 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.396566 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.366198 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.439748 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.366547 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7947, Recall: 0.7913, ROC AUC: 0.9708,  Avg loss: 0.001743\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.513531 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.507879 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.479310 [ 1269/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.571505 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.462033 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.378395 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.425517 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.355209 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.389924 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.310962 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7955, Recall: 0.7921, ROC AUC: 0.9708,  Avg loss: 0.001742\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.375780 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.426573 [  705/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.290924 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.502285 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.420735 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.437444 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.522160 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.352547 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.382217 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.445408 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7952, Recall: 0.7922, ROC AUC: 0.9707,  Avg loss: 0.001756\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.471803 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.411393 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.415500 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.363138 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.336323 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.393508 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.579010 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.622390 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.277627 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.531768 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7964, Recall: 0.7932, ROC AUC: 0.9709,  Avg loss: 0.001754\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.479231 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.511290 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.554151 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.436302 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.517826 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.462420 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.475974 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.382786 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.453082 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.446620 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7980, Recall: 0.7941, ROC AUC: 0.9709,  Avg loss: 0.001733\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.490895 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.475575 [  705/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.553248 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.354908 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.417484 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.475842 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.390273 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.452271 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.388631 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.429798 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7937, Recall: 0.7900, ROC AUC: 0.9708,  Avg loss: 0.001752\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.404573 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.366243 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.429512 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.424439 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.478121 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.407253 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.518173 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.319419 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.379970 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.396160 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7961, Recall: 0.7935, ROC AUC: 0.9708,  Avg loss: 0.001749\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.501639 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.337954 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.591671 [ 1269/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.640512 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.492827 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.330949 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.475865 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.427401 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.527527 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.354423 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7958, Recall: 0.7924, ROC AUC: 0.9708,  Avg loss: 0.001757\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "Accuracy: 94.3%, Loss: 0.294354 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.550571 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.317535 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.542718 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.457972 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.409090 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.560272 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.469679 [ 4089/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.604555 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.392139 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7944, Recall: 0.7901, ROC AUC: 0.9707,  Avg loss: 0.001764\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.553364 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.318093 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.346159 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.345795 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.433872 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.543094 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.286998 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.371314 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.329589 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.351877 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7956, Recall: 0.7921, ROC AUC: 0.9706,  Avg loss: 0.001768\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.404242 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.560250 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.387820 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.403462 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.346583 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.512332 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.484865 [ 3525/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.247263 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.344848 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.440908 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7969, Recall: 0.7933, ROC AUC: 0.9707,  Avg loss: 0.001768\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.396446 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.581716 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.367623 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.436885 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.475783 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.283976 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.425054 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.482712 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.526755 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.488930 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7955, Recall: 0.7914, ROC AUC: 0.9706,  Avg loss: 0.001744\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.344861 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.341760 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.483460 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.367832 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.491504 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.537244 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.483922 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.458451 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.279928 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.483132 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7966, Recall: 0.7914, ROC AUC: 0.9706,  Avg loss: 0.001748\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.485469 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.361390 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.307897 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.463238 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.416924 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.565154 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.365594 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.471081 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.368895 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.554467 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7960, Recall: 0.7913, ROC AUC: 0.9706,  Avg loss: 0.001783\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.325091 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.515239 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.312812 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.355153 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.349471 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.466087 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.386305 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.462892 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.494591 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.469362 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7949, Recall: 0.7915, ROC AUC: 0.9706,  Avg loss: 0.001767\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.360006 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.469908 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.423550 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.460024 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.196909 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.499166 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.289007 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.462238 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.330593 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.326212 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7966, Recall: 0.7935, ROC AUC: 0.9707,  Avg loss: 0.001752\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "Accuracy: 94.3%, Loss: 0.265553 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.432006 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.412780 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.389001 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.575896 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.485766 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.465822 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.383997 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.466429 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.478645 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7979, Recall: 0.7942, ROC AUC: 0.9706,  Avg loss: 0.001750\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.551386 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.383552 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.574829 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.341892 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.409694 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.362354 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.359693 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.359887 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.496975 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.489438 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7938, Recall: 0.7901, ROC AUC: 0.9708,  Avg loss: 0.001760\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.446369 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.547012 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.437925 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.450666 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.603511 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.457482 [ 2961/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.278373 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.419211 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.411919 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.388604 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7948, Recall: 0.7912, ROC AUC: 0.9708,  Avg loss: 0.001763\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.399200 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.550726 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.380978 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.517064 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.442055 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.328033 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.354525 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.310647 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.553482 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.584045 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7956, Recall: 0.7921, ROC AUC: 0.9708,  Avg loss: 0.001752\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.505481 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.434296 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.557370 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.340744 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.313634 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.406944 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.474062 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.516854 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.515990 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.397494 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7950, Recall: 0.7921, ROC AUC: 0.9708,  Avg loss: 0.001756\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.528210 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.384187 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.510187 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.423441 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.471984 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.464698 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.354326 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.517916 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.502585 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.488852 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7970, Recall: 0.7942, ROC AUC: 0.9708,  Avg loss: 0.001766\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.393668 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.410431 [  705/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.488955 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.487910 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.457311 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.373977 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.446206 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.385695 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.413567 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.542383 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7952, Recall: 0.7921, ROC AUC: 0.9708,  Avg loss: 0.001750\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.418591 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.425578 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.402682 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.350076 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.450173 [ 2397/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.611650 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.432985 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.330242 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.414564 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.371815 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7948, Recall: 0.7921, ROC AUC: 0.9709,  Avg loss: 0.001750\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.644156 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.479375 [  705/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.670419 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.414615 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.495385 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.448979 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.463981 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.433307 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.395192 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.304948 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7926, Recall: 0.7895, ROC AUC: 0.9707,  Avg loss: 0.001745\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.454042 [  141/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.234697 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.546196 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.572209 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.434608 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.380586 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.343543 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.373866 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.471220 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.459239 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7932, Recall: 0.7895, ROC AUC: 0.9707,  Avg loss: 0.001747\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.478941 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.330592 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.523925 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.354804 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.460887 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.344489 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.449637 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.367675 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.402327 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.478752 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7936, Recall: 0.7905, ROC AUC: 0.9708,  Avg loss: 0.001763\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.325505 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.551229 [  705/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.274000 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.378089 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.480429 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.515602 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.524389 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.339981 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.494926 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.454844 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7962, Recall: 0.7935, ROC AUC: 0.9708,  Avg loss: 0.001770\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.660300 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.421075 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.395604 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.444241 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.568375 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.517602 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.395028 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.427399 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.314726 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.413988 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7944, Recall: 0.7927, ROC AUC: 0.9709,  Avg loss: 0.001774\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.409848 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.473827 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.397179 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.415159 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.448501 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.328437 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.497119 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.454861 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.357293 [ 4653/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.657515 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7967, Recall: 0.7945, ROC AUC: 0.9707,  Avg loss: 0.001767\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.361292 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.561061 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.559785 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.503348 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.491719 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.530010 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.474348 [ 3525/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.282391 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.374696 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.540699 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7946, Recall: 0.7927, ROC AUC: 0.9707,  Avg loss: 0.001772\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "Accuracy: 94.3%, Loss: 0.268535 [  141/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.631408 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.329939 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.464439 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.404318 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.312743 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.265956 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.263812 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.444771 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.495078 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7938, Recall: 0.7915, ROC AUC: 0.9707,  Avg loss: 0.001778\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.457488 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.529707 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.462891 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.273751 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.518894 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.403720 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.318838 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.449699 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.308789 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.470084 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7918, Recall: 0.7898, ROC AUC: 0.9709,  Avg loss: 0.001762\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.379808 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.522591 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.349915 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.350079 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.416046 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.387928 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.444768 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.346867 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.422728 [ 4653/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.646233 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7943, Recall: 0.7920, ROC AUC: 0.9708,  Avg loss: 0.001771\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.286094 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.474950 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.428434 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.501433 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.574602 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.538969 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.550334 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.449818 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.273050 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.379399 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7971, Recall: 0.7952, ROC AUC: 0.9708,  Avg loss: 0.001748\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.510948 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.345969 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.278965 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.379708 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.444318 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.411740 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.359108 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.467784 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.464333 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.438899 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7968, Recall: 0.7941, ROC AUC: 0.9706,  Avg loss: 0.001770\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.377817 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.391390 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.519156 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.303914 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.342474 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.278991 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.562632 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.500212 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.454027 [ 4653/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.669379 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7961, Recall: 0.7933, ROC AUC: 0.9706,  Avg loss: 0.001777\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.272725 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.503760 [  705/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.635332 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.393229 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.405006 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.586103 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.444645 [ 3525/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.243239 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.398105 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.504906 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7948, Recall: 0.7911, ROC AUC: 0.9705,  Avg loss: 0.001762\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.365416 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.303016 [  705/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.226101 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.426998 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.315147 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.510689 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.470696 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.446648 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.350113 [ 4653/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.311484 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7931, Recall: 0.7901, ROC AUC: 0.9705,  Avg loss: 0.001767\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.578673 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.437173 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.407352 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.328596 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.276396 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.387753 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.345939 [ 3525/ 5250]\n",
      "Accuracy: 96.5%, Loss: 0.155960 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.366065 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.401336 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7971, Recall: 0.7944, ROC AUC: 0.9706,  Avg loss: 0.001776\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.475008 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.404407 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.389008 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.457797 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.568988 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.390403 [ 2961/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.554867 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.490421 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.402018 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.359001 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7958, Recall: 0.7926, ROC AUC: 0.9707,  Avg loss: 0.001779\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.401945 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.393816 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.444789 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.546968 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.423538 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.450449 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.288976 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.462281 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.404696 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.264940 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7963, Recall: 0.7930, ROC AUC: 0.9707,  Avg loss: 0.001788\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.489818 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.450543 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.506015 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.356260 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.366516 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.393406 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.369829 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.481931 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.369911 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.436610 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7966, Recall: 0.7930, ROC AUC: 0.9706,  Avg loss: 0.001813\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.353699 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.311342 [  705/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.206359 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.370752 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.613245 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.537429 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.599836 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.511670 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.569221 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.301920 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7972, Recall: 0.7938, ROC AUC: 0.9706,  Avg loss: 0.001809\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.479913 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.442084 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.493246 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.355225 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.399100 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.339024 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.331017 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.290219 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.482823 [ 4653/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.281509 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7950, Recall: 0.7925, ROC AUC: 0.9707,  Avg loss: 0.001788\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss: 0.513349 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.573806 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.446073 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.379936 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.258762 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.437964 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.361884 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.399060 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.318569 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.563519 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7940, Recall: 0.7913, ROC AUC: 0.9707,  Avg loss: 0.001784\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.378441 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.557020 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.414793 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.569211 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.444440 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.477973 [ 2961/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.626996 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.342645 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.422850 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.461563 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7951, Recall: 0.7921, ROC AUC: 0.9707,  Avg loss: 0.001788\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.528497 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.444543 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.378394 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.303522 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.529990 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.259209 [ 2961/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.224467 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.514913 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.548845 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.323819 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7955, Recall: 0.7930, ROC AUC: 0.9707,  Avg loss: 0.001804\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.610091 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.443273 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.448089 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.387075 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.429986 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.431878 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.512679 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.419262 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.443605 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.463080 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7973, Recall: 0.7953, ROC AUC: 0.9709,  Avg loss: 0.001804\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.557166 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.386174 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.483268 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.640844 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.536373 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.273501 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.499520 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.413145 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.340686 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.381325 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7959, Recall: 0.7941, ROC AUC: 0.9708,  Avg loss: 0.001779\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.325004 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.508812 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.525560 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.510159 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.467625 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.448773 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.460578 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.459234 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.387370 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.458990 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7976, Recall: 0.7953, ROC AUC: 0.9707,  Avg loss: 0.001768\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.503756 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.384895 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.407772 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.415650 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.421002 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.445969 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.328986 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.375786 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.605192 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.347159 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7958, Recall: 0.7935, ROC AUC: 0.9708,  Avg loss: 0.001775\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.365866 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.294632 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.418067 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.584065 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.321290 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.399831 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.460103 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.451526 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.508897 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.642023 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7961, Recall: 0.7928, ROC AUC: 0.9707,  Avg loss: 0.001790\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.340177 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.322927 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.463470 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.426069 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.499304 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.449422 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.334877 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.427346 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.423927 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.317510 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7944, Recall: 0.7914, ROC AUC: 0.9706,  Avg loss: 0.001793\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.366162 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.403409 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.337245 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.430559 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.536750 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.524689 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.337890 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.527443 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.317252 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.527364 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7962, Recall: 0.7932, ROC AUC: 0.9705,  Avg loss: 0.001800\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.402745 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.441775 [  705/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.630897 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.324535 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.430163 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.476949 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.436270 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.487320 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.493342 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.355966 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7973, Recall: 0.7949, ROC AUC: 0.9705,  Avg loss: 0.001780\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.312478 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.515042 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.427268 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.393145 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.391323 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.343286 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.391386 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.541359 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.307463 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.552097 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7943, Recall: 0.7920, ROC AUC: 0.9707,  Avg loss: 0.001810\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.428289 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.530356 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.511626 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.539676 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.397722 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.623705 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.259995 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.508015 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.427963 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.301058 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7971, Recall: 0.7953, ROC AUC: 0.9705,  Avg loss: 0.001791\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.407933 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.405180 [  705/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.491054 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.456456 [ 1833/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.651679 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.519155 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.506429 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.524848 [ 4089/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.712161 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.429293 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7967, Recall: 0.7948, ROC AUC: 0.9705,  Avg loss: 0.001765\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.420255 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.408572 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.375863 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.464392 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.361974 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.362841 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.319681 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.513021 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.464843 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.385003 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7957, Recall: 0.7944, ROC AUC: 0.9706,  Avg loss: 0.001791\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.455713 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.510329 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.504223 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.478784 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.389334 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.336511 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.527994 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.499318 [ 4089/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.278892 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.338307 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7947, Recall: 0.7924, ROC AUC: 0.9704,  Avg loss: 0.001814\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss: 0.637681 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.417454 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.366342 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.451686 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.484934 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.558970 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.476913 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.330774 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.536724 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.511353 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7964, Recall: 0.7933, ROC AUC: 0.9705,  Avg loss: 0.001804\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.294137 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.445945 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.415084 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.336757 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.506006 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.365121 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.316737 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.579218 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.564138 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.322974 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7965, Recall: 0.7931, ROC AUC: 0.9704,  Avg loss: 0.001806\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.431606 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.446186 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.430858 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.386049 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.411468 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.566611 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.347886 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.353470 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.414245 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.377741 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7951, Recall: 0.7914, ROC AUC: 0.9705,  Avg loss: 0.001799\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.380405 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.393875 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.440745 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.409231 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.508837 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.489635 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.373908 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.283626 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.570342 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.480113 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7957, Recall: 0.7923, ROC AUC: 0.9707,  Avg loss: 0.001812\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.531960 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.463150 [  705/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.667574 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.684872 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.484872 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.309376 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.400619 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.467401 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.481502 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.490355 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7953, Recall: 0.7924, ROC AUC: 0.9707,  Avg loss: 0.001785\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss: 0.558696 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.380125 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.462542 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.499063 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.549154 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.474371 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.475790 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.364032 [ 4089/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.502696 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.515071 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7955, Recall: 0.7945, ROC AUC: 0.9707,  Avg loss: 0.001787\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.425073 [  141/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.621200 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.458126 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.448242 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.393700 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.288094 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.445379 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.317778 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.670109 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.520187 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7963, Recall: 0.7941, ROC AUC: 0.9707,  Avg loss: 0.001798\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.237748 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.356197 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.356444 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.418032 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.468928 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.421474 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.329040 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.381777 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.311918 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.668508 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7924, Recall: 0.7910, ROC AUC: 0.9708,  Avg loss: 0.001812\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.455497 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.554725 [  705/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.607695 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.429527 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.579628 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.338583 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.588905 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.347084 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.584906 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.332291 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7939, Recall: 0.7916, ROC AUC: 0.9707,  Avg loss: 0.001786\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.415365 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.497498 [  705/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.252495 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.563947 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.478380 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.405831 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.400508 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.512784 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.453676 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.487918 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7951, Recall: 0.7924, ROC AUC: 0.9707,  Avg loss: 0.001783\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.296475 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.489132 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.244844 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.443847 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.415260 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.446928 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.526338 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.375906 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.597043 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.412620 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7940, Recall: 0.7924, ROC AUC: 0.9707,  Avg loss: 0.001789\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.291152 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.429461 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.454063 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.424714 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.293580 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.381634 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.314240 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.562431 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.489747 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.444276 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7952, Recall: 0.7937, ROC AUC: 0.9707,  Avg loss: 0.001817\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.328131 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.461772 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.333784 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.532587 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.462436 [ 2397/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.594945 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.337808 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.243182 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.409365 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.394277 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7933, Recall: 0.7917, ROC AUC: 0.9707,  Avg loss: 0.001811\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.398613 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.403095 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.567975 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.324597 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.442995 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.406487 [ 2961/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.285992 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.316356 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.398997 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.409750 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7935, Recall: 0.7917, ROC AUC: 0.9705,  Avg loss: 0.001811\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.464346 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.366105 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.392042 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.502165 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.378664 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.312713 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.364339 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.349888 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.449946 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.417677 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7972, Recall: 0.7946, ROC AUC: 0.9706,  Avg loss: 0.001816\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.423613 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.438610 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.358418 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.279144 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.401269 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.413353 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.342813 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.484473 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.393849 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.569563 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7955, Recall: 0.7927, ROC AUC: 0.9707,  Avg loss: 0.001818\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.525935 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.337412 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.378036 [ 1269/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.286456 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.468346 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.556150 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.300983 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.374417 [ 4089/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.569703 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.435396 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7964, Recall: 0.7935, ROC AUC: 0.9706,  Avg loss: 0.001815\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.430857 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.233627 [  705/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.265411 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.429743 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.388006 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.494261 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.419850 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.382805 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.414091 [ 4653/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.757835 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7967, Recall: 0.7944, ROC AUC: 0.9708,  Avg loss: 0.001807\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.376918 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.442094 [  705/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.692361 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.631585 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.517784 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.454090 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.456048 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.345650 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.366802 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.371360 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7983, Recall: 0.7941, ROC AUC: 0.9707,  Avg loss: 0.001782\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.429445 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.479199 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.561716 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.340500 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.534354 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.362693 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.551686 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.363056 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.301359 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.569178 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7964, Recall: 0.7929, ROC AUC: 0.9708,  Avg loss: 0.001792\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.476444 [  141/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.261374 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.385538 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.333294 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.339693 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.428415 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.399780 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.430330 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.422842 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.523389 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.7977, Recall: 0.7942, ROC AUC: 0.9708,  Avg loss: 0.001809\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.328065 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.433820 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.381546 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.475663 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.282311 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.317106 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.439445 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.439996 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.411075 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.510980 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7965, Recall: 0.7921, ROC AUC: 0.9707,  Avg loss: 0.001810\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.445626 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.454824 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.341062 [ 1269/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.566792 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.444061 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.452772 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.405426 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.352189 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.510705 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.492770 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7968, Recall: 0.7924, ROC AUC: 0.9706,  Avg loss: 0.001801\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.453740 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.383208 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.414771 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.396396 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.455849 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.367956 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.436464 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.309895 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.347203 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.438117 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7924, Recall: 0.7888, ROC AUC: 0.9706,  Avg loss: 0.001810\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.374259 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.337154 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.333561 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.434110 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.401639 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.372310 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.451566 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.526483 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.537694 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.455201 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7954, Recall: 0.7917, ROC AUC: 0.9705,  Avg loss: 0.001826\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.480239 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.526842 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.446981 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.560145 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.535483 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.490536 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.547409 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.432066 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.566309 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.442948 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7950, Recall: 0.7906, ROC AUC: 0.9704,  Avg loss: 0.001802\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.446631 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.332903 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.338077 [ 1269/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.633517 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.473405 [ 2397/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.540614 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.476974 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.372789 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.323895 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.303995 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7966, Recall: 0.7931, ROC AUC: 0.9705,  Avg loss: 0.001795\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.545314 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.334258 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.435812 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.532724 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.331313 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.447569 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.341942 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.467409 [ 4089/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.632977 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.476607 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7954, Recall: 0.7922, ROC AUC: 0.9705,  Avg loss: 0.001800\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.369035 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.388106 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.324188 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.331135 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.376228 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.433949 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.455423 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.296200 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.372985 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.383753 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7952, Recall: 0.7914, ROC AUC: 0.9705,  Avg loss: 0.001819\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "Accuracy: 95.0%, Loss: 0.265834 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.365592 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.440031 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.560482 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.379598 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.456458 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.451744 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.434453 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.428736 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.569278 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7936, Recall: 0.7895, ROC AUC: 0.9704,  Avg loss: 0.001820\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.345123 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.327063 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.439304 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.321026 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.473305 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.337446 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.344174 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.331592 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.335476 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.253179 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7933, Recall: 0.7894, ROC AUC: 0.9704,  Avg loss: 0.001833\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.389395 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.398319 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.508971 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.370463 [ 1833/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.182339 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.364388 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.448413 [ 3525/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.615135 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.328112 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.305861 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7927, Recall: 0.7886, ROC AUC: 0.9703,  Avg loss: 0.001847\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.379396 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.461234 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.364434 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.392542 [ 1833/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.195037 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.721788 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.503571 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.383906 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.355606 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.430784 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7939, Recall: 0.7905, ROC AUC: 0.9703,  Avg loss: 0.001823\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.389740 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.328710 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.388369 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.491714 [ 1833/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.302233 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.297446 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.505715 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.465287 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.451690 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.463957 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7940, Recall: 0.7914, ROC AUC: 0.9705,  Avg loss: 0.001846\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.495525 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.308088 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.555299 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.331890 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.426483 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.440479 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.344064 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.371946 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.363610 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.464670 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7934, Recall: 0.7905, ROC AUC: 0.9705,  Avg loss: 0.001838\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.509577 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.466718 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.363931 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.318656 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.490553 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.469961 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.394710 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.446657 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.363369 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.336094 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7939, Recall: 0.7914, ROC AUC: 0.9705,  Avg loss: 0.001843\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.602358 [  141/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.212587 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.482208 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.461715 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.480920 [ 2397/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.586910 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.471156 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.472275 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.558797 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.292605 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7932, Recall: 0.7915, ROC AUC: 0.9705,  Avg loss: 0.001846\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.276896 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.508172 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.272142 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.250919 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.349360 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.294245 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.498211 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.387440 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.468271 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.302553 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7938, Recall: 0.7905, ROC AUC: 0.9703,  Avg loss: 0.001858\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "Accuracy: 94.3%, Loss: 0.267345 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.419033 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.392341 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.418085 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.370657 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.512239 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.409807 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.395560 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.509605 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.216304 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7946, Recall: 0.7903, ROC AUC: 0.9702,  Avg loss: 0.001859\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.349743 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.273780 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.480338 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.392041 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.512281 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.495933 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.341138 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.559376 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.567903 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.533119 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7947, Recall: 0.7912, ROC AUC: 0.9702,  Avg loss: 0.001835\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.479158 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.408788 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.487849 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.344853 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.393212 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.277371 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.352827 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.399079 [ 4089/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.337034 [ 4653/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.584781 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7945, Recall: 0.7912, ROC AUC: 0.9702,  Avg loss: 0.001828\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.348367 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.400194 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.418187 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.269341 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.454462 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.450431 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.464610 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.428103 [ 4089/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.638685 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.480200 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7928, Recall: 0.7904, ROC AUC: 0.9703,  Avg loss: 0.001813\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.434157 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.309801 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.503869 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.357507 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.408202 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.412094 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.435569 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.396008 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.374854 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.421602 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7947, Recall: 0.7914, ROC AUC: 0.9703,  Avg loss: 0.001824\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.453974 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.448985 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.347817 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.465243 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.520952 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.312837 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.478144 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.456408 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.518518 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.307718 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7943, Recall: 0.7912, ROC AUC: 0.9704,  Avg loss: 0.001849\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.366896 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.479720 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.440716 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.382709 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.414366 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.355000 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.391470 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.583694 [ 4089/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.244474 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.478382 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7954, Recall: 0.7910, ROC AUC: 0.9704,  Avg loss: 0.001856\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.338827 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.498630 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.454582 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.392784 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.376593 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.271771 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.349311 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.442082 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.568020 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.424855 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7959, Recall: 0.7927, ROC AUC: 0.9706,  Avg loss: 0.001833\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.553535 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.454554 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.350290 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.462953 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.471290 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.436312 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.481779 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.438864 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.376296 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.434454 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7956, Recall: 0.7932, ROC AUC: 0.9704,  Avg loss: 0.001821\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.437434 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.379553 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.316056 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.448996 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.422842 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.409231 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.455170 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.371515 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.468802 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.359977 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7937, Recall: 0.7914, ROC AUC: 0.9703,  Avg loss: 0.001825\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.502570 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.363037 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.481362 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.370581 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.472991 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.366950 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.384933 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.522277 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.231218 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.508592 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7944, Recall: 0.7914, ROC AUC: 0.9702,  Avg loss: 0.001839\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.388545 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.368669 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.282598 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.274705 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.553260 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.339308 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.368919 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.506097 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.436644 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.295656 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7945, Recall: 0.7916, ROC AUC: 0.9701,  Avg loss: 0.001847\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.393033 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.498813 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.461123 [ 1269/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.581981 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.465752 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.406023 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.487971 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.445125 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.343885 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.262764 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7912, Recall: 0.7887, ROC AUC: 0.9701,  Avg loss: 0.001852\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.403912 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.415553 [  705/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.276636 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.540278 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.423440 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.331914 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.377949 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.276485 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.445130 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.255074 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7924, Recall: 0.7897, ROC AUC: 0.9702,  Avg loss: 0.001858\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.573358 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.492643 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.582171 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.367651 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.303624 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.443945 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.403413 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.584864 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.462333 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.434661 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7943, Recall: 0.7905, ROC AUC: 0.9702,  Avg loss: 0.001854\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.380756 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.332375 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.420653 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.438635 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.301618 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.410986 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.447578 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.479686 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.369697 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.365632 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7922, Recall: 0.7884, ROC AUC: 0.9703,  Avg loss: 0.001840\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.345599 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.320410 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.330084 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.485662 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.408635 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.314621 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.418094 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.492742 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.401970 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.465711 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7956, Recall: 0.7913, ROC AUC: 0.9703,  Avg loss: 0.001845\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.360905 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.494097 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.489180 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.426936 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.422992 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.443650 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.468923 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.434917 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.369451 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.473102 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7969, Recall: 0.7933, ROC AUC: 0.9703,  Avg loss: 0.001837\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.451569 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.400479 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.548036 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.532501 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.380323 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.405140 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.414900 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.283212 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.527153 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.333630 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7952, Recall: 0.7913, ROC AUC: 0.9703,  Avg loss: 0.001826\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.318254 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.419922 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.440917 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.474453 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.496285 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.460112 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.417748 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.363014 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.509262 [ 4653/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.303269 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7938, Recall: 0.7898, ROC AUC: 0.9702,  Avg loss: 0.001839\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.491885 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.451116 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.367078 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.417870 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.401314 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.462333 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.385214 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.388918 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.473822 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.395412 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7981, Recall: 0.7929, ROC AUC: 0.9701,  Avg loss: 0.001844\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.419860 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.487873 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.609770 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.370697 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.428743 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.490816 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.475302 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.429195 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.318047 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.454559 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.52%, Precision: 0.8000, Recall: 0.7944, ROC AUC: 0.9702,  Avg loss: 0.001849\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.535865 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.443848 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.291403 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.560115 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.486408 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.566281 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.306787 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.398281 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.443923 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.247343 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7964, Recall: 0.7924, ROC AUC: 0.9703,  Avg loss: 0.001869\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.511011 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.413251 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.473867 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.296443 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.497697 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.502797 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.337791 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.502406 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.396612 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.322929 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7943, Recall: 0.7916, ROC AUC: 0.9702,  Avg loss: 0.001866\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.459051 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.353500 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.420213 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.459554 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.338717 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.435095 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.439905 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.414130 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.474386 [ 4653/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.714147 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7955, Recall: 0.7922, ROC AUC: 0.9701,  Avg loss: 0.001854\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.521412 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.572471 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.389414 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.358128 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.363162 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.333924 [ 2961/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.532622 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.433870 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.448405 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.392674 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7947, Recall: 0.7913, ROC AUC: 0.9701,  Avg loss: 0.001841\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.604137 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.395761 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.404327 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.467659 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.530060 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.390518 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.408783 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.443671 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.333406 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.277675 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7958, Recall: 0.7927, ROC AUC: 0.9702,  Avg loss: 0.001841\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.460688 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.433922 [  705/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.470087 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.472258 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.594016 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.479854 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.509646 [ 3525/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.578872 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.516151 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.435792 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7916, Recall: 0.7897, ROC AUC: 0.9703,  Avg loss: 0.001842\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.297951 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.520840 [  705/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.525721 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.405395 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.414016 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.590627 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.286089 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.356611 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.563762 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.261952 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7900, Recall: 0.7888, ROC AUC: 0.9702,  Avg loss: 0.001849\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.636248 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.354268 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.530090 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.459260 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.363035 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.435779 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.410522 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.352122 [ 4089/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.241874 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.412612 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7911, Recall: 0.7897, ROC AUC: 0.9703,  Avg loss: 0.001837\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.398558 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.480183 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.559217 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.454533 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.510127 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.368347 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.392938 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.432379 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.290079 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.381808 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7909, Recall: 0.7906, ROC AUC: 0.9704,  Avg loss: 0.001833\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.374476 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.442978 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.351343 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.315209 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.412336 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.329299 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.307379 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.328496 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.487650 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.383375 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7934, Recall: 0.7926, ROC AUC: 0.9705,  Avg loss: 0.001843\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.367686 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.378463 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.348544 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.481247 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.357327 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.329894 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.413664 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.368535 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.299453 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.234211 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7921, Recall: 0.7909, ROC AUC: 0.9705,  Avg loss: 0.001873\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.340345 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.377845 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.305219 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.478363 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.332047 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.334272 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.325434 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.466924 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.467728 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.423891 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7940, Recall: 0.7919, ROC AUC: 0.9703,  Avg loss: 0.001876\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.456909 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.353484 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.414315 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.465395 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.416306 [ 2397/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.722889 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.332711 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.346358 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.317167 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.414092 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7922, Recall: 0.7898, ROC AUC: 0.9704,  Avg loss: 0.001856\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.355586 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.354133 [  705/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.515187 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.442038 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.326433 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.387082 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.438156 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.243755 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.435916 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.363775 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7950, Recall: 0.7915, ROC AUC: 0.9703,  Avg loss: 0.001850\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "Accuracy: 94.3%, Loss: 0.261546 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.381737 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.478805 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.405542 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.420717 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.446707 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.315835 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.497255 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.359602 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.416098 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7975, Recall: 0.7934, ROC AUC: 0.9704,  Avg loss: 0.001851\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.337675 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.362718 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.528370 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.528990 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.433558 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.353107 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.334204 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.361668 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.499040 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.287518 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7969, Recall: 0.7926, ROC AUC: 0.9704,  Avg loss: 0.001846\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss: 0.626900 [  141/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.583386 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.439914 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.262034 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.395886 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.477069 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.586722 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.422994 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.411042 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.309446 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7927, Recall: 0.7898, ROC AUC: 0.9704,  Avg loss: 0.001825\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.344722 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.262535 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.410641 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.465623 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.446738 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.376067 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.486988 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.472008 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.368267 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.305288 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7948, Recall: 0.7908, ROC AUC: 0.9705,  Avg loss: 0.001826\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.311726 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.401894 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.335289 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.429928 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.342622 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.506187 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.422618 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.586237 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.381680 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.299532 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7948, Recall: 0.7917, ROC AUC: 0.9705,  Avg loss: 0.001833\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.559144 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.371203 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.402141 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.273119 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.404756 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.359875 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.422623 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.408032 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.448074 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.430366 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7921, Recall: 0.7889, ROC AUC: 0.9706,  Avg loss: 0.001841\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "Accuracy: 94.3%, Loss: 0.302256 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.426413 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.320968 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.545499 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.401846 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.318394 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.465500 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.604674 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.329938 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.475763 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7936, Recall: 0.7897, ROC AUC: 0.9704,  Avg loss: 0.001852\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.358606 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.395704 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.463444 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.406631 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.528328 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.388503 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.408870 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.488821 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.382579 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.397450 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7957, Recall: 0.7927, ROC AUC: 0.9704,  Avg loss: 0.001869\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.296984 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.555387 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.331298 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.445842 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.519901 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.358401 [ 2961/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.323911 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.338894 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.409134 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.308978 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7896, Recall: 0.7871, ROC AUC: 0.9703,  Avg loss: 0.001871\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.272940 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.388625 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.302810 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.333525 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.274769 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.477206 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.380097 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.331805 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.527536 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.440353 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7923, Recall: 0.7897, ROC AUC: 0.9705,  Avg loss: 0.001870\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.440682 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.612517 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.316490 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.567279 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.354048 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.362283 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.441252 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.315631 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.452926 [ 4653/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.224347 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7916, Recall: 0.7892, ROC AUC: 0.9705,  Avg loss: 0.001846\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.273149 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.276931 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.308778 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.360316 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.420702 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.552134 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.502723 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.415765 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.350248 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.428937 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7904, Recall: 0.7888, ROC AUC: 0.9704,  Avg loss: 0.001844\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.307681 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.568258 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.353886 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.355781 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.295284 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.432534 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.540047 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.314103 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.485355 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.373004 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7886, Recall: 0.7860, ROC AUC: 0.9703,  Avg loss: 0.001863\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.428439 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.404674 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.485593 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.305751 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.370588 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.375347 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.447239 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.421549 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.295647 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.483971 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7891, Recall: 0.7871, ROC AUC: 0.9704,  Avg loss: 0.001857\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.526894 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.389360 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.358957 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.371409 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.453103 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.428858 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.425702 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.501498 [ 4089/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.580786 [ 4653/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.637159 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7882, Recall: 0.7862, ROC AUC: 0.9702,  Avg loss: 0.001866\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.372727 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.483830 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.374829 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.327601 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.367749 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.363970 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.471643 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.327570 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.354746 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.474286 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7929, Recall: 0.7912, ROC AUC: 0.9702,  Avg loss: 0.001871\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.333635 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.677338 [  705/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.582053 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.303753 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.392837 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.445937 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.445816 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.338255 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.412813 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.274774 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7923, Recall: 0.7902, ROC AUC: 0.9703,  Avg loss: 0.001851\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.468181 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.388365 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.401069 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.352107 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.353728 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.427310 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.510601 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.443304 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.366388 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.414770 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7903, Recall: 0.7892, ROC AUC: 0.9703,  Avg loss: 0.001857\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.503844 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.396324 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.408165 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.365196 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.388241 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.513588 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.475063 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.406105 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.379565 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.289091 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7905, Recall: 0.7891, ROC AUC: 0.9702,  Avg loss: 0.001842\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.343889 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.478901 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.270691 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.416619 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.406589 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.452642 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.370583 [ 3525/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.523965 [ 4089/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.590673 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.336808 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7923, Recall: 0.7900, ROC AUC: 0.9703,  Avg loss: 0.001848\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.421987 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.284356 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.341525 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.492270 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.410727 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.447992 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.447510 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.454077 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.383513 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.391217 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7939, Recall: 0.7912, ROC AUC: 0.9703,  Avg loss: 0.001861\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.507483 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.553689 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.373740 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.384220 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.484086 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.484346 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.458617 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.438305 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.403142 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.530115 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7948, Recall: 0.7922, ROC AUC: 0.9702,  Avg loss: 0.001887\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.401838 [  141/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.599415 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.438201 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.317354 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.355610 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.288401 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.298298 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.404934 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.299705 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.340234 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7956, Recall: 0.7928, ROC AUC: 0.9703,  Avg loss: 0.001894\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.469750 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.435894 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.587714 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.441387 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.356417 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.357553 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.616875 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.532391 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.432702 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.536003 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7971, Recall: 0.7938, ROC AUC: 0.9704,  Avg loss: 0.001872\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.518087 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.514542 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.333384 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.453282 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.397309 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.420411 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.413974 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.419559 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.483356 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.297253 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7967, Recall: 0.7936, ROC AUC: 0.9705,  Avg loss: 0.001855\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.334017 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.368960 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.378618 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.440238 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.434578 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.492359 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.334912 [ 3525/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.251992 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.361579 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.458924 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.62%, Precision: 0.7985, Recall: 0.7957, ROC AUC: 0.9703,  Avg loss: 0.001867\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.308288 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.537825 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.235933 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.467539 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.435850 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.386941 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.493010 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.490141 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.481629 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.583478 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.43%, Precision: 0.7968, Recall: 0.7939, ROC AUC: 0.9703,  Avg loss: 0.001864\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.610097 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.359579 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.274288 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.277669 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.423612 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.452923 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.321051 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.410634 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.538760 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.306113 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7956, Recall: 0.7930, ROC AUC: 0.9702,  Avg loss: 0.001861\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.424244 [  141/ 5250]\n",
      "Accuracy: 96.5%, Loss: 0.261452 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.314458 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.410404 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.411485 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.515469 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.439818 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.504633 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.483687 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.589537 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7935, Recall: 0.7911, ROC AUC: 0.9703,  Avg loss: 0.001856\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.328109 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.267665 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.347155 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.439049 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.369656 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.328562 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.250988 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.425185 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.555107 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.341082 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7933, Recall: 0.7911, ROC AUC: 0.9704,  Avg loss: 0.001852\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.414724 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.351578 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.598020 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.403021 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.388190 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.455909 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.304420 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.392341 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.333170 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.380791 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7930, Recall: 0.7911, ROC AUC: 0.9705,  Avg loss: 0.001871\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.302725 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.491915 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.320661 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.379737 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.418221 [ 2397/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.651103 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.407526 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.453051 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.315475 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.417656 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7897, Recall: 0.7874, ROC AUC: 0.9704,  Avg loss: 0.001866\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.524808 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.355162 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.364806 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.327430 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.568946 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.419839 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.434865 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.491469 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.394592 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.462653 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7893, Recall: 0.7874, ROC AUC: 0.9703,  Avg loss: 0.001856\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.462739 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.314939 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.420277 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.394346 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.302953 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.442527 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.455670 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.446596 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.367704 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.419054 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7916, Recall: 0.7893, ROC AUC: 0.9703,  Avg loss: 0.001861\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.362983 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.364343 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.323968 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.566801 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.317725 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.392388 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.330586 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.478874 [ 4089/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.652614 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.343743 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7913, Recall: 0.7893, ROC AUC: 0.9703,  Avg loss: 0.001882\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.397577 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.356211 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.366982 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.442565 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.277562 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.576992 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.476044 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.312665 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.388779 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.379320 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7915, Recall: 0.7892, ROC AUC: 0.9703,  Avg loss: 0.001874\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.348591 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.445866 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.345235 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.413681 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.368360 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.430265 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.469735 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.428507 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.487664 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.363372 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7945, Recall: 0.7924, ROC AUC: 0.9703,  Avg loss: 0.001868\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.538797 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.368038 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.516895 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.470929 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.328713 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.359795 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.264705 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.352085 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.372580 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.355362 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7942, Recall: 0.7924, ROC AUC: 0.9703,  Avg loss: 0.001882\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss: 0.524422 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.479901 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.332345 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.515475 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.472226 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.471043 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.359439 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.311291 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.401661 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.502312 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7924, Recall: 0.7906, ROC AUC: 0.9702,  Avg loss: 0.001863\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "Accuracy: 95.0%, Loss: 0.204060 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.519023 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.369997 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.237061 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.449250 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.386307 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.405527 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.424241 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.442980 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.443467 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7940, Recall: 0.7924, ROC AUC: 0.9702,  Avg loss: 0.001883\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.480006 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.532717 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.363812 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.559247 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.364288 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.456325 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.305246 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.351990 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.351675 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.353026 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7939, Recall: 0.7924, ROC AUC: 0.9703,  Avg loss: 0.001872\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.331985 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.542998 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.449437 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.472951 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.324306 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.407303 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.304474 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.477769 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.337379 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.517122 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7930, Recall: 0.7915, ROC AUC: 0.9702,  Avg loss: 0.001869\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.374418 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.396724 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.348462 [ 1269/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.186200 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.460483 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.373763 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.374975 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.522382 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.514787 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.438538 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7942, Recall: 0.7924, ROC AUC: 0.9703,  Avg loss: 0.001871\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.414542 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.420597 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.486322 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.508302 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.455159 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.364340 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.420415 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.419155 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.584352 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.417083 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7925, Recall: 0.7911, ROC AUC: 0.9704,  Avg loss: 0.001853\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.316002 [  141/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.247618 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.436117 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.420919 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.298282 [ 2397/ 5250]\n",
      "Accuracy: 96.5%, Loss: 0.209656 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.309242 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.469435 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.458618 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.338103 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7948, Recall: 0.7933, ROC AUC: 0.9704,  Avg loss: 0.001854\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.457282 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.433996 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.331347 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.318826 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.332748 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.317354 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.359974 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.527110 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.384249 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.394990 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7933, Recall: 0.7911, ROC AUC: 0.9702,  Avg loss: 0.001879\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "Accuracy: 95.0%, Loss: 0.303757 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.286658 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.443339 [ 1269/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.212463 [ 1833/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.296477 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.380730 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.399091 [ 3525/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.629220 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.510185 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.430988 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7951, Recall: 0.7920, ROC AUC: 0.9703,  Avg loss: 0.001897\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.494406 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.470921 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.509680 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.398725 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.302153 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.243577 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.529351 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.290415 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.492684 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.397762 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7923, Recall: 0.7898, ROC AUC: 0.9702,  Avg loss: 0.001885\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.285061 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.376404 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.388722 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.304784 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.267745 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.291666 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.415847 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.349856 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.328929 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.380898 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7940, Recall: 0.7917, ROC AUC: 0.9703,  Avg loss: 0.001887\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "Accuracy: 95.7%, Loss: 0.211264 [  141/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.538965 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.522364 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.465424 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.328596 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.484329 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.354209 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.355695 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.313662 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.448177 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7952, Recall: 0.7923, ROC AUC: 0.9703,  Avg loss: 0.001887\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.313838 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.459899 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.530816 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.291090 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.304272 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.320739 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.437333 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.340105 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.318584 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.426800 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7917, Recall: 0.7890, ROC AUC: 0.9702,  Avg loss: 0.001895\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.368611 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.501980 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.442341 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.459305 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.348253 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.404291 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.343780 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.384331 [ 4089/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.553274 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.384913 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7895, Recall: 0.7872, ROC AUC: 0.9700,  Avg loss: 0.001890\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.331429 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.324915 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.363427 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.423499 [ 1833/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.284442 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.369309 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.280695 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.326334 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.396642 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.299379 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7911, Recall: 0.7881, ROC AUC: 0.9703,  Avg loss: 0.001916\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.329576 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.317955 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.355990 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.488955 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.390010 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.294684 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.601364 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.379418 [ 4089/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.293954 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.353521 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7917, Recall: 0.7879, ROC AUC: 0.9702,  Avg loss: 0.001927\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.499871 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.428237 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.388949 [ 1269/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.223816 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.527457 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.428775 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.310092 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.517584 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.352914 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.279660 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7926, Recall: 0.7890, ROC AUC: 0.9702,  Avg loss: 0.001909\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.369853 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.356490 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.353089 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.471519 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.444469 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.469842 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.432663 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.360384 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.449419 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.562040 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7924, Recall: 0.7891, ROC AUC: 0.9701,  Avg loss: 0.001910\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.304481 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.435268 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.387542 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.378885 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.398940 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.459526 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.470894 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.454248 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.337857 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.443366 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7903, Recall: 0.7872, ROC AUC: 0.9702,  Avg loss: 0.001885\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.414560 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.338963 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.406933 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.499054 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.290971 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.472134 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.313518 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.333176 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.296896 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.451813 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7917, Recall: 0.7887, ROC AUC: 0.9702,  Avg loss: 0.001894\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.427333 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.360464 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.473628 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.332806 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.448323 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.409802 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.397590 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.440263 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.439230 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.410046 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7910, Recall: 0.7879, ROC AUC: 0.9703,  Avg loss: 0.001877\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.357775 [  141/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.623433 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.381743 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.407861 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.422570 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.435788 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.332187 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.387170 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.353835 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.529103 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7931, Recall: 0.7892, ROC AUC: 0.9702,  Avg loss: 0.001866\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.343187 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.485793 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.450288 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.395698 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.329310 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.437941 [ 2961/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.605966 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.417442 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.332131 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.305223 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7940, Recall: 0.7900, ROC AUC: 0.9701,  Avg loss: 0.001865\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.332551 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.379759 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.305081 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.372911 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.491048 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.184167 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.371758 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.448207 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.505900 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.309667 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7927, Recall: 0.7893, ROC AUC: 0.9700,  Avg loss: 0.001886\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.365118 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.474145 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.542561 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.460800 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.427645 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.248957 [ 2961/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.237164 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.500083 [ 4089/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.606201 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.367095 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7922, Recall: 0.7892, ROC AUC: 0.9700,  Avg loss: 0.001889\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.587309 [  141/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.577888 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.421834 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.313971 [ 1833/ 5250]\n",
      "Accuracy: 97.2%, Loss: 0.174088 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.320882 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.517521 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.449749 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.447286 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.490642 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7918, Recall: 0.7900, ROC AUC: 0.9700,  Avg loss: 0.001889\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.273849 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.561775 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.421760 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.526703 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.359282 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.444544 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.404256 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.346205 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.314184 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.469902 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7904, Recall: 0.7881, ROC AUC: 0.9701,  Avg loss: 0.001875\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.337927 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.267389 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.361423 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.359260 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.483303 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.299256 [ 2961/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.638892 [ 3525/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.236417 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.465833 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.427674 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7897, Recall: 0.7883, ROC AUC: 0.9701,  Avg loss: 0.001883\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.317761 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.410963 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.483604 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.488010 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.444268 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.407065 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.554907 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.532556 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.616194 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.367566 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7924, Recall: 0.7909, ROC AUC: 0.9699,  Avg loss: 0.001872\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.328650 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.330069 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.550828 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.432014 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.389960 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.309331 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.340003 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.334709 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.627874 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.459641 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7907, Recall: 0.7887, ROC AUC: 0.9699,  Avg loss: 0.001872\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.376230 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.304904 [  705/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.571200 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.256308 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.346923 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.386510 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.453229 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.407394 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.296018 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.432336 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7946, Recall: 0.7912, ROC AUC: 0.9699,  Avg loss: 0.001879\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.442632 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.277272 [  705/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.245290 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.403791 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.516066 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.554307 [ 2961/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.556824 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.349733 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.344257 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.489759 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7951, Recall: 0.7912, ROC AUC: 0.9698,  Avg loss: 0.001888\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.291142 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.410546 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.345055 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.347714 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.313978 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.454421 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.431509 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.441276 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.512737 [ 4653/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.506762 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7968, Recall: 0.7933, ROC AUC: 0.9699,  Avg loss: 0.001909\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.387241 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.382563 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.461546 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.316590 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.394849 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.519893 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.355654 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.336939 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.314867 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.493954 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.33%, Precision: 0.7972, Recall: 0.7934, ROC AUC: 0.9700,  Avg loss: 0.001897\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.400693 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.317220 [  705/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.594562 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.329500 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.260225 [ 2397/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.222467 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.245656 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.445148 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.444272 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.557362 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7943, Recall: 0.7907, ROC AUC: 0.9700,  Avg loss: 0.001905\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.354183 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.322482 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.456583 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.368892 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.406073 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.352407 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.376515 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.518618 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.422330 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.535023 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.24%, Precision: 0.7959, Recall: 0.7926, ROC AUC: 0.9699,  Avg loss: 0.001905\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.418631 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.482911 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.487651 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.503633 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.265286 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.378225 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.278978 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.281184 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.420143 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.327093 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7924, Recall: 0.7894, ROC AUC: 0.9700,  Avg loss: 0.001896\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.396793 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.311198 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.528446 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.377890 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.472257 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.383993 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.431425 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.422049 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.356966 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.256683 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7904, Recall: 0.7863, ROC AUC: 0.9702,  Avg loss: 0.001880\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.459195 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.315501 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.432708 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.434341 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.448500 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.372421 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.343095 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.295835 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.413445 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.346730 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7906, Recall: 0.7871, ROC AUC: 0.9702,  Avg loss: 0.001885\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.462111 [  141/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.310846 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.247271 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.342767 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.284394 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.344188 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.329761 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.456639 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.545441 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.381810 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7898, Recall: 0.7859, ROC AUC: 0.9701,  Avg loss: 0.001909\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.358006 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.416651 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.444490 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.447850 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.445213 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.440871 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.226114 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.481899 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.423413 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.280159 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7903, Recall: 0.7861, ROC AUC: 0.9701,  Avg loss: 0.001886\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.467970 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.451675 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.274871 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.392401 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.518333 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.481164 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.382053 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.310812 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.376384 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.385448 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7889, Recall: 0.7862, ROC AUC: 0.9702,  Avg loss: 0.001887\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.407979 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.306845 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.443929 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.452301 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.449686 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.209119 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.425656 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.497067 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.478683 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.316568 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7883, Recall: 0.7851, ROC AUC: 0.9702,  Avg loss: 0.001892\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.421811 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.402230 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.386437 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.457078 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.508195 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.398741 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.309026 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.333582 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.408857 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.337155 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7885, Recall: 0.7855, ROC AUC: 0.9701,  Avg loss: 0.001884\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.346490 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.403765 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.471470 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.232218 [ 1833/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.235045 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.428802 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.390760 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.341393 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.318867 [ 4653/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.213867 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7922, Recall: 0.7882, ROC AUC: 0.9701,  Avg loss: 0.001917\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.375301 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.435270 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.505123 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.322039 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.448045 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.492477 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.313250 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.471706 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.287096 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.568247 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7905, Recall: 0.7883, ROC AUC: 0.9702,  Avg loss: 0.001926\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.510679 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.362110 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.359058 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.391428 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.431234 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.470247 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.428568 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.442616 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.531680 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.489435 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7897, Recall: 0.7871, ROC AUC: 0.9700,  Avg loss: 0.001909\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.360613 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.311460 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.379790 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.516361 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.405180 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.554049 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.284413 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.408624 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.358570 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.479815 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7930, Recall: 0.7901, ROC AUC: 0.9698,  Avg loss: 0.001912\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.522273 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.364943 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.419493 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.316733 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.352093 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.267836 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.377095 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.410750 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.414883 [ 4653/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.527786 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7910, Recall: 0.7882, ROC AUC: 0.9700,  Avg loss: 0.001920\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.357819 [  141/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.252788 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.442551 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.336469 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.361611 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.301624 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.369921 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.229370 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.494711 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.436375 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7919, Recall: 0.7882, ROC AUC: 0.9698,  Avg loss: 0.001916\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.695581 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.380863 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.284283 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.340080 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.332240 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.416066 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.353866 [ 3525/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.238114 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.274920 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.490190 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7918, Recall: 0.7883, ROC AUC: 0.9698,  Avg loss: 0.001919\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.428386 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.453140 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.393257 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.606115 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.506945 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.383221 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.500344 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.353326 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.428484 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.312129 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7918, Recall: 0.7883, ROC AUC: 0.9700,  Avg loss: 0.001932\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.333375 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.309716 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.333736 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.607651 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.387628 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.396252 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.350348 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.280683 [ 4089/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.248601 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.516310 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7869, Recall: 0.7839, ROC AUC: 0.9699,  Avg loss: 0.001937\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.357300 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.309134 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.401429 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.310557 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.383482 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.442078 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.369999 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.255999 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.455044 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.375338 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7888, Recall: 0.7848, ROC AUC: 0.9700,  Avg loss: 0.001935\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.492674 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.411458 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.326114 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.335493 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.313528 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.471633 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.403921 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.466988 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.468304 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.497345 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7900, Recall: 0.7854, ROC AUC: 0.9700,  Avg loss: 0.001922\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.341787 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.358940 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.508906 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.398022 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.430164 [ 2397/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.263426 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.526617 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.440072 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.467871 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.356118 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7892, Recall: 0.7853, ROC AUC: 0.9701,  Avg loss: 0.001922\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "Accuracy: 94.3%, Loss: 0.279829 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.584827 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.348194 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.422659 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.375339 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.418356 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.373824 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.370281 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.371666 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.361627 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7908, Recall: 0.7875, ROC AUC: 0.9701,  Avg loss: 0.001928\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.309904 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.373181 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.499818 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.354679 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.580991 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.402533 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.472616 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.312503 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.408548 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.503906 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7904, Recall: 0.7860, ROC AUC: 0.9700,  Avg loss: 0.001935\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "Accuracy: 94.3%, Loss: 0.221379 [  141/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.243383 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.546477 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.299605 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.284974 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.413437 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.382772 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.485669 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.522250 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.496968 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7911, Recall: 0.7879, ROC AUC: 0.9699,  Avg loss: 0.001930\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "Accuracy: 95.7%, Loss: 0.187477 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.608951 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.520959 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.565713 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.399188 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.381969 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.377219 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.400530 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.537771 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.332513 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7897, Recall: 0.7861, ROC AUC: 0.9699,  Avg loss: 0.001935\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.376173 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.503231 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.285172 [ 1269/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.728168 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.506350 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.428589 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.399390 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.422344 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.339261 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.357945 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7949, Recall: 0.7902, ROC AUC: 0.9697,  Avg loss: 0.001925\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.521357 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.264508 [  705/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.498970 [ 1269/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.237911 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.327648 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.581186 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.374141 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.505130 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.402745 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.421875 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7912, Recall: 0.7869, ROC AUC: 0.9699,  Avg loss: 0.001924\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.292361 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.440217 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.343407 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.389225 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.609709 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.472424 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.403863 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.308403 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.378936 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.432532 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7912, Recall: 0.7872, ROC AUC: 0.9697,  Avg loss: 0.001917\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.415508 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.430764 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.563835 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.446454 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.471679 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.419421 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.388828 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.350737 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.554137 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.423568 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7900, Recall: 0.7861, ROC AUC: 0.9697,  Avg loss: 0.001907\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.369732 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.380414 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.279127 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.378487 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.498234 [ 2397/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.586464 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.443515 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.479528 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.466520 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.283977 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7908, Recall: 0.7862, ROC AUC: 0.9697,  Avg loss: 0.001909\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.406498 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.449504 [  705/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.252772 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.485410 [ 1833/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.260306 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.342429 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.431677 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.523486 [ 4089/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.576316 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.317400 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7908, Recall: 0.7862, ROC AUC: 0.9698,  Avg loss: 0.001888\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.301995 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.400011 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.381846 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.404257 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.254601 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.356975 [ 2961/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.279775 [ 3525/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.537858 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.397345 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.425223 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7932, Recall: 0.7896, ROC AUC: 0.9698,  Avg loss: 0.001909\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.257276 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.393696 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.487974 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.497333 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.439036 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.417836 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.377158 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.605252 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.440375 [ 4653/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.232309 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7925, Recall: 0.7874, ROC AUC: 0.9698,  Avg loss: 0.001905\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.411929 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.313600 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.503909 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.409497 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.535624 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.380148 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.340633 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.484211 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.438451 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.568559 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7917, Recall: 0.7874, ROC AUC: 0.9699,  Avg loss: 0.001911\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.361551 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.311051 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.489978 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.367921 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.312446 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.470659 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.462352 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.344775 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.282940 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.383617 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7894, Recall: 0.7868, ROC AUC: 0.9700,  Avg loss: 0.001915\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "Accuracy: 96.5%, Loss: 0.162724 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.380735 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.384164 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.360312 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.293149 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.537548 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.356803 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.292739 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.459946 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.340060 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7914, Recall: 0.7889, ROC AUC: 0.9700,  Avg loss: 0.001943\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.547491 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.402847 [  705/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.300358 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.483337 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.269626 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.435285 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.497531 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.329010 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.439523 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.391999 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7888, Recall: 0.7857, ROC AUC: 0.9700,  Avg loss: 0.001922\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.404544 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.373214 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.386262 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.244698 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.428864 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.370525 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.298560 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.336398 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.534887 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.430017 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7895, Recall: 0.7866, ROC AUC: 0.9699,  Avg loss: 0.001928\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.366547 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.368188 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.506623 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.417344 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.444386 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.361985 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.350748 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.504644 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.471240 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.356508 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7886, Recall: 0.7855, ROC AUC: 0.9697,  Avg loss: 0.001940\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.391016 [  141/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.259539 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.417780 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.351407 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.329228 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.340887 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.522982 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.484516 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.442754 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.413030 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7892, Recall: 0.7867, ROC AUC: 0.9697,  Avg loss: 0.001943\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.277862 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.460666 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.262231 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.357162 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.401462 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.436380 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.431597 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.293633 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.273188 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.420679 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7883, Recall: 0.7853, ROC AUC: 0.9698,  Avg loss: 0.001962\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.325931 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.465845 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.356160 [ 1269/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.212810 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.451252 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.442035 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.420752 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.285255 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.429580 [ 4653/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.275947 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7895, Recall: 0.7875, ROC AUC: 0.9698,  Avg loss: 0.001953\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.509644 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.637710 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.384959 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.246665 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.467996 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.259044 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.442247 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.321284 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.301755 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.400597 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7886, Recall: 0.7868, ROC AUC: 0.9698,  Avg loss: 0.001927\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.424636 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.416657 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.396719 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.311261 [ 1833/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.247300 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.264867 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.382615 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.420199 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.542644 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.399035 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7896, Recall: 0.7878, ROC AUC: 0.9698,  Avg loss: 0.001934\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.289621 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.362774 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.263901 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.420434 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.310769 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.414835 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.275739 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.397335 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.253736 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.288270 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7910, Recall: 0.7887, ROC AUC: 0.9697,  Avg loss: 0.001909\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.318891 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.451965 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.323893 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.323209 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.232723 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.348902 [ 2961/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.586314 [ 3525/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.270404 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.563594 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.300805 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7912, Recall: 0.7896, ROC AUC: 0.9698,  Avg loss: 0.001922\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.230181 [  141/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.233003 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.356548 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.477544 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.437625 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.377075 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.411151 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.314984 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.247637 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.364086 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7895, Recall: 0.7879, ROC AUC: 0.9699,  Avg loss: 0.001936\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.285547 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.333371 [  705/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.649758 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.426764 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.355145 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.276569 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.451202 [ 3525/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.560761 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.404398 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.523419 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.14%, Precision: 0.7934, Recall: 0.7915, ROC AUC: 0.9699,  Avg loss: 0.001943\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.344755 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.408249 [  705/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.196908 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.502442 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.366349 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.296124 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.290035 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.354697 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.297117 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.461318 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7914, Recall: 0.7896, ROC AUC: 0.9698,  Avg loss: 0.001945\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.394703 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.448947 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.354788 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.489881 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.336107 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.343738 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.420632 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.304256 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.345614 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.307628 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7883, Recall: 0.7869, ROC AUC: 0.9698,  Avg loss: 0.001935\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.435825 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.331709 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.409524 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.439467 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.461685 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.397984 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.309476 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.341592 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.365418 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.354086 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7891, Recall: 0.7878, ROC AUC: 0.9698,  Avg loss: 0.001941\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.415579 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.282858 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.537818 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.541458 [ 1833/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.240350 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.385120 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.405326 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.357056 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.428845 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.294403 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7874, Recall: 0.7859, ROC AUC: 0.9697,  Avg loss: 0.001933\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.255748 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.463951 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.442492 [ 1269/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.520424 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.275967 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.312950 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.391815 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.317741 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.346399 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.561521 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7876, Recall: 0.7860, ROC AUC: 0.9697,  Avg loss: 0.001927\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.344595 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.412244 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.399356 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.482730 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.550612 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.436447 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.468409 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.395739 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.351944 [ 4653/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.282400 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7915, Recall: 0.7895, ROC AUC: 0.9699,  Avg loss: 0.001924\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.224752 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.439289 [  705/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.241082 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.405173 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.349295 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.415255 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.296762 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.474165 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.413902 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.307893 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7924, Recall: 0.7904, ROC AUC: 0.9700,  Avg loss: 0.001941\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss: 0.654016 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.388949 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.261815 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.433816 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.355022 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.443566 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.488095 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.480597 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.438005 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.452665 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7900, Recall: 0.7878, ROC AUC: 0.9700,  Avg loss: 0.001943\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.332607 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.310592 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.366528 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.402987 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.335838 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.470925 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.325331 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.468763 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.393065 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.527844 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7888, Recall: 0.7865, ROC AUC: 0.9699,  Avg loss: 0.001948\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.424331 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.410187 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.419266 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.256207 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.404625 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.342268 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.383484 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.441474 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.423286 [ 4653/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.544160 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7899, Recall: 0.7882, ROC AUC: 0.9698,  Avg loss: 0.001924\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.291482 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.416248 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.472208 [ 1269/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.200245 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.307027 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.410540 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.551283 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.387869 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.323003 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.327242 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7888, Recall: 0.7862, ROC AUC: 0.9699,  Avg loss: 0.001938\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.625902 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.446972 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.404356 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.300720 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.413383 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.487975 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.319399 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.423708 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.482345 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.493719 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7913, Recall: 0.7886, ROC AUC: 0.9699,  Avg loss: 0.001907\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss: 0.620353 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.385508 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.343189 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.357578 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.405101 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.262424 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.456542 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.317218 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.449939 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.354609 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7913, Recall: 0.7885, ROC AUC: 0.9698,  Avg loss: 0.001913\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.366023 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.429187 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.381194 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.337738 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.354736 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.236974 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.301512 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.427981 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.461235 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.311894 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.95%, Precision: 0.7926, Recall: 0.7897, ROC AUC: 0.9699,  Avg loss: 0.001922\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.416069 [  141/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.706736 [  705/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.202367 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.457810 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.384202 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.418831 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.498720 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.290164 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.392487 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.295414 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7932, Recall: 0.7905, ROC AUC: 0.9699,  Avg loss: 0.001902\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.286394 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.425931 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.370647 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.343605 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.316344 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.451389 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.406848 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.230281 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.331174 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.364783 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7918, Recall: 0.7884, ROC AUC: 0.9698,  Avg loss: 0.001922\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.429275 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.357290 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.476992 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.416891 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.321732 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.387426 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.327671 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.241909 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.421093 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.322865 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7910, Recall: 0.7885, ROC AUC: 0.9699,  Avg loss: 0.001941\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.372606 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.427646 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.441405 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.406022 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.346047 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.481461 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.357448 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.415470 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.279530 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.428478 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7896, Recall: 0.7865, ROC AUC: 0.9697,  Avg loss: 0.001936\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.425960 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.386972 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.329579 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.436213 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.327592 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.376725 [ 2961/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.227840 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.584571 [ 4089/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.602497 [ 4653/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.574509 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 79.05%, Precision: 0.7928, Recall: 0.7902, ROC AUC: 0.9697,  Avg loss: 0.001917\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.359996 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.383769 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.504878 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.346287 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.533498 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.254323 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.378950 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.476668 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.445362 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.352018 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7908, Recall: 0.7887, ROC AUC: 0.9698,  Avg loss: 0.001904\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.364936 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.423904 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.301069 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.318186 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.612895 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.572733 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.266122 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.294576 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.388447 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.416620 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7888, Recall: 0.7869, ROC AUC: 0.9699,  Avg loss: 0.001922\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.348814 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.354258 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.453015 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.430944 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.454488 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.425005 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.401203 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.305709 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.456204 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.357642 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7902, Recall: 0.7889, ROC AUC: 0.9698,  Avg loss: 0.001943\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "Accuracy: 95.7%, Loss: 0.233919 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.456518 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.406409 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.455655 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.434941 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.381011 [ 2961/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.684905 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.386644 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.434285 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.386421 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7897, Recall: 0.7882, ROC AUC: 0.9698,  Avg loss: 0.001936\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.410355 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.309236 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.461740 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.419939 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.418628 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.347104 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.417083 [ 3525/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.255615 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.485563 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.506005 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7859, Recall: 0.7840, ROC AUC: 0.9697,  Avg loss: 0.001922\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.392634 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.420932 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.451012 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.252436 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.289326 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.459455 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.360265 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.292623 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.391910 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.434839 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7876, Recall: 0.7861, ROC AUC: 0.9699,  Avg loss: 0.001918\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.453044 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.412042 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.488965 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.395285 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.492243 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.371746 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.536585 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.423221 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.313561 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.421729 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7887, Recall: 0.7874, ROC AUC: 0.9697,  Avg loss: 0.001899\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.350342 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.380755 [  705/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.170936 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.431818 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.272339 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.329896 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.485301 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.290937 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.511742 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.379193 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7895, Recall: 0.7885, ROC AUC: 0.9697,  Avg loss: 0.001919\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.440070 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.472040 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.433175 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.463265 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.383417 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.314755 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.467674 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.386201 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.482742 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.368644 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7894, Recall: 0.7864, ROC AUC: 0.9697,  Avg loss: 0.001942\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.380092 [  141/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.540192 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.387592 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.385210 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.265870 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.461650 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.377548 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.367558 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.322963 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.257879 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7877, Recall: 0.7853, ROC AUC: 0.9697,  Avg loss: 0.001956\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.340626 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.518071 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.404342 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.420809 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.406869 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.464560 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.409358 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.375904 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.372567 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.556946 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7898, Recall: 0.7872, ROC AUC: 0.9698,  Avg loss: 0.001953\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.361894 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.373033 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.385242 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.563880 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.429295 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.282126 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.395702 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.289803 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.268898 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.385110 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7891, Recall: 0.7874, ROC AUC: 0.9698,  Avg loss: 0.001951\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.365966 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.413037 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.472532 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.409505 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.438411 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.423729 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.362869 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.301482 [ 4089/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.565019 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.307256 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7898, Recall: 0.7874, ROC AUC: 0.9699,  Avg loss: 0.001939\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.333898 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.317642 [  705/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.227787 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.373322 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.524236 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.475528 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.336442 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.351179 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.442020 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.337994 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7895, Recall: 0.7874, ROC AUC: 0.9698,  Avg loss: 0.001948\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.502788 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.404055 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.344563 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.311860 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.521685 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.507849 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.310756 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.400619 [ 4089/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.553271 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.440164 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7879, Recall: 0.7862, ROC AUC: 0.9697,  Avg loss: 0.001954\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.360245 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.425251 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.445786 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.466279 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.468739 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.425082 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.370163 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.530660 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.441549 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.374114 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7862, Recall: 0.7845, ROC AUC: 0.9696,  Avg loss: 0.001939\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.403888 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.539047 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.301327 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.395635 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.315987 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.392111 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.310460 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.280045 [ 4089/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.483203 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.271532 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7880, Recall: 0.7854, ROC AUC: 0.9696,  Avg loss: 0.001961\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.381112 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.233092 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.352472 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.505324 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.437689 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.536234 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.398257 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.434120 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.447980 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.280984 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7882, Recall: 0.7860, ROC AUC: 0.9698,  Avg loss: 0.001943\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "Accuracy: 95.0%, Loss: 0.209585 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.427513 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.368939 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.362443 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.617771 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.504737 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.466898 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.340682 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.352607 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.405977 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7863, Recall: 0.7845, ROC AUC: 0.9698,  Avg loss: 0.001931\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.353911 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.371707 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.321632 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.299623 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.318552 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.466801 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.434740 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.371600 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.382767 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.473467 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7890, Recall: 0.7869, ROC AUC: 0.9698,  Avg loss: 0.001952\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.321073 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.292801 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.318286 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.276278 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.552688 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.339541 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.328441 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.349124 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.466475 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.323973 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7890, Recall: 0.7867, ROC AUC: 0.9698,  Avg loss: 0.001971\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.334925 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.382270 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.270212 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.418073 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.413168 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.464819 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.409143 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.424291 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.280631 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.436001 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7883, Recall: 0.7854, ROC AUC: 0.9697,  Avg loss: 0.001956\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.361575 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.298179 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.472104 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.493014 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.448400 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.334765 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.298019 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.450806 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.461078 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.345878 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7863, Recall: 0.7833, ROC AUC: 0.9697,  Avg loss: 0.001955\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.260255 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.391193 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.321435 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.510814 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.250266 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.440462 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.471658 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.473174 [ 4089/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.216855 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.424551 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7869, Recall: 0.7848, ROC AUC: 0.9696,  Avg loss: 0.001964\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.294312 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.427468 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.474887 [ 1269/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.571800 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.500626 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.517601 [ 2961/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.202644 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.342652 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.424774 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.488956 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7886, Recall: 0.7860, ROC AUC: 0.9695,  Avg loss: 0.001953\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.298471 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.273414 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.371455 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.424649 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.375435 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.514173 [ 2961/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.561051 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.443682 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.429769 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.285778 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7893, Recall: 0.7869, ROC AUC: 0.9697,  Avg loss: 0.001926\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss: 0.616188 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.354162 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.328284 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.373518 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.277256 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.454701 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.396414 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.290172 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.337034 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.537179 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7902, Recall: 0.7878, ROC AUC: 0.9698,  Avg loss: 0.001959\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.424195 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.432977 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.337849 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.222524 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.452168 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.335941 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.491874 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.299679 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.317609 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.501282 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7882, Recall: 0.7859, ROC AUC: 0.9696,  Avg loss: 0.001974\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.427765 [  141/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.304313 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.546889 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.386083 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.265877 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.372628 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.577742 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.315788 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.495312 [ 4653/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.280298 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7893, Recall: 0.7876, ROC AUC: 0.9695,  Avg loss: 0.001951\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.462482 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.392278 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.303142 [ 1269/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.628650 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.230863 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.371146 [ 2961/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.285065 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.335077 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.360443 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.353391 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7874, Recall: 0.7858, ROC AUC: 0.9695,  Avg loss: 0.001958\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.467600 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.633396 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.379938 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.374701 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.491998 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.284170 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.466267 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.575134 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.248714 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.428605 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7855, Recall: 0.7841, ROC AUC: 0.9697,  Avg loss: 0.001949\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.366576 [  141/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.215536 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.311600 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.436277 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.339518 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.482403 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.464573 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.418473 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.331234 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.431866 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7868, Recall: 0.7860, ROC AUC: 0.9696,  Avg loss: 0.001940\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.385878 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.337103 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.363067 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.545489 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.526576 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.399861 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.335227 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.418131 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.459357 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.264503 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.19%, Precision: 0.7830, Recall: 0.7824, ROC AUC: 0.9694,  Avg loss: 0.001961\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.415865 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.383932 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.518845 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.472309 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.450682 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.382748 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.514295 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.339628 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.440668 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.299626 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7849, Recall: 0.7842, ROC AUC: 0.9694,  Avg loss: 0.001975\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.326418 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.316051 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.362105 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.411785 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.410134 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.450234 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.435637 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.307128 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.342658 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.299768 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7847, Recall: 0.7839, ROC AUC: 0.9693,  Avg loss: 0.001977\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.504885 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.397505 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.376834 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.324391 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.242335 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.306947 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.476537 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.284384 [ 4089/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.267144 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.425498 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7865, Recall: 0.7847, ROC AUC: 0.9694,  Avg loss: 0.001980\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.448924 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.373097 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.293911 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.322428 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.314262 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.419521 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.375971 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.331717 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.261781 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.281854 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7876, Recall: 0.7857, ROC AUC: 0.9692,  Avg loss: 0.001986\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.270454 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.506527 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.410909 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.353686 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.327768 [ 2397/ 5250]\n",
      "Accuracy: 96.5%, Loss: 0.231681 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.480919 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.445633 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.399871 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.466833 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7840, Recall: 0.7829, ROC AUC: 0.9692,  Avg loss: 0.002008\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.308137 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.441655 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.287819 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.505442 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.453043 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.504686 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.364329 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.313411 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.500573 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.332892 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7876, Recall: 0.7856, ROC AUC: 0.9693,  Avg loss: 0.001986\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.385878 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.575969 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.313174 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.372860 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.357520 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.253625 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.333110 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.286526 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.363888 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.479425 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7881, Recall: 0.7866, ROC AUC: 0.9695,  Avg loss: 0.001984\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.509246 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.414571 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.484337 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.429420 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.366113 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.456579 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.415211 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.543658 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.420111 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.359293 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7886, Recall: 0.7864, ROC AUC: 0.9695,  Avg loss: 0.001977\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.320097 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.281087 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.376746 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.427574 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.501909 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.316572 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.407988 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.250115 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.371683 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.481010 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7881, Recall: 0.7856, ROC AUC: 0.9696,  Avg loss: 0.001967\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.560464 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.397668 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.529656 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.484159 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.418234 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.434153 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.353037 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.557521 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.309560 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.276350 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7908, Recall: 0.7884, ROC AUC: 0.9696,  Avg loss: 0.001939\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.325112 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.346268 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.424466 [ 1269/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.697904 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.384985 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.381106 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.326126 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.324344 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.422398 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.328401 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7892, Recall: 0.7871, ROC AUC: 0.9696,  Avg loss: 0.001935\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss: 0.606699 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.503335 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.419173 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.318446 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.341598 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.405644 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.550058 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.350183 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.456861 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.297900 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7886, Recall: 0.7866, ROC AUC: 0.9695,  Avg loss: 0.001927\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.424075 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.299111 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.457703 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.239066 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.433975 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.404441 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.370730 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.387974 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.408384 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.369489 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7879, Recall: 0.7865, ROC AUC: 0.9695,  Avg loss: 0.001938\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.356595 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.401714 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.453220 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.353051 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.539419 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.447529 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.357394 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.371467 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.295980 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.496720 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7875, Recall: 0.7855, ROC AUC: 0.9696,  Avg loss: 0.001949\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.530096 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.253572 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.336497 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.378507 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.400117 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.483628 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.315126 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.377851 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.394314 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.279172 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7880, Recall: 0.7858, ROC AUC: 0.9695,  Avg loss: 0.001948\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.300786 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.365719 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.370655 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.391747 [ 1833/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.674215 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.508190 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.439654 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.358799 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.367179 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.437337 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.19%, Precision: 0.7840, Recall: 0.7819, ROC AUC: 0.9696,  Avg loss: 0.001943\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.353686 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.518425 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.435446 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.310404 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.442088 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.508313 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.521071 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.366509 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.292237 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.342907 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7883, Recall: 0.7855, ROC AUC: 0.9697,  Avg loss: 0.001947\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.314644 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.437154 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.306527 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.374051 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.439672 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.256854 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.436125 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.393322 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.540302 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.341725 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7877, Recall: 0.7847, ROC AUC: 0.9695,  Avg loss: 0.001981\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.356882 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.292460 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.488332 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.430161 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.592346 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.272639 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.341427 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.350446 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.416906 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.455292 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7863, Recall: 0.7850, ROC AUC: 0.9695,  Avg loss: 0.001965\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.442786 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.334451 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.370120 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.353408 [ 1833/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.260163 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.415299 [ 2961/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.224439 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.378277 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.482074 [ 4653/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.570656 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7897, Recall: 0.7885, ROC AUC: 0.9695,  Avg loss: 0.001965\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.361960 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.563319 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.327449 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.379011 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.480791 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.496908 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.367351 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.388901 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.297145 [ 4653/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.279802 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7874, Recall: 0.7863, ROC AUC: 0.9695,  Avg loss: 0.001963\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.371398 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.443739 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.351787 [ 1269/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.580347 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.484520 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.401585 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.441070 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.364836 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.294938 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.521205 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7894, Recall: 0.7873, ROC AUC: 0.9697,  Avg loss: 0.001956\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.363374 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.433937 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.311219 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.435992 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.453589 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.319257 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.356819 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.259635 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.444719 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.399789 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7884, Recall: 0.7865, ROC AUC: 0.9697,  Avg loss: 0.001958\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.397965 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.301568 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.496338 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.320933 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.260590 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.383378 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.294758 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.280153 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.474218 [ 4653/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.210249 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7893, Recall: 0.7877, ROC AUC: 0.9697,  Avg loss: 0.001963\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.394890 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.311485 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.474027 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.490279 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.567454 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.398007 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.390630 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.386960 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.383255 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.304058 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7897, Recall: 0.7880, ROC AUC: 0.9695,  Avg loss: 0.001983\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.414233 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.460776 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.445159 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.372485 [ 1833/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.198704 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.295777 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.527785 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.418257 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.407900 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.290147 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7899, Recall: 0.7880, ROC AUC: 0.9696,  Avg loss: 0.001982\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.436792 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.406073 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.335171 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.418462 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.477767 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.263728 [ 2961/ 5250]\n",
      "Accuracy: 96.5%, Loss: 0.157436 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.302885 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.277395 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.388377 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7852, Recall: 0.7840, ROC AUC: 0.9696,  Avg loss: 0.001971\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.321030 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.459208 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.474808 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.346501 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.561098 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.452296 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.448577 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.252650 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.326000 [ 4653/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.473884 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7847, Recall: 0.7840, ROC AUC: 0.9693,  Avg loss: 0.001972\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.360125 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.304481 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.531823 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.471121 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.395478 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.391635 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.394383 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.387173 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.438644 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.361461 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7850, Recall: 0.7831, ROC AUC: 0.9694,  Avg loss: 0.001967\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.637568 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.437443 [  705/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.251181 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.408701 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.319356 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.416377 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.572294 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.396188 [ 4089/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.250855 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.431942 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7844, Recall: 0.7831, ROC AUC: 0.9696,  Avg loss: 0.001973\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.541878 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.299402 [  705/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.217293 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.277985 [ 1833/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.621079 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.366111 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.444943 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.483876 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.436811 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.299108 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7845, Recall: 0.7833, ROC AUC: 0.9694,  Avg loss: 0.001986\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.416689 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.443157 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.534575 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.391687 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.477899 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.363965 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.537266 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.396493 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.362962 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.428184 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7899, Recall: 0.7880, ROC AUC: 0.9695,  Avg loss: 0.001991\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.389873 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.327418 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.370386 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.244295 [ 1833/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.559116 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.458183 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.316446 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.327387 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.410867 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.488058 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7863, Recall: 0.7845, ROC AUC: 0.9696,  Avg loss: 0.001996\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.410408 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.350603 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.501212 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.440672 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.289459 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.214968 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.304982 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.400487 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.382074 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.413889 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7855, Recall: 0.7844, ROC AUC: 0.9695,  Avg loss: 0.002008\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.448275 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.277696 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.301084 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.346538 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.470661 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.250241 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.409602 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.215950 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.296984 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.392013 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7892, Recall: 0.7872, ROC AUC: 0.9695,  Avg loss: 0.001993\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.320470 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.422174 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.296272 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.431441 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.407230 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.441508 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.306097 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.331616 [ 4089/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.204504 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.330130 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7883, Recall: 0.7869, ROC AUC: 0.9694,  Avg loss: 0.001977\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.419429 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.409570 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.377192 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.402532 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.301875 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.493255 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.379713 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.492290 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.325220 [ 4653/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.572566 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7857, Recall: 0.7843, ROC AUC: 0.9694,  Avg loss: 0.001972\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.358758 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.420669 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.397136 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.309823 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.463500 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.305542 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.401892 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.479983 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.416239 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.447767 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7879, Recall: 0.7853, ROC AUC: 0.9693,  Avg loss: 0.001972\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.311898 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.322058 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.310116 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.378741 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.290333 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.579847 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.462096 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.501450 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.401646 [ 4653/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.220473 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7887, Recall: 0.7858, ROC AUC: 0.9694,  Avg loss: 0.001994\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.422538 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.246235 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.277285 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.524218 [ 1833/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.488556 [ 2397/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.209843 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.367347 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.320889 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.485309 [ 4653/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.265990 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7891, Recall: 0.7868, ROC AUC: 0.9694,  Avg loss: 0.002012\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.350826 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.286272 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.390491 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.425297 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.451765 [ 2397/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.643846 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.428842 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.285383 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.439233 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.434782 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7867, Recall: 0.7850, ROC AUC: 0.9694,  Avg loss: 0.002005\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.286229 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.377725 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.512223 [ 1269/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.577816 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.575575 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.411105 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.428908 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.425587 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.316104 [ 4653/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.227896 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.76%, Precision: 0.7898, Recall: 0.7876, ROC AUC: 0.9693,  Avg loss: 0.001995\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.409385 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.276054 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.300729 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.381388 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.402056 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.389414 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.383544 [ 3525/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.512991 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.421177 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.302303 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7868, Recall: 0.7846, ROC AUC: 0.9692,  Avg loss: 0.002003\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.498286 [  141/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.516051 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.423084 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.455422 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.419138 [ 2397/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.490118 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.380473 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.445676 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.465703 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.412476 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7851, Recall: 0.7829, ROC AUC: 0.9692,  Avg loss: 0.002003\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.357308 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.428416 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.503016 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.545963 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.487930 [ 2397/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.173980 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.314884 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.332581 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.233880 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.452743 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.19%, Precision: 0.7838, Recall: 0.7819, ROC AUC: 0.9694,  Avg loss: 0.001982\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.458874 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.391922 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.283689 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.273936 [ 1833/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.571206 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.367375 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.329030 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.486538 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.529932 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.310118 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7845, Recall: 0.7828, ROC AUC: 0.9694,  Avg loss: 0.001994\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "Accuracy: 96.5%, Loss: 0.220226 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.425204 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.431550 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.397435 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.443422 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.256810 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.330717 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.507034 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.371594 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.322312 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7849, Recall: 0.7828, ROC AUC: 0.9695,  Avg loss: 0.001990\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.333258 [  141/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.191434 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.481621 [ 1269/ 5250]\n",
      "Accuracy: 96.5%, Loss: 0.186729 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.435637 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.279718 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.414431 [ 3525/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.230847 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.330950 [ 4653/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.611230 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.19%, Precision: 0.7831, Recall: 0.7819, ROC AUC: 0.9694,  Avg loss: 0.002005\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.425215 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.341911 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.308602 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.280814 [ 1833/ 5250]\n",
      "Accuracy: 83.0%, Loss: 0.646799 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.318974 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.338937 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.337710 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.310225 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.421418 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7839, Recall: 0.7827, ROC AUC: 0.9695,  Avg loss: 0.001993\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.480305 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.399308 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.314672 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.241188 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.401165 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.298921 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.411849 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.288646 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.460149 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.450617 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7855, Recall: 0.7841, ROC AUC: 0.9695,  Avg loss: 0.001995\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.375687 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.280671 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.347719 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.298332 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.405805 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.433212 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.289006 [ 3525/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.217465 [ 4089/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.599305 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.226192 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.19%, Precision: 0.7831, Recall: 0.7823, ROC AUC: 0.9696,  Avg loss: 0.002003\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.418872 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.457046 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.401066 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.605574 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.471203 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.466920 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.427012 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.458389 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.327682 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.526897 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7858, Recall: 0.7842, ROC AUC: 0.9695,  Avg loss: 0.001991\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.517491 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.258739 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.426598 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.315461 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.365719 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.399412 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.508069 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.247894 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.407511 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.582423 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7864, Recall: 0.7850, ROC AUC: 0.9696,  Avg loss: 0.001980\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.350929 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.308895 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.465061 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.323678 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.371592 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.413110 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.418818 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.239449 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.367938 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.389915 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7865, Recall: 0.7850, ROC AUC: 0.9696,  Avg loss: 0.001981\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.385937 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.368792 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.250348 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.306554 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.215689 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.335084 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.450350 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.454586 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.305196 [ 4653/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.254077 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7858, Recall: 0.7852, ROC AUC: 0.9696,  Avg loss: 0.002001\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.432474 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.342557 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.348598 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.358728 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.290808 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.328974 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.377305 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.493013 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.360637 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.300937 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.19%, Precision: 0.7830, Recall: 0.7824, ROC AUC: 0.9696,  Avg loss: 0.002000\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.347213 [  141/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.185488 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.429410 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.478604 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.338678 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.424105 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.393049 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.324418 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.408614 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.575568 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7836, Recall: 0.7831, ROC AUC: 0.9696,  Avg loss: 0.002002\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.585455 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.405806 [  705/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.459226 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.287459 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.276383 [ 2397/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.239649 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.488453 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.340851 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.358559 [ 4653/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.586246 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7845, Recall: 0.7840, ROC AUC: 0.9695,  Avg loss: 0.001995\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.314988 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.289008 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.316630 [ 1269/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.200893 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.615608 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.365389 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.294505 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.290344 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.296905 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.301960 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7844, Recall: 0.7840, ROC AUC: 0.9696,  Avg loss: 0.002001\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.288841 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.399602 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.463319 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.318167 [ 1833/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.220224 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.262614 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.456900 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.256539 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.410693 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.544238 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7840, Recall: 0.7840, ROC AUC: 0.9695,  Avg loss: 0.002000\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.321114 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.482409 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.488944 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.232683 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.404676 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.318056 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.490016 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.413652 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.387663 [ 4653/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.561482 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7848, Recall: 0.7851, ROC AUC: 0.9693,  Avg loss: 0.001994\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.355816 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.429864 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.266126 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.471458 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.433336 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.424358 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.424030 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.345830 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.408137 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.388949 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7852, Recall: 0.7851, ROC AUC: 0.9694,  Avg loss: 0.001982\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.326871 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.428649 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.366312 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.366114 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.446418 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.381229 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.504381 [ 3525/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.364936 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.495151 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.357154 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7834, Recall: 0.7830, ROC AUC: 0.9694,  Avg loss: 0.001963\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.504582 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.314882 [  705/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.282178 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.313085 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.410928 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.312850 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.298546 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.374982 [ 4089/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.498593 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.472901 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7853, Recall: 0.7850, ROC AUC: 0.9693,  Avg loss: 0.001974\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.466148 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.529453 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.430773 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.380795 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.388224 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.501320 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.406567 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.437449 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.437216 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.358743 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7842, Recall: 0.7841, ROC AUC: 0.9692,  Avg loss: 0.001971\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss: 0.497900 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.418144 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.476962 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.281286 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.555728 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.427862 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.376628 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.341813 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.341401 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.543023 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7863, Recall: 0.7858, ROC AUC: 0.9691,  Avg loss: 0.001969\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.292310 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.386903 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.446216 [ 1269/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.574423 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.377579 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.434592 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.513989 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.355148 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.376177 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.473165 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7875, Recall: 0.7867, ROC AUC: 0.9692,  Avg loss: 0.001975\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.608171 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.465688 [  705/ 5250]\n",
      "Accuracy: 79.4%, Loss: 0.663080 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.375728 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.408565 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.447725 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.464398 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.450770 [ 4089/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.612158 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.335987 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7874, Recall: 0.7869, ROC AUC: 0.9692,  Avg loss: 0.001962\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.419182 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.357177 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.318150 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.339579 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.383280 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.348922 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.456228 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.358825 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.347715 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.442811 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7869, Recall: 0.7867, ROC AUC: 0.9692,  Avg loss: 0.001967\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.463541 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.376882 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.254914 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.326193 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.450063 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.416830 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.540266 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.320553 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.362743 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.506773 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7849, Recall: 0.7847, ROC AUC: 0.9692,  Avg loss: 0.001985\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.383885 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.271221 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.430115 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.577062 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.498386 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.433683 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.377838 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.281314 [ 4089/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.585251 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.418171 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7834, Recall: 0.7831, ROC AUC: 0.9692,  Avg loss: 0.001991\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss: 0.579913 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.326042 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.340294 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.432385 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.468489 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.302583 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.365684 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.315362 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.355659 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.277094 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7848, Recall: 0.7840, ROC AUC: 0.9694,  Avg loss: 0.002006\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss: 0.646840 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.275486 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.396088 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.531243 [ 1833/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.398312 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.375097 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.486132 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.394004 [ 4089/ 5250]\n",
      "Accuracy: 96.5%, Loss: 0.168475 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.342483 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7862, Recall: 0.7849, ROC AUC: 0.9694,  Avg loss: 0.002013\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.285271 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.298025 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.394957 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.270845 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.498634 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.346820 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.431164 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.543729 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.415139 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.345910 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7843, Recall: 0.7829, ROC AUC: 0.9693,  Avg loss: 0.002013\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss: 0.555550 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.514895 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.335360 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.542017 [ 1833/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.196030 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.304401 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.443257 [ 3525/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.447445 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.458007 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.391290 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7833, Recall: 0.7829, ROC AUC: 0.9693,  Avg loss: 0.002025\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "Accuracy: 94.3%, Loss: 0.292916 [  141/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.507961 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.429652 [ 1269/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.217007 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.390159 [ 2397/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.616335 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.370632 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.317308 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.296980 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.358479 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7859, Recall: 0.7851, ROC AUC: 0.9696,  Avg loss: 0.002020\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.290238 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.451750 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.269484 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.605503 [ 1833/ 5250]\n",
      "Accuracy: 80.9%, Loss: 0.716121 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.396720 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.390236 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.450031 [ 4089/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.496258 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.251169 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.67%, Precision: 0.7874, Recall: 0.7871, ROC AUC: 0.9694,  Avg loss: 0.002007\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "Accuracy: 95.7%, Loss: 0.197776 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.385466 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.249104 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.274987 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.336266 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.361575 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.442449 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.288470 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.296652 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.375033 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7845, Recall: 0.7842, ROC AUC: 0.9692,  Avg loss: 0.002032\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.411922 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.381880 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.302307 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.488201 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.342130 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.481283 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.524127 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.299263 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.256726 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.378861 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7854, Recall: 0.7849, ROC AUC: 0.9691,  Avg loss: 0.002023\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss: 0.518900 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.430023 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.296494 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.461892 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.406437 [ 2397/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.555318 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.536935 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.303989 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.317808 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.355530 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7858, Recall: 0.7850, ROC AUC: 0.9690,  Avg loss: 0.002022\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.330974 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.397834 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.434972 [ 1269/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.489782 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.532075 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.388577 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.516143 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.225907 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.374774 [ 4653/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.182824 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7869, Recall: 0.7850, ROC AUC: 0.9692,  Avg loss: 0.002017\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.346257 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.324964 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.363726 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.354569 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.472039 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.371885 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.268227 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.361327 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.342910 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.365667 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7836, Recall: 0.7832, ROC AUC: 0.9691,  Avg loss: 0.002020\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.372529 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.469741 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.404104 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.336376 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.304371 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.341044 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.359591 [ 3525/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.631800 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.422481 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.293996 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.19%, Precision: 0.7825, Recall: 0.7822, ROC AUC: 0.9690,  Avg loss: 0.002034\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.482054 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.482417 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.286370 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.295815 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.338408 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.302446 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.252550 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.300049 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.452332 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.434149 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.19%, Precision: 0.7827, Recall: 0.7822, ROC AUC: 0.9691,  Avg loss: 0.002038\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.373511 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.285205 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.251738 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.368536 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.474458 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.398516 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.406802 [ 3525/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.500842 [ 4089/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.201751 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.296405 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7845, Recall: 0.7830, ROC AUC: 0.9689,  Avg loss: 0.002031\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.392374 [  141/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.474162 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.283259 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.433653 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.425136 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.366809 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.472760 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.348001 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.305613 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.312842 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7846, Recall: 0.7833, ROC AUC: 0.9689,  Avg loss: 0.002042\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss: 0.558114 [  141/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.213945 [  705/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.293478 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.417667 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.264755 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.450701 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.525112 [ 3525/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.306616 [ 4089/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.515917 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.402647 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.19%, Precision: 0.7830, Recall: 0.7823, ROC AUC: 0.9690,  Avg loss: 0.002056\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.383620 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.333767 [  705/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.478664 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.410990 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.369990 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.495868 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.423013 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.371491 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.363406 [ 4653/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.416803 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.19%, Precision: 0.7827, Recall: 0.7823, ROC AUC: 0.9689,  Avg loss: 0.002060\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.351859 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.276709 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.310232 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.409518 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.317735 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.386609 [ 2961/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.391008 [ 3525/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.298488 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.374237 [ 4653/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.445407 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7835, Recall: 0.7832, ROC AUC: 0.9689,  Avg loss: 0.002068\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss: 0.257483 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.505438 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.318344 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.516681 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.508538 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.394001 [ 2961/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.575958 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.403420 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.398693 [ 4653/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.312448 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7847, Recall: 0.7841, ROC AUC: 0.9690,  Avg loss: 0.002066\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.365323 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.304943 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.346733 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.394831 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.339012 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.345548 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.258281 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.344059 [ 4089/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.275549 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.324084 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.19%, Precision: 0.7834, Recall: 0.7822, ROC AUC: 0.9691,  Avg loss: 0.002055\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.418542 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.359622 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.469741 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.358390 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.420535 [ 2397/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.419129 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.475497 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.368505 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.315403 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.509020 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7844, Recall: 0.7841, ROC AUC: 0.9691,  Avg loss: 0.002043\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.355251 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.389371 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.367273 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.383179 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.261713 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.397308 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.306485 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.392803 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.269339 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.312524 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7837, Recall: 0.7834, ROC AUC: 0.9690,  Avg loss: 0.002044\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.445716 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.362815 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.347677 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.512101 [ 1833/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.519596 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.548548 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.335626 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.359447 [ 4089/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.422618 [ 4653/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.251432 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7854, Recall: 0.7842, ROC AUC: 0.9692,  Avg loss: 0.002037\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.319837 [  141/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.187306 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.602893 [ 1269/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.207211 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.464349 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.388288 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.350174 [ 3525/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.391044 [ 4089/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.455734 [ 4653/ 5250]\n",
      "Accuracy: 81.6%, Loss: 0.684410 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7861, Recall: 0.7843, ROC AUC: 0.9690,  Avg loss: 0.002038\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.425399 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.461150 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.357042 [ 1269/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.579542 [ 1833/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.415070 [ 2397/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.241805 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.266260 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.480744 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.318067 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.309870 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7847, Recall: 0.7830, ROC AUC: 0.9689,  Avg loss: 0.002020\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss: 0.302801 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.430859 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.416061 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.373781 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.405454 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.482510 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.400556 [ 3525/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.249403 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.387571 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.368766 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.19%, Precision: 0.7839, Recall: 0.7826, ROC AUC: 0.9690,  Avg loss: 0.002018\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.310337 [  141/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.305232 [  705/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.365752 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.420302 [ 1833/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.370623 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.355077 [ 2961/ 5250]\n",
      "Accuracy: 96.5%, Loss: 0.176588 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.356304 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.356088 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.341311 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.10%, Precision: 0.7818, Recall: 0.7813, ROC AUC: 0.9689,  Avg loss: 0.002013\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.461335 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.269848 [  705/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.481425 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.289474 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.328789 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.330627 [ 2961/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.544538 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.544818 [ 4089/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.376418 [ 4653/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.525788 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7849, Recall: 0.7843, ROC AUC: 0.9690,  Avg loss: 0.002007\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "Accuracy: 96.5%, Loss: 0.152584 [  141/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.462490 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.306816 [ 1269/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.474941 [ 1833/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.354935 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.358557 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.400767 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.362956 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.451779 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.280264 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7854, Recall: 0.7845, ROC AUC: 0.9690,  Avg loss: 0.001985\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.465069 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.397991 [  705/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.423311 [ 1269/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.409691 [ 1833/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.568314 [ 2397/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.340817 [ 2961/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.487756 [ 3525/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.643299 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.393216 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.267471 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7844, Recall: 0.7834, ROC AUC: 0.9690,  Avg loss: 0.001974\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.520439 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.368182 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.324617 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.323654 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.481473 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.440938 [ 2961/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.243167 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.334102 [ 4089/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.621532 [ 4653/ 5250]\n",
      "Accuracy: 84.4%, Loss: 0.527061 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.10%, Precision: 0.7823, Recall: 0.7814, ROC AUC: 0.9691,  Avg loss: 0.001984\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss: 0.441205 [  141/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.330529 [  705/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.543694 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.351626 [ 1833/ 5250]\n",
      "Accuracy: 83.7%, Loss: 0.562013 [ 2397/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.445900 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.420996 [ 3525/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.454959 [ 4089/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.463928 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.339882 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7847, Recall: 0.7830, ROC AUC: 0.9691,  Avg loss: 0.001984\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss: 0.463696 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.355918 [  705/ 5250]\n",
      "Accuracy: 95.0%, Loss: 0.225270 [ 1269/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.317779 [ 1833/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.223455 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.314797 [ 2961/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.423429 [ 3525/ 5250]\n",
      "Accuracy: 82.3%, Loss: 0.658369 [ 4089/ 5250]\n",
      "Accuracy: 94.3%, Loss: 0.270770 [ 4653/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.321850 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7840, Recall: 0.7832, ROC AUC: 0.9692,  Avg loss: 0.002009\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.348691 [  141/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.308678 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.392690 [ 1269/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.305668 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.399323 [ 2397/ 5250]\n",
      "Accuracy: 95.7%, Loss: 0.180220 [ 2961/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.457356 [ 3525/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.495716 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.381633 [ 4653/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.359747 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7859, Recall: 0.7850, ROC AUC: 0.9692,  Avg loss: 0.002001\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss: 0.323071 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.410473 [  705/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.253813 [ 1269/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.480099 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.363419 [ 2397/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.401503 [ 2961/ 5250]\n",
      "Accuracy: 85.1%, Loss: 0.549463 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.303358 [ 4089/ 5250]\n",
      "Accuracy: 97.9%, Loss: 0.123167 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.291982 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7836, Recall: 0.7832, ROC AUC: 0.9693,  Avg loss: 0.002010\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.350885 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.406794 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.392035 [ 1269/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.400458 [ 1833/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.406734 [ 2397/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.457510 [ 2961/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.410484 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.305561 [ 4089/ 5250]\n",
      "Accuracy: 96.5%, Loss: 0.237924 [ 4653/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.288374 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.57%, Precision: 0.7855, Recall: 0.7857, ROC AUC: 0.9694,  Avg loss: 0.002018\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss: 0.401663 [  141/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.402211 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.352879 [ 1269/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.257936 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.475036 [ 2397/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.344708 [ 2961/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.310056 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.380598 [ 4089/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.265689 [ 4653/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.410386 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7853, Recall: 0.7847, ROC AUC: 0.9693,  Avg loss: 0.002026\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss: 0.285052 [  141/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.296866 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.396506 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.376065 [ 1833/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.473301 [ 2397/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.377264 [ 2961/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.382057 [ 3525/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.365423 [ 4089/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.329681 [ 4653/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.294121 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7838, Recall: 0.7834, ROC AUC: 0.9693,  Avg loss: 0.002044\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss: 0.283787 [  141/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.435977 [  705/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.278910 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.350017 [ 1833/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.296744 [ 2397/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.443886 [ 2961/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.452951 [ 3525/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.389709 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.290196 [ 4653/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.447438 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.48%, Precision: 0.7859, Recall: 0.7851, ROC AUC: 0.9692,  Avg loss: 0.002058\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss: 0.467728 [  141/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.378592 [  705/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.299404 [ 1269/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.408040 [ 1833/ 5250]\n",
      "Accuracy: 90.1%, Loss: 0.382195 [ 2397/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.251124 [ 2961/ 5250]\n",
      "Accuracy: 92.9%, Loss: 0.318740 [ 3525/ 5250]\n",
      "Accuracy: 89.4%, Loss: 0.391701 [ 4089/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.363776 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.326339 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.29%, Precision: 0.7834, Recall: 0.7830, ROC AUC: 0.9693,  Avg loss: 0.002041\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.449225 [  141/ 5250]\n",
      "Accuracy: 87.9%, Loss: 0.387729 [  705/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.486510 [ 1269/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.308042 [ 1833/ 5250]\n",
      "Accuracy: 93.6%, Loss: 0.289161 [ 2397/ 5250]\n",
      "Accuracy: 85.8%, Loss: 0.466520 [ 2961/ 5250]\n",
      "Accuracy: 87.2%, Loss: 0.486116 [ 3525/ 5250]\n",
      "Accuracy: 86.5%, Loss: 0.563182 [ 4089/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.478825 [ 4653/ 5250]\n",
      "Accuracy: 90.8%, Loss: 0.408392 [ 5217/ 5250]\n",
      "Finished training\n",
      "Test Metrics: \n",
      " Accuracy: 78.38%, Precision: 0.7847, Recall: 0.7839, ROC AUC: 0.9692,  Avg loss: 0.002034\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss: 0.382296 [  141/ 5250]\n",
      "Accuracy: 88.7%, Loss: 0.451712 [  705/ 5250]\n",
      "Accuracy: 91.5%, Loss: 0.326540 [ 1269/ 5250]\n",
      "Accuracy: 92.2%, Loss: 0.340487 [ 1833/ 5250]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m     accuracy, loss \u001b[38;5;241m=\u001b[39m validate_model(model, X_val, y_val, criterion)\n",
      "Cell \u001b[1;32mIn[17], line 23\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, X_train, y_train, criterion, optimizer)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Gradiant Descent using Adam optimizer for best performance\u001b[39;00m\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 23\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     26\u001b[0m correct \u001b[38;5;241m=\u001b[39m (logits\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y_true\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mtype(T\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Global Variables\n",
    "epochs = 1_000\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Load Pre-Trained Models\n",
    "# model_1.load(\"NeuralNetwork-1_acc-50.29_loss-0.000003\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "best_accuracy = 0.80 # ???\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "\n",
    "    train_model(model, X_train, y_train, criterion, optimizer)\n",
    "    print('Finished training')\n",
    "    \n",
    "    accuracy, loss = validate_model(model, X_val, y_val, criterion)\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        print(f\"[+] Saving Model...\")\n",
    "        model.save(f\"Conv-NeuralNetwork-Ensemble-Advance_acc-{accuracy * 100:.2f}_loss-{loss:>8f}\")\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "        print(f\"[!] Models Saved.\")\n",
    "\n",
    "    epoch += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_confusion_matrix(y_pred, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def test_model(model, X_test, y_test, criterion):\n",
    "    size = len(y_test)\n",
    "    loss = 0\n",
    "    model.eval()\n",
    "    with T.no_grad():\n",
    "        X = T.from_numpy(X_test).to(T.float32).to(device)\n",
    "        y_true = T.Tensor(y_test).to(T.float).to(device)\n",
    "\n",
    "        logits = model.forward(X)\n",
    "\n",
    "        loss = criterion(logits, y_true)\n",
    "\n",
    "        y_pred = logits.argmax(1).cpu().numpy()\n",
    "        y_true = y_true.argmax(1).cpu().numpy()\n",
    "        labels = np.unique(y_true)\n",
    "        \n",
    "        make_confusion_matrix(y_pred, y_true, labels)\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, average='macro')\n",
    "        recall = recall_score(y_true, y_pred, average='macro')\n",
    "        roc_auc = roc_auc_score(y_true, F.softmax(logits, dim=1).cpu().numpy(), multi_class='ovo')\n",
    "        cohen_kappa = cohen_kappa_score(y_true, y_pred)\n",
    "        \n",
    "        loss /= size\n",
    "        \n",
    "        print(f\"Test Metrics: \\n Accuracy: {100 * accuracy:>0.2f}%, Precision: {precision:>0.4f}, Recall: {recall:>0.4f}, ROC AUC: {roc_auc:>0.4f}, Cohen Kappa: {cohen_kappa:>0.4f}, Avg loss: {loss:>8f}\")\n",
    "    \n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics: \n",
      " Accuracy: 78.86%, Precision: 0.7927, Recall: 0.7893, ROC AUC: 0.9705, Cohen Kappa: 0.7779, Avg loss: 0.001719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7885714285714286, tensor(0.0017, device='cuda:0'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_1.save_dir = \"./best_models\"\n",
    "# model_2.save_dir = \"./best_models\"\n",
    "\n",
    "model.load(\"Conv-NeuralNetwork-Ensemble-Advance_acc-80.67_loss-0.001625\")\n",
    "# model_2.load(\"NeuralNetwork-2_acc-61.81_loss-0.000008\")\n",
    "test_model(model, X_test, y_test, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
