{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(x):\n",
    "    labels = np.unique(x)\n",
    "    result = np.zeros(shape=(x.shape[0], labels.shape[0]))\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        result[i][x[i]] = 1.0\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_feature_cover(X, std_tol = 500):\n",
    "    x_mean = np.mean(X, axis = 0)\n",
    "    x_std = np.mean(X, axis = 0)\n",
    "    feature_cover = np.zeros(len(x_mean), dtype = bool)\n",
    "\n",
    "    for i in range(len(x_mean)):\n",
    "        if np.abs(x_std[i]) > std_tol:\n",
    "            feature_cover[i] = True    \n",
    "\n",
    "    return feature_cover\n",
    "\n",
    "\n",
    "def split_data(X, y, test_size=0.2, val_size=0.2, random_state=42):\n",
    "   \n",
    "    # Splitting the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Further splitting the training data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size / (1 - test_size),\n",
    "                                                      random_state=random_state)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [] # Features per class\n",
    "training_labels = [] # Labels\n",
    "testing_data = [] # Features per class\n",
    "testing_labels = [] # Labels\n",
    "N = 5250 # Amount of data we want to use max: 5250\n",
    "\n",
    "# Import the features\n",
    "with open(\"traindata.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        features = [float(i) for i in line.split(\",\")]\n",
    "        training_data.append(features)\n",
    "\n",
    "with open(\"testdata.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        features = [float(i) for i in line.split(\",\")]\n",
    "        testing_data.append(features)\n",
    "\n",
    "\n",
    "# Import the labels\n",
    "with open(\"trainlabels.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        label = float(line.rstrip())\n",
    "        training_labels.append(label)\n",
    "\n",
    "with open(\"targetlabels.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        label = float(line.rstrip())\n",
    "        testing_labels.append(label)\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "# X = np.array(training_data)\n",
    "# y = to_onehot(np.array(training_labels, dtype=np.int64))\n",
    "\n",
    "# feature_cover = generate_feature_cover(X, 1000)\n",
    "\n",
    "X_train = np.load(\"augmented_traindata.npy\")\n",
    "y_train = to_onehot(np.load(\"augmented_trainlabels.npy\"))\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(np.array(testing_data), to_onehot(np.array(testing_labels, dtype=np.int64)), test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the number of components to consider when performing pca\n",
    "def num_components(X, variance_tol = 0.8):\n",
    "    # Standardize each feature of the matrix\n",
    "    x_mean = np.mean(X, axis = 0)\n",
    "    x_std = np.std(X, axis = 0)\n",
    "    Z = (X - x_mean) / x_std\n",
    "\n",
    "    # Calculate covariance matrix\n",
    "    C = np.cov(Z, rowvar=False)\n",
    "    # Calculate eigenvalues and eigenvectors and sort by size\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(C)\n",
    "    index = eigenvalues.argsort()[:: -1]\n",
    "    eigenvalues = eigenvalues[index]\n",
    "    eigenvectors = eigenvectors[:, index]\n",
    "\n",
    "    # Calculate explained variance matrix \n",
    "    explained_var = np.cumsum(eigenvalues) / np.sum(eigenvalues)\n",
    "\n",
    "    # Select number of components responsible for variance_tol% of variance\n",
    "    n_components = np.argmax(explained_var >= variance_tol) + 1\n",
    "    return Z, x_mean, x_std, n_components\n",
    "\n",
    "# Parameters are trained components, trained mean, trained standard deviation and the new inputs X\n",
    "# Changes to the PCA basis\n",
    "def convert_to_pca(components, mean, std, X):\n",
    "    Z = (X - mean)/std\n",
    "    return Z @ components.transpose()\n",
    "\n",
    "Z, mean, std, n_components = num_components(X_train, 0.70)\n",
    "# Initialize prinicipal component analysis\n",
    "pca = PCA(n_components, random_state=453)\n",
    "pca.fit(Z)\n",
    "components = pca.components_\n",
    "X_train_PCA = pca.transform(Z)\n",
    "temp = pca.transform(X_test)\n",
    "X_test_PCA = convert_to_pca(components, mean, std, X_test)\n",
    "X_val_PCA = convert_to_pca(components, mean, std, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"pca_utils/pca_components\", components)\n",
    "np.save(\"pca_utils/X_mean\", mean)\n",
    "np.save(\"pca_utils/X_std\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5922, 63)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_PCA.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, p_dropout=0.20, save_dir=\"./models\"):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        activation = nn.ReLU()\n",
    "        dropout = nn.AlphaDropout(p=p_dropout)\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(in_features=n_inputs, out_features=1024),\n",
    "            activation,\n",
    "            dropout,\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            activation,\n",
    "            dropout,\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            activation,\n",
    "            dropout,\n",
    "            nn.Linear(in_features=256, out_features=n_outputs),\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        logits = self.network(X)\n",
    "        return logits\n",
    "    \n",
    "    def save(self, name):\n",
    "        T.save(self.state_dict(), f\"{self.save_dir}/{name}.pth\")\n",
    "\n",
    "    def load(self, name):\n",
    "        self.load_state_dict(T.load(f\"{self.save_dir}/{name}.pth\"))\n",
    "\n",
    "n_inputs = X_train_PCA.shape[1] # 140 inputs\n",
    "n_outputs = 21 # 21 labels\n",
    "\n",
    "# Move a tensor to the GPU\n",
    "device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model\n",
    "model_1 = NeuralNetwork(n_inputs=n_inputs, n_outputs=n_outputs, p_dropout=0.4).to(device)\n",
    "model_2 = NeuralNetwork(n_inputs=n_inputs, n_outputs=n_outputs, p_dropout=0.4).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(nn.Module):\n",
    "    def __init__(self, model_1, model_2, n_inputs, n_outputs, save_dir=\"./models\"):\n",
    "        super(Ensemble, self).__init__()\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.model_1 = model_1\n",
    "        self.model_2 = model_2\n",
    "\n",
    "        activation = nn.ReLU()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            activation,\n",
    "            nn.Linear(in_features=n_inputs, out_features=n_outputs)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_1 = self.model_1(x.clone())\n",
    "        x_2 = self.model_2(x.clone())\n",
    "\n",
    "        x = T.cat([x_1, x_2], dim=1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n",
    "    \n",
    "    def save(self, name):\n",
    "        T.save(self.state_dict(), f\"{self.save_dir}/{name}.pth\")\n",
    "\n",
    "    def load(self, name):\n",
    "        self.load_state_dict(T.load(f\"{self.save_dir}/{name}.pth\"))\n",
    "\n",
    "\n",
    "model_1.save_dir = \"./best_models\"\n",
    "model_2.save_dir = \"./best_models\"\n",
    "\n",
    "#Freeze these models \n",
    "model_1.load(\"NeuralNetwork-1_acc-61.81_loss-0.000009\")\n",
    "for param in model_1.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "model_2.load(\"NeuralNetwork-2_acc-61.62_loss-0.000004\")\n",
    "for param in model_2.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "model = Ensemble(model_1, model_2, 42, 21).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(y_pred, y_true, labels):\n",
    "    N = labels.shape[0]\n",
    "    matrix = [[0] * (N + 1) for _ in range(N + 1)]\n",
    "\n",
    "    matrix[0][0] = \" \"\n",
    "    for i in range(1, N):\n",
    "        matrix[i][0] = f\"{i}\"\n",
    "        matrix[0][i] = f\"{i}\"\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        matrix[round(y_pred[i]) + 1][y_true[i] + 1] += 1\n",
    "\n",
    "    for i in range(N):\n",
    "        print(\" \".join(map(str, matrix[i])))\n",
    "\n",
    "    return sum([matrix[i + 1][i + 1] for i in range(2)]) / len(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, X_val, y_val, criterion):\n",
    "    size = len(y_val)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with T.no_grad():\n",
    "        X = T.from_numpy(X_val).to(T.float32).to(device)\n",
    "        y_true = T.Tensor(y_val).to(T.float).to(device)\n",
    "\n",
    "        logits = model.forward(X)\n",
    "\n",
    "        loss = criterion(logits, y_true)\n",
    "\n",
    "        correct = (logits.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "        \n",
    "        loss /= size\n",
    "        accuracy = correct/size\n",
    "        print(f\"Validation Error: \\n Accuracy: {(100 * (accuracy)):>0.1f}%, Avg loss: {loss:>8f}\\n\")\n",
    "    \n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, criterion, optimizer):\n",
    "    size = len(X_train)\n",
    "    batch_size = 141\n",
    "\n",
    "    #Prevents model from memorizing the position of data\n",
    "    indices = np.random.randint(0, size, size)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i in range(size//batch_size):\n",
    "        start = batch_size * i\n",
    "        end = start + batch_size\n",
    "\n",
    "        X = T.from_numpy(X_train[indices[start:end]]).to(T.float32).to(device)\n",
    "        y_true = T.Tensor(y_train[indices[start:end]]).to(T.float).to(device)\n",
    "\n",
    "        logits = model.forward(X)\n",
    "        \n",
    "        loss = criterion(logits, y_true)\n",
    "\n",
    "        # Gradiant Descent using Adam optimizer for best performance\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = (logits.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "        accuracy = correct/batch_size\n",
    "\n",
    "        if (i * batch_size) % 564 == 0:\n",
    "            loss, current = loss.item(), (i + 1) * batch_size\n",
    "            print(f\"Accuracy: {(100 * (accuracy)):>0.1f}%, Loss_1: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Accuracy: 4.3%, Loss_1: 4.218879 [  141/ 5922]\n",
      "Accuracy: 7.1%, Loss_1: 4.097961 [  705/ 5922]\n",
      "Accuracy: 5.0%, Loss_1: 3.916252 [ 1269/ 5922]\n",
      "Accuracy: 7.1%, Loss_1: 4.531962 [ 1833/ 5922]\n",
      "Accuracy: 3.5%, Loss_1: 4.361672 [ 2397/ 5922]\n",
      "Accuracy: 6.4%, Loss_1: 3.832826 [ 2961/ 5922]\n",
      "Accuracy: 10.6%, Loss_1: 4.387230 [ 3525/ 5922]\n",
      "Accuracy: 8.5%, Loss_1: 4.114189 [ 4089/ 5922]\n",
      "Accuracy: 7.1%, Loss_1: 4.048773 [ 4653/ 5922]\n",
      "Accuracy: 5.7%, Loss_1: 4.188960 [ 5217/ 5922]\n",
      "Accuracy: 5.7%, Loss_1: 4.198960 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 7.8%, Avg loss: 0.015580\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Accuracy: 6.4%, Loss_1: 3.967680 [  141/ 5922]\n",
      "Accuracy: 7.1%, Loss_1: 4.168066 [  705/ 5922]\n",
      "Accuracy: 11.3%, Loss_1: 3.845173 [ 1269/ 5922]\n",
      "Accuracy: 6.4%, Loss_1: 4.190248 [ 1833/ 5922]\n",
      "Accuracy: 9.9%, Loss_1: 3.957819 [ 2397/ 5922]\n",
      "Accuracy: 7.8%, Loss_1: 4.197525 [ 2961/ 5922]\n",
      "Accuracy: 7.8%, Loss_1: 3.881728 [ 3525/ 5922]\n",
      "Accuracy: 9.2%, Loss_1: 4.126809 [ 4089/ 5922]\n",
      "Accuracy: 7.1%, Loss_1: 4.102489 [ 4653/ 5922]\n",
      "Accuracy: 5.7%, Loss_1: 4.221105 [ 5217/ 5922]\n",
      "Accuracy: 4.3%, Loss_1: 3.979080 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 9.2%, Avg loss: 0.014638\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Accuracy: 9.9%, Loss_1: 3.988866 [  141/ 5922]\n",
      "Accuracy: 7.1%, Loss_1: 4.096442 [  705/ 5922]\n",
      "Accuracy: 11.3%, Loss_1: 3.807897 [ 1269/ 5922]\n",
      "Accuracy: 6.4%, Loss_1: 3.821147 [ 1833/ 5922]\n",
      "Accuracy: 11.3%, Loss_1: 3.817189 [ 2397/ 5922]\n",
      "Accuracy: 12.1%, Loss_1: 3.693696 [ 2961/ 5922]\n",
      "Accuracy: 10.6%, Loss_1: 3.831085 [ 3525/ 5922]\n",
      "Accuracy: 9.9%, Loss_1: 3.760137 [ 4089/ 5922]\n",
      "Accuracy: 5.0%, Loss_1: 4.179613 [ 4653/ 5922]\n",
      "Accuracy: 8.5%, Loss_1: 3.914552 [ 5217/ 5922]\n",
      "Accuracy: 7.1%, Loss_1: 3.851515 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 10.6%, Avg loss: 0.013730\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Accuracy: 10.6%, Loss_1: 3.803296 [  141/ 5922]\n",
      "Accuracy: 9.9%, Loss_1: 4.002231 [  705/ 5922]\n",
      "Accuracy: 9.2%, Loss_1: 3.661874 [ 1269/ 5922]\n",
      "Accuracy: 10.6%, Loss_1: 3.951180 [ 1833/ 5922]\n",
      "Accuracy: 9.2%, Loss_1: 3.697742 [ 2397/ 5922]\n",
      "Accuracy: 10.6%, Loss_1: 3.999803 [ 2961/ 5922]\n",
      "Accuracy: 16.3%, Loss_1: 3.414612 [ 3525/ 5922]\n",
      "Accuracy: 7.8%, Loss_1: 3.932019 [ 4089/ 5922]\n",
      "Accuracy: 12.8%, Loss_1: 3.443645 [ 4653/ 5922]\n",
      "Accuracy: 9.2%, Loss_1: 3.827181 [ 5217/ 5922]\n",
      "Accuracy: 9.9%, Loss_1: 3.816597 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 12.3%, Avg loss: 0.012850\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Accuracy: 11.3%, Loss_1: 4.016717 [  141/ 5922]\n",
      "Accuracy: 14.9%, Loss_1: 3.418541 [  705/ 5922]\n",
      "Accuracy: 8.5%, Loss_1: 3.874364 [ 1269/ 5922]\n",
      "Accuracy: 13.5%, Loss_1: 3.613761 [ 1833/ 5922]\n",
      "Accuracy: 12.8%, Loss_1: 3.604681 [ 2397/ 5922]\n",
      "Accuracy: 11.3%, Loss_1: 3.725637 [ 2961/ 5922]\n",
      "Accuracy: 8.5%, Loss_1: 3.634362 [ 3525/ 5922]\n",
      "Accuracy: 11.3%, Loss_1: 3.496490 [ 4089/ 5922]\n",
      "Accuracy: 9.2%, Loss_1: 3.643668 [ 4653/ 5922]\n",
      "Accuracy: 13.5%, Loss_1: 3.594319 [ 5217/ 5922]\n",
      "Accuracy: 17.0%, Loss_1: 3.416720 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 14.2%, Avg loss: 0.012018\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Accuracy: 14.9%, Loss_1: 3.351917 [  141/ 5922]\n",
      "Accuracy: 10.6%, Loss_1: 3.612361 [  705/ 5922]\n",
      "Accuracy: 12.8%, Loss_1: 3.586825 [ 1269/ 5922]\n",
      "Accuracy: 12.1%, Loss_1: 3.502207 [ 1833/ 5922]\n",
      "Accuracy: 17.0%, Loss_1: 3.472913 [ 2397/ 5922]\n",
      "Accuracy: 14.9%, Loss_1: 3.303037 [ 2961/ 5922]\n",
      "Accuracy: 16.3%, Loss_1: 3.371056 [ 3525/ 5922]\n",
      "Accuracy: 16.3%, Loss_1: 3.517935 [ 4089/ 5922]\n",
      "Accuracy: 20.6%, Loss_1: 3.246724 [ 4653/ 5922]\n",
      "Accuracy: 12.8%, Loss_1: 3.461235 [ 5217/ 5922]\n",
      "Accuracy: 20.6%, Loss_1: 3.187676 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 15.2%, Avg loss: 0.011223\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Accuracy: 19.9%, Loss_1: 3.221091 [  141/ 5922]\n",
      "Accuracy: 17.0%, Loss_1: 3.686069 [  705/ 5922]\n",
      "Accuracy: 14.2%, Loss_1: 3.599703 [ 1269/ 5922]\n",
      "Accuracy: 15.6%, Loss_1: 3.414144 [ 1833/ 5922]\n",
      "Accuracy: 19.1%, Loss_1: 3.216096 [ 2397/ 5922]\n",
      "Accuracy: 15.6%, Loss_1: 3.412650 [ 2961/ 5922]\n",
      "Accuracy: 22.7%, Loss_1: 3.233634 [ 3525/ 5922]\n",
      "Accuracy: 22.7%, Loss_1: 3.116131 [ 4089/ 5922]\n",
      "Accuracy: 19.1%, Loss_1: 3.267457 [ 4653/ 5922]\n",
      "Accuracy: 13.5%, Loss_1: 3.429343 [ 5217/ 5922]\n",
      "Accuracy: 19.1%, Loss_1: 3.091692 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 17.8%, Avg loss: 0.010469\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Accuracy: 19.1%, Loss_1: 3.112423 [  141/ 5922]\n",
      "Accuracy: 22.0%, Loss_1: 3.324484 [  705/ 5922]\n",
      "Accuracy: 23.4%, Loss_1: 3.088785 [ 1269/ 5922]\n",
      "Accuracy: 18.4%, Loss_1: 3.194459 [ 1833/ 5922]\n",
      "Accuracy: 20.6%, Loss_1: 3.293156 [ 2397/ 5922]\n",
      "Accuracy: 19.1%, Loss_1: 3.332024 [ 2961/ 5922]\n",
      "Accuracy: 17.0%, Loss_1: 3.229051 [ 3525/ 5922]\n",
      "Accuracy: 26.2%, Loss_1: 2.983414 [ 4089/ 5922]\n",
      "Accuracy: 20.6%, Loss_1: 3.177717 [ 4653/ 5922]\n",
      "Accuracy: 26.2%, Loss_1: 3.058568 [ 5217/ 5922]\n",
      "Accuracy: 17.7%, Loss_1: 3.033297 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 20.0%, Avg loss: 0.009774\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Accuracy: 21.3%, Loss_1: 3.136713 [  141/ 5922]\n",
      "Accuracy: 18.4%, Loss_1: 3.254075 [  705/ 5922]\n",
      "Accuracy: 19.1%, Loss_1: 3.149516 [ 1269/ 5922]\n",
      "Accuracy: 24.8%, Loss_1: 3.019465 [ 1833/ 5922]\n",
      "Accuracy: 24.8%, Loss_1: 3.058135 [ 2397/ 5922]\n",
      "Accuracy: 14.9%, Loss_1: 3.301324 [ 2961/ 5922]\n",
      "Accuracy: 17.7%, Loss_1: 3.251479 [ 3525/ 5922]\n",
      "Accuracy: 20.6%, Loss_1: 2.993830 [ 4089/ 5922]\n",
      "Accuracy: 20.6%, Loss_1: 3.007479 [ 4653/ 5922]\n",
      "Accuracy: 24.8%, Loss_1: 3.098771 [ 5217/ 5922]\n",
      "Accuracy: 21.3%, Loss_1: 3.045761 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 21.0%, Avg loss: 0.009138\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Accuracy: 20.6%, Loss_1: 2.996466 [  141/ 5922]\n",
      "Accuracy: 18.4%, Loss_1: 3.082597 [  705/ 5922]\n",
      "Accuracy: 24.1%, Loss_1: 2.964363 [ 1269/ 5922]\n",
      "Accuracy: 23.4%, Loss_1: 2.905958 [ 1833/ 5922]\n",
      "Accuracy: 21.3%, Loss_1: 2.918384 [ 2397/ 5922]\n",
      "Accuracy: 27.7%, Loss_1: 2.829143 [ 2961/ 5922]\n",
      "Accuracy: 24.1%, Loss_1: 2.915638 [ 3525/ 5922]\n",
      "Accuracy: 30.5%, Loss_1: 2.626071 [ 4089/ 5922]\n",
      "Accuracy: 25.5%, Loss_1: 2.908909 [ 4653/ 5922]\n",
      "Accuracy: 24.1%, Loss_1: 2.901400 [ 5217/ 5922]\n",
      "Accuracy: 21.3%, Loss_1: 2.867160 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 23.3%, Avg loss: 0.008555\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Accuracy: 22.7%, Loss_1: 3.080383 [  141/ 5922]\n",
      "Accuracy: 22.7%, Loss_1: 3.078651 [  705/ 5922]\n",
      "Accuracy: 22.0%, Loss_1: 3.099433 [ 1269/ 5922]\n",
      "Accuracy: 22.0%, Loss_1: 2.940335 [ 1833/ 5922]\n",
      "Accuracy: 26.2%, Loss_1: 2.878255 [ 2397/ 5922]\n",
      "Accuracy: 21.3%, Loss_1: 3.069917 [ 2961/ 5922]\n",
      "Accuracy: 22.0%, Loss_1: 2.909872 [ 3525/ 5922]\n",
      "Accuracy: 27.7%, Loss_1: 2.739100 [ 4089/ 5922]\n",
      "Accuracy: 28.4%, Loss_1: 2.722239 [ 4653/ 5922]\n",
      "Accuracy: 31.9%, Loss_1: 2.655976 [ 5217/ 5922]\n",
      "Accuracy: 27.7%, Loss_1: 2.889141 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 26.0%, Avg loss: 0.007987\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Accuracy: 30.5%, Loss_1: 2.726202 [  141/ 5922]\n",
      "Accuracy: 32.6%, Loss_1: 2.734457 [  705/ 5922]\n",
      "Accuracy: 31.2%, Loss_1: 2.621376 [ 1269/ 5922]\n",
      "Accuracy: 31.9%, Loss_1: 2.647847 [ 1833/ 5922]\n",
      "Accuracy: 33.3%, Loss_1: 2.662488 [ 2397/ 5922]\n",
      "Accuracy: 29.1%, Loss_1: 2.705623 [ 2961/ 5922]\n",
      "Accuracy: 27.0%, Loss_1: 2.690220 [ 3525/ 5922]\n",
      "Accuracy: 30.5%, Loss_1: 2.823274 [ 4089/ 5922]\n",
      "Accuracy: 29.1%, Loss_1: 2.843338 [ 4653/ 5922]\n",
      "Accuracy: 33.3%, Loss_1: 2.557436 [ 5217/ 5922]\n",
      "Accuracy: 24.8%, Loss_1: 2.733820 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 29.1%, Avg loss: 0.007485\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Accuracy: 18.4%, Loss_1: 2.935973 [  141/ 5922]\n",
      "Accuracy: 33.3%, Loss_1: 2.561761 [  705/ 5922]\n",
      "Accuracy: 24.8%, Loss_1: 2.791712 [ 1269/ 5922]\n",
      "Accuracy: 29.8%, Loss_1: 2.664522 [ 1833/ 5922]\n",
      "Accuracy: 27.7%, Loss_1: 2.616483 [ 2397/ 5922]\n",
      "Accuracy: 24.1%, Loss_1: 2.703170 [ 2961/ 5922]\n",
      "Accuracy: 29.8%, Loss_1: 2.651007 [ 3525/ 5922]\n",
      "Accuracy: 26.2%, Loss_1: 2.678528 [ 4089/ 5922]\n",
      "Accuracy: 29.1%, Loss_1: 2.575949 [ 4653/ 5922]\n",
      "Accuracy: 27.7%, Loss_1: 2.664309 [ 5217/ 5922]\n",
      "Accuracy: 25.5%, Loss_1: 2.787522 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 30.7%, Avg loss: 0.007006\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Accuracy: 34.8%, Loss_1: 2.486948 [  141/ 5922]\n",
      "Accuracy: 25.5%, Loss_1: 2.732399 [  705/ 5922]\n",
      "Accuracy: 36.9%, Loss_1: 2.433019 [ 1269/ 5922]\n",
      "Accuracy: 34.8%, Loss_1: 2.511172 [ 1833/ 5922]\n",
      "Accuracy: 29.8%, Loss_1: 2.602232 [ 2397/ 5922]\n",
      "Accuracy: 30.5%, Loss_1: 2.489320 [ 2961/ 5922]\n",
      "Accuracy: 27.7%, Loss_1: 2.493910 [ 3525/ 5922]\n",
      "Accuracy: 29.1%, Loss_1: 2.707874 [ 4089/ 5922]\n",
      "Accuracy: 28.4%, Loss_1: 2.552946 [ 4653/ 5922]\n",
      "Accuracy: 29.1%, Loss_1: 2.653960 [ 5217/ 5922]\n",
      "Accuracy: 31.2%, Loss_1: 2.641123 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 32.2%, Avg loss: 0.006572\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Accuracy: 28.4%, Loss_1: 2.616326 [  141/ 5922]\n",
      "Accuracy: 28.4%, Loss_1: 2.455487 [  705/ 5922]\n",
      "Accuracy: 28.4%, Loss_1: 2.644541 [ 1269/ 5922]\n",
      "Accuracy: 30.5%, Loss_1: 2.537974 [ 1833/ 5922]\n",
      "Accuracy: 36.9%, Loss_1: 2.294637 [ 2397/ 5922]\n",
      "Accuracy: 32.6%, Loss_1: 2.467626 [ 2961/ 5922]\n",
      "Accuracy: 36.9%, Loss_1: 2.355205 [ 3525/ 5922]\n",
      "Accuracy: 36.9%, Loss_1: 2.398981 [ 4089/ 5922]\n",
      "Accuracy: 36.2%, Loss_1: 2.406698 [ 4653/ 5922]\n",
      "Accuracy: 34.0%, Loss_1: 2.373126 [ 5217/ 5922]\n",
      "Accuracy: 31.9%, Loss_1: 2.584011 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 33.1%, Avg loss: 0.006165\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Accuracy: 35.5%, Loss_1: 2.402642 [  141/ 5922]\n",
      "Accuracy: 35.5%, Loss_1: 2.359947 [  705/ 5922]\n",
      "Accuracy: 31.9%, Loss_1: 2.347045 [ 1269/ 5922]\n",
      "Accuracy: 36.2%, Loss_1: 2.323162 [ 1833/ 5922]\n",
      "Accuracy: 36.2%, Loss_1: 2.296517 [ 2397/ 5922]\n",
      "Accuracy: 44.7%, Loss_1: 2.164015 [ 2961/ 5922]\n",
      "Accuracy: 34.8%, Loss_1: 2.314346 [ 3525/ 5922]\n",
      "Accuracy: 24.1%, Loss_1: 2.534050 [ 4089/ 5922]\n",
      "Accuracy: 31.9%, Loss_1: 2.344426 [ 4653/ 5922]\n",
      "Accuracy: 37.6%, Loss_1: 2.368990 [ 5217/ 5922]\n",
      "Accuracy: 35.5%, Loss_1: 2.251635 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 34.6%, Avg loss: 0.005790\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Accuracy: 33.3%, Loss_1: 2.426683 [  141/ 5922]\n",
      "Accuracy: 36.9%, Loss_1: 2.427226 [  705/ 5922]\n",
      "Accuracy: 36.9%, Loss_1: 2.350114 [ 1269/ 5922]\n",
      "Accuracy: 41.1%, Loss_1: 2.227007 [ 1833/ 5922]\n",
      "Accuracy: 33.3%, Loss_1: 2.257519 [ 2397/ 5922]\n",
      "Accuracy: 38.3%, Loss_1: 2.298074 [ 2961/ 5922]\n",
      "Accuracy: 38.3%, Loss_1: 2.136381 [ 3525/ 5922]\n",
      "Accuracy: 39.7%, Loss_1: 2.128329 [ 4089/ 5922]\n",
      "Accuracy: 39.7%, Loss_1: 2.131749 [ 4653/ 5922]\n",
      "Accuracy: 44.7%, Loss_1: 2.210699 [ 5217/ 5922]\n",
      "Accuracy: 27.7%, Loss_1: 2.434255 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 36.0%, Avg loss: 0.005461\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Accuracy: 44.7%, Loss_1: 1.987470 [  141/ 5922]\n",
      "Accuracy: 48.9%, Loss_1: 2.014928 [  705/ 5922]\n",
      "Accuracy: 44.0%, Loss_1: 2.069194 [ 1269/ 5922]\n",
      "Accuracy: 37.6%, Loss_1: 2.329031 [ 1833/ 5922]\n",
      "Accuracy: 37.6%, Loss_1: 2.129014 [ 2397/ 5922]\n",
      "Accuracy: 48.9%, Loss_1: 1.881058 [ 2961/ 5922]\n",
      "Accuracy: 35.5%, Loss_1: 2.275605 [ 3525/ 5922]\n",
      "Accuracy: 39.7%, Loss_1: 2.231589 [ 4089/ 5922]\n",
      "Accuracy: 39.7%, Loss_1: 2.129717 [ 4653/ 5922]\n",
      "Accuracy: 39.0%, Loss_1: 2.157284 [ 5217/ 5922]\n",
      "Accuracy: 35.5%, Loss_1: 2.166356 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 37.0%, Avg loss: 0.005156\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Accuracy: 40.4%, Loss_1: 2.038826 [  141/ 5922]\n",
      "Accuracy: 42.6%, Loss_1: 2.141164 [  705/ 5922]\n",
      "Accuracy: 45.4%, Loss_1: 2.055292 [ 1269/ 5922]\n",
      "Accuracy: 51.8%, Loss_1: 1.952260 [ 1833/ 5922]\n",
      "Accuracy: 44.7%, Loss_1: 2.108862 [ 2397/ 5922]\n",
      "Accuracy: 40.4%, Loss_1: 2.168423 [ 2961/ 5922]\n",
      "Accuracy: 44.0%, Loss_1: 2.029588 [ 3525/ 5922]\n",
      "Accuracy: 44.0%, Loss_1: 2.200191 [ 4089/ 5922]\n",
      "Accuracy: 39.7%, Loss_1: 2.133762 [ 4653/ 5922]\n",
      "Accuracy: 44.7%, Loss_1: 2.100349 [ 5217/ 5922]\n",
      "Accuracy: 44.7%, Loss_1: 1.974462 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 39.0%, Avg loss: 0.004889\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Accuracy: 45.4%, Loss_1: 2.166826 [  141/ 5922]\n",
      "Accuracy: 43.3%, Loss_1: 2.113979 [  705/ 5922]\n",
      "Accuracy: 47.5%, Loss_1: 2.022181 [ 1269/ 5922]\n",
      "Accuracy: 32.6%, Loss_1: 2.290932 [ 1833/ 5922]\n",
      "Accuracy: 52.5%, Loss_1: 1.837882 [ 2397/ 5922]\n",
      "Accuracy: 45.4%, Loss_1: 2.036472 [ 2961/ 5922]\n",
      "Accuracy: 43.3%, Loss_1: 2.081964 [ 3525/ 5922]\n",
      "Accuracy: 46.8%, Loss_1: 2.030340 [ 4089/ 5922]\n",
      "Accuracy: 48.2%, Loss_1: 1.970742 [ 4653/ 5922]\n",
      "Accuracy: 46.8%, Loss_1: 1.907930 [ 5217/ 5922]\n",
      "Accuracy: 44.7%, Loss_1: 2.038490 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 40.4%, Avg loss: 0.004644\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Accuracy: 44.7%, Loss_1: 1.970823 [  141/ 5922]\n",
      "Accuracy: 39.7%, Loss_1: 2.080042 [  705/ 5922]\n",
      "Accuracy: 41.8%, Loss_1: 2.159498 [ 1269/ 5922]\n",
      "Accuracy: 52.5%, Loss_1: 1.806677 [ 1833/ 5922]\n",
      "Accuracy: 54.6%, Loss_1: 1.779589 [ 2397/ 5922]\n",
      "Accuracy: 44.0%, Loss_1: 2.039788 [ 2961/ 5922]\n",
      "Accuracy: 48.2%, Loss_1: 1.896310 [ 3525/ 5922]\n",
      "Accuracy: 44.0%, Loss_1: 1.925571 [ 4089/ 5922]\n",
      "Accuracy: 58.2%, Loss_1: 1.675485 [ 4653/ 5922]\n",
      "Accuracy: 46.8%, Loss_1: 1.924105 [ 5217/ 5922]\n",
      "Accuracy: 47.5%, Loss_1: 1.942360 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 42.4%, Avg loss: 0.004424\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Accuracy: 44.0%, Loss_1: 2.029009 [  141/ 5922]\n",
      "Accuracy: 48.2%, Loss_1: 1.958865 [  705/ 5922]\n",
      "Accuracy: 51.8%, Loss_1: 1.864016 [ 1269/ 5922]\n",
      "Accuracy: 44.7%, Loss_1: 1.919597 [ 1833/ 5922]\n",
      "Accuracy: 39.7%, Loss_1: 2.113047 [ 2397/ 5922]\n",
      "Accuracy: 52.5%, Loss_1: 1.838701 [ 2961/ 5922]\n",
      "Accuracy: 53.2%, Loss_1: 1.846340 [ 3525/ 5922]\n",
      "Accuracy: 49.6%, Loss_1: 1.868325 [ 4089/ 5922]\n",
      "Accuracy: 51.1%, Loss_1: 1.775684 [ 4653/ 5922]\n",
      "Accuracy: 51.8%, Loss_1: 1.743494 [ 5217/ 5922]\n",
      "Accuracy: 54.6%, Loss_1: 1.805099 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 44.3%, Avg loss: 0.004220\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Accuracy: 53.2%, Loss_1: 1.693632 [  141/ 5922]\n",
      "Accuracy: 50.4%, Loss_1: 1.844510 [  705/ 5922]\n",
      "Accuracy: 56.7%, Loss_1: 1.669831 [ 1269/ 5922]\n",
      "Accuracy: 50.4%, Loss_1: 1.791147 [ 1833/ 5922]\n",
      "Accuracy: 51.1%, Loss_1: 1.850587 [ 2397/ 5922]\n",
      "Accuracy: 45.4%, Loss_1: 2.007156 [ 2961/ 5922]\n",
      "Accuracy: 48.9%, Loss_1: 1.990807 [ 3525/ 5922]\n",
      "Accuracy: 49.6%, Loss_1: 1.823939 [ 4089/ 5922]\n",
      "Accuracy: 51.1%, Loss_1: 1.740489 [ 4653/ 5922]\n",
      "Accuracy: 60.3%, Loss_1: 1.555958 [ 5217/ 5922]\n",
      "Accuracy: 56.0%, Loss_1: 1.701395 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 46.0%, Avg loss: 0.004067\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Accuracy: 53.9%, Loss_1: 1.801509 [  141/ 5922]\n",
      "Accuracy: 51.1%, Loss_1: 1.813626 [  705/ 5922]\n",
      "Accuracy: 45.4%, Loss_1: 1.955116 [ 1269/ 5922]\n",
      "Accuracy: 56.0%, Loss_1: 1.725409 [ 1833/ 5922]\n",
      "Accuracy: 46.1%, Loss_1: 1.797963 [ 2397/ 5922]\n",
      "Accuracy: 53.2%, Loss_1: 1.747634 [ 2961/ 5922]\n",
      "Accuracy: 51.1%, Loss_1: 1.824277 [ 3525/ 5922]\n",
      "Accuracy: 58.9%, Loss_1: 1.687233 [ 4089/ 5922]\n",
      "Accuracy: 48.9%, Loss_1: 1.782582 [ 4653/ 5922]\n",
      "Accuracy: 52.5%, Loss_1: 1.805979 [ 5217/ 5922]\n",
      "Accuracy: 53.9%, Loss_1: 1.664921 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 47.9%, Avg loss: 0.003938\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Accuracy: 52.5%, Loss_1: 1.791419 [  141/ 5922]\n",
      "Accuracy: 39.7%, Loss_1: 2.061067 [  705/ 5922]\n",
      "Accuracy: 54.6%, Loss_1: 1.806935 [ 1269/ 5922]\n",
      "Accuracy: 56.0%, Loss_1: 1.699922 [ 1833/ 5922]\n",
      "Accuracy: 54.6%, Loss_1: 1.764747 [ 2397/ 5922]\n",
      "Accuracy: 60.3%, Loss_1: 1.638602 [ 2961/ 5922]\n",
      "Accuracy: 48.2%, Loss_1: 1.821700 [ 3525/ 5922]\n",
      "Accuracy: 55.3%, Loss_1: 1.705189 [ 4089/ 5922]\n",
      "Accuracy: 58.9%, Loss_1: 1.670947 [ 4653/ 5922]\n",
      "Accuracy: 51.8%, Loss_1: 1.684714 [ 5217/ 5922]\n",
      "Accuracy: 48.9%, Loss_1: 1.808872 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 49.5%, Avg loss: 0.003819\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Accuracy: 51.8%, Loss_1: 1.601071 [  141/ 5922]\n",
      "Accuracy: 51.1%, Loss_1: 1.700742 [  705/ 5922]\n",
      "Accuracy: 53.9%, Loss_1: 1.852029 [ 1269/ 5922]\n",
      "Accuracy: 52.5%, Loss_1: 1.696107 [ 1833/ 5922]\n",
      "Accuracy: 49.6%, Loss_1: 1.822252 [ 2397/ 5922]\n",
      "Accuracy: 56.7%, Loss_1: 1.759142 [ 2961/ 5922]\n",
      "Accuracy: 55.3%, Loss_1: 1.701590 [ 3525/ 5922]\n",
      "Accuracy: 59.6%, Loss_1: 1.587945 [ 4089/ 5922]\n",
      "Accuracy: 58.2%, Loss_1: 1.622106 [ 4653/ 5922]\n",
      "Accuracy: 53.9%, Loss_1: 1.602637 [ 5217/ 5922]\n",
      "Accuracy: 58.9%, Loss_1: 1.604872 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 50.9%, Avg loss: 0.003737\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Accuracy: 60.3%, Loss_1: 1.572263 [  141/ 5922]\n",
      "Accuracy: 58.9%, Loss_1: 1.608023 [  705/ 5922]\n",
      "Accuracy: 60.3%, Loss_1: 1.569757 [ 1269/ 5922]\n",
      "Accuracy: 58.2%, Loss_1: 1.669319 [ 1833/ 5922]\n",
      "Accuracy: 54.6%, Loss_1: 1.655724 [ 2397/ 5922]\n",
      "Accuracy: 61.0%, Loss_1: 1.534752 [ 2961/ 5922]\n",
      "Accuracy: 53.9%, Loss_1: 1.674406 [ 3525/ 5922]\n",
      "Accuracy: 61.7%, Loss_1: 1.476070 [ 4089/ 5922]\n",
      "Accuracy: 59.6%, Loss_1: 1.627641 [ 4653/ 5922]\n",
      "Accuracy: 56.0%, Loss_1: 1.654102 [ 5217/ 5922]\n",
      "Accuracy: 63.8%, Loss_1: 1.594365 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 52.0%, Avg loss: 0.003665\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Accuracy: 59.6%, Loss_1: 1.524247 [  141/ 5922]\n",
      "Accuracy: 61.0%, Loss_1: 1.602295 [  705/ 5922]\n",
      "Accuracy: 61.0%, Loss_1: 1.565263 [ 1269/ 5922]\n",
      "Accuracy: 65.2%, Loss_1: 1.472294 [ 1833/ 5922]\n",
      "Accuracy: 70.2%, Loss_1: 1.382893 [ 2397/ 5922]\n",
      "Accuracy: 61.7%, Loss_1: 1.675131 [ 2961/ 5922]\n",
      "Accuracy: 63.8%, Loss_1: 1.498781 [ 3525/ 5922]\n",
      "Accuracy: 63.1%, Loss_1: 1.503006 [ 4089/ 5922]\n",
      "Accuracy: 63.1%, Loss_1: 1.556335 [ 4653/ 5922]\n",
      "Accuracy: 65.2%, Loss_1: 1.518928 [ 5217/ 5922]\n",
      "Accuracy: 56.7%, Loss_1: 1.562590 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 53.3%, Avg loss: 0.003619\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Accuracy: 66.0%, Loss_1: 1.523416 [  141/ 5922]\n",
      "Accuracy: 58.9%, Loss_1: 1.593535 [  705/ 5922]\n",
      "Accuracy: 71.6%, Loss_1: 1.340025 [ 1269/ 5922]\n",
      "Accuracy: 69.5%, Loss_1: 1.338705 [ 1833/ 5922]\n",
      "Accuracy: 61.0%, Loss_1: 1.465272 [ 2397/ 5922]\n",
      "Accuracy: 67.4%, Loss_1: 1.413241 [ 2961/ 5922]\n",
      "Accuracy: 65.2%, Loss_1: 1.519521 [ 3525/ 5922]\n",
      "Accuracy: 65.2%, Loss_1: 1.514334 [ 4089/ 5922]\n",
      "Accuracy: 70.9%, Loss_1: 1.380998 [ 4653/ 5922]\n",
      "Accuracy: 61.7%, Loss_1: 1.415407 [ 5217/ 5922]\n",
      "Accuracy: 62.4%, Loss_1: 1.510389 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 54.9%, Avg loss: 0.003588\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Accuracy: 70.2%, Loss_1: 1.413592 [  141/ 5922]\n",
      "Accuracy: 70.2%, Loss_1: 1.432011 [  705/ 5922]\n",
      "Accuracy: 61.7%, Loss_1: 1.494807 [ 1269/ 5922]\n",
      "Accuracy: 69.5%, Loss_1: 1.381834 [ 1833/ 5922]\n",
      "Accuracy: 66.0%, Loss_1: 1.545609 [ 2397/ 5922]\n",
      "Accuracy: 63.8%, Loss_1: 1.549158 [ 2961/ 5922]\n",
      "Accuracy: 56.0%, Loss_1: 1.653487 [ 3525/ 5922]\n",
      "Accuracy: 66.7%, Loss_1: 1.524069 [ 4089/ 5922]\n",
      "Accuracy: 61.7%, Loss_1: 1.509460 [ 4653/ 5922]\n",
      "Accuracy: 74.5%, Loss_1: 1.326549 [ 5217/ 5922]\n",
      "Accuracy: 70.9%, Loss_1: 1.392816 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.003572\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Accuracy: 68.1%, Loss_1: 1.377374 [  141/ 5922]\n",
      "Accuracy: 66.7%, Loss_1: 1.408042 [  705/ 5922]\n",
      "Accuracy: 62.4%, Loss_1: 1.548803 [ 1269/ 5922]\n",
      "Accuracy: 67.4%, Loss_1: 1.478941 [ 1833/ 5922]\n",
      "Accuracy: 63.1%, Loss_1: 1.515544 [ 2397/ 5922]\n",
      "Accuracy: 67.4%, Loss_1: 1.501560 [ 2961/ 5922]\n",
      "Accuracy: 61.7%, Loss_1: 1.551232 [ 3525/ 5922]\n",
      "Accuracy: 66.7%, Loss_1: 1.604020 [ 4089/ 5922]\n",
      "Accuracy: 70.9%, Loss_1: 1.414978 [ 4653/ 5922]\n",
      "Accuracy: 67.4%, Loss_1: 1.506160 [ 5217/ 5922]\n",
      "Accuracy: 67.4%, Loss_1: 1.488115 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 57.4%, Avg loss: 0.003575\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Accuracy: 63.8%, Loss_1: 1.545444 [  141/ 5922]\n",
      "Accuracy: 66.0%, Loss_1: 1.505008 [  705/ 5922]\n",
      "Accuracy: 68.1%, Loss_1: 1.512746 [ 1269/ 5922]\n",
      "Accuracy: 73.0%, Loss_1: 1.390169 [ 1833/ 5922]\n",
      "Accuracy: 68.1%, Loss_1: 1.437770 [ 2397/ 5922]\n",
      "Accuracy: 70.9%, Loss_1: 1.333538 [ 2961/ 5922]\n",
      "Accuracy: 72.3%, Loss_1: 1.250751 [ 3525/ 5922]\n",
      "Accuracy: 67.4%, Loss_1: 1.492779 [ 4089/ 5922]\n",
      "Accuracy: 68.8%, Loss_1: 1.400347 [ 4653/ 5922]\n",
      "Accuracy: 64.5%, Loss_1: 1.534182 [ 5217/ 5922]\n",
      "Accuracy: 74.5%, Loss_1: 1.370206 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.003591\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Accuracy: 72.3%, Loss_1: 1.330248 [  141/ 5922]\n",
      "Accuracy: 70.9%, Loss_1: 1.414468 [  705/ 5922]\n",
      "Accuracy: 70.9%, Loss_1: 1.419868 [ 1269/ 5922]\n",
      "Accuracy: 73.8%, Loss_1: 1.243592 [ 1833/ 5922]\n",
      "Accuracy: 73.0%, Loss_1: 1.427306 [ 2397/ 5922]\n",
      "Accuracy: 68.8%, Loss_1: 1.340826 [ 2961/ 5922]\n",
      "Accuracy: 68.1%, Loss_1: 1.543829 [ 3525/ 5922]\n",
      "Accuracy: 68.8%, Loss_1: 1.448746 [ 4089/ 5922]\n",
      "Accuracy: 73.8%, Loss_1: 1.363950 [ 4653/ 5922]\n",
      "Accuracy: 75.2%, Loss_1: 1.370156 [ 5217/ 5922]\n",
      "Accuracy: 70.9%, Loss_1: 1.455959 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 58.6%, Avg loss: 0.003614\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Accuracy: 71.6%, Loss_1: 1.399397 [  141/ 5922]\n",
      "Accuracy: 71.6%, Loss_1: 1.347022 [  705/ 5922]\n",
      "Accuracy: 69.5%, Loss_1: 1.389494 [ 1269/ 5922]\n",
      "Accuracy: 72.3%, Loss_1: 1.375410 [ 1833/ 5922]\n",
      "Accuracy: 73.8%, Loss_1: 1.358229 [ 2397/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.212064 [ 2961/ 5922]\n",
      "Accuracy: 68.8%, Loss_1: 1.495701 [ 3525/ 5922]\n",
      "Accuracy: 71.6%, Loss_1: 1.482911 [ 4089/ 5922]\n",
      "Accuracy: 75.2%, Loss_1: 1.229938 [ 4653/ 5922]\n",
      "Accuracy: 70.2%, Loss_1: 1.388270 [ 5217/ 5922]\n",
      "Accuracy: 72.3%, Loss_1: 1.405820 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.003641\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Accuracy: 68.8%, Loss_1: 1.438539 [  141/ 5922]\n",
      "Accuracy: 72.3%, Loss_1: 1.370215 [  705/ 5922]\n",
      "Accuracy: 69.5%, Loss_1: 1.320515 [ 1269/ 5922]\n",
      "Accuracy: 73.0%, Loss_1: 1.296468 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.258928 [ 2397/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.255099 [ 2961/ 5922]\n",
      "Accuracy: 68.1%, Loss_1: 1.411945 [ 3525/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.156826 [ 4089/ 5922]\n",
      "Accuracy: 68.8%, Loss_1: 1.392827 [ 4653/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.324233 [ 5217/ 5922]\n",
      "Accuracy: 70.9%, Loss_1: 1.472536 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.003675\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Accuracy: 74.5%, Loss_1: 1.311513 [  141/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.251814 [  705/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.185131 [ 1269/ 5922]\n",
      "Accuracy: 71.6%, Loss_1: 1.255219 [ 1833/ 5922]\n",
      "Accuracy: 73.0%, Loss_1: 1.378967 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.207193 [ 2961/ 5922]\n",
      "Accuracy: 72.3%, Loss_1: 1.387472 [ 3525/ 5922]\n",
      "Accuracy: 74.5%, Loss_1: 1.272586 [ 4089/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.160430 [ 4653/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.172216 [ 5217/ 5922]\n",
      "Accuracy: 71.6%, Loss_1: 1.304897 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 59.5%, Avg loss: 0.003708\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Accuracy: 74.5%, Loss_1: 1.359398 [  141/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.195581 [  705/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.268717 [ 1269/ 5922]\n",
      "Accuracy: 69.5%, Loss_1: 1.437227 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 1.093137 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.203535 [ 2961/ 5922]\n",
      "Accuracy: 74.5%, Loss_1: 1.375759 [ 3525/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.231327 [ 4089/ 5922]\n",
      "Accuracy: 72.3%, Loss_1: 1.402490 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 1.042317 [ 5217/ 5922]\n",
      "Accuracy: 73.8%, Loss_1: 1.267990 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.003749\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 1.144169 [  141/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.244691 [  705/ 5922]\n",
      "Accuracy: 74.5%, Loss_1: 1.344804 [ 1269/ 5922]\n",
      "Accuracy: 70.9%, Loss_1: 1.319994 [ 1833/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.249390 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.242489 [ 2961/ 5922]\n",
      "Accuracy: 72.3%, Loss_1: 1.299657 [ 3525/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.272645 [ 4089/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.262308 [ 4653/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.344611 [ 5217/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.061081 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 60.1%, Avg loss: 0.003787\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Accuracy: 78.7%, Loss_1: 1.122930 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.134476 [  705/ 5922]\n",
      "Accuracy: 71.6%, Loss_1: 1.335759 [ 1269/ 5922]\n",
      "Accuracy: 75.2%, Loss_1: 1.239251 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.184662 [ 2397/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.149721 [ 2961/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.160688 [ 3525/ 5922]\n",
      "Accuracy: 74.5%, Loss_1: 1.191604 [ 4089/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.205197 [ 4653/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.214622 [ 5217/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.227884 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 60.1%, Avg loss: 0.003828\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Accuracy: 77.3%, Loss_1: 1.240085 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.038144 [  705/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.175064 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 1.086245 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.996940 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 1.150437 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 1.179031 [ 3525/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.185904 [ 4089/ 5922]\n",
      "Accuracy: 74.5%, Loss_1: 1.242757 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 1.149334 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.182812 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 60.4%, Avg loss: 0.003869\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 1.142082 [  141/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.217973 [  705/ 5922]\n",
      "Accuracy: 74.5%, Loss_1: 1.311730 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 1.095119 [ 1833/ 5922]\n",
      "Accuracy: 75.2%, Loss_1: 1.239286 [ 2397/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.149594 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.251243 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 1.070757 [ 4089/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.196597 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.162916 [ 5217/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.195010 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.003906\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 1.170324 [  141/ 5922]\n",
      "Accuracy: 69.5%, Loss_1: 1.377079 [  705/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.187231 [ 1269/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.273560 [ 1833/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.203092 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.996157 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 1.042351 [ 3525/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.095735 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.114399 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.113292 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 1.130884 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 60.7%, Avg loss: 0.003947\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Accuracy: 78.0%, Loss_1: 1.094743 [  141/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.162569 [  705/ 5922]\n",
      "Accuracy: 75.2%, Loss_1: 1.149381 [ 1269/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.206360 [ 1833/ 5922]\n",
      "Accuracy: 73.0%, Loss_1: 1.214063 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.155962 [ 2961/ 5922]\n",
      "Accuracy: 75.2%, Loss_1: 1.254834 [ 3525/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.112975 [ 4089/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.063656 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 1.043983 [ 5217/ 5922]\n",
      "Accuracy: 74.5%, Loss_1: 1.307166 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 60.7%, Avg loss: 0.003990\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 1.019141 [  141/ 5922]\n",
      "Accuracy: 72.3%, Loss_1: 1.264331 [  705/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.157731 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.901980 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.029121 [ 2397/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.169519 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 1.122279 [ 3525/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.143290 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 1.075694 [ 4653/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.124279 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.995266 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 60.8%, Avg loss: 0.004034\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 1.017810 [  141/ 5922]\n",
      "Accuracy: 74.5%, Loss_1: 1.159967 [  705/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.020902 [ 1269/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.091759 [ 1833/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.072783 [ 2397/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.102289 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.974159 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.026241 [ 4089/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.114872 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.066666 [ 5217/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.066264 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.004073\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 1.017006 [  141/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.116037 [  705/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.105781 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 1.020797 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.875504 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.930500 [ 2961/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.187837 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.053260 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 1.053699 [ 4653/ 5922]\n",
      "Accuracy: 73.8%, Loss_1: 1.207857 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.035493 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.004116\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Accuracy: 77.3%, Loss_1: 1.083365 [  141/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.194097 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.983323 [ 1269/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.172905 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.155425 [ 2397/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.123049 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.019676 [ 3525/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.188144 [ 4089/ 5922]\n",
      "Accuracy: 74.5%, Loss_1: 1.126068 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.975958 [ 5217/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.159010 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.004156\n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.950800 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 1.024831 [  705/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.106712 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.944764 [ 1833/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.078763 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.107697 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.971838 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 1.044067 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.946334 [ 4653/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.087510 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 1.066064 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.004199\n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Accuracy: 75.2%, Loss_1: 1.103355 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.953158 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.116259 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 1.026031 [ 1833/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.199098 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.005521 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.014948 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 1.020609 [ 4089/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.163056 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.093895 [ 5217/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.120426 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.004239\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 1.050772 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.003305 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.124041 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 1.111768 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 1.068109 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.065589 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 1.066594 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.113529 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.079628 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.925330 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.038650 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.004277\n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.951713 [  141/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.148912 [  705/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.038675 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.987767 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.874741 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.964433 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.823679 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.892005 [ 4089/ 5922]\n",
      "Accuracy: 73.8%, Loss_1: 1.179160 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 1.070812 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.958706 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.004317\n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Accuracy: 79.4%, Loss_1: 1.059641 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.060521 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.911757 [ 1269/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.977299 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.882934 [ 2397/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.083102 [ 2961/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.999205 [ 3525/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.222120 [ 4089/ 5922]\n",
      "Accuracy: 73.8%, Loss_1: 1.182470 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 1.003435 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.923206 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.004353\n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Accuracy: 78.0%, Loss_1: 1.104614 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.964892 [  705/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.061042 [ 1269/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.088203 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.056070 [ 2397/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.978394 [ 2961/ 5922]\n",
      "Accuracy: 74.5%, Loss_1: 1.110434 [ 3525/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.048158 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.896972 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.922803 [ 5217/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.054653 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.004392\n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 1.056682 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.962794 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.870136 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.985242 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.921621 [ 2397/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.133627 [ 2961/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.076909 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 1.029320 [ 4089/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.009834 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.984190 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.978517 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.004430\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 1.004532 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.916654 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.965165 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.945276 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.798939 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.000636 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.819813 [ 3525/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.068144 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.976432 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.014398 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.910011 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.004470\n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Accuracy: 75.9%, Loss_1: 1.088597 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.957886 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.897747 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.958034 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.930379 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.990229 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.992505 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.917098 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.834283 [ 4653/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.981658 [ 5217/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.205477 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.004509\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Accuracy: 76.6%, Loss_1: 1.091828 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.979410 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.997700 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.938578 [ 1833/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.102475 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.855698 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.971266 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.864979 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.068747 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.066633 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.955424 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.004547\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.959067 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.928016 [  705/ 5922]\n",
      "Accuracy: 74.5%, Loss_1: 1.119909 [ 1269/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.086468 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.891477 [ 2397/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.013589 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.851992 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.961125 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.934107 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.903705 [ 5217/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.022092 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.004586\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.979248 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.914814 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.993103 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.801430 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 1.005426 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.996888 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.039811 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.942669 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.962765 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.096242 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.962675 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.004620\n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.961932 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.938696 [  705/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.930565 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.822014 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.884727 [ 2397/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.127850 [ 2961/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.244290 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 1.027262 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.914423 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.772608 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.854782 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.004657\n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 1.040345 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.843036 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.073244 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.944456 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.729523 [ 2397/ 5922]\n",
      "Accuracy: 75.2%, Loss_1: 1.175161 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.906548 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 1.000091 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.859009 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.745613 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.781119 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.004690\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.648599 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.980607 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.939957 [ 1269/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.907739 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.983430 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.976810 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.920329 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.869908 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.884933 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.169909 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.915114 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.004727\n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.944660 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.915001 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.014766 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.897362 [ 1833/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.961042 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.787115 [ 2961/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.013539 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.847533 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.979123 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.866217 [ 5217/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.030846 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.004760\n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Accuracy: 78.7%, Loss_1: 1.071912 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.708971 [  705/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.068125 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.959080 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.968143 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.898472 [ 2961/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.043804 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.954153 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.901258 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.811993 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.863973 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.004797\n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Accuracy: 79.4%, Loss_1: 0.948353 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.906365 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.799466 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.867408 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.881135 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.899088 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.773467 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.880215 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.868565 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.068949 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.784548 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.004833\n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.820768 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.118252 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.966710 [ 1269/ 5922]\n",
      "Accuracy: 75.2%, Loss_1: 1.094751 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.841518 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.058873 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.829556 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.687828 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.124430 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.957571 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.966049 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.004868\n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 1.004174 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.159870 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.838131 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.901367 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.851471 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.011959 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.775739 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.846499 [ 4089/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.043641 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.750721 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.847847 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.004899\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.747347 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.926175 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.879906 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.895616 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.919118 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.902457 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.838954 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.943952 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.877479 [ 4653/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.063736 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.977719 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.004930\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.850550 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.991788 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.986199 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.895218 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.105639 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.968283 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.973095 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.775113 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.909814 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.821362 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.871824 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.004964\n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.843273 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.893428 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.830721 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.960949 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.851931 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.759085 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.791787 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.939248 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.935980 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.964387 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.868656 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.005000\n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Accuracy: 77.3%, Loss_1: 1.080968 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.811692 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.848399 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.985365 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.715604 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.917094 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.784838 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.881138 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.814723 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.697326 [ 5217/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.038593 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.005031\n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.925582 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.932304 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.845376 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.804707 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.908313 [ 2397/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.057366 [ 2961/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.035088 [ 3525/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.052201 [ 4089/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.039091 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 1.008441 [ 5217/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.992881 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.005063\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.827902 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.004488 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.699077 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.629582 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.804557 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.814812 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.914298 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.791714 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.748709 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.753852 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.804751 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.005094\n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Accuracy: 79.4%, Loss_1: 0.910728 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.870991 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.920828 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.811580 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.783729 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.012061 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.795911 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.726717 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.905888 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.007350 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.883919 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.005126\n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss_1: 0.543181 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.786138 [  705/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.942181 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.631457 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.774605 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.819669 [ 2961/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.031244 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.836002 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.871999 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.878486 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.869316 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.005159\n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.785295 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.821950 [  705/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.626985 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.811811 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.914667 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.868097 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.785826 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.851632 [ 4089/ 5922]\n",
      "Accuracy: 70.9%, Loss_1: 1.328288 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.891419 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.836362 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.005189\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss_1: 0.531017 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 1.005413 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.821260 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.822213 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.859798 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.821029 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.849803 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.857572 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.945834 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.876987 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.872189 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.005218\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.718285 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.834137 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.774483 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.740818 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.867509 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.799597 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.824415 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.860625 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.745434 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.842611 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.824643 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.005247\n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.824154 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.875659 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.792196 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.752545 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.912207 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.933659 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.784638 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.860989 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.899256 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.952755 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.967473 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.005276\n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.708720 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.856189 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.743448 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.854052 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.850955 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.838024 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.768536 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.810492 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.969161 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.801403 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.753296 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.005308\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.781950 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.917019 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.888426 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.933077 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.718828 [ 2397/ 5922]\n",
      "Accuracy: 74.5%, Loss_1: 1.000287 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.865846 [ 3525/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.556268 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.712654 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.721574 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.703474 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.005335\n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.789073 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.693688 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.876495 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.800535 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.831069 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.896372 [ 2961/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.976617 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.954567 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.797978 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.721562 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.904729 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.005364\n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.871134 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.946623 [  705/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.922812 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.787999 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.683602 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.888828 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.826112 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.784117 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.846577 [ 4653/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.665802 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.966547 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.005390\n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.994232 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.812246 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.878917 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.583190 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.789671 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.870321 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.902879 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.816626 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.724586 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.792249 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.724891 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.005415\n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.733076 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.753373 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.911617 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.794398 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.841596 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.759674 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.923443 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.727955 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.744910 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.862190 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.869979 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.005442\n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.835097 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 1.010651 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.906957 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.819191 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.805015 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.688922 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.866630 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.809326 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.642608 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.788424 [ 5217/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.959468 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.005468\n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.565089 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.849882 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.884954 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.802318 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.895023 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.712692 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.812136 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 1.002565 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.772985 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.865566 [ 5217/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.614699 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.005495\n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.639228 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.728324 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.931363 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.641877 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.955808 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.738890 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.917874 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.610845 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.741847 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.802005 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.762684 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.005522\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.792256 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.957063 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.032689 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.920533 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.957005 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.780089 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.539311 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.785045 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.757038 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.851426 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.011084 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.005544\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.844087 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.638187 [  705/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.946657 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.819951 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.940644 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.912105 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.827798 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.781606 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.652166 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.660431 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.750738 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.005567\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.626714 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.835809 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.933673 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.820712 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.002444 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.828186 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.721285 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.755543 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.886756 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.941850 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.749834 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.005598\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.780185 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.753258 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.828158 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.664355 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.845807 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.804175 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.900075 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.773130 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.787443 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.793975 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.787558 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.005622\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.993856 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.717108 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.753421 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.888156 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.896417 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.745881 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.773658 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.943627 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.744375 [ 4653/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.015998 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.696728 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.005647\n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss_1: 0.673317 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.888371 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.681773 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.911077 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.704842 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.748896 [ 2961/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.864988 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.895565 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.897835 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.745684 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.643097 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.005673\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.675346 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.837572 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.747761 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.694919 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.776760 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.775051 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.873862 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.755254 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.773306 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.725583 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.580273 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.005696\n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.828571 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.756299 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.716386 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.808748 [ 1833/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.935704 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.843267 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.673920 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.673551 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.711510 [ 4653/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.512369 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.751870 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.005722\n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.733418 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.763433 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.842505 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.851734 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.800588 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.729668 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.674235 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.819350 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.771957 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.894172 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.647544 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.005750\n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.839018 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.715869 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.801034 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.941432 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.750893 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.921266 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.750536 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.656356 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.782664 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.753310 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.745975 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.005775\n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.725432 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.887871 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.677872 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.860095 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.870980 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.777757 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.639572 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.820563 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.903390 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.790396 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.666844 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.005796\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 1.037612 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.682204 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.921659 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.867457 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.779454 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.802877 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.718324 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.842246 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.793199 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.747254 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.848429 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.005815\n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.770853 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.738376 [  705/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.569761 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.797220 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.878464 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.790300 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.647998 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.748472 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.477808 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.583340 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.781673 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.005839\n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.594680 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.672478 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.863596 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.786679 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.831974 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.787828 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.766620 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.916605 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.745975 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.813172 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.635624 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.005869\n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.902033 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.694218 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.711591 [ 1269/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.940700 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.540456 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.742751 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.701013 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.820496 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.721944 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.791431 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.617924 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.005898\n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.763459 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.747325 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.786315 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.661212 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.839892 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.740441 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.858499 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.778041 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.683139 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.667123 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.885544 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.005924\n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.779581 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.783896 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.735096 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.808485 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.900890 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.767722 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.700311 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.770232 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.667769 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.711645 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.929915 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.005949\n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.777667 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.759216 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.664894 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.747743 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.663509 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.614213 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.704212 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.914491 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.576715 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.885522 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.813495 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.005972\n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.812902 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.019134 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.927212 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.751039 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.960201 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.805902 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.833579 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.697888 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.775084 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.759439 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.767967 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.005992\n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.559009 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.747494 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.532780 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.773936 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.720963 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.805875 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.678769 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.603825 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.729378 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.705779 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.935590 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.006014\n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.657386 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.878852 [  705/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 0.930351 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.822883 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.761468 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.805833 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.954395 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.710985 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.857976 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.519300 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.679083 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.006038\n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.679168 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.769122 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.807458 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.723442 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.914712 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.707018 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.760193 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.766621 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.620564 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.790394 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.709585 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.006061\n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.684942 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.622910 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.638071 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.788866 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.792896 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.851626 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.791436 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.788776 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.855192 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.951930 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.671027 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.006083\n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "Accuracy: 78.7%, Loss_1: 0.869460 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.735235 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.668402 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.759025 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.917446 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.584164 [ 2961/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.001864 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.632024 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.803984 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.672030 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.789248 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.006104\n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.766278 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.930177 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.718946 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.633850 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.796890 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.771196 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.808221 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.832393 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.568382 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.804093 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.675751 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.006123\n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.793979 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.802386 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.815788 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.704234 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.696828 [ 2397/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.927644 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.794310 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.712102 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.619793 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.828837 [ 5217/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.002588 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.006144\n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.637350 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.775937 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.815404 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.802516 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.748853 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.744325 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.638176 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.525823 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.601180 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.819337 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.741277 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.006162\n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.837968 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.508412 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.750338 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.861219 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.643444 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.710733 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.888499 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.690260 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.669162 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.698134 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.696423 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.006181\n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.663115 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.923770 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.577863 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.729413 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.801629 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.756801 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.750255 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.679968 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.883691 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.813908 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.556237 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.006203\n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "Accuracy: 79.4%, Loss_1: 0.987648 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.622795 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.593865 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.820642 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.974416 [ 2397/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.029932 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.724506 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.934259 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.867680 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.772931 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.658114 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.006221\n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.598627 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.608111 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.775856 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.819716 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.827317 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.694291 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.787772 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.783163 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.575659 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.806689 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.689261 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.006246\n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.795864 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.632762 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.734733 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.899266 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.640821 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.780435 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.723663 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.703957 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.906510 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.550932 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.718541 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.006269\n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.873311 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.650584 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.787966 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.586597 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.677348 [ 2397/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.021665 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.654658 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.651899 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.683725 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.701175 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.727143 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.006290\n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.780935 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.868982 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.622420 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.709280 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.683608 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.815979 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.730145 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.728584 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.741211 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.594595 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.885197 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.006310\n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.686858 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.811462 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.691831 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.773677 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.668923 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.758535 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.744086 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.779762 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.646312 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.602226 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.786312 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.006332\n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.574824 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.702663 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.564583 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.717509 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.659818 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.671504 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.787584 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.771889 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.944323 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.694742 [ 5217/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.980711 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.006350\n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.636200 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.710132 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.644098 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.737746 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.727830 [ 2397/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.957308 [ 2961/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.045623 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.585040 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.506827 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.857763 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.892480 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.006366\n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.578703 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.770463 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.878914 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.788555 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.719814 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.672356 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.703242 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.754018 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.628371 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.705228 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.686262 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.006387\n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.688599 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.613542 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.761950 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.736422 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.748590 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.837103 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.932565 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.782295 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.725966 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.928453 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.905038 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.006407\n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.843215 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.678174 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.787408 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.691426 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.928528 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.781109 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.769706 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.830509 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.829487 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.704255 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.718458 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.006430\n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.754871 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.660841 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.826609 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.686800 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.734395 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.858635 [ 2961/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.518496 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.780479 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.614377 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.843449 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.688905 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.006451\n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "Accuracy: 78.0%, Loss_1: 1.012122 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.723733 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.637945 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.752288 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.777552 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.671742 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.775054 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.795764 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.586026 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.878677 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.559046 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.006466\n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.684474 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.788451 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.672848 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.761804 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.818102 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.607151 [ 2961/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.475356 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.710719 [ 4089/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.947497 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.543479 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.725186 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.006485\n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.840857 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.843116 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.687521 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.721754 [ 1833/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.561332 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.510998 [ 2961/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.926576 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.698816 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.480337 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.782637 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.661484 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.006506\n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.761227 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.840770 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.574502 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.812696 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.755749 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.604904 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.609843 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.667181 [ 4089/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.017893 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.720920 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.703307 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.006520\n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.674648 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.826334 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.878460 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.652769 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.843094 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.914003 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.844620 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.704005 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.841536 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.740497 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.527197 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.006533\n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.611247 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.701041 [  705/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.979169 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.611433 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.716526 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.800472 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.739966 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.722805 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.746514 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.777767 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.767856 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.006549\n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss_1: 0.538552 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.699882 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.613634 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.620175 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.737349 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.460353 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.850069 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.686935 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.856607 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.698714 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.612363 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.006569\n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.821484 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.725004 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.769136 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.686505 [ 1833/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.467693 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.735114 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.562361 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.712378 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.842082 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.764856 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.528765 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.006584\n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.653330 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.685190 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.627609 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.723515 [ 1833/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.966548 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.691549 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.596808 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.624662 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.670263 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.826717 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.662798 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.006602\n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.663557 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.598580 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.779426 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.673565 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.844551 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.754371 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.717336 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.675229 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.752708 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.721223 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.734258 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.006618\n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.719880 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.699362 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.581701 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.598205 [ 1833/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.416480 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.768552 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.741477 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.893842 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.718978 [ 4653/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.566397 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.662973 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.006637\n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.815364 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.647770 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.699784 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.533136 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.637463 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.694868 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.699702 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.663203 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.651720 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.869743 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.584738 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.006652\n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.585173 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.764516 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.810789 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.630213 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.581151 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.810690 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.779328 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.603991 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.684093 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.574447 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.746857 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.006669\n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.889552 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.772096 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.577995 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.650580 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.662525 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.561378 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.829249 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.744894 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.648638 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.764190 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.569695 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.006682\n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.713853 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.558545 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.923039 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.681636 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.808036 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.544231 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.604181 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.747918 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.701753 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.597278 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.557593 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.006698\n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.802017 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.910123 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.752468 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.820121 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.572589 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.555209 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.738477 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.709762 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.548446 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.639975 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.614379 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.006714\n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.755056 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.794890 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.811076 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.711465 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.750907 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.690165 [ 2961/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.026959 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.660597 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.446387 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.685685 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.635538 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.006730\n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.733444 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.659316 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.538515 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.795190 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.653702 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.674632 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.769140 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.750441 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.753556 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.680964 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.854414 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.006749\n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.734371 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.603767 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.575284 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.842035 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.833562 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.720231 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.709266 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.786433 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.525212 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.636176 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.769442 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.006762\n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "Accuracy: 76.6%, Loss_1: 0.987814 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.939623 [  705/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.965340 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.739685 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.713389 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.780428 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.973001 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.813121 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.640879 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.699935 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.787011 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.006773\n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.672536 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.662998 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.615020 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.598712 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.738711 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.728709 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.877435 [ 3525/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.935833 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.981192 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.668981 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.834516 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.006786\n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.672096 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.659011 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.847564 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.728789 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.865466 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.675797 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.639640 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.781772 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.596534 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.662741 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.895304 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.006800\n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.723398 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.641714 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.666514 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.819649 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.652023 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.798427 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.553085 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.670914 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.671799 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.729538 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.722103 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.006812\n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.564980 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.745868 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.621596 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.655689 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.563045 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.690511 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.700415 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.811468 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.606659 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.545161 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.843225 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.006830\n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.766261 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.670129 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.685744 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.874059 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.518131 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.687065 [ 2961/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.795832 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.584805 [ 4089/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.476988 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.705483 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.598732 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.006847\n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.780936 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.505875 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.449539 [ 1269/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.546589 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.758823 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.615562 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.562720 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.756290 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.634020 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.691706 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.821061 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.006863\n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.808045 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.614298 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.713560 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.706444 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.628438 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.589018 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.738083 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.493450 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.771553 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.720239 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.655740 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.006875\n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.717243 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.809226 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.635792 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.789289 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.743906 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.652893 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.713909 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.805522 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.665709 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.784417 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.924026 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.006890\n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.756290 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.453928 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.755224 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.532286 [ 1833/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.494229 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.659135 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.796935 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.776182 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.778722 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.823675 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.515250 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.006900\n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.719748 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.718329 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.861020 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.617206 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.676564 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.640713 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.677233 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.575053 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.714991 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.808749 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.629449 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.006914\n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.763554 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.642065 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.759651 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.573033 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.715606 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.697718 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.658638 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.540971 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.739508 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.836493 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.517761 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.006927\n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.632664 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.614102 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.741341 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.739147 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.447064 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.530020 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.787699 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.660014 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.588362 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.476076 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.758354 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.006944\n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.772843 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.686086 [  705/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 0.999500 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.533611 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.841592 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.478549 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.771880 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.770975 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.681416 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.728433 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.722938 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.006962\n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.650679 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.899767 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.785347 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.861703 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.828578 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.744961 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.508170 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.513569 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.666450 [ 4653/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.891183 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.783921 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.006976\n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.704028 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.685179 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.540387 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.636883 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.667802 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.773651 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.871803 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.749423 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.619580 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.763759 [ 5217/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.853144 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.006988\n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.578087 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.754049 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.801597 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.652850 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.823307 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.524176 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.807993 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.654406 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.594162 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.807729 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.616827 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007002\n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.806724 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.529613 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.868632 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.858233 [ 1833/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.523599 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.710278 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.825629 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.932548 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.574683 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.618391 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.555605 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007014\n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.674788 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.604238 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.729300 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.509818 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.687773 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.676146 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.763568 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.504965 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.648210 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.558885 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.657934 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007026\n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.693143 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.822406 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.647025 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.805844 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.816470 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.596251 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.693268 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.713919 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.718916 [ 4653/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.878246 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.747899 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007043\n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.679235 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.653673 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.611690 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.599277 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.742041 [ 2397/ 5922]\n",
      "Accuracy: 93.6%, Loss_1: 0.429339 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.639517 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.592116 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.777835 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.696978 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.694890 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007058\n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "Accuracy: 78.7%, Loss_1: 0.881987 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.853988 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.613812 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.669272 [ 1833/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.937961 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.622835 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.861451 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.725358 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.695793 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.809250 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.709425 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007069\n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss_1: 0.479435 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.585151 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.808756 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.481131 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.590550 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.775090 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.701696 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.732328 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.824138 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.727546 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.505567 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007085\n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.579030 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.763604 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.863325 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.806288 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.711133 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.623354 [ 2961/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.507198 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.830746 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.774104 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.630520 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.591168 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007098\n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "Accuracy: 78.7%, Loss_1: 0.916530 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.737189 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.666623 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.655577 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.766774 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.597645 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.726300 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.808178 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.673153 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.700689 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.781453 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007111\n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.743379 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.683942 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.689799 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.676169 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.730635 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.782296 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.714572 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.755093 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.797798 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.974347 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.738233 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007130\n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.796416 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.541111 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.691234 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.621773 [ 1833/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.847304 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.744864 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.644376 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.611554 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.600305 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.619884 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.855799 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007144\n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.702096 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.673715 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.703235 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.628477 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.680601 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.574597 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.560527 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.568158 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.783313 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.781014 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.729154 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007161\n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.722832 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.614555 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.811463 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.811301 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.644757 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.747283 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.645055 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.786003 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.561248 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.704510 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.746768 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007175\n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.867654 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.691994 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.556945 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.691334 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.677070 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.677811 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.856417 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.580196 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.769499 [ 4653/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.434698 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.712419 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007188\n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.695992 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.660667 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.762538 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.691353 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.779433 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.692042 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.672339 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.639143 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.533804 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.779874 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.551318 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007199\n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.674507 [  141/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.369564 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.607655 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.603292 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.858191 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.760128 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.663189 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.546933 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.667627 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.757407 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.594062 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007208\n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.930339 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.786975 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.724057 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.713243 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.621965 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.620998 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.599067 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.584718 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.815141 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.812321 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.700279 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007223\n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.758334 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.717563 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.687330 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.680119 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.610145 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.645148 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.755458 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.527674 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.829861 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.648309 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.748358 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007230\n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.870952 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.817445 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.522917 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.733687 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.519956 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.676339 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.669205 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.566111 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.613964 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.560048 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.575388 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007242\n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.530632 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.684161 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.683618 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.593766 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.477598 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.663727 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.612880 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.564773 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.826818 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.597909 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.714172 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007250\n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.799577 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.724069 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.799350 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.685696 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.631360 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.729027 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.746336 [ 3525/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.871154 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.690713 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.679887 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.579656 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007258\n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.761355 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.664247 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.747970 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.546773 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.679452 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.609114 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.584554 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.809925 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.618621 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.860161 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.736152 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007267\n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.718493 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.797126 [  705/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.464543 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.553251 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.736432 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.566074 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.386085 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.581321 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.594915 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.559039 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.639037 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007275\n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.773292 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.702312 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.774452 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.647819 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.702680 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.610566 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.763009 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.713704 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.638578 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.774446 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.627954 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007281\n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.802078 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.554623 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.594581 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.686609 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.623218 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.634269 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.562941 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.693515 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.635769 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.699546 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.591472 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007289\n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.811714 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.699652 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.722128 [ 1269/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.040195 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.660938 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.834600 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.648235 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.753564 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.684513 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.665690 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.837093 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007299\n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.664187 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.662204 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.596107 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.570909 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.573066 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.750758 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.496558 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.664615 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.596018 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.503200 [ 5217/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.500161 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007310\n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.649424 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.623350 [  705/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.373123 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.831933 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.614939 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.651800 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.799358 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.948222 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.696373 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.586465 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.817566 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007324\n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.629817 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.481284 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.754945 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.760801 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.535698 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.675134 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.756663 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.928829 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.793053 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.705323 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.677055 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007328\n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.713176 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.781055 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.670508 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.702919 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.734181 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.673335 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.593714 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.597656 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.622754 [ 4653/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.964017 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.823640 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007342\n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.578093 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.733758 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.642128 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.789327 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.890568 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.634043 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.807600 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.855817 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.610757 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.522170 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.682435 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007344\n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.699308 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.583706 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.657724 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.704415 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.501106 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.551081 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.575891 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.549446 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.658487 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.752346 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.719522 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007359\n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.747718 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.623136 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.586521 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.675948 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.608266 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.490175 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.887975 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.682936 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.709638 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.466122 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.483643 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007374\n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.544238 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.625387 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.522104 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.776473 [ 1833/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.473468 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.668793 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.869206 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.737429 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.637409 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.643538 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.472429 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007381\n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.555064 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.727179 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.622842 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.805309 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.882115 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.687858 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.821450 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.682457 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.789864 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.773094 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.815815 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007387\n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.643389 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.563011 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.823620 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.724182 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.697160 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.658294 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.573933 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.745669 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.760383 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.804859 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.609492 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007393\n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.605677 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.564010 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.688577 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.637640 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.519426 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.735554 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.716932 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.727196 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.516126 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.595139 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.454891 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007403\n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.546154 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.789298 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.824494 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.831406 [ 1833/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.913886 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.733346 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.605760 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.543383 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.598069 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.696320 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.566116 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007408\n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.766011 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.588443 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.689090 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.735139 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.587629 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.668711 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.531869 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.764645 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.699938 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.643330 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.961907 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007421\n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.793841 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.749726 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.584113 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.562626 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.707780 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.612619 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.797190 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.764343 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.823567 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.732599 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.544747 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007429\n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss_1: 0.514898 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.700565 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.521051 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.578386 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.483636 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.853676 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.654457 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.698455 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.860512 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.816149 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.661474 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007438\n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.677241 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.621503 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.739861 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.756054 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.732838 [ 2397/ 5922]\n",
      "Accuracy: 94.3%, Loss_1: 0.377891 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.687635 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.548363 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.739790 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.629490 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.647491 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007442\n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.660200 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.858899 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.676845 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.831495 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.895003 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.549981 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.656373 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.727768 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.655704 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.670288 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.797052 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007446\n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.751709 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.563142 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.826127 [ 1269/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.953350 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.794383 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.679205 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.815790 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.530703 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.493919 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.603771 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.887371 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007455\n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.690556 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.622434 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.858612 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.606161 [ 1833/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.525096 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.790941 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.774279 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.611322 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.800108 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.644501 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.633274 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007460\n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.791869 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.570295 [  705/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.431230 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.902228 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.581529 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.581156 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.770642 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.810872 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.578694 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.474669 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.716799 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007464\n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.747488 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.488866 [  705/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.896564 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.633241 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.592105 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.928530 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.688625 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.688707 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.770507 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.909514 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.655853 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007474\n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.750288 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.643506 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.634245 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.477811 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.774319 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.628388 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.683326 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.635998 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.767502 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.884690 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.676313 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007483\n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.726986 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.798388 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.634665 [ 1269/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.464643 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.658739 [ 2397/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.476654 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.626198 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.811800 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.765699 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.707560 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.526754 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007495\n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.778000 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.785038 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.847206 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.704386 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.760511 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.670278 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.628658 [ 3525/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.540361 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.817259 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.684909 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.860279 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007504\n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.521750 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.522547 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.969671 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.694573 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.725261 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.669321 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.765384 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.803539 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.863614 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.570750 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.880382 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007514\n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.561259 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.561291 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.637720 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.613288 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.773874 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.816159 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.793257 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.502609 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.721967 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.717457 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.447943 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007524\n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.721623 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.511143 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.807700 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.559998 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.535592 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.581816 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.652284 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.686499 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.647933 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.591291 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.731388 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007534\n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.811952 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.563305 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.534983 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.619061 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.695626 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.806953 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.556603 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.816425 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.878429 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.588184 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.575177 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007540\n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.755643 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.859236 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.773798 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.755790 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.675166 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.660445 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.633711 [ 3525/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.384443 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.737079 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.747341 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.658374 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007546\n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.609045 [  141/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.383254 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.746989 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.762830 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.757149 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.700359 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.742953 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.846377 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.722261 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.690870 [ 5217/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.473437 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007560\n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.797679 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.586947 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.760220 [ 1269/ 5922]\n",
      "Accuracy: 94.3%, Loss_1: 0.384420 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.698039 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.746660 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.618810 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.815059 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616327 [ 4653/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.397892 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.832590 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007565\n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "Accuracy: 75.9%, Loss_1: 1.021848 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.574015 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.686662 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.666568 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.630379 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.546951 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.626311 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.609814 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.680339 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.769127 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.724532 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007564\n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.687791 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.883372 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.803643 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.655232 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.596892 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.858659 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.758689 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.720433 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.631024 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.541756 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.700497 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007571\n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.652929 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.789783 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.595801 [ 1269/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.094541 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.565100 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.796598 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.587137 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.841324 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.674841 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.738519 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.687069 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007570\n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.555057 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.729693 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.858349 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.683175 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.671124 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.670362 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.446558 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.537142 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.870507 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.776191 [ 5217/ 5922]\n",
      "Accuracy: 95.0%, Loss_1: 0.343116 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007572\n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.713883 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.606070 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.787632 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.592353 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.705122 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.540607 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.628967 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.589375 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.569152 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.682672 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.792040 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007580\n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.617149 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.793127 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.675138 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.662390 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.714832 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.717470 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.579202 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.726020 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.565908 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.713628 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.781443 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007584\n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.606440 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.610524 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.655405 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.645212 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.734043 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.502154 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.781001 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.591899 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.567535 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.666912 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.704664 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007588\n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.639679 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.639635 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.722994 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.634386 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.819071 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.633374 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.552577 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.621911 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.519841 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.621654 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.852116 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007588\n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.679381 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.586226 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.593239 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.740976 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.631762 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.698418 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.761390 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.629830 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.664233 [ 4653/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.446522 [ 5217/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.543667 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007598\n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.820374 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.661705 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.573891 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.926160 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.835821 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.638811 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.634776 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.512643 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.660666 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.831244 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.811252 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007603\n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.590227 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.667695 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.571952 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.691562 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.600525 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.900915 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.688232 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.772457 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.828927 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.782547 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.781382 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007611\n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.755698 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.552799 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.673856 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.808979 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.629353 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.914629 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.766461 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.827536 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.628601 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.527378 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.739546 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007618\n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.709615 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.737625 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.456616 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.629192 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.630450 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.877397 [ 2961/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.945769 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.579555 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.542429 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.592239 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.682097 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.007625\n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.676593 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.870328 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.644202 [ 1269/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.428212 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.619423 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.776401 [ 2961/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.864905 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.870227 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.829421 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.764867 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.564022 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.007635\n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "Accuracy: 78.7%, Loss_1: 0.984440 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.497524 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.731304 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.544155 [ 1833/ 5922]\n",
      "Accuracy: 93.6%, Loss_1: 0.390663 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.723245 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.790174 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.682820 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.827980 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.551828 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.690987 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007642\n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.575342 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.661681 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.649463 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.435523 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.783775 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.822174 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.707345 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.723258 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.481451 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.788995 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.859237 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007649\n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.517652 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.546806 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.626413 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.762219 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.656158 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.640582 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.657450 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.529062 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.672221 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.658645 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.624167 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007652\n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.707843 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.716008 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.612256 [ 1269/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.993790 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.617461 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.912632 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.575586 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.695086 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.575684 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.728418 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.532077 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007659\n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss_1: 0.461775 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.805304 [  705/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.964803 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.801318 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.789493 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.606292 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.578679 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.628697 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.701577 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.696631 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.894194 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007668\n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "Accuracy: 77.3%, Loss_1: 0.949842 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.592146 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.863988 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.586556 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.741179 [ 2397/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.911943 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.553314 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.660806 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.704898 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.657102 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.660713 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007676\n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "Accuracy: 75.9%, Loss_1: 0.949947 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.666914 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.797018 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.668616 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.536594 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.500852 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.561511 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.729162 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.621731 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.570675 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.756951 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007678\n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.646636 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.744403 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.856747 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.616636 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.782380 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.718816 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.745567 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.610092 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.691460 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.665044 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.704522 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007685\n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.721276 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.827225 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.491076 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.495121 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.728636 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.619573 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.781401 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.533198 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.525399 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.636685 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.671580 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007694\n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.780134 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.747903 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.737739 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.605534 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.793693 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.555653 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.466979 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.757540 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.561136 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.807016 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.807413 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007701\n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.732245 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.588130 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.728253 [ 1269/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.888583 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.766745 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.634062 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.556495 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.592320 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.549235 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.978788 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.693096 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007708\n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.846112 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.801530 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.699905 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.656576 [ 1833/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.452496 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.770599 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.623870 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.670165 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.588249 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.774668 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.615076 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007715\n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.611750 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.730590 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.687617 [ 1269/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.516090 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.794355 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.799155 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.721858 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.872629 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.634650 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.730334 [ 5217/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.984102 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007724\n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.619077 [  141/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.023484 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.638056 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.684617 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.621168 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.670703 [ 2961/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 0.985200 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.640108 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.581474 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.610768 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.436036 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007727\n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.642180 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.648204 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.580207 [ 1269/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.793626 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.728904 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.566557 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.545885 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.636228 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.580156 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.879172 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.598837 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007736\n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.623049 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.564522 [  705/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.445112 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.618558 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.722315 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.629982 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.873617 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.783961 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.600482 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.683464 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.464622 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007741\n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.758127 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.922078 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.653203 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.595300 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.625083 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.752844 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.828736 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.608183 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.707651 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.631580 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.613629 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007749\n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.812232 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.741399 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.725284 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.801787 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.823423 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.602221 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.643743 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.810240 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.557280 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.650004 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.659516 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.007752\n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.717526 [  141/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.403643 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.567534 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.584011 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.626263 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.691910 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.613179 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.646789 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.609199 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.575948 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.780757 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007758\n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.684559 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.687708 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.700506 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.591300 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.659218 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.755752 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.666239 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.702097 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.556324 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.734086 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.616896 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007767\n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.660290 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.498542 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.482888 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.700101 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.658769 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.555216 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.521959 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.674405 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.807980 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.682825 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.696930 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007777\n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.605187 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.633563 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.538286 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.545718 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.888089 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.704719 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.705978 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.598203 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.573805 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.758381 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.629433 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007783\n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.626841 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.612395 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.835109 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.760713 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.761277 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.633654 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.795745 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.676801 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.751168 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.523430 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.527246 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007789\n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.722433 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.617041 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.757813 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.696177 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.677029 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.766165 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616023 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.708767 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.582417 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.784232 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.692196 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007797\n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.655251 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.666337 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.606613 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.645684 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.749906 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.447787 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.682292 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.573080 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.851183 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.602456 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.821735 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007797\n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.613982 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.439498 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.704083 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.643969 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.522732 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.544117 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.522611 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.560282 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.719395 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.877581 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.739085 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007794\n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.596289 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.650575 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.671606 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.623347 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.744248 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.651190 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.564373 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.470190 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.733251 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.880248 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.521450 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007797\n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.791968 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.627858 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.678204 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.771360 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.714325 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.684803 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.590281 [ 3525/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.010870 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.803299 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.577211 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.616775 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007799\n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.624522 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.576272 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.766297 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.622631 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.679322 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.724458 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.836011 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.802385 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.691296 [ 4653/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.989152 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.563086 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007809\n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.738847 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.432103 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.674674 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.710500 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.611110 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.823431 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.546022 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.668764 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.679691 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.637826 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.685485 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007815\n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.615135 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.753511 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.718139 [ 1269/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.460783 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.775739 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.834217 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.613088 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.724444 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.821385 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.495446 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.678724 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007824\n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.709877 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.823158 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.705111 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.599671 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.630978 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.459053 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.893977 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.590629 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.511744 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.624628 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.674229 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007831\n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.560550 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.525147 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.517885 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.644745 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.863653 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.774829 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.862634 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.827054 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.665497 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.702561 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.920731 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007834\n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.672680 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.645241 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.715606 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.696097 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.758371 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.776874 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.553396 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.705683 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.706243 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.641991 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.734860 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007833\n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.641172 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.731750 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.694792 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.586713 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.678613 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.828239 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.711923 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.560460 [ 4089/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.504474 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.627640 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.692628 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007835\n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.715753 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.778210 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.763983 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.654024 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.712577 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.743874 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.571870 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.619762 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.547548 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.773994 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.593892 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007836\n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.703030 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.879933 [  705/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.824178 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.842823 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.578357 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.679442 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.715092 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.555791 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.623041 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.729362 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.593163 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007840\n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.721567 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.489446 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.987999 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.568696 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.636904 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.838930 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.600242 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.578376 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.676349 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.755672 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.831193 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007843\n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.642930 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.612958 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.779253 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.536851 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.569303 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.624131 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.537109 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.783941 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.724415 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.746525 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.490077 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007848\n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.638985 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.564683 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.691676 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.730781 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.630273 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.663955 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.550793 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.714859 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.513645 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.790414 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.720110 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007859\n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.669217 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.656546 [  705/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.890444 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.662561 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.749598 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.513695 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.763424 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.614345 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.760609 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.601851 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.660893 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007867\n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.611820 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.824328 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.862926 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.682856 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.855393 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.621906 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.846270 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.728829 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.674308 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.656285 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.713344 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007865\n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.663282 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.647580 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.836534 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.769302 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.673840 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.622211 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.688932 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.455154 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.812271 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.678653 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.549156 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007861\n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.688617 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.643358 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.697201 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.594457 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.833736 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.994889 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.900032 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.640949 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.571276 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.631175 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.753535 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.007867\n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.709491 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.516447 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.560249 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.650089 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.686968 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.525480 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.571902 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.680872 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.595381 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.500001 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.751225 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007875\n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.543274 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.744656 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.669046 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.618259 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.597811 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.688935 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.722190 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.589313 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.787874 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.830822 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.799433 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007883\n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.746478 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.603812 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.655459 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.676549 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.653234 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.751724 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.600504 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.776021 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.638673 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.961400 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.885955 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007888\n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.552375 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.694906 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.657175 [ 1269/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.480063 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.677074 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.774362 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.884229 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.758808 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.711498 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.792092 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.679971 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007891\n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.538844 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.701710 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.734007 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.530708 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.608786 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.577402 [ 2961/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.470913 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.703201 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.545750 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.491533 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.666471 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007895\n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "Accuracy: 78.0%, Loss_1: 0.997278 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.604245 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.659187 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.475893 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.482573 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.500491 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.666832 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.807833 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.780065 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.615231 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.797889 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.007903\n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.812792 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.840853 [  705/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.894331 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.940797 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.730165 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.572545 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.660649 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.693344 [ 4089/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.820023 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.583379 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.774361 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007902\n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.645009 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.912733 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.610192 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.472572 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.767531 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.724129 [ 2961/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.907189 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.538310 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.618599 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.579916 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.587603 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007900\n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.795357 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.486076 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.615671 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.582138 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.778529 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.789036 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.602422 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.694758 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.664207 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.718607 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.491254 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007903\n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.636723 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.796050 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.715828 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.821966 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.672328 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.853297 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.681620 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.760989 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.700872 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.547129 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.780049 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007907\n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.724108 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.639295 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.672948 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.817261 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.660832 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.826192 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.786177 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.845012 [ 4089/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.839085 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.693337 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.699461 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007913\n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.791549 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.792210 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.576027 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.753261 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.574323 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.868857 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.804740 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.731161 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.532421 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.541632 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.690292 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007919\n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.789778 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.636296 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.736329 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.543008 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.669251 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.564945 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.712399 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.698044 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.582979 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.522567 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.640363 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.007926\n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.560117 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.567432 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.779224 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.616374 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.644818 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.693019 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.742285 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.596469 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.778174 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.816175 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.704778 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007930\n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.870868 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.658907 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.693928 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.732187 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.606491 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.561195 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.558860 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.709756 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.597155 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.495892 [ 5217/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.397709 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007932\n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.736941 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.662625 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.665233 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.663156 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.704955 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.591532 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.819100 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.441754 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.624525 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.720646 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.648266 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007938\n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.865734 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.838648 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.801526 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.597444 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.744400 [ 2397/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.006905 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.519396 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.651110 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.588550 [ 4653/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.414461 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.599395 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007943\n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.698998 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.697470 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.738175 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.652053 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.499655 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.782151 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.598955 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.663079 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.562988 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.662562 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.680035 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007945\n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.813215 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.610487 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.829877 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.727874 [ 1833/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.427180 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.745464 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.716190 [ 3525/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.370408 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.693528 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.697435 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.838833 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007947\n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.620897 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.740024 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.843223 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.725925 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.597552 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.699303 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.626350 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.736662 [ 4089/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.827364 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.535000 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.635154 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007947\n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.610303 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.756018 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.652972 [ 1269/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.834921 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.710195 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.512381 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.552558 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.581778 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.656081 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.853093 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.472035 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007944\n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.739699 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.850544 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.560310 [ 1269/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.809358 [ 1833/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.491540 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.896192 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.642506 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.637713 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.791995 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.676909 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.648863 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007948\n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.714403 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.550383 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.846188 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.760218 [ 1833/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.950882 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.711968 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.870241 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.751686 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.586309 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.794628 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.502668 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007956\n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.906467 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.799975 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.537594 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.721608 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.563951 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.503560 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.847666 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.583766 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.582258 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.722974 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.887194 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007963\n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.597985 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.932622 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.693337 [ 1269/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.806550 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.592362 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.593502 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.785631 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.600215 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.738389 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.638142 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.615887 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007973\n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.561776 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.650998 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.889754 [ 1269/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.472878 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.714262 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.607232 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.617639 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.743814 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.874711 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.564880 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.575685 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007972\n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.569588 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.618134 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.625694 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.664672 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.695368 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.518368 [ 2961/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.944710 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.450885 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.847203 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.608597 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.517575 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.007974\n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.559941 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.642069 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.829116 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.731020 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.560709 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.742094 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.534394 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.579688 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.843852 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.821437 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.628075 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.007980\n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.605109 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.539295 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.585580 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.645701 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.683443 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.932137 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.555504 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.656139 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.660158 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.688909 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.772788 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007983\n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.586700 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.704672 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.614983 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.568762 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.649516 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.628913 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.666648 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.735724 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.741601 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.666208 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.645125 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007983\n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.632222 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.676380 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.698532 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.710642 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.830582 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.583405 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.945153 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.629901 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.669329 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.525991 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.517723 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007983\n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.693677 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.574464 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.744448 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.787560 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.596374 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.886307 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.725222 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.711642 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.613307 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.819046 [ 5217/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.520662 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007986\n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.741676 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.770672 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.635128 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.617560 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.577988 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.703651 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.777735 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.595398 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.631171 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.551612 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.688168 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007990\n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.844410 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.643798 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.627311 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.779656 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.508780 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.656594 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.540186 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.747523 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.616738 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.821344 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.612347 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.007997\n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.654592 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.731345 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.467991 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.754245 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.587895 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.610353 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.659428 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.821612 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.689859 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.759872 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.811248 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008009\n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.626608 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.874080 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.538705 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.575725 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.546696 [ 2397/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.521181 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.475482 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.651689 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.679431 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.581266 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.673900 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008016\n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss_1: 0.465125 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.578973 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.782395 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.782037 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.471860 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.942721 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.620892 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.495059 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.659518 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.899309 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.533140 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008020\n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.767950 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.774560 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.522465 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.714923 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.588821 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.690757 [ 2961/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.458167 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.565126 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.734090 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.631352 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.626620 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008020\n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.829032 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.577899 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.552380 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.607187 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.964018 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.912926 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.623723 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.652433 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.617467 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.716496 [ 5217/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.464425 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008025\n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.623033 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.706239 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.829806 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.696752 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.644453 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.623790 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.755563 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.572681 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.652848 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.640531 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.624104 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008034\n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.712973 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.793843 [  705/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.944219 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.697223 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.730972 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.780323 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.694533 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.665735 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.844546 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.703469 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.669404 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008038\n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.725268 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.483537 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.598823 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.596283 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.633557 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.754307 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.641877 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.645041 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.848867 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.564706 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.543187 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008047\n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.674581 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.684538 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.539463 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.730348 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.844504 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.730807 [ 2961/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.880454 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.758642 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.672785 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.723855 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.524560 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008049\n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.611421 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.459131 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.607629 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.802848 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.832536 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.746792 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.555423 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.568024 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.477226 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.458412 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.778758 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008051\n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.731468 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.633956 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.579173 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.783596 [ 1833/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.153627 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.643354 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.620553 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.657996 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.578926 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.583678 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.669794 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008054\n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.832380 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.820271 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.598296 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.740826 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.549422 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.779559 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.520830 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.920080 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.796776 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.665034 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.526626 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008055\n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.669929 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.501709 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.508387 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.510570 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.613920 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.448956 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.538929 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.583270 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.492277 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.606941 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.490051 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008059\n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.694433 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.669705 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.581762 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.592177 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.720109 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.635098 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.667701 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.723113 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.478776 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.653166 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.660511 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008068\n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.661739 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.695048 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.585726 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.522308 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.724876 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.770738 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.865724 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.678241 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.780066 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.730861 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.672777 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008071\n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.744029 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.585639 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.584568 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.746425 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.823330 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.531932 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.745068 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.655902 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.868089 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.840567 [ 5217/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.852546 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008069\n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.628254 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.604207 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.583129 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.698363 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.647635 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.516954 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.848203 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.514501 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.816297 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.804089 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.690151 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008071\n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.604144 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.576229 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.679902 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.438513 [ 1833/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.410982 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.427914 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.547374 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.575963 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.575631 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.735132 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.810384 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008076\n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.628864 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.751190 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.596195 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.441178 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.485072 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.611532 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.523863 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.694360 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.812831 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.696684 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.857902 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008081\n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.561743 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.984594 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.852537 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.677295 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.701485 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.541004 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.707554 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.738863 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.554195 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.562453 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.923895 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008081\n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.734573 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.584690 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.738466 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.751966 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.730388 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.777719 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.679880 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.622236 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.841295 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.713148 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.923460 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008081\n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.696009 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.808429 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.709053 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.771495 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.754876 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.563901 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.733060 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.494652 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.592800 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.568067 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.599897 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008083\n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.724746 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.576615 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.747875 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.704099 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.552570 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.717971 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.484465 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.753625 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.637979 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.562886 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.558288 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008096\n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.643336 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.603257 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.543413 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.643417 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.835310 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.637387 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.705554 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.640979 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.660934 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.681566 [ 5217/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.981170 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008100\n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.596444 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.880262 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.595007 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.589188 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.755016 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.724397 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.677361 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.633062 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.718291 [ 4653/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.378858 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.665917 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008102\n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.737750 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.640942 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.721657 [ 1269/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.007674 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.828418 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.607376 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.702635 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.513999 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.680770 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.541269 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.809623 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008099\n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.612031 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.529819 [  705/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.831445 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.771780 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.768799 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.454521 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.602446 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.672821 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.625962 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.587941 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.578317 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008100\n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.739081 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.671350 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.537738 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.801420 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.701693 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.599378 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.683045 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.735761 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.620538 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.740765 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.517755 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008105\n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.599364 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.768612 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.597572 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.754403 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.540301 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.691606 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.849735 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.618528 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.581146 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.693524 [ 5217/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.030346 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008101\n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.707523 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.617841 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.742716 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.749003 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.597250 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.550911 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.736070 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.674162 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.620425 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.651537 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.695610 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008102\n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.740932 [  141/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.965782 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.534487 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.483670 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.563224 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.677966 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.705799 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.745421 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.568325 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.535130 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.630973 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008108\n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "Accuracy: 79.4%, Loss_1: 0.800897 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.568234 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.825379 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.841371 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.696730 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.673143 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.581104 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.700460 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.581687 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.618730 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.641659 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008108\n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.516887 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.850408 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.544190 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.576334 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.763131 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.549558 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.664677 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.786762 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.724217 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.618923 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.665804 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008099\n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.729285 [  141/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.427974 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.670712 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.596300 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.565285 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.521172 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.632399 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.608959 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.506301 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.644429 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.545434 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008097\n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.842663 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.437906 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.753159 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.892991 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.531598 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.668871 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.793223 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.638649 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.772398 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.628728 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.554504 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008101\n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.595485 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.497466 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.648392 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.505345 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.558498 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.646841 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.816915 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.778323 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.671677 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.892184 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.557106 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008105\n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.561786 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.641427 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.730508 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.553572 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.743903 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.481465 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.629642 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.793617 [ 4089/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.346253 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.663085 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.873272 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008112\n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.574843 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.513667 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.595513 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.688346 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.534365 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.648530 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.878170 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.822785 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.764183 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.688022 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.540210 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008117\n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.631376 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.625570 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.679059 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.691668 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.556528 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.520130 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.534798 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.596958 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.589306 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.763775 [ 5217/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.878267 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008122\n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.556241 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.767056 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.740082 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.643918 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.482134 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.569726 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.452433 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.689089 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.646865 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.832816 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.814847 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008124\n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.672880 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.853184 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.710850 [ 1269/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.952715 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.766082 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.793749 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.538303 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.650621 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.717005 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.692287 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.667866 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008120\n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.643495 [  141/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.543639 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.651943 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.803043 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.750085 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.473982 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.437146 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.921333 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.603978 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.719512 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.607047 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008120\n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.631499 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.527927 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.615151 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.600552 [ 1833/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.477504 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.839286 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.680800 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.651619 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.708999 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.896566 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.612314 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008117\n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.587769 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.666394 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.605465 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.638186 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.826340 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.508651 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.780915 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.599011 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.659975 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.856639 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.573258 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008120\n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.579466 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.648220 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.743335 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.790236 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.736493 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.658931 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.697621 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.600332 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.692355 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.709901 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.827976 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008121\n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.537383 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.751284 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.846112 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.632392 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.472148 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.652867 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.706804 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.845412 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.463566 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.637381 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.680147 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008124\n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.604689 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.704497 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.516414 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.598708 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.658921 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.841242 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.675670 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.599731 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.554980 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.672273 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.733483 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008127\n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.807257 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.627130 [  705/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.425982 [ 1269/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.425527 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.741573 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.730357 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.758685 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.469039 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.639816 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.614591 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.624808 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008134\n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.452992 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.886313 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.512153 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.663500 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.594382 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.588161 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.682365 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.643535 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.571253 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.793303 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.525900 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008138\n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.715189 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.519472 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.555192 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.662473 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.548264 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.747630 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.756512 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.633901 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.557148 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.665054 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.876018 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008141\n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.703190 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.682006 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.764379 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.630973 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616329 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.670931 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.592640 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.680281 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.499878 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.579534 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.687764 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008144\n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.839495 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.814669 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.795409 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.730762 [ 1833/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.070415 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.680486 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.534136 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.882201 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.752394 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.504761 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.570751 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008142\n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.824510 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.790816 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.592481 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.687687 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.716812 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.434877 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.804307 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.596464 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.572669 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.707480 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.509478 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008145\n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.664169 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.545210 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.626884 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.512537 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.471914 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.551531 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.768528 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.740171 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.711449 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.793962 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.617931 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008152\n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.735513 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.892787 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.724436 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.806652 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.601259 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.617499 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.527073 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.674861 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.525027 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.701597 [ 5217/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.480607 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008155\n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.589490 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.788962 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.655834 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.728195 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.706126 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.684552 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.708865 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.677641 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.523563 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.719226 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.594898 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008156\n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.883369 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.432262 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.905661 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.786469 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.655209 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.637909 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.686660 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.680187 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.590906 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.548309 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.733473 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008157\n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.741894 [  141/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.437372 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.655196 [ 1269/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.380823 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.585605 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.549978 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.592356 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.916975 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.704818 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.838459 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.553356 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008164\n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.623821 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.799086 [  705/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.880052 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.693980 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.835419 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.872001 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.676371 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.725776 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.828192 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.755725 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.847616 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008166\n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.717410 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.651929 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.567396 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.710414 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.792728 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.860725 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.832802 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.729310 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.672546 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.782685 [ 5217/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.437324 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008167\n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.523710 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.836370 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.820970 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.632191 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.818309 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.672608 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.386912 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.623476 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.729464 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.564333 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.562021 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008172\n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.785572 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.655623 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.813324 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.641025 [ 1833/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.467594 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.503879 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.591671 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.543045 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.615082 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.517144 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.550815 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008178\n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.597122 [  141/ 5922]\n",
      "Accuracy: 93.6%, Loss_1: 0.381538 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.598247 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.821754 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.446924 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.886654 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.707016 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.570731 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.566055 [ 4653/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.885729 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.703724 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008186\n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss_1: 0.445743 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.623257 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.786462 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.447234 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.663705 [ 2397/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.185093 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.671272 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.492543 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.653657 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.501331 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.768911 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008186\n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.508634 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.732028 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.622328 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.626153 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.622867 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.654027 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.547421 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.594093 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.751836 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.694714 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.626795 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008188\n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.773883 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.786311 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.698982 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.718984 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.716856 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.514274 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.669585 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.579123 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.754077 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.623074 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.624501 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008191\n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.593537 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.811287 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.544576 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.469134 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.657072 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.738586 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.600348 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.938438 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.592104 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.508077 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.684994 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008201\n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.521397 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.570436 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.762974 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.731930 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.563140 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.715986 [ 2961/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.979151 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.594066 [ 4089/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.016457 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.751091 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.755135 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008200\n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.753662 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.830833 [  705/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.468343 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.764874 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.705199 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.462304 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.661930 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.736804 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.740671 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.732510 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.613317 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008205\n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.581911 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.628844 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.860802 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.611575 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.522265 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.608206 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.595903 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.601222 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.434588 [ 4653/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.457330 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.614841 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008210\n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.809172 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.462875 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.583197 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.842356 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.725701 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.637634 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.687806 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.751215 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.602225 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.691523 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.569955 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008218\n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.642632 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.803320 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.725779 [ 1269/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.855918 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.529698 [ 2397/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.441101 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.769767 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.536537 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.700522 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.699286 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.674374 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008220\n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.647192 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.731381 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.565878 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.815318 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.583109 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.670031 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.765770 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.755535 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.716756 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.679055 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.604104 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008221\n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.802238 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.771606 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.915975 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.567306 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.706294 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.788403 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.737285 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.667372 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.617355 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.616949 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.709088 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008220\n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.489711 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.690477 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.752791 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.536713 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.638658 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.554265 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.681778 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.739107 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.724003 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.644627 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.486336 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008227\n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss_1: 0.350348 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.709810 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.774905 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.818456 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.597380 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.656214 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.664505 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.847234 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.827442 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.756177 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.770247 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008230\n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.573312 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.553696 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.526483 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.820016 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.610689 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.751243 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.591937 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.677320 [ 4089/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.453867 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.745172 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.760635 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008228\n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.657844 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.733163 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.622442 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.500013 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.717909 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.607976 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.754577 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.793840 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.515079 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.627738 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.507446 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008224\n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss_1: 0.415478 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.718877 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.606382 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.516473 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.712669 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.550776 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.787801 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.657399 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.609412 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.699565 [ 5217/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.933923 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008222\n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.720804 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.701495 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.683527 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.694362 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.541744 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.525010 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.768382 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.577581 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.645605 [ 4653/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.374745 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.763877 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008221\n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss_1: 0.452748 [  141/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.428134 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.688138 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.430858 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.563238 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.602264 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.637151 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.779076 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.475162 [ 4653/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.491441 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.584086 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008230\n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.732496 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.576922 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.755173 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.610180 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.528950 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.656665 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.492177 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.618524 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.605495 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.764137 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.704811 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008233\n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "Accuracy: 75.9%, Loss_1: 0.906693 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.791141 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.667932 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.828763 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.606180 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.606578 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.747532 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.827787 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.769237 [ 4653/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.482278 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.762709 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008231\n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.715167 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.604225 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.558323 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.815791 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.676112 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.606325 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.742129 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.751356 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.494066 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.693023 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.545400 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008232\n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.720709 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.713503 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.579474 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.682688 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.587585 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.467451 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.599385 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.664140 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.555287 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.654571 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.607443 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008234\n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.626981 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.744743 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.679892 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.481635 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 1.036865 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.486492 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.667527 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.511001 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.636655 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.661391 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.608486 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008239\n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.684381 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.606520 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.581859 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.632486 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.738240 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.812563 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.714073 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.760816 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.677196 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.717073 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.722824 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008235\n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.627257 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.694831 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.884134 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.569559 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.757858 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.722642 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.666984 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.567746 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.451424 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.633632 [ 5217/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.451000 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008238\n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.588154 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.651061 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.692553 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.721757 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.634141 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.490848 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.589715 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.734216 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.440416 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.528157 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.708423 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008241\n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.792946 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.735217 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616224 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.684609 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.826982 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.730799 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.575282 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.662641 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.711481 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.556591 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.695925 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008244\n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.581640 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.686206 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.843031 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.646998 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.693397 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.490309 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.564249 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.741034 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.908115 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.575504 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.608083 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008255\n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "Accuracy: 93.6%, Loss_1: 0.366334 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.557437 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.765486 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.696934 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.884522 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.593858 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.655566 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.499558 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.622593 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.653153 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.663031 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008261\n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.511882 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.582078 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.591369 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.548157 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.756239 [ 2397/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.335470 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.479013 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.735384 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.641755 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.760650 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.438115 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008263\n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.582200 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.664512 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.497184 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.686846 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.452011 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.789105 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.529079 [ 3525/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.493914 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.555856 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.508871 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.576940 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008270\n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.576324 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.698762 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.671667 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.690879 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.599787 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.657044 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.733897 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.590956 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.505996 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.820847 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.542847 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008273\n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.729541 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.666797 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.743621 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.584730 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.634363 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.680574 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.705093 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.853379 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.740428 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.715355 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.779776 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008272\n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.598520 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.704787 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.593219 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.559688 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.798780 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.671357 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.642614 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.743245 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.758620 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.640476 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.763342 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008270\n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "Accuracy: 78.7%, Loss_1: 0.899338 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.683077 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.780109 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.850721 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.648847 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.567846 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.562248 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.736232 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.581966 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.672856 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.596645 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008274\n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.722353 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.577473 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.646033 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.748178 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.775300 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.634948 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.540697 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.856339 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.871933 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.710587 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.831908 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008277\n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.713255 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.722546 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.534504 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.882657 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.627998 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.522705 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.794294 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.576351 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.738802 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.742255 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.790375 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008279\n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss_1: 0.499791 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.668677 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.452270 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.601213 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.931359 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.713589 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.500450 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.856781 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.598169 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.727488 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.535574 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008281\n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.415935 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.701867 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.521484 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.530892 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.497826 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.838335 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.545651 [ 3525/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.504390 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.586062 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.644284 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.513713 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008292\n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.694547 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.895416 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.805126 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.650328 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.879757 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.671643 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.649988 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.476493 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.533641 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.568898 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.768207 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008295\n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.592963 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.714147 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.656190 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.461590 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.471293 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.921639 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.622462 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.682510 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.790736 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.611560 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.623884 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008292\n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.797180 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.569941 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.626596 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.541414 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.590367 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.469869 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.795302 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.423683 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.837218 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.554150 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.752710 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008292\n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.759427 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.441685 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.772875 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.698328 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.414162 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.689090 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.696828 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.649041 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.689362 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.778744 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.708498 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008294\n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.606736 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.558482 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.611732 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.700514 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.628638 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.696308 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.604003 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.533512 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.650896 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.773624 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.634442 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008295\n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.521933 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.690128 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.736843 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.694646 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.792023 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.748880 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.808312 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.493543 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.805259 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.687131 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.754731 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008296\n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.839466 [  141/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.418214 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.816821 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.651892 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.749425 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.678903 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.841866 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.676164 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.672477 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.537982 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.644473 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008297\n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.650729 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.657699 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.483116 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.500825 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.629565 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.630202 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.666556 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.559982 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.597023 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.601429 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.465809 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008298\n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.572345 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.552017 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.672097 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.753531 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.629688 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.492806 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.582032 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.802449 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.719733 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.550869 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.793833 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008299\n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.666415 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.647245 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.590509 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.579084 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.494707 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.428390 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.591344 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.704838 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.464028 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.827417 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.772801 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008303\n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.581118 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.609625 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.748983 [ 1269/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.361816 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.777394 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.440159 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.778016 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616894 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.539022 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.495545 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.575760 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008302\n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.565733 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.893933 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.609931 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.437927 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.917695 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.618249 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.613887 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.693593 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.552546 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.993253 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.604064 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008300\n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.534690 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.725014 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.762569 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.747777 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.815156 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.777631 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.641236 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.430023 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.669111 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.571821 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.496618 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008299\n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.710092 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.558921 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.642171 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.659911 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.628912 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.550058 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.730435 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.647362 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.717235 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.625622 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.628728 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008296\n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.559602 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.674837 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.478611 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.570231 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.836468 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.644271 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.706666 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.613678 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.758817 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.688644 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.526444 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008300\n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.630201 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.675088 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.671443 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.621417 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.713679 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.719903 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.551631 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.550384 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.710663 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.754177 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.878799 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008307\n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.691330 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.403387 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.444203 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.720876 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.775913 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.637275 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.698442 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.711963 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.596425 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.526439 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.454928 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008311\n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss_1: 0.429916 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.670031 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.608283 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.694801 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.651172 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.816272 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.641234 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.802760 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.634145 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.775422 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.607325 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008316\n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss_1: 0.541772 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.743500 [  705/ 5922]\n",
      "Accuracy: 93.6%, Loss_1: 0.395955 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.824911 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.514551 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.794700 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.646155 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.727592 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.657210 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.759564 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.612327 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008320\n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.777142 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.534436 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.597326 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.640691 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.686285 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.735305 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.672177 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.762950 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.701371 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.837414 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.710941 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008316\n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.521751 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.574926 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.689614 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.448143 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.525833 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.531856 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.631487 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.784516 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.696749 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.533000 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.883251 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008320\n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.593099 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.649183 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.727254 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.558601 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.558120 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.681404 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.610261 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.486345 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.547667 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.718623 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.577536 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008324\n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.687948 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.430203 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.598593 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.837694 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.512097 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.792653 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.493840 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.599717 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.600130 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.560049 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.643500 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008324\n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss_1: 0.575364 [  141/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.387379 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.676095 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.510282 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.649341 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.703587 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.606483 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.760381 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.783277 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.632751 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.648829 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008327\n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.532671 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.535423 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.711357 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.699885 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.673409 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.796646 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.795462 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.535565 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.643607 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.881425 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.486808 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008327\n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.636682 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.631653 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.698583 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.481457 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.597350 [ 2397/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.438329 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.682942 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.538506 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.544306 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.904031 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.611978 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008329\n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.732751 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.642042 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.690549 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.700166 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.710800 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.636672 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.530431 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.614910 [ 4089/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.456464 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.663035 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.677886 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008333\n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.612771 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.512159 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.599934 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.509334 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.545186 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.662153 [ 2961/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.401062 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.654603 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.390513 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.707269 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.694482 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008335\n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.694566 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.575361 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.532007 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.647838 [ 1833/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.426107 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.806580 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.515003 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.766876 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.661078 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.798163 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.584690 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008337\n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.609900 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.694420 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.552097 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.792573 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.887239 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.669376 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.890626 [ 3525/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.932191 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.643754 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.704113 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.504276 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008334\n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.878673 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.548934 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.745586 [ 1269/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.078481 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.560790 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.862801 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.607577 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.798212 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.790343 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.667951 [ 5217/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.452448 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008341\n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss_1: 0.493658 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.646358 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.646983 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.654406 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.593279 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.778311 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.655076 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.697769 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.723331 [ 4653/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.450856 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.550127 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008341\n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.470087 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.561359 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.686446 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.581325 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.581053 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.682667 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.559127 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.755990 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.797809 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.506085 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.548801 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008343\n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.562585 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.814140 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.791493 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.556430 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.813205 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.707366 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.759939 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.841787 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.601148 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.901124 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.713097 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008343\n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.906751 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.708985 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.828662 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.554282 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.697838 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.726587 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.677024 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.648334 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.682585 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.724654 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.785397 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008341\n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.676344 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.613365 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.550096 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.749952 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.718687 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.713734 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.706287 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.692140 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.718515 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.470093 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.518453 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008341\n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.727276 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.697981 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.632068 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.616119 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.667085 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.783412 [ 2961/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.441871 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.410101 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.447981 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.819498 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.521521 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008348\n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.689032 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.818543 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.785233 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.649454 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.729375 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.532647 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.535739 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.556392 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.510417 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.791815 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.643229 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008347\n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "Accuracy: 76.6%, Loss_1: 0.882884 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.669276 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.692559 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.803719 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.790396 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.766072 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.697786 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.556797 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.499443 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.606738 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.604252 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008349\n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.793701 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.642951 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.753411 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.664659 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.603896 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.550003 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.713913 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.727323 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.747240 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.548013 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.524250 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008350\n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.668467 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.807357 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.574164 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.558409 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.731090 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.572598 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.720006 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.623811 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.580158 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.714090 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.685107 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008347\n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.592560 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.875347 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.687323 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.746005 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.490494 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.654347 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.594266 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.660723 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.615774 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.699070 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.505946 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008350\n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.508754 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.985216 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.695215 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.649270 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.812800 [ 2397/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.913422 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.515344 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.455676 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.604886 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.634474 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.464523 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008348\n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.498123 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.660883 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.892899 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.385919 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.565057 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.912240 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.515727 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.647450 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.531100 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.603701 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.833160 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008354\n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "Accuracy: 95.0%, Loss_1: 0.300761 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.625493 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.631787 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.596018 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.553641 [ 2397/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.394522 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.603703 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.540089 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.593094 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.679868 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.487358 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008361\n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.725074 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.635990 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.658734 [ 1269/ 5922]\n",
      "Accuracy: 93.6%, Loss_1: 0.397150 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.809478 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.753639 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.571069 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.519864 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.442779 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.893472 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.506644 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008371\n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.714857 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.690480 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.743210 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.639997 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.816032 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.715034 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.827586 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.595092 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.735344 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.721623 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.646280 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008375\n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.560718 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.791166 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.792310 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.621709 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.776286 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.517426 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.775502 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.558984 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.537036 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.887936 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.575623 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008374\n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.795306 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.529401 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.744971 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.671669 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.559193 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.624968 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.769277 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.467389 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.705512 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.861154 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.626336 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008378\n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.779976 [  141/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.888030 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.608671 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.568616 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.772859 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.784304 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.723802 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.529108 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.773037 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.970791 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.754134 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008378\n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.536970 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.518698 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.734653 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.708775 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.680041 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.652347 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.720763 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.542097 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.497424 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.544372 [ 5217/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.820292 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008383\n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.640243 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.807817 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.671163 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.642441 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.639800 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.537975 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.624704 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.739762 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.374181 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.502458 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.500447 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008381\n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.497423 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.753827 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.737078 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.748756 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.638521 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.568794 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.589376 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.664172 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.766431 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.503116 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.680608 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008384\n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.434573 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.822147 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.757615 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.713073 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.684922 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.710235 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.829594 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.613450 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.692987 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.585464 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.694521 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008387\n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.560745 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.731700 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.720885 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.554141 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.784695 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.504979 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.670079 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.791988 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.446354 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.604266 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.612572 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008381\n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.592265 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.655986 [  705/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.028211 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.707145 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.568540 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.856757 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.689460 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.713239 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.754346 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.574176 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.711876 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008375\n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.651542 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.565543 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.632756 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.607843 [ 1833/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.492385 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.791891 [ 2961/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.937028 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.535328 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.692363 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.663032 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.630053 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008378\n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.664777 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.734380 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.605631 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.660416 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.648551 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.806603 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.558114 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.890249 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.779447 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.686440 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.753404 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008374\n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.855014 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.608819 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.563396 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.690487 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.515903 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.729787 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.777613 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.677696 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.606229 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.580094 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.451157 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008381\n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.646179 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.897732 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.734335 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.586283 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.699904 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.719512 [ 2961/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.424159 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.468528 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.734289 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.639299 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.625859 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008385\n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.594579 [  141/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.538448 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.687478 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.664495 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.687824 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.770469 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.726969 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.489518 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.663796 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.630772 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.568828 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008389\n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.748949 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.612018 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.753345 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.688184 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.570190 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.639633 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.548969 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.532493 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.497984 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.428114 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.501691 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008394\n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.636390 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.646175 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.549626 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.528959 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.688816 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.688781 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.620715 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.550260 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.646383 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.550648 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.719949 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008399\n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.691714 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.574251 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.786925 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.444289 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.681872 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.483401 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.531448 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.770690 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.713113 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.540932 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.650343 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008408\n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.534586 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.758676 [  705/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.420889 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.651715 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.676064 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.541534 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.758936 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.496384 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.777061 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.626299 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.765760 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008411\n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.775703 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.534586 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.608820 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.636105 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.616020 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.449488 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.750115 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.905478 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.689113 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.554925 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.730539 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008407\n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.758487 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.742462 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.761832 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.858451 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.774371 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.891130 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.547668 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.619475 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.699268 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.594311 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.622012 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008401\n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.632864 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.846542 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.783013 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.495229 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.905560 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.511255 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.767564 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.723274 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.612337 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.744670 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.694900 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008397\n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.691996 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.801117 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.681709 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.661650 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.510751 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.755575 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.675400 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.797972 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.484588 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.742266 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.747936 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008391\n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.526853 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.717616 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.685738 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.821970 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.681747 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.729892 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.758340 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.634930 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.903073 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.573802 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.516643 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008394\n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.580290 [  141/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.437716 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.453560 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.702922 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.555625 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.583886 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.670187 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.643343 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.660968 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.519107 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.662518 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008402\n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.601800 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.569197 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.564324 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.701023 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.635653 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.709736 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.744582 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.624226 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.594802 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.666138 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.762626 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008406\n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.830353 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.539266 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.584207 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.687193 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.845062 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.595183 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.492756 [ 3525/ 5922]\n",
      "Accuracy: 94.3%, Loss_1: 0.373899 [ 4089/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.427051 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.510310 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.699251 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008402\n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.535293 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.515634 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.596328 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.648223 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.753749 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.654581 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.640878 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.654911 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.828036 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.862863 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.668388 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008401\n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.543568 [  141/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.416037 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.634417 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.788398 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.663649 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.537440 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.735891 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.700093 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.694352 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.654366 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.576500 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008398\n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.692449 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.656930 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.694911 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.654042 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.718069 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.624110 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.714434 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.615360 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.731559 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.642004 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.565876 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008398\n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss_1: 0.566158 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.589912 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.643114 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.642745 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.521823 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.802271 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.749423 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.697991 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.604662 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.791935 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.707885 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008406\n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.682508 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.622925 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.739641 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.592815 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.537979 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.708640 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.768286 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.489111 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.712115 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.715408 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.636160 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008407\n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.611621 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.774255 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.533261 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.622594 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.710557 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.655539 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.776026 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.571669 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.800685 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.726719 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.801333 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008406\n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.764887 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.709503 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.791007 [ 1269/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.855230 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.582021 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.547518 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.426585 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.438290 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.621785 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.633383 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.611324 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008408\n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.690500 [  141/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.989210 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.547160 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.749923 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.579251 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.652879 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.562980 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.611416 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.626808 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.895155 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.582925 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008403\n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.778690 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.610889 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.565655 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.470383 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.693760 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.672252 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.644631 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.749117 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.593717 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.776921 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.873729 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008404\n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.822756 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.672635 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.717351 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.630543 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.613743 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.728743 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.522482 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.824827 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.591008 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.550461 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.615033 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008401\n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.591514 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.736321 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.652303 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.766499 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.817067 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.604805 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.723054 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.610645 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.737512 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.724438 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.677793 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008404\n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.639157 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.478425 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.500600 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.596534 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.525433 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.630228 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.689830 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.397530 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.574052 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.783259 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.657241 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008406\n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.470479 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.655001 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.624861 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.757903 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.712836 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.759504 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.709678 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.668843 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.510564 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.689940 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.695041 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008405\n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.728685 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.575453 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.580448 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.915649 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.703851 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.828579 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.652964 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.917395 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.794873 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.749801 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.764321 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008405\n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.703027 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.700553 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.539443 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.803105 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.606914 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.590290 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.570803 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.607710 [ 4089/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.001969 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.551512 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.787282 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008404\n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.598917 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.798702 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.862478 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.724107 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.697853 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.618216 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.620706 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.645598 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.417417 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.738577 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.742086 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008408\n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.803403 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.622430 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.629704 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.638350 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.705005 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.749024 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.977833 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.699481 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.546748 [ 4653/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.410744 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.642760 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008405\n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.799566 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.657449 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.819894 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.475738 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.835720 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.610250 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.570496 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.817288 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.725464 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.741190 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.502560 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008406\n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.660437 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.640077 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.664322 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.733921 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.510087 [ 2397/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.432515 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.552859 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.451892 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.555376 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.509812 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.613724 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008412\n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.601711 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.783747 [  705/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.460410 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.602284 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.752015 [ 2397/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.460381 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.617978 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.581989 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.642940 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.519692 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.448902 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008414\n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.648434 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.515172 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.521477 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.668342 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.572377 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.667641 [ 2961/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.815130 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.679341 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.858552 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.541843 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.592904 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008413\n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.683637 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.584996 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.584061 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.718308 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.760267 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.610145 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.662723 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.779523 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.675996 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.713129 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.660525 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008423\n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.681255 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.546036 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.651967 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.639002 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.629015 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.512369 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.737492 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.881062 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.833253 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.913798 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.768418 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008425\n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.481032 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.712440 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.714516 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.769333 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.628782 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.762715 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.649653 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.688706 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.602232 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.471244 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.750615 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008424\n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.590292 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.685963 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.633820 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.718657 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.712218 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.509710 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.552964 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.648721 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.714686 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.548465 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.517363 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008426\n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.603432 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.709871 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.595218 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.588008 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.686450 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.602014 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.686882 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.828763 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.530381 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.810671 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.594536 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008423\n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.631249 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.898186 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.679213 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.724393 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.569541 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.718926 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.561694 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.395184 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.751304 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.624768 [ 5217/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.060383 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008422\n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.725357 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.546637 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.655832 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.634817 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.670220 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.659389 [ 2961/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.497175 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.616579 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.565650 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.731427 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.580292 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008424\n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.714502 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.648400 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.691064 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.514717 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.693310 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.598378 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.798674 [ 3525/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.438157 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.481373 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.551321 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.619743 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008429\n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.484149 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.723041 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.504753 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.632326 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.675764 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.739527 [ 2961/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.942440 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.642481 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.524053 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.759825 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.738626 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008427\n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.653073 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.538864 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.683705 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.585416 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.661825 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.568039 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.673569 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.725885 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.585082 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.709000 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.712958 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008431\n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.759374 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.629260 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.693012 [ 1269/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.760397 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.748101 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.522794 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.756458 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.602357 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.678506 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.624599 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.616297 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008427\n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.738629 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.529807 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.623220 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.724580 [ 1833/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.437283 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.592661 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.790856 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.742687 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.653115 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.677495 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.549730 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008429\n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.547686 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.453997 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.786452 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.664635 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.579634 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.855069 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.677540 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.721977 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.559082 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.685673 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.763244 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008428\n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.854946 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.596497 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.617780 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.668014 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.770427 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.502206 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.723473 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.567525 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.672010 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.629943 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.581280 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008435\n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss_1: 0.453793 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.678971 [  705/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.467941 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.678556 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.640698 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.583049 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.806323 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.719139 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.711366 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.522599 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.504792 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008433\n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.799010 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.807548 [  705/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.882239 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.688818 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.688481 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.533650 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.773539 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.566892 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.776461 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.774644 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.678685 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008434\n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.682774 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.647634 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.608775 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.513618 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.703287 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.840876 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.515863 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.875947 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.486313 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.477727 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.607636 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008436\n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.713251 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.707825 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.743984 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.689063 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.666426 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.655177 [ 2961/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.449340 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.797745 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.717893 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.872096 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.677389 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008433\n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.500521 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.630719 [  705/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.860994 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.762342 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.599045 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.571307 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.756588 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.682808 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.923849 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.649199 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.729399 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008432\n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.535613 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.617641 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.820224 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.527182 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.821852 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.695083 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.621355 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.662984 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.658939 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.513359 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.749630 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008432\n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.470351 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.673261 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.785306 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.535253 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.501659 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.646867 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.696795 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.464966 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.640259 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.712844 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.697055 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008438\n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.597897 [  141/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.127999 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.599553 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.543030 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.792546 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.547561 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.735545 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.621478 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.544034 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.722938 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.750045 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008437\n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.649447 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.717373 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.592833 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.662158 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.494832 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.636293 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.589195 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.485569 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.718179 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.704674 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.664987 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008437\n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.855107 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.590013 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.611500 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.720028 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.506378 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.652547 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.774128 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.728154 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.629386 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.714961 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.486292 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008441\n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.590298 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.803580 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.628822 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.781858 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.622417 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.625584 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.692981 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.501085 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.851429 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.764961 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.538779 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008441\n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.572518 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.588478 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.788457 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.662447 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.688217 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.644936 [ 2961/ 5922]\n",
      "Accuracy: 75.2%, Loss_1: 1.095798 [ 3525/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.386108 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.646040 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.662396 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.816667 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008443\n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.502166 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.547459 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.538265 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.622081 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.692340 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.747004 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.720729 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.799187 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.439009 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.592995 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.764201 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008445\n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.774172 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.822243 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.597784 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.656538 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.678599 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.648540 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 1.063273 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.681672 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.711003 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.723352 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.637729 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008448\n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.609486 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.475649 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.508249 [ 1269/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.924060 [ 1833/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.438251 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.612015 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.539171 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.455219 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.509718 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.582057 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.756273 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008448\n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.667890 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.594785 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.769939 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.538004 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.578601 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.720630 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.549582 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.620338 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.817846 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.775801 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.657481 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008445\n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.497327 [  141/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.995401 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.688635 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.712101 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.762688 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.807483 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.748334 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.751888 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.592345 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.648782 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.469487 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008443\n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.764616 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.431323 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.663184 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.754005 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.608154 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.449148 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.653469 [ 3525/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.892263 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.539479 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.538778 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.604822 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008440\n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.654702 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.572757 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.607983 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.547317 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.844932 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.690337 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616151 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.593013 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.813340 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.710432 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.514674 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008443\n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.725362 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.702655 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.883731 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.608768 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.671975 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.721751 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.463532 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.451750 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.890306 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.565240 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.615395 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008446\n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.686189 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.665302 [  705/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.918434 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.681947 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.660882 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.501128 [ 2961/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.030403 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.642497 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.592208 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.573665 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.424501 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008443\n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.558365 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.537441 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.769271 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.836844 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.757961 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.641655 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.644017 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.596179 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.557259 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.848623 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.629697 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008446\n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.709230 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.570174 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.632395 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.604157 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.488442 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.726496 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.667951 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.770242 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.695133 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.866862 [ 5217/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.402062 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008447\n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.731367 [  141/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.430665 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.828872 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.707387 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.873993 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.709450 [ 2961/ 5922]\n",
      "Accuracy: 75.2%, Loss_1: 1.020702 [ 3525/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.414440 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.569761 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.501380 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.577812 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008449\n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.639891 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.753145 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.844005 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.666655 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.496561 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.516959 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.763253 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.674815 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.759710 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.740847 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.689407 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008457\n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.575925 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.658927 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.735214 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.799139 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.594150 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.530224 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.690707 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.811610 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.695863 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.578170 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.625525 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008459\n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.606161 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.699158 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.687806 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.842846 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.671389 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.716271 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.625718 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.526556 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.581789 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.722038 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.813340 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008461\n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.813193 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.520210 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.761671 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.866807 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.678736 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.696638 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.676027 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.815694 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.754165 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.629657 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.529729 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008463\n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.638621 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.677328 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.691240 [ 1269/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.880888 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 1.046382 [ 2397/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.906260 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.515231 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.792045 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.606197 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.626799 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.499230 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008460\n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.730738 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.588757 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.748555 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.803709 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.871893 [ 2397/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.341836 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.664455 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.507037 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.712642 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.817060 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.678262 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008455\n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.709566 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.499520 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.697763 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.605952 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.579988 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.600576 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.547627 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.629756 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.679825 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.707160 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.645989 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008457\n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.689614 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.552110 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.613384 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.616108 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.644065 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.683228 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.583527 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.646272 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.422964 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.821612 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.720424 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008460\n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.600499 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.714343 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.366184 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.821434 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.515136 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.626049 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.765695 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.726349 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.691822 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.535098 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.686031 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008460\n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.460035 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.463104 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.586800 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.647698 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.519260 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.890262 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.590744 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.840728 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.570454 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.762407 [ 5217/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.982011 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008457\n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.762814 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.728214 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.422213 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.502428 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.880727 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.642878 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.853404 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.699898 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.518410 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.668725 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.650195 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008450\n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.558888 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.647529 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.537487 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.531337 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.400314 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.469573 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.696597 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.710805 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.838358 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.977620 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.629640 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008454\n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.620177 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.623313 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.731188 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.703475 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.700923 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.495069 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.614350 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.605485 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.504028 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.609242 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.778139 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008452\n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.744791 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.677524 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.805999 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.762588 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.684938 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.599130 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.695061 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.814363 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.956289 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.662030 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.663119 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008447\n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.760335 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.699454 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.604261 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.495464 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.673819 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.598927 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.650350 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.885102 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.667520 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.708430 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.572180 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008441\n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.716235 [  141/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.316408 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.596247 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.630693 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.774195 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.522572 [ 2961/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.461523 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.815150 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.788956 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.669726 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.811933 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008442\n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.811227 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.845248 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.705965 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.656849 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.562326 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.768527 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.736712 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.607166 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.789871 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.618104 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.622583 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008447\n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.641112 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.586044 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.549587 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.571381 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.585803 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.606591 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.824684 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.746490 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.755021 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.840847 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.785205 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008452\n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.637265 [  141/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 0.888219 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.574265 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.813578 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.733894 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.534435 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.810776 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.649276 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.766295 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.678161 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.609180 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008450\n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.750938 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.379925 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.633746 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.555058 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.773750 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.435587 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.639723 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.678739 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.703719 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.689724 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.693717 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008447\n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.475520 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.073369 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.671390 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.833581 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.720416 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.449827 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.542610 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.723682 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.738357 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.656089 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.499657 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008448\n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.864203 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.797076 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.647522 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.503823 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.567838 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.677938 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.809343 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.698335 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.622154 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.640374 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.539610 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008455\n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.609277 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.552260 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.616454 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.651924 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.769703 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.598001 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.707707 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.813100 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.499647 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.803724 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.450040 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008458\n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.641755 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.627172 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.467864 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.649190 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.693657 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.473181 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.620834 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.572201 [ 4089/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.906259 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.714998 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.653140 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008466\n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.847164 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.783077 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.696255 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.631578 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.033597 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.745577 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.670165 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.594448 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.686879 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.622159 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.501732 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008463\n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.488843 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.516191 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.687523 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.645087 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.495408 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.562741 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.547838 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.579308 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.678808 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.686318 [ 5217/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.906869 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008465\n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.823177 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.717521 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.653361 [ 1269/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.919535 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.800118 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.546774 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.607180 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.658417 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.475744 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.699696 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.731108 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008470\n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.696686 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.518335 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.794346 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.611922 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.583573 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.960724 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.725132 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.671890 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.625611 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.608394 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.676430 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008467\n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.520911 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.664842 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.526210 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.643251 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.637185 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.520807 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.756163 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.707153 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.628750 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.564034 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.634763 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008468\n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.767460 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.828273 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.663041 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.718808 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.703828 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.897140 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.716458 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.697634 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.593028 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.631089 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.768735 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008464\n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.694302 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.037915 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.651007 [ 1269/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.373935 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.699456 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.724021 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.689221 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.832457 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.686076 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.705684 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.622870 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008463\n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.663469 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.567653 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.677556 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.577645 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.726403 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.637116 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.550779 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.518263 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.700343 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.581302 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.594890 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008469\n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.826483 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.755791 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.544837 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.727255 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.725023 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.735988 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.650829 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.715728 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.725827 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.608748 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.569854 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008468\n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.619627 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.576340 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.638476 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.472797 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.655485 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.773219 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.571535 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.696607 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.457791 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.698538 [ 5217/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.428029 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008464\n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.730840 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.727143 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.494541 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.667790 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.702111 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.645328 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.765601 [ 3525/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.468237 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.792286 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.555105 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.785947 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008466\n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "Accuracy: 79.4%, Loss_1: 0.791524 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.646021 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.768799 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.672423 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.685005 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.556926 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.712646 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.548028 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.707537 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.751340 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.657907 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008465\n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.778913 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.488962 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.676571 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.524714 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.819523 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.675697 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.628737 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.537918 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.575435 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.691130 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.749925 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008473\n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.617775 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.902994 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.718842 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.778070 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.681054 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.526197 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616668 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.670745 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.910594 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.569103 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.715690 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008475\n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.671472 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.436674 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.662533 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.692622 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.593197 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.689368 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.913627 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.597887 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.693218 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.551609 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.529639 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008481\n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.755189 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.728663 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.752131 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.548752 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.583346 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.595111 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.535174 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.633796 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.676650 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.673687 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.533384 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008484\n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.689377 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.640182 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.633546 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.609488 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.769782 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.792513 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.841826 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.501092 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.738991 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.710372 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.523610 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008481\n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.602691 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.562207 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.625200 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.458656 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.716231 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.457575 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.676223 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.711558 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.621607 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.463801 [ 5217/ 5922]\n",
      "Accuracy: 94.3%, Loss_1: 0.396075 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008482\n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.565946 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.593571 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.487468 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.717992 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.642022 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.805260 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.586578 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.625915 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.760025 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.700123 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.597225 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008482\n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.668803 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.790675 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.436611 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.616355 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.560695 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.563879 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.793771 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.592675 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.540428 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.797223 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.638492 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008485\n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.833211 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.548072 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.707625 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.605388 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.542977 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.717100 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 1.045191 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.685550 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.708435 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.476247 [ 5217/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.327944 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008486\n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.786788 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.514783 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.481057 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.438776 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.679977 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.643964 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.620415 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.924210 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.713372 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.721116 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.616014 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008486\n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.679733 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.662662 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.507628 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.501475 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.597804 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.540657 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.674245 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.674475 [ 4089/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.920656 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.803400 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.778819 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008483\n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "Accuracy: 78.7%, Loss_1: 0.917760 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.689509 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.499510 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.417735 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.683489 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.566201 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.951344 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.813676 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.844711 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.660546 [ 5217/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.794142 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008480\n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.653925 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.656100 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.675522 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.537226 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.557519 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.568159 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.663463 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.770296 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.749959 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.762548 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.577208 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008477\n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.622310 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.611335 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.623506 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.745670 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.608484 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.616730 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.588555 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.719462 [ 4089/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.883153 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.903435 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.651546 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008481\n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.511481 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.532040 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.590907 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.394353 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.830586 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.599649 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.562796 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.585428 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.667338 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.668773 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.593263 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008485\n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.620856 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.689849 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.892794 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.620434 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.678333 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.697132 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.731751 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.664489 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.677176 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.493083 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.662260 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008487\n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss_1: 0.398316 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.714868 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.625740 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.632778 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.623362 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.541678 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.676411 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.653817 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.660304 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.787927 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.720046 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008486\n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.482166 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.643687 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.610576 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.725104 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.582711 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.555591 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.599065 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.547234 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.626787 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.738486 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.771295 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008489\n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.632466 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.526984 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.603981 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.491773 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.539599 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.774589 [ 2961/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.455931 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.516894 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.612485 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.641507 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.646363 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008490\n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.534827 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.635832 [  705/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.468364 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.717256 [ 1833/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.963184 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.838556 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.665668 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.578789 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.712801 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.682547 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.487127 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008489\n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.629428 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.625954 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.664985 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.565676 [ 1833/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.431855 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.686419 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.609914 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.600962 [ 4089/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.940391 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.580555 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.701034 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008490\n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.620204 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.731215 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.657511 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.839285 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.647467 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.695355 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.762248 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.716385 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.645686 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.546676 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.679123 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008489\n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.728240 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.523050 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.640384 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.753188 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.730745 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.487684 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.784758 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.623502 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.643319 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.655911 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.616251 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008492\n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.626182 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.750718 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.630322 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.616097 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.644677 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.857737 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.613554 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.667444 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.679964 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.633052 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.597950 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008491\n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.708599 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.824399 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.540437 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.563253 [ 1833/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.553635 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.641727 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.697268 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.682145 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.643415 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.566736 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.720552 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008492\n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.789098 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.762472 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.714543 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.567179 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.567091 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.629655 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.731811 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.773089 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.583474 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.594067 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.514799 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008493\n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.618768 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.639970 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.487839 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.733812 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.632333 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.683125 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.706572 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.709500 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.772303 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.714074 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.715327 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008498\n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.747949 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.786381 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.717856 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.731168 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.699369 [ 2397/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.499653 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.767685 [ 3525/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.945801 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.439231 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.736357 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.552440 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008499\n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.724545 [  141/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.467571 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.839223 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.897744 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.696508 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.472301 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.672367 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.853995 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.577895 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.666721 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.423530 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008500\n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.874831 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.490158 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.706704 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.651321 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.739421 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.813085 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.568153 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.601529 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.659164 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.737801 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.587960 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008496\n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.695525 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.718840 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.638835 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.602099 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.429695 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.481513 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.929964 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.551012 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.621749 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.510216 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.739399 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008496\n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.571943 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.591757 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.739263 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.540992 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.821891 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.757852 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.886648 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.791754 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.785621 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.679576 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.548948 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008492\n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.692425 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.895978 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.488478 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.687366 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.636672 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.573565 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.734536 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.756791 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.828190 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.607943 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.754660 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008495\n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.728388 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.530061 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.774300 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.795674 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.743239 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.396210 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.528228 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.765934 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.455598 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.706293 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.538136 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008497\n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.487927 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.631236 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.623813 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.722283 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.711561 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.680535 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.605355 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.555766 [ 4089/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.107687 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.684403 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.752991 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008493\n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.718538 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.781013 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.781643 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.639040 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.579835 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.547099 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.538372 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.679184 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.808194 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.603435 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.626728 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008498\n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.650984 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.570117 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.602280 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.497745 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.669122 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.626944 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.591127 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.456416 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.635475 [ 4653/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.537246 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.687607 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008506\n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.671243 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.658015 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.697582 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.573970 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.819647 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.667013 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.805686 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.800279 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.869757 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.605049 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.647480 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008505\n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss_1: 0.371826 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.530974 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.726016 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.662384 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.659974 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.596641 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.750097 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.577107 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.578728 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.568287 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.616790 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008504\n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.947072 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.534616 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.633099 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.772340 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.745089 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.593238 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.513311 [ 3525/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.884646 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.739422 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.854498 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.709869 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008502\n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.574687 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.509902 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.730842 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.530841 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.625634 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.711385 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.620848 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.789196 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.665209 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.778284 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.586550 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008503\n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.633106 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.771758 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.706478 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.601071 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.806948 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.714774 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.709709 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.810805 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.728455 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.596436 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.717990 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008502\n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.654068 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.569876 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.698128 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.660084 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.555402 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.641842 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.615314 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.693564 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.625329 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.510708 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.574874 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008510\n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.655902 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.718084 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.577582 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.804926 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.489600 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.734675 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.791196 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.689998 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.509903 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.590251 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.553268 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008507\n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.620049 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.652948 [  705/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.540398 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.524066 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.666335 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.879518 [ 2961/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.368172 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.736584 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.639360 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.552190 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.833096 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008515\n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.537746 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.582295 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.710677 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.872633 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.689817 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.598845 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.642647 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.519618 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.513869 [ 4653/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.528154 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.773331 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008521\n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.694247 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.624414 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.592688 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.800926 [ 1833/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.404302 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.747894 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.647160 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.644900 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.504787 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.642337 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.861485 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008521\n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.592576 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.678624 [  705/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.774535 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.701963 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.778090 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.659850 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.581349 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.679534 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.737545 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.719281 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.456262 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008519\n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.818622 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.449854 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.762359 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.816959 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.593917 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.656347 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.739455 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.658664 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.766208 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.728280 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.812360 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008522\n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.657471 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.700836 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.658360 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.606406 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.622256 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.724883 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.685543 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.857150 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.851060 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.594319 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.705536 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008515\n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.793527 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.662572 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.695967 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.482650 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.684247 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.456599 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.787685 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.953830 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.525909 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.774239 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.484938 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008515\n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.823283 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.698619 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.572549 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.599565 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.704821 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.573098 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.635997 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.715537 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.600058 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.761619 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.713453 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008513\n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.879185 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.683658 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.726552 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.735488 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.575689 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.723554 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.634681 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.518017 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.505916 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.657300 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.780993 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008516\n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.645610 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.768356 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.653576 [ 1269/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.408799 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.712568 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.748144 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.569763 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.516796 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.680587 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.814369 [ 5217/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.863184 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008516\n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.533423 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.661027 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.522324 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.612907 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.607259 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.743986 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.602554 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.495551 [ 4089/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.861716 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.547191 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.808321 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008516\n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.702155 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.564253 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.615857 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.448141 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.683650 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.641486 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.695611 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.753232 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.649674 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.480561 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.685376 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008514\n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.600786 [  141/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.460988 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.692882 [ 1269/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.370039 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.753179 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.590741 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.648461 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.673296 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.772064 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.917347 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.492646 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008513\n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.861934 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.743011 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.786126 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.564691 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.588795 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.533311 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.605300 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.578167 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.712531 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.732741 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.779839 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008510\n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.562882 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.654303 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.589385 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.796980 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.523862 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.571600 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.699049 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.776846 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.590002 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.897123 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.543681 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008513\n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.886084 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.478540 [  705/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.459022 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.780559 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.533619 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.741730 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.603446 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.670429 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.571842 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.589383 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.503042 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008515\n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.697502 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.704041 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.879660 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.553884 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.658671 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.467854 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.553151 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.646897 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.594515 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.520795 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.644264 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008513\n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.435478 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.839058 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.831455 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.546943 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.637080 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.693738 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.627055 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.578361 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.726936 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.657986 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.821796 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008512\n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "Accuracy: 79.4%, Loss_1: 0.871522 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.613753 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.719864 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.605413 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.438829 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.828015 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.659907 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.625490 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.602898 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.514649 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.645507 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008512\n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.762169 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.853804 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.754733 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.607512 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.591156 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.612631 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.567076 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.550364 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.615767 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.657201 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.731940 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008513\n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.765632 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.652496 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.724145 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.620951 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.895931 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.653146 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.453560 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.563895 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.828540 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.802638 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.554472 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008517\n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.731253 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.795260 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.615774 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.680526 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.735061 [ 2397/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.099922 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.807923 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.810682 [ 4089/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.924588 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.805760 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.661082 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008518\n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.484557 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.569357 [  705/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.847803 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.796210 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.747442 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.682598 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.587202 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.625165 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.707849 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.767567 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.785570 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008516\n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.690962 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.446384 [  705/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.380790 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.608372 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.619463 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.641606 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.513932 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.697828 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.627773 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.590443 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.503788 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008520\n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.547532 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.926626 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.704902 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.620028 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.591082 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.841687 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.736975 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.688727 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.581177 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.887607 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.682566 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008520\n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.647870 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.682410 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.671194 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.965333 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.565717 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.734193 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.650029 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.714829 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.712752 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.770191 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.554147 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008519\n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.858735 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.605143 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.687627 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.502054 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.876455 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.623607 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.534929 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.461533 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.719761 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.639826 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.738915 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008521\n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "Accuracy: 78.7%, Loss_1: 0.798970 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.524055 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.538420 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.639262 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.701438 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.561256 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.774827 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.709858 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.583794 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.561416 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.860466 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008518\n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.855332 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.806073 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.647336 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.682612 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.601553 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.605370 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.470415 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.723050 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.739839 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.553313 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.690200 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008519\n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.573259 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.560675 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.684806 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.636361 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.687936 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.509610 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.645843 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.853977 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.711016 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.596901 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.483811 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008513\n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.726973 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.714355 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.461355 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.614525 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.756510 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.753217 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.815060 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.682833 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.545714 [ 4653/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.029494 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.651162 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008512\n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.668766 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.673395 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.602464 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.526773 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.724105 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.667747 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.456577 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.633189 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.666006 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.527283 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.754526 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008512\n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.697865 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.700728 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.635265 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.845233 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.752069 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.699869 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.623897 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.671332 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.708631 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.613829 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.650137 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008512\n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.616255 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.595735 [  705/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.805798 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.635023 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.658446 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.727227 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.772245 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.667921 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.526849 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.728511 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.014650 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008511\n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.615358 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.510024 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.650960 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.892857 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.681863 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.691217 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.524301 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.434005 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.602328 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.499923 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.709795 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008510\n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 1.053196 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.495478 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.491147 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.713288 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.769550 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.572708 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.588959 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.803461 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.784490 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.597318 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.592800 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008508\n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.747117 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.596874 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.765144 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.662031 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.491150 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.600867 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.677649 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.493761 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.639098 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.676449 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.781387 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008511\n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.491493 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.690032 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.604971 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.676874 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.627191 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.579949 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.544433 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.465139 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.581385 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.626690 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.932988 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008507\n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss_1: 0.386897 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.744698 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.650829 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.570536 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.651089 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.680113 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.521918 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.595451 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.606734 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.635462 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.678955 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008510\n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.584619 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.772821 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.542824 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.576871 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.758068 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.813081 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.681153 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.685481 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.749564 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.551975 [ 5217/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.871037 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008508\n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.634307 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.621522 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.597029 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.787364 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.510277 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.703338 [ 2961/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.360313 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.690382 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.824497 [ 4653/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.953703 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.717753 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008509\n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.721617 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.739754 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.518062 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.556737 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.804067 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.633825 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.739570 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.758996 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.641255 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.566720 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.652301 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008512\n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.673882 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.655623 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.647154 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.490230 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.866813 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.636918 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.496740 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.566557 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.463086 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.688599 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.748743 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008516\n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.638401 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.648999 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.646028 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.568577 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.579973 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.669206 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.573969 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.783555 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.611779 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.695900 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.682485 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008515\n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.691048 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.513084 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.615240 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.774008 [ 1833/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.331786 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.648525 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.832630 [ 3525/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.408103 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.535511 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.597698 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.913902 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008522\n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.711930 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.528270 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.509832 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.835823 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.520307 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.609950 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.506424 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.707935 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.776540 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.639060 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.631986 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008522\n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.660004 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.620738 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.836093 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.473091 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.527016 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.673930 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.843445 [ 3525/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.875096 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.624379 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.734261 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.717351 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008521\n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.596988 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.459420 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.681682 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.727728 [ 1833/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.866314 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.563454 [ 2961/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.980377 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.778114 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.508115 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.647301 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.693571 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008521\n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.630831 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.632276 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.623579 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.586725 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.589513 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.674861 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.388271 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.714603 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.620877 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.796759 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.716506 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008524\n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.649445 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.515002 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.555616 [ 1269/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.879817 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.789349 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.494850 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.675303 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.441350 [ 4089/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.984297 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.530518 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.595232 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008526\n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.551790 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.688932 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.591679 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.669654 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.611663 [ 2397/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.379541 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.556336 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.559550 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.637604 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.487850 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.584691 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008522\n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.742872 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.656272 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.616157 [ 1269/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.368108 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.615220 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.647894 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.803837 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.757516 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.567491 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.715427 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.737520 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008526\n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.679694 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.647926 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.619137 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.685941 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.609663 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.694085 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.638485 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.693050 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.543832 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.590531 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.608748 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008528\n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.762072 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.633619 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.792816 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.733681 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.487796 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.746905 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.616324 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.606501 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.722978 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.676217 [ 5217/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.444709 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008530\n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.611420 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.702049 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.772100 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.834137 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.577948 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.643124 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.495647 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.708808 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.798216 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.665396 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.811283 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008531\n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.659639 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.601906 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.692932 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.592307 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.714869 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.734342 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.720125 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.624714 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.630780 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.566309 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.907744 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008534\n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "Accuracy: 79.4%, Loss_1: 0.879299 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.540882 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.734282 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.664447 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.504722 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.710438 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.842357 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.665261 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.548244 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.705580 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.923387 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008535\n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.639038 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.660244 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.614827 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.772946 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.697966 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.551736 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.669318 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.799740 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.937439 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.607591 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.834601 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008533\n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.678499 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.838261 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.771129 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.596337 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.907468 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.718748 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.811867 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.595590 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.828553 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.673531 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.725145 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008529\n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.722593 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.650842 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.673468 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.841740 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.607564 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.609152 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.644008 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.692640 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.713833 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.668890 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.722858 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008526\n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.707882 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.471879 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.607386 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.600068 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.623787 [ 2397/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.018622 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.572520 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.666380 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.740540 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.709702 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.643532 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008527\n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "Accuracy: 78.7%, Loss_1: 0.880351 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.634345 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.585333 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.545755 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.652028 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.800506 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.742178 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.641837 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.475450 [ 4653/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.468782 [ 5217/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.947962 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008527\n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.679354 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.549446 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.761117 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.820801 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.635534 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.925098 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.642180 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.712732 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.594191 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.764280 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.603885 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008530\n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.525391 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.856286 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.566109 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.798931 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.673397 [ 2397/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.898461 [ 2961/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.845027 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.779061 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.453397 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.467621 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.802759 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008529\n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.556527 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.585444 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.844530 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.756349 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.658361 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.657762 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.563591 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.586445 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.626141 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.682300 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.623631 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008531\n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.615817 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.548298 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.810910 [ 1269/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.894979 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.726362 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.523370 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.707812 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.676827 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.684390 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.759479 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.559219 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008533\n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.702687 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.754424 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.570102 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.922036 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.549026 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.686224 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.528047 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.804540 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.691240 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.644687 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.468409 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008535\n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.513406 [  141/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.413200 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.618543 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.739256 [ 1833/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.408514 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.689940 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.704550 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.755743 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.778103 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.552186 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.467933 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008542\n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.846901 [  141/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.424106 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.860414 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.573531 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.563898 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.551883 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.509685 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.821648 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.533087 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.552132 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.639331 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008543\n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.695814 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.692386 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.712574 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.796807 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.684215 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.811134 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.614331 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.753911 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.580877 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.921098 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616129 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008542\n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.663270 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.575024 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.563220 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.767016 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.722929 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.647777 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.780224 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.659717 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.797771 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.762119 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.831321 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008540\n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.758197 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.658977 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.518932 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.731311 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.559210 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.656966 [ 2961/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.531110 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.715333 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.618957 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.526950 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.486697 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008542\n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.801244 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.665554 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.510895 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.704899 [ 1833/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.418296 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.679041 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.683515 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.544966 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.770224 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.674340 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.516281 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008547\n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.623875 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.767366 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.537523 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.649753 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.589847 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.801789 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.669071 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.562400 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.606346 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.688350 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.780233 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008546\n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.669960 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.716372 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.622131 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.629128 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.448775 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.656668 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.558593 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.632660 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.568211 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.793246 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.621986 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008550\n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.619121 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.569137 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.598725 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.772639 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.720470 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.785309 [ 2961/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.861208 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.453071 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.841681 [ 4653/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.441023 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.584636 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008554\n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.845068 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.820289 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.802319 [ 1269/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.382656 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.698650 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.759654 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.546968 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.643139 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.419488 [ 4653/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.455754 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.917463 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008549\n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.611177 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.613769 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.582634 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.776535 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.682690 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.771299 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.797063 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.589611 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.597985 [ 4653/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.505280 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.791872 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008549\n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.598930 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.622729 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.528679 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.639716 [ 1833/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.372271 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.587134 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.628465 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.661957 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.702157 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.688254 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.679894 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008553\n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.652325 [  141/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.425186 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.642745 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.764645 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.760857 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.537403 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.547165 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.789103 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.768275 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.531875 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.537784 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008551\n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.591555 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.634658 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.592711 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.625077 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.520495 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.615820 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.616159 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.564633 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.714933 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.720885 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.537416 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008551\n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.632818 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.569693 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.736753 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.477788 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.711503 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.880680 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.844422 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.656484 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.708684 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.736429 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.555035 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008552\n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.762559 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.456485 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.676516 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.637965 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.636297 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.483335 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.609281 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.504360 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.546099 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.519543 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.554387 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008552\n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.649854 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.534183 [  705/ 5922]\n",
      "Accuracy: 75.2%, Loss_1: 0.999177 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.551908 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.634324 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.669083 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.577607 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.688292 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.497771 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.729802 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.651872 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008560\n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.503907 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.537013 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.795911 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.573761 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.582741 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.605487 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.696395 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.803901 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.540577 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.782768 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.825110 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008564\n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.516384 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.561350 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.746437 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.515730 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.850274 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.541660 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.629493 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.434932 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.740872 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.518920 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.532723 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008565\n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.603416 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.888723 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.645069 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.651805 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.525663 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.601183 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.682922 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.832331 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.588553 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.675328 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.778876 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008568\n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.560085 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.773307 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.775984 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.620742 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.578778 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.740456 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.748713 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.714630 [ 4089/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.851164 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.495377 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.690508 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008569\n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.803502 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.540687 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.672714 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.570029 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.656469 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.806545 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.545554 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.500892 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.730147 [ 4653/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.512389 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.546531 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008573\n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.775855 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.620802 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.752311 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.461878 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.875569 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.800106 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.612850 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.699209 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.517119 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.546303 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.784481 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008578\n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.635302 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.556202 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.731819 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.555702 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.840357 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.793605 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.707837 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.700080 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.608884 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.749328 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.794198 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008582\n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.624268 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.585842 [  705/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.481565 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.793173 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.613557 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.763252 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.797404 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.626381 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.542713 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.490722 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.744627 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008582\n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.712332 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.804476 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.548476 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.607439 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.668171 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.728296 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.822289 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.523514 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.446984 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.704570 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.548100 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008589\n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.805413 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.428213 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.722230 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.421196 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.595841 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.555510 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.433675 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.853915 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.610758 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.775739 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.815283 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008589\n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.659410 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.567326 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.700131 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.528348 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.472371 [ 2397/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.469973 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.761275 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.702250 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.643539 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.888200 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.638501 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008588\n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.605649 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.619158 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.781013 [ 1269/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.829671 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.598291 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.642094 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.713281 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.626377 [ 4089/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 0.946276 [ 4653/ 5922]\n",
      "Accuracy: 93.6%, Loss_1: 0.392024 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.621279 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.008582\n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.674499 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.539943 [  705/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.459936 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.584031 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.768992 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.560009 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.748312 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.833351 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.610702 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.773767 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.705158 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.008581\n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.620380 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.739570 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.498238 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.542930 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.557091 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.475921 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.602629 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.640220 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.892188 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.798938 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.634243 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008585\n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.747066 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.816961 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.852655 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.710477 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.654870 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.664810 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.719096 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.784039 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.576050 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.631098 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.743849 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008584\n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.731017 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.572998 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.694193 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.687082 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.604804 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.624123 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.533149 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.706192 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.627312 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.560802 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.608898 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008584\n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.752199 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.648364 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.728631 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.724324 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.622227 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.471731 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.584331 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.688525 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.599873 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.723419 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.737226 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008582\n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.800138 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.632506 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.707145 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.675506 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.645642 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.838634 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.657396 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.606780 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.908282 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.608404 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.643170 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008582\n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.440368 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.484691 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.812661 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.788885 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.521824 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.603949 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.614808 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.425861 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.526726 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.677667 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.805732 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008582\n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.683553 [  141/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.818255 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.790751 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.922484 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.682547 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.520071 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.699453 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.624230 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.697382 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.456483 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.597992 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008583\n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.811195 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.738904 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.643506 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.731025 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.671271 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.773249 [ 2961/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.500376 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.730152 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.552663 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.878801 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.634811 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008581\n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.550839 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.494294 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.543892 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.723425 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.797053 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.644414 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 1.038615 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.644236 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.540535 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.404189 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.725669 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.008578\n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.775596 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.768492 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.555054 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.687674 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.568572 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.669793 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.806880 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.739246 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.705809 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.564060 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.614446 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008574\n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.668144 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.408341 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.797688 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.621523 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.752273 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.629589 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.661362 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.625446 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.595047 [ 4653/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.442120 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.574380 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.008577\n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.688760 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.556605 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.420221 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.606780 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.770486 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.683023 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.458911 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.382800 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.779497 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.635249 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.814514 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008582\n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss_1: 0.401468 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.777371 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.648469 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.662672 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.775606 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.700143 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.793610 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.705255 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.730793 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.512852 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.779357 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008584\n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 1.005660 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.737685 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.715599 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.739621 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.635965 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.788010 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.612615 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.754595 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.624033 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.703565 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.520386 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008583\n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.697490 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.713725 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.526994 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.607524 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.709065 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.787897 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.619560 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.513035 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.687684 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.457956 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.698880 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008586\n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.734641 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.773442 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.644391 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.889878 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.650887 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.747989 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.491459 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.834744 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.738796 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.619807 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.717806 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008588\n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss_1: 0.510195 [  141/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.930706 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.564125 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.752959 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.979894 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.641051 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.698125 [ 3525/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.423931 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.459888 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.666109 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.659203 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.008590\n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.558828 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.581960 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.580982 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.657032 [ 1833/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.477853 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.475024 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.674385 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.527214 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.740507 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.702577 [ 5217/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.859913 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008595\n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.538016 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.606606 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.875464 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.676423 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.459366 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.617415 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.531559 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.659984 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.698472 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.770056 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.832610 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008596\n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.880109 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.735443 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.680147 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.671593 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.657518 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.745766 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.438414 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.658786 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.752310 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.681457 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.787216 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008594\n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.532472 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.609024 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.678749 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.743673 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.746035 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.874478 [ 2961/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.941208 [ 3525/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.912656 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.551595 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.868282 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.810193 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008591\n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.680672 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.716564 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.585165 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.675214 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.503672 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.606585 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.711340 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.714338 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.527898 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.683472 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.526687 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008590\n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.578333 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.586086 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.732458 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.599007 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.545875 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.642938 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.613838 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.609265 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.517449 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.526386 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.603400 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008589\n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.674206 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.600069 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.640248 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.669194 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.625822 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.765055 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.555606 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.832746 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.715448 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.708533 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.639931 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008589\n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.586512 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.751537 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.653920 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.671650 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.785295 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.906838 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.682366 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.618462 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.656581 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.507548 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.575420 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008592\n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.607062 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.621634 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.754701 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.383718 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.753692 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.619579 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.833828 [ 3525/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.388020 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.812714 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.759430 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.827039 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008594\n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.631375 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.631744 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.537704 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.723205 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.649097 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.608091 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.569090 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.635661 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.493621 [ 4653/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.944322 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.584066 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008596\n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.664082 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.687414 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.798621 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.714578 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.591457 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.590529 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.734154 [ 3525/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 0.972520 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.495232 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.615170 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.644003 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008595\n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.520518 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.546571 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.728006 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.629713 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.798926 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.676042 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.460992 [ 3525/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.902852 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.749283 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.670190 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.640105 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008594\n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.566284 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.725737 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.616157 [ 1269/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.806364 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.628191 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.688410 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.630665 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.703380 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.556974 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.559554 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.730525 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008593\n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.837588 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.775606 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.449053 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.645393 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.593329 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.651792 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.408367 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.656631 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.791344 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.579744 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.640220 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008592\n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.630513 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.701933 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.703748 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.514303 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.700343 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.762324 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.502482 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.581856 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.805942 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.889740 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.540123 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008592\n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.523542 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.555204 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.669789 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.617854 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.697539 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.641544 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.719513 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.732329 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.767639 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.599519 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.655579 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008590\n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.653981 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.760299 [  705/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.430932 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.502819 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.631575 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.440511 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.633335 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.643681 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.684065 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.722698 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.671632 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008588\n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "Accuracy: 79.4%, Loss_1: 0.773288 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.518409 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.637923 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.500248 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.700422 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.751178 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.612247 [ 3525/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.435694 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.747991 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.851056 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.522154 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008591\n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "Accuracy: 90.8%, Loss_1: 0.478166 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.503058 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.569810 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.669595 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.601848 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.793511 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.808993 [ 3525/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.784330 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.758782 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.776961 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.511482 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008590\n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.717541 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.648031 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.649626 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.539651 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.753104 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.573432 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.617275 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.697997 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.607919 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.794825 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.620055 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008596\n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.691980 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.522019 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.541153 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.721611 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.697291 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.368884 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.486647 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.493897 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.713493 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.490019 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.697493 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008599\n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.646306 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.535155 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.498114 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.656288 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.624638 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.464897 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.818107 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.698137 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.616928 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.769282 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.534394 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008593\n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.442601 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.689371 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.690369 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.641460 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.801115 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.484852 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.515781 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.741714 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.682936 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.618731 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.614108 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008597\n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.536457 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.482284 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.464581 [ 1269/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.022263 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.667494 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.642404 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.664303 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.580751 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.527137 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.543715 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.573223 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008596\n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.622938 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.764570 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.463241 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.637878 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.945916 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.487350 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.743929 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.539508 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.766439 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616287 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.550315 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008596\n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.786531 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.777095 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.750234 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.718476 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.741412 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.884720 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.692596 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.478861 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.634826 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.715280 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.731598 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008596\n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.795003 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.692311 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.463161 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.489024 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.504131 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.513247 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.792263 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.612693 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.557039 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.760110 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.612023 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008598\n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.647938 [  141/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.507725 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.571805 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.607993 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.602856 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.468861 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.548272 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.776435 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.648215 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.573025 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.701282 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008603\n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.578386 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.585883 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.878910 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.789773 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.490217 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.677198 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.772108 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.782506 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.615277 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.687519 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.613855 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008605\n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.485383 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.755250 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.660262 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.846153 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.626182 [ 2397/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.330221 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.583455 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.632161 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.559101 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.667804 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.431375 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008605\n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.730026 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.588149 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.771739 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.643498 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.869611 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.786860 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.743397 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.687078 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.487275 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.587581 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.681164 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008607\n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.693932 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.704674 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.578408 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.702261 [ 1833/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.833449 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.822931 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.611566 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.669377 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.442293 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.672915 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.517286 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008605\n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.773035 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.612362 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.705221 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.620135 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.588563 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.658203 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.712691 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.620881 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.606887 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.822303 [ 5217/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.815052 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008607\n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.559926 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.817741 [  705/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.487900 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.578915 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.617886 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.711480 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.519512 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.594218 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.510934 [ 4653/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.382564 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.558884 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008612\n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.726189 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.659983 [  705/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.528671 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.530489 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.548832 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.786984 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.684991 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.544928 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.768538 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.770152 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.585410 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008615\n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.686782 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.562792 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.571062 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.553668 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.616430 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.648167 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.597412 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.635563 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.527723 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.601034 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.670548 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008621\n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "Accuracy: 79.4%, Loss_1: 0.974784 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.696624 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.648930 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.584163 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.581418 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.714554 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.649049 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.719032 [ 4089/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.861052 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.542293 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.545902 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008618\n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.539094 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.667396 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.725358 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.684272 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.678137 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.791222 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.884492 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.791625 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.728618 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.730527 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.408010 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008614\n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.576988 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.570582 [  705/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.506487 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.690739 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.659843 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.521687 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.458682 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.559072 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.804690 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.504933 [ 5217/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 1.075413 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008614\n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.636338 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.735388 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.547078 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.889405 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.822449 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.624734 [ 2961/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.765439 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.515499 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.520017 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.648716 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.760328 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008609\n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "Accuracy: 91.5%, Loss_1: 0.457029 [  141/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.392892 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.510663 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.719476 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.738894 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.565087 [ 2961/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.926647 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.590006 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.601849 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.685115 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.539806 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008609\n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.557015 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.755506 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.547924 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.540828 [ 1833/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.866151 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.800178 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.554887 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.773080 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.633977 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.578202 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.749242 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008612\n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.700022 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.528519 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.689698 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.701750 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.950226 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.709930 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.635441 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.561256 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.830662 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.693275 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.816355 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008612\n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.562615 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.687226 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.712553 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.573871 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.656105 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.587535 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.777202 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.704989 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.640159 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.622455 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.635681 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008616\n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.759650 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.675787 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.696788 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.523275 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.609713 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.795998 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.703612 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.874718 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.666549 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.887501 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.405802 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008618\n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.690572 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.649516 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.562335 [ 1269/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.876870 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.563092 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.658803 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.579790 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.878540 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.589823 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.583556 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.639704 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008619\n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.635552 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.757484 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.520725 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.660851 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.582243 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.613499 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.645002 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.860856 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.493126 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.702654 [ 5217/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.001059 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008621\n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.705931 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.524177 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.514590 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.582628 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.689566 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.511351 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.553021 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.528394 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.744354 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.759526 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.659628 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008622\n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.583205 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.722201 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.829482 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.664046 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.642373 [ 2397/ 5922]\n",
      "Accuracy: 95.0%, Loss_1: 0.304311 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.898708 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.558929 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.488739 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.507114 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.744957 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008625\n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.520213 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.589806 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.600614 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.825705 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.638040 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.601779 [ 2961/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.828920 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.707460 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.831593 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.697428 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.605988 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008627\n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.715308 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.694632 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.673240 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.773280 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.838587 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.629269 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.713640 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.531167 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.780292 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.793196 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.674642 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008623\n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.649711 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.689794 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.760040 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.791661 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.732406 [ 2397/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 0.888447 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.755130 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.799570 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.507208 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.509359 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.659217 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008622\n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.660506 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.674935 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.728298 [ 1269/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.537659 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.816079 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.575422 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.599888 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.564535 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.610134 [ 4653/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.487099 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.699003 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008625\n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.633566 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.575267 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.800517 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.527456 [ 1833/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.139449 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.655187 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.519849 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.673858 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.897192 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.454753 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.762050 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008626\n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.505686 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.515772 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.589280 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.520698 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.622859 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 1.039083 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.651479 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.514557 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.691719 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.587571 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.589665 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008624\n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.663498 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.636300 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.714005 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.668409 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.749002 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.465237 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.647719 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.695824 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.489766 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.600405 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.634962 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008625\n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.603896 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.561778 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.750934 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.671966 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.734546 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.723432 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.627665 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.482074 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.619536 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.466277 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.763382 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008625\n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.547165 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.526584 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.586261 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.867488 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.619956 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.685125 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.676706 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.953635 [ 4089/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.961365 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.709885 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.739656 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008625\n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.651801 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.742754 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.515850 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.640816 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.618169 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.804912 [ 2961/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.974577 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.540321 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.444027 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.444515 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.750975 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008622\n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "Accuracy: 92.2%, Loss_1: 0.441083 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.628397 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.586658 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.587589 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.566756 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.636920 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.838834 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.618712 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.896951 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.463571 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.744074 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008623\n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "Accuracy: 79.4%, Loss_1: 0.885456 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.716326 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.610509 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.644716 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.588673 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.698521 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.509901 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.734614 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.522548 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.603330 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.644831 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008618\n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.595109 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.685123 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.560719 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.633156 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.828758 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.834061 [ 2961/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.904019 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.793591 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.693150 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.674019 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.710722 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008612\n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.701298 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.648940 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.547185 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.589930 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.564415 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.954418 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.566601 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.405791 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.776694 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.699791 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.770484 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008614\n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.755285 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.724012 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.440770 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.587742 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.435680 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.752767 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.760285 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.885285 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.672920 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.738293 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.543898 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008614\n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.621436 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.580592 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.830444 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.607187 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.795817 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.671818 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.632666 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.697635 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.693635 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.613085 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.838241 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008617\n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.586215 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.447962 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.582337 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.575599 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.602640 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.752616 [ 2961/ 5922]\n",
      "Accuracy: 93.6%, Loss_1: 0.314922 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.555028 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.628573 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.548316 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.807186 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008620\n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.765216 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.660611 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.561536 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.515504 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.659243 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.669422 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.671258 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.545310 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.721290 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.781957 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.765346 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008622\n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.873234 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.596275 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.536362 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.560859 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.784664 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.892300 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.627587 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.804795 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.649566 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.498072 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616634 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008619\n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.764490 [  141/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.857190 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.576095 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.654111 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.672006 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.581060 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.708492 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.750961 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.777823 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.755671 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.654264 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008622\n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.638345 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.646937 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.537610 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.888259 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.700001 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.693808 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.685070 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.722519 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.434635 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.465058 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.676307 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008624\n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.707374 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.647247 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.745894 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.660843 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.740962 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.704499 [ 2961/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.796916 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.688991 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.581107 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.842437 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.580818 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008620\n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.457142 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.739501 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.714516 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.730207 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.747069 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.690026 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.740356 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.623898 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.442920 [ 4653/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.453605 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.702853 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008617\n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.716401 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.639752 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.657571 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.643220 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.599425 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.709569 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.599191 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.642309 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.577835 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.712230 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.887748 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008615\n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "Accuracy: 79.4%, Loss_1: 0.836464 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.859637 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.815116 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.603871 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.715197 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.533698 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.598567 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.678097 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.536519 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.648225 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.714807 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008613\n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "Accuracy: 92.9%, Loss_1: 0.416127 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.485396 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.676428 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.646452 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.498304 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.533670 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.635661 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.700150 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.742251 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.731881 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.619274 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008617\n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.549373 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.687421 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.672291 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.761197 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.678543 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.491644 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.661944 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.630690 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.593218 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.575602 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.764679 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008614\n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.615828 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.580787 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.705446 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.760456 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.694235 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.631488 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.693564 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.554846 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.456121 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.758894 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.597290 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008619\n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.898474 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.723478 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.586592 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.689497 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.701680 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.635239 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.722452 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.605594 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.591698 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.892921 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.575758 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008618\n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "Accuracy: 78.7%, Loss_1: 0.949758 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.643319 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.560778 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.696485 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.760541 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.875940 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.831495 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.695683 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.745483 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.612885 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.651284 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008620\n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.654803 [  141/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.973387 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.816515 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.851418 [ 1833/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.532523 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.529224 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.638710 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.752436 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.547399 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.935247 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.662188 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008617\n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.750328 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.611759 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.498902 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.558989 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.970940 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.787729 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.703838 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.631871 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.626922 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.746792 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.664629 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008619\n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.660834 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.810949 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.743938 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.460474 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.703983 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.820515 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.854778 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.827813 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.735634 [ 4653/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.528330 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.565840 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008623\n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.587839 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.745924 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.884608 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.509694 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.734956 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.634870 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.568569 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.588580 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.758353 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.594241 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.531714 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008622\n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.581790 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.728414 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.684832 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.689268 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.760156 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.650094 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.698241 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.644493 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.796057 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.786527 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.825093 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008619\n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.713358 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.501110 [  705/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.861168 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.589661 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.639774 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.565524 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.645665 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.526581 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.618542 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.590807 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.599136 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008626\n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.624744 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.638325 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.574479 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.660330 [ 1833/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.416471 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.657110 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.533836 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.757274 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.675778 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.664843 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.742073 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008633\n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.855576 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.597970 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.650532 [ 1269/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.890289 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.544482 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.815672 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.480728 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.732248 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.712750 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.584587 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.790966 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008635\n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.624601 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.622412 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.784032 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.649713 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.597683 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.581476 [ 2961/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.301478 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.798978 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.468457 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.705381 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.616746 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008636\n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.523626 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.579875 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.583203 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.815122 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.669808 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.608316 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.623680 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.699112 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.517603 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.720890 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.714001 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008641\n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.708852 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.695482 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.482205 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.591065 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.687783 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.674831 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.600306 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.869434 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.699354 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.523993 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.706872 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008636\n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.633675 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.843142 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.592976 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.782836 [ 1833/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.444088 [ 2397/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.445623 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.642626 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.562621 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.538680 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.385590 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.544626 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008637\n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.827161 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.493922 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.574433 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.952909 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.627506 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.592801 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.459215 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.652491 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.681313 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.790928 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.465437 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008642\n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.591717 [  141/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.436988 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.660838 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.625297 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.804301 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.706765 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.494667 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.752375 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.566011 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.621912 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.727373 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008639\n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.501322 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.696951 [  705/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.803647 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.664984 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.761817 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.582986 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.573618 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.555446 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.697824 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.629181 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.630023 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008639\n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.591860 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.719340 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.778563 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.516934 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.764493 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.584245 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.529559 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.661276 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.694280 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.754481 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.835879 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008639\n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.529767 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.573103 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.616496 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.516705 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.621849 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.762948 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.587433 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.648381 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.765857 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.631118 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.669323 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008641\n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.755745 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.544875 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.479109 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.645588 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.517450 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.537983 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.645178 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.804528 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.665195 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.731447 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.433674 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008645\n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.682904 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.772801 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.513671 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.688723 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.701096 [ 2397/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.384145 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.759464 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.788854 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.685062 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.643237 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.598846 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008641\n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.916981 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.511052 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.769903 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.655894 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.838817 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.640273 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.681421 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.526196 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.646672 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.491307 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.804220 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008642\n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.445336 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.927580 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.885092 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.817865 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.667400 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.548075 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.634449 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.709452 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.570763 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.783844 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.648754 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008645\n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.439879 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.721060 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.516842 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.752016 [ 1833/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.374769 [ 2397/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.461116 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.675011 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.714001 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.561102 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.540684 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.747167 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008644\n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.677810 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.713665 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.686242 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.549126 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.554171 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.705140 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.767356 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.511664 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.677650 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.832739 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.804498 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008645\n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.665462 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.576025 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.550891 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.445281 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.591327 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.650794 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.548877 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.621942 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.747967 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.627813 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.732922 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008648\n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.624935 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.538861 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.653727 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.693800 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.539414 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 1.004051 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.856514 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.800950 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.548500 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.619936 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.740290 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008645\n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.575421 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.822137 [  705/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.431141 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.774691 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.681403 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.626945 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.621394 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.603545 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.496982 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.680182 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.678089 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008643\n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.701564 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.594198 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.608149 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.646387 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.499872 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.701484 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.714225 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.441609 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.917949 [ 4653/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.465048 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.750936 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008651\n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.773837 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.480986 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.758735 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.443919 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.603716 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.597229 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.578279 [ 3525/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.400127 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.706342 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.583345 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.513819 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008647\n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.591584 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.572221 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.589263 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.769786 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.747362 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.556404 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.628708 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.470133 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.796118 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.750062 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.668676 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008653\n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.535157 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.739043 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.578413 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616709 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.607170 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.657735 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.732207 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.722566 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.517103 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.667196 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.592025 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008657\n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.684946 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.581442 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.811901 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.537520 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.626482 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.648220 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.520232 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.604948 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.627517 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.968446 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.496585 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008656\n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.614279 [  141/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.873245 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.781616 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.688903 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.714646 [ 2397/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.413268 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.590469 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.814785 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.424139 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.571078 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.839526 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008658\n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.566012 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.788777 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.714033 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.677481 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.740647 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.579150 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.780437 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.635351 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.408813 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.619376 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.662864 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008657\n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.629769 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.532763 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.401170 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.827459 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.598032 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.525927 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.509945 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.680556 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.563058 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.604558 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.678244 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008658\n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.671887 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.602935 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.747750 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.706196 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.665832 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.828217 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.517669 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.684272 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.708778 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.610865 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.685660 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008656\n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.676130 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.677715 [  705/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.498553 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.782391 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.944951 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.581625 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.784538 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.705799 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.729483 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.848200 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.851211 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008653\n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.611984 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.881928 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.887930 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.763522 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.532639 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.847168 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.486306 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.765092 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.732524 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.801272 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.614384 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008651\n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.426218 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.484095 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.578992 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.834482 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.690154 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.655912 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.795301 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.707924 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.669330 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.635246 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.645994 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008653\n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.681734 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.726173 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.705949 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.829627 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.681424 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.471136 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.732030 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.692013 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.825931 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.731902 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.628553 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008650\n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.680633 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.731399 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.842637 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.668458 [ 1833/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.932811 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.811559 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.680132 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.619687 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.511833 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.806115 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.480423 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008648\n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.622374 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.822066 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.561467 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.735185 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.611052 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.446183 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.545058 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.721789 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.706040 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.699120 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.603033 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008648\n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.614606 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.784378 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.599746 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.619667 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.595186 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.718709 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.583181 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.593085 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.470104 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.682909 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.652239 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008645\n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.614670 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.660266 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.617960 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.735169 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.816731 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.686836 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.567711 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.836200 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.584660 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.770056 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.801019 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008643\n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.597306 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.559063 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.573883 [ 1269/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.369111 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.603985 [ 2397/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.864829 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.535013 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.832356 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.496048 [ 4653/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.450744 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.792312 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008643\n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.560409 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.831749 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.559504 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.734964 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.438918 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.543773 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.735849 [ 3525/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.422605 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.554114 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.843713 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.682935 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008644\n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.741713 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.773225 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.647818 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.565206 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.754305 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.581723 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.508855 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.614443 [ 4089/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.353951 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.800105 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.494991 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008643\n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.695605 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.687551 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.682243 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.679084 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.786812 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.694545 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.753216 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.713696 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.723283 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.727292 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.584514 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008645\n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.730137 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.644875 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.483409 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.536306 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.607756 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.603688 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.646612 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.649782 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.517339 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.465686 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.651969 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008644\n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.573642 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.604679 [  705/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.492468 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.490412 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.744435 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.789990 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.655144 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.541867 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.694830 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.750114 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.670066 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008651\n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.590706 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.730079 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.486164 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.603989 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.715500 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.546312 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.650895 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.611196 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.811652 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.575613 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.740194 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008651\n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.519983 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.608768 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.545758 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.532960 [ 1833/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.462128 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.705510 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.601793 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.617091 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.584269 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.682828 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.618547 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008651\n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.676269 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.684938 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.716905 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616472 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.811037 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.894916 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.484751 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.621307 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.522056 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.559287 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.468558 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008648\n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.537625 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.900876 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.628029 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.719111 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.743246 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.491107 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.575639 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.623471 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.482905 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.685614 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.733114 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008651\n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.733273 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.598806 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.573678 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.626225 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.647183 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.604887 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.756283 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.659160 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.830895 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.794195 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.704054 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008648\n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.742320 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.693714 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.595065 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.785425 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.507638 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.703284 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.822102 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.606493 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.598588 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.714451 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.599697 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008649\n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.726237 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.626865 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.700066 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.667634 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.880762 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.866046 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.436577 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.545194 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.610554 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.434977 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.869916 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008653\n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.608715 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.748480 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.532185 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.579125 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.638852 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.679736 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.586356 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.685192 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.733806 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.726759 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.832208 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008655\n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.641214 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.740123 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.530579 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.750610 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.652614 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.833310 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.576756 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.716099 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.613730 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.609296 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.840136 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008653\n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.617814 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.603494 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.621601 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.628115 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.725718 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.724592 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.555966 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.659330 [ 4089/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.776141 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.493508 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.644430 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.008653\n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.533608 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.910545 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.618912 [ 1269/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.803318 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.740467 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.707258 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.541268 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.732118 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.629024 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.683553 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.524989 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008647\n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.625321 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.628474 [  705/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.945907 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.683926 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.583152 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.745745 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.746642 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.623817 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.562817 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.640259 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.500372 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008643\n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.718593 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.493550 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.602860 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.792381 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.677826 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.582182 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.635850 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.744274 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.582802 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.602352 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.524609 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008633\n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.581479 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.706116 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.675604 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.789044 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.764006 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.615457 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.658135 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.493236 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.573776 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.564488 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.710537 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008637\n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.804493 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.485919 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.433064 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.714145 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.454583 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.665760 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.472423 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.712539 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.651226 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.811335 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.743619 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008635\n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.768324 [  141/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.773737 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.841683 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.703136 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.640775 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.594946 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.695342 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.507068 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.605583 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.780780 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.640440 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008631\n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.675690 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.689001 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.528482 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.548150 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.820098 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.681545 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.597010 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.716912 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.618287 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.632112 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.765963 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008634\n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.571629 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.684475 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.829452 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.593082 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.697378 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.562399 [ 2961/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.458174 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.862522 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.849066 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.563746 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.537703 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008637\n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.695429 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.790204 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.730000 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.543546 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.733730 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.500163 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.715796 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.676186 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.776798 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.742352 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.755028 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008638\n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.593477 [  141/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.131455 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.551871 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.657417 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.652431 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.580632 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.734001 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.598835 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.577835 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.784990 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.583886 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008639\n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.709434 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.600461 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.505217 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.551368 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.789734 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.732801 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.731679 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.616397 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.770020 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.422955 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.668812 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008639\n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.610190 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.873169 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.546133 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.494425 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.600987 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.508562 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.621976 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.669676 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.624172 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.716343 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.638486 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008641\n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.494232 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.945587 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.689900 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.458344 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.756762 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.694379 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.678926 [ 3525/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.384306 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.718054 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.528175 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.491912 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008637\n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "Accuracy: 78.7%, Loss_1: 0.957128 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.565911 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.725237 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.549348 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.682135 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.596380 [ 2961/ 5922]\n",
      "Accuracy: 76.6%, Loss_1: 1.058486 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.560428 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.516703 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.589622 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616968 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008638\n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.559310 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.560050 [  705/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.529368 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.593259 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.765642 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.582558 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.630340 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.765919 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.734430 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.696265 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.868049 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008641\n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.597318 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.714605 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.711743 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.710470 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.681270 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.775911 [ 2961/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.823928 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.752685 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.684004 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.809374 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616648 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008642\n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.602886 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.662170 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.678593 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.524744 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.685626 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.727800 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.769430 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.768478 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.757009 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.663185 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.668098 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008640\n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.458843 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.593954 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.568582 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.686769 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.524922 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.601903 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.536169 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.650017 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.876485 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.642026 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.649416 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008643\n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.682788 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.669366 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.646959 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.577248 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.614021 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.744558 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.641172 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.507001 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.526050 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.817052 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.813919 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008639\n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.578304 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.719126 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.580081 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.674940 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.520174 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.718153 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.730836 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.548564 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.589446 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.572496 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.788755 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008639\n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.445322 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.756687 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.763221 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.441493 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.678725 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.515719 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.782373 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.630061 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.791459 [ 4653/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.495905 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.498929 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008640\n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.533142 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.777082 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.679946 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.745768 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.538314 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.909854 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.673552 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.664743 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.648099 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.666858 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.542481 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008642\n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.633762 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.598063 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.754240 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.691603 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.700104 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.790190 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.679875 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.547168 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.540287 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.700809 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.749411 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008640\n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.612939 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.509494 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.550250 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.931985 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.726383 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.663354 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.599838 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.712925 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.704021 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.633674 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.661348 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008646\n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.636699 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.739783 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.827917 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.635903 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.572427 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.590237 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.585767 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.645564 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.421664 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.515365 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.616728 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008647\n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.732420 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.588985 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.727495 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.577631 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.605302 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.535302 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.581927 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.668414 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.580913 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.488846 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.625872 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008647\n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.788821 [  141/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.807042 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.710217 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.581001 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.636480 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.715184 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.857776 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.568759 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.807810 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.683070 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.862229 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008649\n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.576282 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.660142 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.580184 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.575143 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.531511 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.601320 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.452330 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.700331 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.629616 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.644201 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.686759 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008647\n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.509497 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.632390 [  705/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.520072 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.695592 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.757729 [ 2397/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.458126 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.537407 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.657699 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.609271 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.724206 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.620592 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008647\n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.609435 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.724283 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.558149 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.505334 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.863981 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.485037 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.598520 [ 3525/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.035578 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.697481 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.723200 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.745783 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008648\n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.561821 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.743292 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.655812 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.549900 [ 1833/ 5922]\n",
      "Accuracy: 93.6%, Loss_1: 0.325221 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.574619 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.821720 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.765295 [ 4089/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.979477 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.664035 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.649066 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008650\n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.676095 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.859658 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.680790 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.702267 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.765314 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.595648 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.755959 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.580060 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.716731 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.464946 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.782966 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008649\n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.779526 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.589462 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.712135 [ 1269/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.419842 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.709013 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.790030 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.618530 [ 3525/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.388625 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.600396 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.676578 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.665690 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008648\n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.661629 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.768868 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.502454 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.695583 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.660555 [ 2397/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.415248 [ 2961/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.778905 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.724969 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.585344 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.597294 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.699606 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008651\n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.622957 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.602998 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.695219 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.454277 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.789791 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.729674 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.668300 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.708372 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.497810 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.731459 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.539530 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008654\n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.562794 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.751326 [  705/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.414427 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.650183 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.505365 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.518483 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.617161 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.745516 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.577932 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.724310 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.488299 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008657\n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.699551 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.586005 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.566198 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.680037 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.635153 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.822064 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.718565 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.452022 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.612308 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.615767 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.917378 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008660\n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.567735 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.834358 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.792572 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.778295 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.487617 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.806060 [ 2961/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.438752 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.607777 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.862295 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.676668 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.709158 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008659\n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.633800 [  141/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.438035 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.603027 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.706198 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.627387 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.881485 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.717075 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.508801 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.572747 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.544333 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.523512 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008659\n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.685453 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.625082 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.724674 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.470122 [ 1833/ 5922]\n",
      "Accuracy: 94.3%, Loss_1: 0.317639 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.819148 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.829360 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.681004 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.549695 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.673901 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.601601 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008660\n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.593847 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.491748 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.798810 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.526434 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.522563 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.670413 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.598214 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.590124 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.510860 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.667643 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.602279 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008660\n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.606538 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.573712 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.569850 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.630692 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.514460 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.705263 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.596325 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.497364 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.770666 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.543205 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.466611 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008658\n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.605265 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.692652 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.983634 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.805845 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.778110 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.613991 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.570261 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.751934 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.542904 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.656548 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.514873 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008658\n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.610558 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.622690 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.604111 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.602344 [ 1833/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.879946 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.691497 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.550518 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.702539 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.502235 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.697153 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.575962 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008661\n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.545883 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.558170 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.760879 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.902069 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.660475 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.641930 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.761192 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.675025 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.640794 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.580349 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.715196 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008661\n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.567377 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.601288 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.602141 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.531058 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.564323 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.550428 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.658398 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.586992 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.643813 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.631090 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.813433 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008660\n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.447530 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.399436 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.682515 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.701960 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.672011 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.757404 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.769801 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.885549 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.586887 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.795919 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.796237 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008659\n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.541195 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.443019 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.774345 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.649364 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.635113 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.552218 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.713434 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.679130 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.620998 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.724494 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.653760 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008658\n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.621762 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.623100 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.636398 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.747934 [ 1833/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.605016 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.820295 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.642193 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.593919 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.593770 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.717895 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.674148 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008659\n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.551296 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.605718 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.781556 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.679908 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.698842 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.754861 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.587389 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.568142 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.825707 [ 4653/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.455205 [ 5217/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.470236 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.008660\n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.628836 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.615383 [  705/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.783529 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.592892 [ 1833/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.412203 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.545275 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.827401 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.773177 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.693536 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.834165 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.564406 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008660\n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.654776 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.746872 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.634655 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.565496 [ 1833/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 1.013313 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.673596 [ 2961/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.842495 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.657577 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.591905 [ 4653/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.609354 [ 5217/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.781967 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008659\n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.799433 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.655161 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.706201 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.723490 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.855750 [ 2397/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.416987 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.735535 [ 3525/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.467197 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.785939 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.892255 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.567452 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008658\n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.685102 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.722300 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.689655 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.659279 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.802285 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.708142 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.655474 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.536892 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.487542 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.567207 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.671284 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008656\n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.623116 [  141/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.905425 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.770164 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.739192 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.779177 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.791944 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.684791 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.745308 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.753695 [ 4653/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.932088 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.569775 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008655\n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.603304 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.620630 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.701482 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.472459 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.496539 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.672202 [ 2961/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.436155 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.756865 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.698541 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.509142 [ 5217/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.395719 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008653\n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.658231 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.748501 [  705/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.968387 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.497611 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.547748 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.556250 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.615622 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.600404 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.661151 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.517256 [ 5217/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.433852 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008656\n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.463601 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.512692 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.697657 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.753894 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.770909 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.724904 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.627803 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.585661 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.521653 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.745077 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.778672 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008653\n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.639229 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.537687 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.566161 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.532910 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.782196 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.868207 [ 2961/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.367987 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.698333 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.568811 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.527889 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.580996 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008650\n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.582473 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.732218 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.623534 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.687981 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.662895 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.555535 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.576635 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.461127 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.648553 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.588706 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.675348 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008653\n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.654385 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.687311 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.842273 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.588703 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.736424 [ 2397/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.493617 [ 2961/ 5922]\n",
      "Accuracy: 75.9%, Loss_1: 1.111596 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.583091 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.660818 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.517388 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.721845 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008652\n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.834212 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.684645 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.679493 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.519560 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.696106 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.784191 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.705409 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.519415 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.837180 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.721850 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.771400 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008653\n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.805353 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.659375 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.750437 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.495961 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.616228 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.800700 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.543831 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.682297 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.576744 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.921519 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.646551 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008654\n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.628814 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.496337 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.742512 [ 1269/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.512800 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.521048 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.555819 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.751711 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.645009 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.536114 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.518816 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.752366 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008654\n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.575027 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.644243 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.564406 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.685685 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.689876 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.623990 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.461030 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.650744 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.712410 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.769493 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.661075 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008655\n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.534300 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.524958 [  705/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.846694 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.540516 [ 1833/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.951284 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.746038 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.701458 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.748990 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.511193 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.711290 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.459450 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008653\n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.825811 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.612546 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.713627 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.807799 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.640830 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.638794 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.573782 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.723726 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.566149 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.632883 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.742495 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008655\n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.632325 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.565208 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.588264 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.491663 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.765644 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.806926 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.720466 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.751508 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.577124 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.817323 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.724989 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008664\n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.826230 [  141/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.843738 [  705/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.000657 [ 1269/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.865524 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.674215 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.648594 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.561436 [ 3525/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.664024 [ 4089/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.804224 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.741427 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.506603 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008670\n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.679766 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.729589 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.509111 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.913012 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.608608 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.600659 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.711993 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.611232 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.704744 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.631281 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.699552 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008673\n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.501244 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.811209 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.702983 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.710691 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.549147 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.720305 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.757367 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.604411 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.615935 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.554242 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.431705 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008671\n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.554283 [  141/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.891188 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.683304 [ 1269/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.751817 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.524218 [ 2397/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.786593 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.709985 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.742052 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.699512 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.822961 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.700389 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008666\n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.592839 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.720883 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.591321 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.736090 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.709167 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.603339 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.623303 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.732403 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.709079 [ 4653/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.460505 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.782387 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008666\n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.738431 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.416827 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.599215 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.601936 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.636360 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.733702 [ 2961/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.362366 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.752276 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.671331 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.599771 [ 5217/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.818633 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008673\n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.723583 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.708859 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.734282 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.649419 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.687663 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.796336 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.849722 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.563258 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.624988 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.493801 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.660608 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008669\n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "Accuracy: 82.3%, Loss_1: 0.795746 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.688287 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.761061 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.507547 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.548392 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.747139 [ 2961/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.841678 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.450690 [ 4089/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.432843 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.610982 [ 5217/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.499216 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008670\n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.567730 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.548558 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.707745 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.639685 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.666903 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.698405 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.696173 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.748036 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.617222 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.511155 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.647776 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008670\n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.778630 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.761613 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.622303 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.591746 [ 1833/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.561777 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.688850 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.810829 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.795351 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.606362 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.520820 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.767633 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008669\n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.581706 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.646122 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.616942 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.694817 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.786465 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.624470 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.715044 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.835407 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.564121 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.590857 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.657685 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008671\n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.807015 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.613138 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.662724 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.494656 [ 1833/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 1.006721 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.754943 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.526462 [ 3525/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.751926 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.788592 [ 4653/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.766278 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.613613 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008670\n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.680646 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.669194 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.670533 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.552011 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.636793 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.654213 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.503868 [ 3525/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.496507 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.883513 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.704925 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.455279 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008674\n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.630858 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.724015 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.668872 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.492158 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.495624 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.751384 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.535567 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.639365 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.714750 [ 4653/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.432998 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.611492 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008674\n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.671029 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.565873 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.776793 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.763809 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.722758 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.645006 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.617955 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.542281 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.699223 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.737504 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.744618 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008675\n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.493829 [  141/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.790150 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.602252 [ 1269/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.457944 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.635824 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.638817 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.442524 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.608397 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.473953 [ 4653/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.368025 [ 5217/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.814935 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008679\n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "Accuracy: 95.7%, Loss_1: 0.283092 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.481456 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.619239 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.813437 [ 1833/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.517845 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.679943 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.651448 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.634081 [ 4089/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.427656 [ 4653/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.779236 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.701218 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008681\n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.511478 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.545214 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.620294 [ 1269/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.776532 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.761522 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.737301 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.785098 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.710297 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.434701 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.654571 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.619425 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008682\n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.672387 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.435885 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.668481 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.693293 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.656129 [ 2397/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.495117 [ 2961/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.886229 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.623186 [ 4089/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.651151 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.681494 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.499700 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008683\n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "Accuracy: 80.9%, Loss_1: 0.790856 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.800815 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.780508 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.659394 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.655264 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.709186 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.788453 [ 3525/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.764340 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.675578 [ 4653/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.414560 [ 5217/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.654920 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008679\n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "Accuracy: 90.1%, Loss_1: 0.437034 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.638816 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.645443 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.716250 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.741961 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.669522 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.662277 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.757530 [ 4089/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.678038 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.644760 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.571710 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.008675\n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.620001 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.477131 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.551566 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.720907 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.647281 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.577354 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.551197 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.594423 [ 4089/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.703615 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.602002 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.599779 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008679\n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.617257 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.635011 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.709342 [ 1269/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.803738 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.538172 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.688277 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.613772 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.523238 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.731204 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.710152 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.628861 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008678\n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.909135 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.594660 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.734891 [ 1269/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.928623 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.761513 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.750032 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.487544 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.627329 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.396774 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.624842 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.859356 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008682\n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.560131 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.769901 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.734159 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.725115 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.516157 [ 2397/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.822507 [ 2961/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.572381 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.553670 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.539721 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.802248 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.610492 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.008679\n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.627631 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.604029 [  705/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.788272 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.814056 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.637032 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.516889 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.648383 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.656565 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.567458 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.511444 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.602369 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008673\n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.727626 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.710273 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.537663 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.621549 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.660600 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.708740 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.677859 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.522004 [ 4089/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.762862 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.580058 [ 5217/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.764029 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008672\n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.597121 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.618778 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.588219 [ 1269/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.683342 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.578514 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.761684 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.692429 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.697138 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.563622 [ 4653/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.768087 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.556580 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008674\n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.700161 [  141/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.716721 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.779395 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.589974 [ 1833/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.416445 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.756693 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.616187 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.558927 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.759310 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.515761 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.755856 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008675\n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.692396 [  141/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.896993 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.670970 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.817201 [ 1833/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.675265 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.696617 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.703642 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.791458 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.525234 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.694272 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.726953 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008671\n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "Accuracy: 78.0%, Loss_1: 0.855656 [  141/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.672132 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.621473 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.454133 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.721599 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.643829 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.741865 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.614262 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.642483 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.718760 [ 5217/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.874429 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008677\n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "Accuracy: 89.4%, Loss_1: 0.449288 [  141/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.733939 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.650543 [ 1269/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.532337 [ 1833/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.898866 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.624590 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.625055 [ 3525/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.619237 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.603054 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.667354 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.734957 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008675\n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.626914 [  141/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.583018 [  705/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.040680 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.541217 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.730184 [ 2397/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.611795 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.557704 [ 3525/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.440643 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.591075 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.642541 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.605323 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008676\n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "Accuracy: 80.1%, Loss_1: 0.903072 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.656985 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.883854 [ 1269/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.771091 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.670710 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.822622 [ 2961/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.445945 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.647284 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.796513 [ 4653/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.818757 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.644555 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008676\n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.601783 [  141/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.528104 [  705/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.913436 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.644844 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.566209 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.704310 [ 2961/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.504435 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.516221 [ 4089/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.480366 [ 4653/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.551617 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.582114 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008673\n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "Accuracy: 83.7%, Loss_1: 0.825619 [  141/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.876455 [  705/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.684860 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.554328 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.623132 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.552427 [ 2961/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.677465 [ 3525/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 1.121247 [ 4089/ 5922]\n",
      "Accuracy: 91.5%, Loss_1: 0.457654 [ 4653/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.699307 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.783795 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008670\n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.659306 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.583796 [  705/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.526121 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.512509 [ 1833/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.780846 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.703997 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.719909 [ 3525/ 5922]\n",
      "Accuracy: 95.0%, Loss_1: 0.337956 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.645792 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.458060 [ 5217/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.728307 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008670\n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.588941 [  141/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.542614 [  705/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.430126 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.639388 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.711479 [ 2397/ 5922]\n",
      "Accuracy: 79.4%, Loss_1: 0.981123 [ 2961/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.628675 [ 3525/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.766937 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.529327 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.596068 [ 5217/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.456996 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008672\n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.731435 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.669618 [  705/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.706614 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.679280 [ 1833/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.647028 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.573084 [ 2961/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.554507 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.616885 [ 4089/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.815454 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.641600 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.688504 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008669\n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "Accuracy: 88.7%, Loss_1: 0.638617 [  141/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.539037 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.466662 [ 1269/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.708716 [ 1833/ 5922]\n",
      "Accuracy: 77.3%, Loss_1: 0.943837 [ 2397/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.471638 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.592146 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.664912 [ 4089/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.741364 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.643044 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.625080 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008664\n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.563141 [  141/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.376648 [  705/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.789890 [ 1269/ 5922]\n",
      "Accuracy: 95.0%, Loss_1: 0.305042 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.772671 [ 2397/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.794961 [ 2961/ 5922]\n",
      "Accuracy: 78.0%, Loss_1: 0.873614 [ 3525/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.606888 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.597243 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.512065 [ 5217/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.841753 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008661\n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.766781 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.816747 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.608901 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.584895 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.596999 [ 2397/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.688746 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.664754 [ 3525/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.729514 [ 4089/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.789960 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.605589 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.632934 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008656\n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.619625 [  141/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.770995 [  705/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.580115 [ 1269/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.615565 [ 1833/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.681874 [ 2397/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.739302 [ 2961/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.718694 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.697137 [ 4089/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.689244 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.666594 [ 5217/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.665302 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008661\n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "Accuracy: 81.6%, Loss_1: 0.794547 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.663949 [  705/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.771009 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.697920 [ 1833/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.897655 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.803154 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.695743 [ 3525/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.607906 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.593002 [ 4653/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.569548 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.708423 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008665\n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "Accuracy: 85.1%, Loss_1: 0.661982 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.688984 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.608090 [ 1269/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.585406 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.690025 [ 2397/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.634106 [ 2961/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.636028 [ 3525/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.706950 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.805080 [ 4653/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.507697 [ 5217/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.635849 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008663\n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.736854 [  141/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.428205 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.712520 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.805009 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.574975 [ 2397/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.530466 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.772159 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.690542 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.580992 [ 4653/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.663764 [ 5217/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.623228 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008666\n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "Accuracy: 83.0%, Loss_1: 0.763757 [  141/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.642782 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.627539 [ 1269/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.544515 [ 1833/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.670142 [ 2397/ 5922]\n",
      "Accuracy: 92.9%, Loss_1: 0.416404 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.753541 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.575473 [ 4089/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.452362 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.573020 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.659013 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008672\n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.655829 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.800726 [  705/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.654432 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.697877 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.641721 [ 2397/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.600508 [ 2961/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.481177 [ 3525/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.858975 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.635458 [ 4653/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.674541 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.664308 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008676\n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "Accuracy: 86.5%, Loss_1: 0.530586 [  141/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.758739 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.661989 [ 1269/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.654203 [ 1833/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.569186 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.602485 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.691806 [ 3525/ 5922]\n",
      "Accuracy: 78.7%, Loss_1: 0.805412 [ 4089/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.474039 [ 4653/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.808172 [ 5217/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.746918 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008673\n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "Accuracy: 85.8%, Loss_1: 0.694867 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.529151 [  705/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.511737 [ 1269/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.581175 [ 1833/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.713726 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.765314 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.739437 [ 3525/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.626334 [ 4089/ 5922]\n",
      "Accuracy: 87.9%, Loss_1: 0.548585 [ 4653/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.610152 [ 5217/ 5922]\n",
      "Accuracy: 90.8%, Loss_1: 0.505077 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008673\n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "Accuracy: 87.9%, Loss_1: 0.572228 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.566394 [  705/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.707672 [ 1269/ 5922]\n",
      "Accuracy: 80.9%, Loss_1: 0.826483 [ 1833/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.490506 [ 2397/ 5922]\n",
      "Accuracy: 80.1%, Loss_1: 0.884078 [ 2961/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.750592 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.724198 [ 4089/ 5922]\n",
      "Accuracy: 87.2%, Loss_1: 0.664528 [ 4653/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.473132 [ 5217/ 5922]\n",
      "Accuracy: 92.2%, Loss_1: 0.360285 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008674\n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "Accuracy: 87.2%, Loss_1: 0.588475 [  141/ 5922]\n",
      "Accuracy: 90.1%, Loss_1: 0.464851 [  705/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.656850 [ 1269/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.699257 [ 1833/ 5922]\n",
      "Accuracy: 81.6%, Loss_1: 0.775264 [ 2397/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.721526 [ 2961/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.647468 [ 3525/ 5922]\n",
      "Accuracy: 83.0%, Loss_1: 0.742084 [ 4089/ 5922]\n",
      "Accuracy: 83.7%, Loss_1: 0.678870 [ 4653/ 5922]\n",
      "Accuracy: 89.4%, Loss_1: 0.457049 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.645823 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008673\n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "Accuracy: 84.4%, Loss_1: 0.671244 [  141/ 5922]\n",
      "Accuracy: 85.8%, Loss_1: 0.796842 [  705/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.590099 [ 1269/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.642245 [ 1833/ 5922]\n",
      "Accuracy: 84.4%, Loss_1: 0.643657 [ 2397/ 5922]\n",
      "Accuracy: 86.5%, Loss_1: 0.612789 [ 2961/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.689420 [ 3525/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.559585 [ 4089/ 5922]\n",
      "Accuracy: 82.3%, Loss_1: 0.842694 [ 4653/ 5922]\n",
      "Accuracy: 88.7%, Loss_1: 0.542514 [ 5217/ 5922]\n",
      "Accuracy: 85.1%, Loss_1: 0.664528 [ 5781/ 5922]\n",
      "Finished training\n",
      "Validation Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.008672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Global Variables\n",
    "epochs = 1_000\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Load Pre-Trained Models\n",
    "# model_1.load(\"NeuralNetwork-1_acc-50.29_loss-0.000003\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "best_accuracy = 0.61 # ???\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\\n-------------------------------\")\n",
    "\n",
    "    train_model(model, X_train_PCA, y_train, criterion, optimizer)\n",
    "    print('Finished training')\n",
    "    \n",
    "    accuracy, loss = validate_model(model, X_val_PCA, y_val, criterion)\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        print(f\"[+] Saving Model...\")\n",
    "        model.save(f\"NeuralNetwork-Ensemble_acc-{accuracy * 100:.2f}_loss-{loss:>8f}\")\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "        print(f\"[!] Models Saved.\")\n",
    "\n",
    "    epoch += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_test, y_test, criterion):\n",
    "    size = len(y_test)\n",
    "\n",
    "    model.eval()\n",
    "    with T.no_grad():\n",
    "        X = T.from_numpy(X_test).to(T.float32).to(device)\n",
    "        y_true = T.Tensor(y_test).to(T.float).to(device)\n",
    "\n",
    "        logits = model.forward(X)\n",
    "\n",
    "        loss = criterion(logits, y_true)\n",
    "\n",
    "        correct = (logits.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "        \n",
    "        loss /= size\n",
    "        accuracy = correct/size\n",
    "        \n",
    "        print(f\"Test Error: \\n Accuracy: {(100 * (accuracy)):>0.1f}%, Avg loss: {loss:>8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 62.4%, Avg loss: 0.005019\n"
     ]
    }
   ],
   "source": [
    "# model_1.save_dir = \"./best_models\"\n",
    "# model_2.save_dir = \"./best_models\"\n",
    "\n",
    "model.load(\"NeuralNetwork-Ensemble_acc-62.10_loss-0.005126\")\n",
    "# model_2.load(\"NeuralNetwork-2_acc-61.81_loss-0.000008\")\n",
    "test_model(model, X_test_PCA, y_test, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
