{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [] # Features per class\n",
    "training_labels = [] # Labels\n",
    "testing_data = [] # Features per class\n",
    "testing_labels = [] # Labels\n",
    "N = 5250 # Amount of data we want to use max: 5250\n",
    "\n",
    "# Import the features\n",
    "with open(\"traindata.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        features = [float(i) for i in line.split(\",\")]\n",
    "        training_data.append(features)\n",
    "\n",
    "with open(\"testdata.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        features = [float(i) for i in line.split(\",\")]\n",
    "        testing_data.append(features)\n",
    "\n",
    "\n",
    "# Import the labels\n",
    "with open(\"trainlabels.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        label = float(line.rstrip())\n",
    "        training_labels.append(label)\n",
    "\n",
    "with open(\"targetlabels.txt\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        label = float(line.rstrip())\n",
    "        testing_labels.append(label)\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "training_data = np.array(training_data)\n",
    "training_labels = np.array(training_labels, dtype=np.int64)\n",
    "\n",
    "testing_data = np.array(testing_data)\n",
    "testing_labels = np.array(testing_labels, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:  (5250, 1041) (5250,)\n",
      "Testing Data:  (2100, 1041) (2100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data: \", training_data.shape, training_labels.shape)\n",
    "print(\"Testing Data: \", testing_data.shape, testing_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(x):\n",
    "    labels = np.unique(x)\n",
    "    result = np.zeros(shape=(x.shape[0], labels.shape[0]))\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        result[i][x[i]] = 1.0\n",
    "\n",
    "    return result\n",
    "\n",
    "def rotate_image(image, orientation):\n",
    "    angle = 90 * orientation\n",
    "    \n",
    "    if angle == 0:\n",
    "        return image\n",
    "    elif angle == 90:\n",
    "        return np.fliplr(np.transpose(image))  # Rotate 90 degrees clockwise\n",
    "    elif angle == 180:\n",
    "        return np.flipud(np.fliplr(image))  # Rotate 180 degrees\n",
    "    elif angle == 270:\n",
    "        return np.transpose(np.fliplr(image))  # Rotate 270 degrees clockwise\n",
    "\n",
    "def preprocess_data(X):\n",
    "    x = X[:-1]\n",
    "    orientation = X[-1] # 4 orientations: 0, 1, 2, 3\n",
    "\n",
    "    filtered_x = x[x >= 0] # Filter out negative values\n",
    "    filtered_x = np.minimum(filtered_x, 255.0) # cap values greater than 255 to 255\n",
    "    image = filtered_x.reshape([32, 32]) # reshape to an image\n",
    "\n",
    "    normalized_image = MinMaxScaler().fit_transform(image) # Normalize Image\n",
    "\n",
    "    rotated_image = rotate_image(normalized_image, orientation) #Rotate Image\n",
    "    return rotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_training_data = []\n",
    "preprocess_testing_data = []\n",
    "\n",
    "for X in training_data:\n",
    "    preprocess_X = preprocess_data(X)\n",
    "    preprocess_training_data.append(preprocess_X)\n",
    "\n",
    "for X in testing_data:\n",
    "    preprocess_X = preprocess_data(X)\n",
    "    preprocess_testing_data.append(preprocess_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, val_size=0.2, random_state=42):\n",
    "   \n",
    "    # Splitting the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Further splitting the training data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size / (1 - test_size),\n",
    "                                                      random_state=random_state)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "X_train = np.array(preprocess_training_data)\n",
    "y_train = to_onehot(training_labels)\n",
    "X_test, X_val, y_test, y_val = train_test_split(np.array(preprocess_testing_data), to_onehot(testing_labels), test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5250, 1, 32, 32) (1050, 1, 32, 32) (1050, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "new_shape = [-1, 1, 32, 32]\n",
    "X_train = np.reshape(X_train, new_shape)\n",
    "X_test = np.reshape(X_test, new_shape)\n",
    "X_val = np.reshape(X_val, new_shape)\n",
    "\n",
    "print(X_train.shape, X_test.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_data = np.load(\"additional_data-10000.npy\").reshape([-1, 1, 32, 32])\n",
    "additional_labels = np.load(\"additional_labels-10000.npy\")\n",
    "\n",
    "X_train = np.vstack([X_train, additional_data])\n",
    "y_train = np.vstack([y_train, to_onehot(additional_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15250, 1, 32, 32) (15250, 21)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(image, title):\n",
    "    plt.imshow(image.reshape([32, 32]), cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_point = 45\n",
    "plot_images(X_train[data_point], f\"Training Label: {np.argmax(y_train[data_point])}\")\n",
    "plot_images(X_test[data_point], f\"Testing Label: {np.argmax(y_test[data_point])}\")\n",
    "plot_images(X_val[data_point], f\"Validation Label: {np.argmax(y_val[data_point])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dims, n_outputs, p_dropout=0.20, save_dir=\"./models\"):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        activation = nn.ReLU()\n",
    "        dropout = nn.AlphaDropout(p=p_dropout)\n",
    "\n",
    "        # Define layers with expected sizes\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, input_dims[0], kernel_size=3, padding=1),  # Input shape: (1, 32, 32)\n",
    "            nn.GroupNorm(16, 32),\n",
    "            activation,\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output shape: (32, 16, 16)\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # Output shape: (64, 16, 16)\n",
    "            nn.GroupNorm(32, 64),  \n",
    "            activation,\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output shape: (64, 8, 8)\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=64 * 8 * 8, out_features=1024),\n",
    "            nn.GroupNorm(128, 1024),\n",
    "            activation,\n",
    "            dropout,\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.GroupNorm(64, 512),\n",
    "            activation,\n",
    "            dropout,\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.GroupNorm(64, 256),\n",
    "            activation,\n",
    "            dropout,\n",
    "            nn.Linear(in_features=256, out_features=n_outputs),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        logits = self.network(X)\n",
    "        return logits\n",
    "\n",
    "    def save(self, name):\n",
    "        T.save(self.state_dict(), f\"{self.save_dir}/{name}.pth\")\n",
    "\n",
    "    def load(self, name):\n",
    "        self.load_state_dict(T.load(f\"{self.save_dir}/{name}.pth\"))\n",
    "\n",
    "\n",
    "# Adjust dimensions for input and output\n",
    "n_inputs = [32, 32]  # Width and height of the input image\n",
    "n_outputs = 21  # Number of output classes\n",
    "\n",
    "# Move a tensor to the GPU\n",
    "device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model\n",
    "model_1 = NeuralNetwork(input_dims=n_inputs, n_outputs=n_outputs, p_dropout=0.4).to(device)\n",
    "model_2 = NeuralNetwork(input_dims=n_inputs, n_outputs=n_outputs, p_dropout=0.4).to(device)\n",
    "\n",
    "# dummy_image = T.rand(size=[1, 1, n_inputs[0], n_inputs[1]]).to(device)  # Dummy image tensor\n",
    "# pred_1 = model_1(dummy_image)\n",
    "# pred_2 = model_2(dummy_image)\n",
    "\n",
    "# print(pred_1, pred_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(y_pred, y_true, labels):\n",
    "    N = labels.shape[0]\n",
    "    matrix = [[0] * (N + 1) for _ in range(N + 1)]\n",
    "\n",
    "    matrix[0][0] = \" \"\n",
    "    for i in range(1, N):\n",
    "        matrix[i][0] = f\"{i}\"\n",
    "        matrix[0][i] = f\"{i}\"\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        matrix[round(y_pred[i]) + 1][y_true[i] + 1] += 1\n",
    "\n",
    "    for i in range(N):\n",
    "        print(\" \".join(map(str, matrix[i])))\n",
    "\n",
    "    return sum([matrix[i + 1][i + 1] for i in range(2)]) / len(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model1, model2, X_val, y_val, criterion):\n",
    "    size = len(y_val)\n",
    "\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "\n",
    "    with T.no_grad():\n",
    "        X = T.from_numpy(X_val).to(T.float32).to(device)\n",
    "        y_true = T.Tensor(y_val).to(T.float).to(device)\n",
    "\n",
    "        logits_1 = model1.forward(X)\n",
    "        logits_2 = model2.forward(X)\n",
    "\n",
    "        loss_1, loss_2 = criterion(logits_1, logits_2, y_true, 0.2)\n",
    "\n",
    "        correct_1 = (logits_1.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "        correct_2 = (logits_2.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "        \n",
    "        loss_1 /= size\n",
    "        loss_2 /= size\n",
    "        accuracy_1 = correct_1/size\n",
    "        accuracy_2 = correct_2/size\n",
    "        print(f\"Validation Error (Model 1): \\n Accuracy: {(100 * (accuracy_1)):>0.1f}%, Avg loss: {loss_1:>8f}\")\n",
    "        print(f\"Validation Error (Model 2): \\n Accuracy: {(100 * (accuracy_2)):>0.1f}%, Avg loss: {loss_2:>8f} \\n\")\n",
    "    \n",
    "    return accuracy_1, accuracy_2, loss_1, loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_1, model_2, X_train, y_train, criterion, optimizer_1, optimizer_2):\n",
    "    size = len(X_train)\n",
    "    batch_size = 141\n",
    "\n",
    "    #Prevents model from memorizing the position of data\n",
    "    indices = np.random.randint(0, size, size)\n",
    "\n",
    "    model_1.train()\n",
    "    model_2.train()\n",
    "\n",
    "    for i in range(size//batch_size):\n",
    "        start = batch_size * i\n",
    "        end = start + batch_size\n",
    "\n",
    "        X = T.from_numpy(X_train[indices[start:end]]).to(T.float32).to(device)\n",
    "        y_true = T.Tensor(y_train[indices[start:end]]).to(T.float).to(device)\n",
    "\n",
    "        logits_1 = model_1.forward(X)\n",
    "        logits_2 = model_2.forward(X)\n",
    "\n",
    "        loss_1, loss_2 = criterion(logits_1, logits_2, y_true, 0.2)\n",
    "\n",
    "        # Gradiant Descent using Adam optimizer for best performance\n",
    "        optimizer_1.zero_grad()\n",
    "        loss_1.backward()\n",
    "        optimizer_1.step()\n",
    "\n",
    "        optimizer_2.zero_grad()\n",
    "        loss_2.backward()\n",
    "        optimizer_2.step()\n",
    "\n",
    "        correct_1 = (logits_1.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "        correct_2 = (logits_2.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "\n",
    "        accuracy_1 = correct_1/batch_size\n",
    "        accuracy_2 = correct_2/batch_size\n",
    "\n",
    "        if (i * batch_size) % 564 == 0:\n",
    "            loss_1, loss_2, current = loss_1.item(), loss_2.item(), (i + 1) * batch_size\n",
    "            print(f\"Accuracy_1: {(100 * (accuracy_1)):>0.1f}%, Loss_1: {loss_1:>7f}, \", end=\"\")\n",
    "            print(f\"Accuracy_2: {(100 * (accuracy_2)):>0.1f}% Loss_2: {loss_2:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Loss functions\n",
    "def loss_coteaching(y_1, y_2, t, forget_rate):\n",
    "    loss_1 = F.cross_entropy(y_1, t, reduction=\"none\")\n",
    "    ind_1_sorted = T.argsort(loss_1.data)\n",
    "    loss_1_sorted = loss_1[ind_1_sorted]\n",
    "\n",
    "    loss_2 = F.cross_entropy(y_2, t, reduction=\"none\")\n",
    "    ind_2_sorted = T.argsort(loss_2.data)\n",
    "    loss_2_sorted = loss_2[ind_2_sorted]\n",
    "\n",
    "    remember_rate = 1 - forget_rate\n",
    "    num_remember = int(remember_rate * len(loss_1_sorted))\n",
    "\n",
    "\n",
    "    ind_1_update=ind_1_sorted[:num_remember]\n",
    "    ind_2_update=ind_2_sorted[:num_remember]\n",
    "    # exchange\n",
    "    loss_1_update = F.cross_entropy(y_1[ind_2_update], t[ind_2_update])\n",
    "    loss_2_update = F.cross_entropy(y_2[ind_1_update], t[ind_1_update])\n",
    "\n",
    "    return T.sum(loss_1_update)/num_remember, T.sum(loss_2_update)/num_remember\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "Accuracy_1: 7.8%, Loss_1: 0.028414, Accuracy_2: 5.0% Loss_2: 0.029510  [  141/15250]\n",
      "Accuracy_1: 4.3%, Loss_1: 0.029311, Accuracy_2: 2.1% Loss_2: 0.029232  [  705/15250]\n",
      "Accuracy_1: 5.7%, Loss_1: 0.030449, Accuracy_2: 8.5% Loss_2: 0.029484  [ 1269/15250]\n",
      "Accuracy_1: 3.5%, Loss_1: 0.029231, Accuracy_2: 2.8% Loss_2: 0.031639  [ 1833/15250]\n",
      "Accuracy_1: 4.3%, Loss_1: 0.029100, Accuracy_2: 5.0% Loss_2: 0.030428  [ 2397/15250]\n",
      "Accuracy_1: 6.4%, Loss_1: 0.028992, Accuracy_2: 5.0% Loss_2: 0.029744  [ 2961/15250]\n",
      "Accuracy_1: 3.5%, Loss_1: 0.029399, Accuracy_2: 4.3% Loss_2: 0.030197  [ 3525/15250]\n",
      "Accuracy_1: 7.1%, Loss_1: 0.029282, Accuracy_2: 7.1% Loss_2: 0.029216  [ 4089/15250]\n",
      "Accuracy_1: 5.0%, Loss_1: 0.029468, Accuracy_2: 4.3% Loss_2: 0.029914  [ 4653/15250]\n",
      "Accuracy_1: 6.4%, Loss_1: 0.029337, Accuracy_2: 5.7% Loss_2: 0.028854  [ 5217/15250]\n",
      "Accuracy_1: 5.0%, Loss_1: 0.028813, Accuracy_2: 5.7% Loss_2: 0.028681  [ 5781/15250]\n",
      "Accuracy_1: 7.1%, Loss_1: 0.029439, Accuracy_2: 2.1% Loss_2: 0.029233  [ 6345/15250]\n",
      "Accuracy_1: 2.8%, Loss_1: 0.030625, Accuracy_2: 2.1% Loss_2: 0.029894  [ 6909/15250]\n",
      "Accuracy_1: 6.4%, Loss_1: 0.029240, Accuracy_2: 6.4% Loss_2: 0.028601  [ 7473/15250]\n",
      "Accuracy_1: 4.3%, Loss_1: 0.028810, Accuracy_2: 5.0% Loss_2: 0.028495  [ 8037/15250]\n",
      "Accuracy_1: 8.5%, Loss_1: 0.029546, Accuracy_2: 7.1% Loss_2: 0.028217  [ 8601/15250]\n",
      "Accuracy_1: 5.7%, Loss_1: 0.028723, Accuracy_2: 4.3% Loss_2: 0.028959  [ 9165/15250]\n",
      "Accuracy_1: 5.7%, Loss_1: 0.028753, Accuracy_2: 4.3% Loss_2: 0.029155  [ 9729/15250]\n",
      "Accuracy_1: 9.2%, Loss_1: 0.028065, Accuracy_2: 3.5% Loss_2: 0.028853  [10293/15250]\n",
      "Accuracy_1: 5.7%, Loss_1: 0.028944, Accuracy_2: 8.5% Loss_2: 0.028524  [10857/15250]\n",
      "Accuracy_1: 7.1%, Loss_1: 0.029245, Accuracy_2: 5.0% Loss_2: 0.028908  [11421/15250]\n",
      "Accuracy_1: 8.5%, Loss_1: 0.028465, Accuracy_2: 5.7% Loss_2: 0.028927  [11985/15250]\n",
      "Accuracy_1: 4.3%, Loss_1: 0.027680, Accuracy_2: 7.1% Loss_2: 0.028437  [12549/15250]\n",
      "Accuracy_1: 5.7%, Loss_1: 0.028867, Accuracy_2: 7.8% Loss_2: 0.029434  [13113/15250]\n",
      "Accuracy_1: 5.7%, Loss_1: 0.028645, Accuracy_2: 3.5% Loss_2: 0.029166  [13677/15250]\n",
      "Accuracy_1: 7.1%, Loss_1: 0.027253, Accuracy_2: 3.5% Loss_2: 0.028690  [14241/15250]\n",
      "Accuracy_1: 5.0%, Loss_1: 0.028514, Accuracy_2: 6.4% Loss_2: 0.028503  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 8.2%, Avg loss: 0.000003\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 8.7%, Avg loss: 0.000003 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Accuracy_1: 7.1%, Loss_1: 0.027929, Accuracy_2: 7.1% Loss_2: 0.028369  [  141/15250]\n",
      "Accuracy_1: 4.3%, Loss_1: 0.029551, Accuracy_2: 6.4% Loss_2: 0.029029  [  705/15250]\n",
      "Accuracy_1: 6.4%, Loss_1: 0.028010, Accuracy_2: 5.0% Loss_2: 0.029469  [ 1269/15250]\n",
      "Accuracy_1: 5.0%, Loss_1: 0.027607, Accuracy_2: 5.7% Loss_2: 0.029271  [ 1833/15250]\n",
      "Accuracy_1: 9.9%, Loss_1: 0.027892, Accuracy_2: 5.7% Loss_2: 0.028339  [ 2397/15250]\n",
      "Accuracy_1: 6.4%, Loss_1: 0.027761, Accuracy_2: 3.5% Loss_2: 0.030034  [ 2961/15250]\n",
      "Accuracy_1: 3.5%, Loss_1: 0.028063, Accuracy_2: 4.3% Loss_2: 0.027684  [ 3525/15250]\n",
      "Accuracy_1: 6.4%, Loss_1: 0.026265, Accuracy_2: 9.9% Loss_2: 0.027515  [ 4089/15250]\n",
      "Accuracy_1: 9.2%, Loss_1: 0.024622, Accuracy_2: 7.1% Loss_2: 0.028651  [ 4653/15250]\n",
      "Accuracy_1: 7.1%, Loss_1: 0.027051, Accuracy_2: 9.9% Loss_2: 0.027118  [ 5217/15250]\n",
      "Accuracy_1: 10.6%, Loss_1: 0.025669, Accuracy_2: 5.7% Loss_2: 0.027207  [ 5781/15250]\n",
      "Accuracy_1: 10.6%, Loss_1: 0.026907, Accuracy_2: 9.2% Loss_2: 0.026855  [ 6345/15250]\n",
      "Accuracy_1: 12.8%, Loss_1: 0.023550, Accuracy_2: 7.1% Loss_2: 0.026143  [ 6909/15250]\n",
      "Accuracy_1: 12.1%, Loss_1: 0.025295, Accuracy_2: 5.0% Loss_2: 0.027874  [ 7473/15250]\n",
      "Accuracy_1: 12.1%, Loss_1: 0.025666, Accuracy_2: 7.1% Loss_2: 0.026981  [ 8037/15250]\n",
      "Accuracy_1: 10.6%, Loss_1: 0.024588, Accuracy_2: 3.5% Loss_2: 0.026528  [ 8601/15250]\n",
      "Accuracy_1: 10.6%, Loss_1: 0.024925, Accuracy_2: 7.1% Loss_2: 0.026301  [ 9165/15250]\n",
      "Accuracy_1: 11.3%, Loss_1: 0.024256, Accuracy_2: 8.5% Loss_2: 0.025434  [ 9729/15250]\n",
      "Accuracy_1: 15.6%, Loss_1: 0.023987, Accuracy_2: 7.1% Loss_2: 0.025541  [10293/15250]\n",
      "Accuracy_1: 11.3%, Loss_1: 0.024580, Accuracy_2: 10.6% Loss_2: 0.026966  [10857/15250]\n",
      "Accuracy_1: 11.3%, Loss_1: 0.024205, Accuracy_2: 9.9% Loss_2: 0.024378  [11421/15250]\n",
      "Accuracy_1: 13.5%, Loss_1: 0.022742, Accuracy_2: 10.6% Loss_2: 0.025964  [11985/15250]\n",
      "Accuracy_1: 14.2%, Loss_1: 0.023084, Accuracy_2: 9.9% Loss_2: 0.023452  [12549/15250]\n",
      "Accuracy_1: 18.4%, Loss_1: 0.021636, Accuracy_2: 10.6% Loss_2: 0.024282  [13113/15250]\n",
      "Accuracy_1: 17.7%, Loss_1: 0.022475, Accuracy_2: 12.8% Loss_2: 0.024654  [13677/15250]\n",
      "Accuracy_1: 14.2%, Loss_1: 0.023728, Accuracy_2: 13.5% Loss_2: 0.023662  [14241/15250]\n",
      "Accuracy_1: 17.7%, Loss_1: 0.021576, Accuracy_2: 12.8% Loss_2: 0.023189  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 19.5%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 12.8%, Avg loss: 0.000003 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Accuracy_1: 19.1%, Loss_1: 0.021475, Accuracy_2: 15.6% Loss_2: 0.023828  [  141/15250]\n",
      "Accuracy_1: 16.3%, Loss_1: 0.021037, Accuracy_2: 14.2% Loss_2: 0.022947  [  705/15250]\n",
      "Accuracy_1: 19.9%, Loss_1: 0.022471, Accuracy_2: 6.4% Loss_2: 0.024350  [ 1269/15250]\n",
      "Accuracy_1: 17.7%, Loss_1: 0.021121, Accuracy_2: 14.2% Loss_2: 0.022945  [ 1833/15250]\n",
      "Accuracy_1: 20.6%, Loss_1: 0.020199, Accuracy_2: 17.7% Loss_2: 0.023270  [ 2397/15250]\n",
      "Accuracy_1: 14.9%, Loss_1: 0.021413, Accuracy_2: 10.6% Loss_2: 0.022386  [ 2961/15250]\n",
      "Accuracy_1: 17.0%, Loss_1: 0.019179, Accuracy_2: 7.8% Loss_2: 0.023516  [ 3525/15250]\n",
      "Accuracy_1: 22.0%, Loss_1: 0.019752, Accuracy_2: 14.2% Loss_2: 0.023213  [ 4089/15250]\n",
      "Accuracy_1: 17.7%, Loss_1: 0.020558, Accuracy_2: 12.1% Loss_2: 0.023859  [ 4653/15250]\n",
      "Accuracy_1: 13.5%, Loss_1: 0.021060, Accuracy_2: 13.5% Loss_2: 0.022367  [ 5217/15250]\n",
      "Accuracy_1: 19.9%, Loss_1: 0.019061, Accuracy_2: 16.3% Loss_2: 0.021630  [ 5781/15250]\n",
      "Accuracy_1: 22.7%, Loss_1: 0.018688, Accuracy_2: 13.5% Loss_2: 0.021050  [ 6345/15250]\n",
      "Accuracy_1: 18.4%, Loss_1: 0.018468, Accuracy_2: 12.8% Loss_2: 0.023636  [ 6909/15250]\n",
      "Accuracy_1: 25.5%, Loss_1: 0.019869, Accuracy_2: 9.2% Loss_2: 0.022826  [ 7473/15250]\n",
      "Accuracy_1: 29.8%, Loss_1: 0.019838, Accuracy_2: 18.4% Loss_2: 0.022117  [ 8037/15250]\n",
      "Accuracy_1: 27.7%, Loss_1: 0.018474, Accuracy_2: 12.8% Loss_2: 0.022860  [ 8601/15250]\n",
      "Accuracy_1: 27.7%, Loss_1: 0.017561, Accuracy_2: 16.3% Loss_2: 0.021121  [ 9165/15250]\n",
      "Accuracy_1: 25.5%, Loss_1: 0.019069, Accuracy_2: 14.2% Loss_2: 0.023021  [ 9729/15250]\n",
      "Accuracy_1: 34.0%, Loss_1: 0.018453, Accuracy_2: 17.0% Loss_2: 0.021833  [10293/15250]\n",
      "Accuracy_1: 39.0%, Loss_1: 0.017389, Accuracy_2: 21.3% Loss_2: 0.019906  [10857/15250]\n",
      "Accuracy_1: 29.8%, Loss_1: 0.017680, Accuracy_2: 21.3% Loss_2: 0.020017  [11421/15250]\n",
      "Accuracy_1: 29.1%, Loss_1: 0.018772, Accuracy_2: 19.9% Loss_2: 0.021862  [11985/15250]\n",
      "Accuracy_1: 37.6%, Loss_1: 0.017426, Accuracy_2: 22.0% Loss_2: 0.022350  [12549/15250]\n",
      "Accuracy_1: 35.5%, Loss_1: 0.013591, Accuracy_2: 22.7% Loss_2: 0.019630  [13113/15250]\n",
      "Accuracy_1: 36.9%, Loss_1: 0.015238, Accuracy_2: 24.1% Loss_2: 0.018994  [13677/15250]\n",
      "Accuracy_1: 38.3%, Loss_1: 0.017369, Accuracy_2: 20.6% Loss_2: 0.020071  [14241/15250]\n",
      "Accuracy_1: 33.3%, Loss_1: 0.016038, Accuracy_2: 22.7% Loss_2: 0.019342  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 47.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 29.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Accuracy_1: 34.8%, Loss_1: 0.016167, Accuracy_2: 23.4% Loss_2: 0.018805  [  141/15250]\n",
      "Accuracy_1: 29.8%, Loss_1: 0.016865, Accuracy_2: 19.1% Loss_2: 0.019093  [  705/15250]\n",
      "Accuracy_1: 33.3%, Loss_1: 0.016608, Accuracy_2: 19.9% Loss_2: 0.021023  [ 1269/15250]\n",
      "Accuracy_1: 34.0%, Loss_1: 0.015667, Accuracy_2: 20.6% Loss_2: 0.018520  [ 1833/15250]\n",
      "Accuracy_1: 46.1%, Loss_1: 0.012042, Accuracy_2: 22.7% Loss_2: 0.018739  [ 2397/15250]\n",
      "Accuracy_1: 42.6%, Loss_1: 0.014498, Accuracy_2: 19.9% Loss_2: 0.017938  [ 2961/15250]\n",
      "Accuracy_1: 36.9%, Loss_1: 0.014938, Accuracy_2: 25.5% Loss_2: 0.018900  [ 3525/15250]\n",
      "Accuracy_1: 41.1%, Loss_1: 0.013331, Accuracy_2: 29.1% Loss_2: 0.016341  [ 4089/15250]\n",
      "Accuracy_1: 36.2%, Loss_1: 0.017736, Accuracy_2: 24.8% Loss_2: 0.018619  [ 4653/15250]\n",
      "Accuracy_1: 40.4%, Loss_1: 0.016694, Accuracy_2: 19.9% Loss_2: 0.019120  [ 5217/15250]\n",
      "Accuracy_1: 42.6%, Loss_1: 0.013703, Accuracy_2: 22.0% Loss_2: 0.018834  [ 5781/15250]\n",
      "Accuracy_1: 39.0%, Loss_1: 0.013548, Accuracy_2: 19.9% Loss_2: 0.018090  [ 6345/15250]\n",
      "Accuracy_1: 38.3%, Loss_1: 0.014683, Accuracy_2: 24.8% Loss_2: 0.017262  [ 6909/15250]\n",
      "Accuracy_1: 31.2%, Loss_1: 0.015816, Accuracy_2: 23.4% Loss_2: 0.017521  [ 7473/15250]\n",
      "Accuracy_1: 35.5%, Loss_1: 0.014079, Accuracy_2: 24.8% Loss_2: 0.017899  [ 8037/15250]\n",
      "Accuracy_1: 37.6%, Loss_1: 0.014835, Accuracy_2: 27.0% Loss_2: 0.015569  [ 8601/15250]\n",
      "Accuracy_1: 47.5%, Loss_1: 0.014541, Accuracy_2: 34.0% Loss_2: 0.017605  [ 9165/15250]\n",
      "Accuracy_1: 41.1%, Loss_1: 0.013747, Accuracy_2: 31.9% Loss_2: 0.016872  [ 9729/15250]\n",
      "Accuracy_1: 44.0%, Loss_1: 0.011860, Accuracy_2: 31.2% Loss_2: 0.016082  [10293/15250]\n",
      "Accuracy_1: 43.3%, Loss_1: 0.013363, Accuracy_2: 31.2% Loss_2: 0.015948  [10857/15250]\n",
      "Accuracy_1: 41.1%, Loss_1: 0.012434, Accuracy_2: 27.7% Loss_2: 0.016458  [11421/15250]\n",
      "Accuracy_1: 38.3%, Loss_1: 0.015564, Accuracy_2: 29.8% Loss_2: 0.016957  [11985/15250]\n",
      "Accuracy_1: 42.6%, Loss_1: 0.012450, Accuracy_2: 33.3% Loss_2: 0.014904  [12549/15250]\n",
      "Accuracy_1: 46.1%, Loss_1: 0.013390, Accuracy_2: 34.8% Loss_2: 0.016114  [13113/15250]\n",
      "Accuracy_1: 42.6%, Loss_1: 0.012386, Accuracy_2: 31.2% Loss_2: 0.015169  [13677/15250]\n",
      "Accuracy_1: 41.1%, Loss_1: 0.014815, Accuracy_2: 36.2% Loss_2: 0.014738  [14241/15250]\n",
      "Accuracy_1: 46.1%, Loss_1: 0.011035, Accuracy_2: 32.6% Loss_2: 0.016181  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 63.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 41.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Accuracy_1: 43.3%, Loss_1: 0.011543, Accuracy_2: 40.4% Loss_2: 0.015581  [  141/15250]\n",
      "Accuracy_1: 44.7%, Loss_1: 0.012463, Accuracy_2: 35.5% Loss_2: 0.014639  [  705/15250]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.008778, Accuracy_2: 40.4% Loss_2: 0.012116  [ 1269/15250]\n",
      "Accuracy_1: 45.4%, Loss_1: 0.011797, Accuracy_2: 31.9% Loss_2: 0.015619  [ 1833/15250]\n",
      "Accuracy_1: 48.2%, Loss_1: 0.012401, Accuracy_2: 36.2% Loss_2: 0.014407  [ 2397/15250]\n",
      "Accuracy_1: 44.7%, Loss_1: 0.013310, Accuracy_2: 33.3% Loss_2: 0.014325  [ 2961/15250]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.011342, Accuracy_2: 41.8% Loss_2: 0.012712  [ 3525/15250]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.010631, Accuracy_2: 36.9% Loss_2: 0.014977  [ 4089/15250]\n",
      "Accuracy_1: 47.5%, Loss_1: 0.012481, Accuracy_2: 38.3% Loss_2: 0.013957  [ 4653/15250]\n",
      "Accuracy_1: 53.9%, Loss_1: 0.010120, Accuracy_2: 42.6% Loss_2: 0.013351  [ 5217/15250]\n",
      "Accuracy_1: 57.4%, Loss_1: 0.009540, Accuracy_2: 41.8% Loss_2: 0.012188  [ 5781/15250]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.011487, Accuracy_2: 41.8% Loss_2: 0.014481  [ 6345/15250]\n",
      "Accuracy_1: 58.2%, Loss_1: 0.009273, Accuracy_2: 37.6% Loss_2: 0.013232  [ 6909/15250]\n",
      "Accuracy_1: 48.9%, Loss_1: 0.011121, Accuracy_2: 34.8% Loss_2: 0.015241  [ 7473/15250]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.008013, Accuracy_2: 51.1% Loss_2: 0.009439  [ 8037/15250]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.008291, Accuracy_2: 54.6% Loss_2: 0.009725  [ 8601/15250]\n",
      "Accuracy_1: 62.4%, Loss_1: 0.008058, Accuracy_2: 49.6% Loss_2: 0.012287  [ 9165/15250]\n",
      "Accuracy_1: 50.4%, Loss_1: 0.009818, Accuracy_2: 49.6% Loss_2: 0.011334  [ 9729/15250]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.009541, Accuracy_2: 48.2% Loss_2: 0.011181  [10293/15250]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.010188, Accuracy_2: 40.4% Loss_2: 0.012813  [10857/15250]\n",
      "Accuracy_1: 56.7%, Loss_1: 0.009836, Accuracy_2: 41.1% Loss_2: 0.014221  [11421/15250]\n",
      "Accuracy_1: 51.8%, Loss_1: 0.010145, Accuracy_2: 51.1% Loss_2: 0.011306  [11985/15250]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.008848, Accuracy_2: 49.6% Loss_2: 0.010914  [12549/15250]\n",
      "Accuracy_1: 48.9%, Loss_1: 0.012157, Accuracy_2: 49.6% Loss_2: 0.011589  [13113/15250]\n",
      "Accuracy_1: 58.9%, Loss_1: 0.008392, Accuracy_2: 52.5% Loss_2: 0.010457  [13677/15250]\n",
      "Accuracy_1: 58.9%, Loss_1: 0.007389, Accuracy_2: 53.2% Loss_2: 0.009640  [14241/15250]\n",
      "Accuracy_1: 53.9%, Loss_1: 0.010725, Accuracy_2: 51.1% Loss_2: 0.013296  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 69.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 65.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Accuracy_1: 48.2%, Loss_1: 0.008496, Accuracy_2: 54.6% Loss_2: 0.009278  [  141/15250]\n",
      "Accuracy_1: 53.2%, Loss_1: 0.010181, Accuracy_2: 56.7% Loss_2: 0.009914  [  705/15250]\n",
      "Accuracy_1: 63.8%, Loss_1: 0.007030, Accuracy_2: 53.9% Loss_2: 0.010508  [ 1269/15250]\n",
      "Accuracy_1: 60.3%, Loss_1: 0.007452, Accuracy_2: 53.9% Loss_2: 0.010605  [ 1833/15250]\n",
      "Accuracy_1: 55.3%, Loss_1: 0.009168, Accuracy_2: 56.7% Loss_2: 0.007617  [ 2397/15250]\n",
      "Accuracy_1: 61.7%, Loss_1: 0.007370, Accuracy_2: 57.4% Loss_2: 0.009900  [ 2961/15250]\n",
      "Accuracy_1: 51.1%, Loss_1: 0.011513, Accuracy_2: 51.1% Loss_2: 0.011039  [ 3525/15250]\n",
      "Accuracy_1: 61.0%, Loss_1: 0.007838, Accuracy_2: 56.7% Loss_2: 0.009942  [ 4089/15250]\n",
      "Accuracy_1: 61.7%, Loss_1: 0.006556, Accuracy_2: 56.0% Loss_2: 0.009182  [ 4653/15250]\n",
      "Accuracy_1: 58.9%, Loss_1: 0.007283, Accuracy_2: 61.0% Loss_2: 0.006431  [ 5217/15250]\n",
      "Accuracy_1: 64.5%, Loss_1: 0.008119, Accuracy_2: 63.1% Loss_2: 0.007296  [ 5781/15250]\n",
      "Accuracy_1: 58.9%, Loss_1: 0.009425, Accuracy_2: 61.7% Loss_2: 0.006196  [ 6345/15250]\n",
      "Accuracy_1: 57.4%, Loss_1: 0.008102, Accuracy_2: 59.6% Loss_2: 0.007855  [ 6909/15250]\n",
      "Accuracy_1: 56.0%, Loss_1: 0.010859, Accuracy_2: 59.6% Loss_2: 0.009651  [ 7473/15250]\n",
      "Accuracy_1: 54.6%, Loss_1: 0.010827, Accuracy_2: 64.5% Loss_2: 0.007939  [ 8037/15250]\n",
      "Accuracy_1: 61.7%, Loss_1: 0.007523, Accuracy_2: 58.9% Loss_2: 0.008332  [ 8601/15250]\n",
      "Accuracy_1: 68.8%, Loss_1: 0.007404, Accuracy_2: 61.0% Loss_2: 0.008592  [ 9165/15250]\n",
      "Accuracy_1: 56.0%, Loss_1: 0.009096, Accuracy_2: 55.3% Loss_2: 0.009898  [ 9729/15250]\n",
      "Accuracy_1: 58.2%, Loss_1: 0.009035, Accuracy_2: 58.2% Loss_2: 0.008291  [10293/15250]\n",
      "Accuracy_1: 65.2%, Loss_1: 0.008034, Accuracy_2: 48.2% Loss_2: 0.011077  [10857/15250]\n",
      "Accuracy_1: 65.2%, Loss_1: 0.006523, Accuracy_2: 61.0% Loss_2: 0.007550  [11421/15250]\n",
      "Accuracy_1: 63.8%, Loss_1: 0.006107, Accuracy_2: 62.4% Loss_2: 0.007152  [11985/15250]\n",
      "Accuracy_1: 69.5%, Loss_1: 0.006401, Accuracy_2: 61.7% Loss_2: 0.007516  [12549/15250]\n",
      "Accuracy_1: 63.1%, Loss_1: 0.008415, Accuracy_2: 61.7% Loss_2: 0.007568  [13113/15250]\n",
      "Accuracy_1: 58.2%, Loss_1: 0.009186, Accuracy_2: 61.0% Loss_2: 0.007709  [13677/15250]\n",
      "Accuracy_1: 63.1%, Loss_1: 0.006647, Accuracy_2: 59.6% Loss_2: 0.007619  [14241/15250]\n",
      "Accuracy_1: 68.1%, Loss_1: 0.006268, Accuracy_2: 56.0% Loss_2: 0.008367  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 71.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 70.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Accuracy_1: 61.0%, Loss_1: 0.006405, Accuracy_2: 65.2% Loss_2: 0.006969  [  141/15250]\n",
      "Accuracy_1: 64.5%, Loss_1: 0.007026, Accuracy_2: 63.8% Loss_2: 0.005379  [  705/15250]\n",
      "Accuracy_1: 65.2%, Loss_1: 0.007326, Accuracy_2: 62.4% Loss_2: 0.007266  [ 1269/15250]\n",
      "Accuracy_1: 66.0%, Loss_1: 0.006898, Accuracy_2: 68.1% Loss_2: 0.005440  [ 1833/15250]\n",
      "Accuracy_1: 70.2%, Loss_1: 0.006417, Accuracy_2: 59.6% Loss_2: 0.008887  [ 2397/15250]\n",
      "Accuracy_1: 61.7%, Loss_1: 0.011179, Accuracy_2: 57.4% Loss_2: 0.012258  [ 2961/15250]\n",
      "Accuracy_1: 65.2%, Loss_1: 0.006093, Accuracy_2: 66.0% Loss_2: 0.006377  [ 3525/15250]\n",
      "Accuracy_1: 68.8%, Loss_1: 0.006115, Accuracy_2: 61.0% Loss_2: 0.007471  [ 4089/15250]\n",
      "Accuracy_1: 58.2%, Loss_1: 0.010102, Accuracy_2: 56.7% Loss_2: 0.009249  [ 4653/15250]\n",
      "Accuracy_1: 71.6%, Loss_1: 0.005592, Accuracy_2: 63.1% Loss_2: 0.006793  [ 5217/15250]\n",
      "Accuracy_1: 70.9%, Loss_1: 0.006635, Accuracy_2: 65.2% Loss_2: 0.006532  [ 5781/15250]\n",
      "Accuracy_1: 66.7%, Loss_1: 0.008545, Accuracy_2: 67.4% Loss_2: 0.006506  [ 6345/15250]\n",
      "Accuracy_1: 60.3%, Loss_1: 0.008377, Accuracy_2: 61.0% Loss_2: 0.007527  [ 6909/15250]\n",
      "Accuracy_1: 65.2%, Loss_1: 0.006858, Accuracy_2: 58.9% Loss_2: 0.007850  [ 7473/15250]\n",
      "Accuracy_1: 66.7%, Loss_1: 0.006556, Accuracy_2: 61.7% Loss_2: 0.006565  [ 8037/15250]\n",
      "Accuracy_1: 68.8%, Loss_1: 0.008679, Accuracy_2: 67.4% Loss_2: 0.008709  [ 8601/15250]\n",
      "Accuracy_1: 68.8%, Loss_1: 0.005814, Accuracy_2: 61.7% Loss_2: 0.008273  [ 9165/15250]\n",
      "Accuracy_1: 72.3%, Loss_1: 0.005498, Accuracy_2: 70.2% Loss_2: 0.006001  [ 9729/15250]\n",
      "Accuracy_1: 65.2%, Loss_1: 0.006591, Accuracy_2: 56.7% Loss_2: 0.009707  [10293/15250]\n",
      "Accuracy_1: 75.2%, Loss_1: 0.005989, Accuracy_2: 70.9% Loss_2: 0.005458  [10857/15250]\n",
      "Accuracy_1: 65.2%, Loss_1: 0.009777, Accuracy_2: 63.1% Loss_2: 0.009704  [11421/15250]\n",
      "Accuracy_1: 65.2%, Loss_1: 0.006299, Accuracy_2: 68.8% Loss_2: 0.005469  [11985/15250]\n",
      "Accuracy_1: 66.0%, Loss_1: 0.005855, Accuracy_2: 68.1% Loss_2: 0.006191  [12549/15250]\n",
      "Accuracy_1: 66.7%, Loss_1: 0.004864, Accuracy_2: 70.9% Loss_2: 0.006603  [13113/15250]\n",
      "Accuracy_1: 66.0%, Loss_1: 0.005138, Accuracy_2: 67.4% Loss_2: 0.005446  [13677/15250]\n",
      "Accuracy_1: 64.5%, Loss_1: 0.006604, Accuracy_2: 72.3% Loss_2: 0.005901  [14241/15250]\n",
      "Accuracy_1: 58.2%, Loss_1: 0.007550, Accuracy_2: 61.7% Loss_2: 0.007740  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 73.5%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 72.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Accuracy_1: 67.4%, Loss_1: 0.005900, Accuracy_2: 67.4% Loss_2: 0.006432  [  141/15250]\n",
      "Accuracy_1: 62.4%, Loss_1: 0.008537, Accuracy_2: 62.4% Loss_2: 0.007498  [  705/15250]\n",
      "Accuracy_1: 63.8%, Loss_1: 0.007216, Accuracy_2: 66.7% Loss_2: 0.008159  [ 1269/15250]\n",
      "Accuracy_1: 70.9%, Loss_1: 0.004446, Accuracy_2: 66.7% Loss_2: 0.005698  [ 1833/15250]\n",
      "Accuracy_1: 62.4%, Loss_1: 0.008524, Accuracy_2: 54.6% Loss_2: 0.010802  [ 2397/15250]\n",
      "Accuracy_1: 70.2%, Loss_1: 0.005802, Accuracy_2: 60.3% Loss_2: 0.007363  [ 2961/15250]\n",
      "Accuracy_1: 72.3%, Loss_1: 0.004796, Accuracy_2: 73.0% Loss_2: 0.005469  [ 3525/15250]\n",
      "Accuracy_1: 72.3%, Loss_1: 0.003340, Accuracy_2: 71.6% Loss_2: 0.004527  [ 4089/15250]\n",
      "Accuracy_1: 73.0%, Loss_1: 0.005408, Accuracy_2: 70.2% Loss_2: 0.004914  [ 4653/15250]\n",
      "Accuracy_1: 68.8%, Loss_1: 0.005467, Accuracy_2: 68.8% Loss_2: 0.004586  [ 5217/15250]\n",
      "Accuracy_1: 70.9%, Loss_1: 0.004481, Accuracy_2: 73.0% Loss_2: 0.004700  [ 5781/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.004010, Accuracy_2: 70.2% Loss_2: 0.004810  [ 6345/15250]\n",
      "Accuracy_1: 73.8%, Loss_1: 0.003646, Accuracy_2: 70.2% Loss_2: 0.005699  [ 6909/15250]\n",
      "Accuracy_1: 63.8%, Loss_1: 0.006132, Accuracy_2: 68.1% Loss_2: 0.004533  [ 7473/15250]\n",
      "Accuracy_1: 72.3%, Loss_1: 0.005446, Accuracy_2: 68.1% Loss_2: 0.005837  [ 8037/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.003430, Accuracy_2: 71.6% Loss_2: 0.006153  [ 8601/15250]\n",
      "Accuracy_1: 70.2%, Loss_1: 0.004975, Accuracy_2: 72.3% Loss_2: 0.004397  [ 9165/15250]\n",
      "Accuracy_1: 64.5%, Loss_1: 0.004986, Accuracy_2: 70.2% Loss_2: 0.005775  [ 9729/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.003056, Accuracy_2: 78.7% Loss_2: 0.005447  [10293/15250]\n",
      "Accuracy_1: 70.9%, Loss_1: 0.006029, Accuracy_2: 66.7% Loss_2: 0.007860  [10857/15250]\n",
      "Accuracy_1: 73.0%, Loss_1: 0.004204, Accuracy_2: 71.6% Loss_2: 0.004139  [11421/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.003829, Accuracy_2: 76.6% Loss_2: 0.003702  [11985/15250]\n",
      "Accuracy_1: 73.0%, Loss_1: 0.005641, Accuracy_2: 70.9% Loss_2: 0.006321  [12549/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.004089, Accuracy_2: 74.5% Loss_2: 0.004020  [13113/15250]\n",
      "Accuracy_1: 73.0%, Loss_1: 0.005058, Accuracy_2: 64.5% Loss_2: 0.007218  [13677/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.003156, Accuracy_2: 76.6% Loss_2: 0.004040  [14241/15250]\n",
      "Accuracy_1: 66.7%, Loss_1: 0.007858, Accuracy_2: 66.7% Loss_2: 0.006312  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 76.9%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 75.8%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Accuracy_1: 68.1%, Loss_1: 0.004610, Accuracy_2: 71.6% Loss_2: 0.004279  [  141/15250]\n",
      "Accuracy_1: 70.9%, Loss_1: 0.004721, Accuracy_2: 73.0% Loss_2: 0.006155  [  705/15250]\n",
      "Accuracy_1: 73.8%, Loss_1: 0.003915, Accuracy_2: 72.3% Loss_2: 0.003417  [ 1269/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.003806, Accuracy_2: 71.6% Loss_2: 0.004680  [ 1833/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.003246, Accuracy_2: 73.0% Loss_2: 0.004061  [ 2397/15250]\n",
      "Accuracy_1: 75.2%, Loss_1: 0.006134, Accuracy_2: 75.9% Loss_2: 0.005160  [ 2961/15250]\n",
      "Accuracy_1: 73.8%, Loss_1: 0.004176, Accuracy_2: 73.8% Loss_2: 0.004080  [ 3525/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.004470, Accuracy_2: 77.3% Loss_2: 0.003657  [ 4089/15250]\n",
      "Accuracy_1: 70.2%, Loss_1: 0.007733, Accuracy_2: 73.0% Loss_2: 0.004953  [ 4653/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.003805, Accuracy_2: 74.5% Loss_2: 0.003604  [ 5217/15250]\n",
      "Accuracy_1: 73.0%, Loss_1: 0.004906, Accuracy_2: 66.7% Loss_2: 0.004364  [ 5781/15250]\n",
      "Accuracy_1: 69.5%, Loss_1: 0.004600, Accuracy_2: 72.3% Loss_2: 0.003842  [ 6345/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.003166, Accuracy_2: 73.8% Loss_2: 0.003980  [ 6909/15250]\n",
      "Accuracy_1: 64.5%, Loss_1: 0.007493, Accuracy_2: 66.0% Loss_2: 0.006336  [ 7473/15250]\n",
      "Accuracy_1: 68.1%, Loss_1: 0.006434, Accuracy_2: 71.6% Loss_2: 0.006094  [ 8037/15250]\n",
      "Accuracy_1: 75.2%, Loss_1: 0.002641, Accuracy_2: 80.1% Loss_2: 0.003177  [ 8601/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.004548, Accuracy_2: 75.9% Loss_2: 0.004939  [ 9165/15250]\n",
      "Accuracy_1: 68.1%, Loss_1: 0.005180, Accuracy_2: 66.0% Loss_2: 0.005485  [ 9729/15250]\n",
      "Accuracy_1: 73.0%, Loss_1: 0.005085, Accuracy_2: 79.4% Loss_2: 0.004089  [10293/15250]\n",
      "Accuracy_1: 68.8%, Loss_1: 0.005972, Accuracy_2: 73.8% Loss_2: 0.005661  [10857/15250]\n",
      "Accuracy_1: 72.3%, Loss_1: 0.004178, Accuracy_2: 75.2% Loss_2: 0.003029  [11421/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.004544, Accuracy_2: 73.8% Loss_2: 0.005471  [11985/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002538, Accuracy_2: 80.1% Loss_2: 0.002828  [12549/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.004176, Accuracy_2: 70.2% Loss_2: 0.008073  [13113/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.002706, Accuracy_2: 73.8% Loss_2: 0.003115  [13677/15250]\n",
      "Accuracy_1: 74.5%, Loss_1: 0.005914, Accuracy_2: 70.9% Loss_2: 0.005085  [14241/15250]\n",
      "Accuracy_1: 74.5%, Loss_1: 0.004283, Accuracy_2: 68.8% Loss_2: 0.005806  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 76.1%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 77.7%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003218, Accuracy_2: 70.9% Loss_2: 0.005458  [  141/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002537, Accuracy_2: 73.0% Loss_2: 0.003756  [  705/15250]\n",
      "Accuracy_1: 72.3%, Loss_1: 0.005290, Accuracy_2: 76.6% Loss_2: 0.002439  [ 1269/15250]\n",
      "Accuracy_1: 70.2%, Loss_1: 0.005874, Accuracy_2: 67.4% Loss_2: 0.005315  [ 1833/15250]\n",
      "Accuracy_1: 68.1%, Loss_1: 0.007045, Accuracy_2: 71.6% Loss_2: 0.005955  [ 2397/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.004079, Accuracy_2: 71.6% Loss_2: 0.005494  [ 2961/15250]\n",
      "Accuracy_1: 72.3%, Loss_1: 0.003666, Accuracy_2: 75.9% Loss_2: 0.002558  [ 3525/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001473, Accuracy_2: 77.3% Loss_2: 0.003151  [ 4089/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002549, Accuracy_2: 80.9% Loss_2: 0.002731  [ 4653/15250]\n",
      "Accuracy_1: 74.5%, Loss_1: 0.003198, Accuracy_2: 83.0% Loss_2: 0.002421  [ 5217/15250]\n",
      "Accuracy_1: 71.6%, Loss_1: 0.005038, Accuracy_2: 73.8% Loss_2: 0.005672  [ 5781/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.005314, Accuracy_2: 72.3% Loss_2: 0.005105  [ 6345/15250]\n",
      "Accuracy_1: 68.8%, Loss_1: 0.007593, Accuracy_2: 71.6% Loss_2: 0.004524  [ 6909/15250]\n",
      "Accuracy_1: 73.8%, Loss_1: 0.005933, Accuracy_2: 73.8% Loss_2: 0.004873  [ 7473/15250]\n",
      "Accuracy_1: 69.5%, Loss_1: 0.006719, Accuracy_2: 71.6% Loss_2: 0.004213  [ 8037/15250]\n",
      "Accuracy_1: 69.5%, Loss_1: 0.006750, Accuracy_2: 71.6% Loss_2: 0.006236  [ 8601/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.003702, Accuracy_2: 78.7% Loss_2: 0.002875  [ 9165/15250]\n",
      "Accuracy_1: 71.6%, Loss_1: 0.006899, Accuracy_2: 70.2% Loss_2: 0.006264  [ 9729/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002161, Accuracy_2: 76.6% Loss_2: 0.003974  [10293/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.003578, Accuracy_2: 75.2% Loss_2: 0.005478  [10857/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.002872, Accuracy_2: 80.1% Loss_2: 0.001911  [11421/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002798, Accuracy_2: 80.1% Loss_2: 0.002232  [11985/15250]\n",
      "Accuracy_1: 73.8%, Loss_1: 0.003520, Accuracy_2: 73.8% Loss_2: 0.003265  [12549/15250]\n",
      "Accuracy_1: 75.2%, Loss_1: 0.004574, Accuracy_2: 71.6% Loss_2: 0.005011  [13113/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.003884, Accuracy_2: 72.3% Loss_2: 0.004971  [13677/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.003452, Accuracy_2: 73.0% Loss_2: 0.004891  [14241/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.003165, Accuracy_2: 73.8% Loss_2: 0.003085  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 79.0%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 79.0%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Accuracy_1: 72.3%, Loss_1: 0.005420, Accuracy_2: 72.3% Loss_2: 0.005717  [  141/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.003897, Accuracy_2: 76.6% Loss_2: 0.003801  [  705/15250]\n",
      "Accuracy_1: 69.5%, Loss_1: 0.005270, Accuracy_2: 73.8% Loss_2: 0.004387  [ 1269/15250]\n",
      "Accuracy_1: 69.5%, Loss_1: 0.004810, Accuracy_2: 74.5% Loss_2: 0.004128  [ 1833/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002045, Accuracy_2: 78.0% Loss_2: 0.003218  [ 2397/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.003594, Accuracy_2: 80.1% Loss_2: 0.001708  [ 2961/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.003288, Accuracy_2: 75.2% Loss_2: 0.004056  [ 3525/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.005351, Accuracy_2: 78.0% Loss_2: 0.002710  [ 4089/15250]\n",
      "Accuracy_1: 73.0%, Loss_1: 0.004893, Accuracy_2: 75.2% Loss_2: 0.003425  [ 4653/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.004230, Accuracy_2: 75.2% Loss_2: 0.003674  [ 5217/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001850, Accuracy_2: 81.6% Loss_2: 0.001518  [ 5781/15250]\n",
      "Accuracy_1: 72.3%, Loss_1: 0.005286, Accuracy_2: 76.6% Loss_2: 0.003560  [ 6345/15250]\n",
      "Accuracy_1: 71.6%, Loss_1: 0.005301, Accuracy_2: 78.7% Loss_2: 0.002357  [ 6909/15250]\n",
      "Accuracy_1: 70.9%, Loss_1: 0.003952, Accuracy_2: 77.3% Loss_2: 0.003340  [ 7473/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.003204, Accuracy_2: 80.1% Loss_2: 0.003695  [ 8037/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003087, Accuracy_2: 77.3% Loss_2: 0.003852  [ 8601/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.003230, Accuracy_2: 78.0% Loss_2: 0.004304  [ 9165/15250]\n",
      "Accuracy_1: 64.5%, Loss_1: 0.006777, Accuracy_2: 72.3% Loss_2: 0.005694  [ 9729/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.001593, Accuracy_2: 75.2% Loss_2: 0.003360  [10293/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002923, Accuracy_2: 82.3% Loss_2: 0.002095  [10857/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.002797, Accuracy_2: 75.9% Loss_2: 0.004251  [11421/15250]\n",
      "Accuracy_1: 74.5%, Loss_1: 0.004385, Accuracy_2: 75.9% Loss_2: 0.003702  [11985/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.003149, Accuracy_2: 77.3% Loss_2: 0.001922  [12549/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.004226, Accuracy_2: 78.7% Loss_2: 0.002576  [13113/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.003620, Accuracy_2: 75.9% Loss_2: 0.003405  [13677/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.003632, Accuracy_2: 77.3% Loss_2: 0.003635  [14241/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.004641, Accuracy_2: 73.0% Loss_2: 0.004143  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 79.7%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 79.6%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Accuracy_1: 74.5%, Loss_1: 0.002428, Accuracy_2: 75.2% Loss_2: 0.002903  [  141/15250]\n",
      "Accuracy_1: 75.2%, Loss_1: 0.002944, Accuracy_2: 75.2% Loss_2: 0.004945  [  705/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.003299, Accuracy_2: 76.6% Loss_2: 0.002935  [ 1269/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002562, Accuracy_2: 76.6% Loss_2: 0.003332  [ 1833/15250]\n",
      "Accuracy_1: 75.2%, Loss_1: 0.003222, Accuracy_2: 71.6% Loss_2: 0.005493  [ 2397/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002520, Accuracy_2: 78.0% Loss_2: 0.002838  [ 2961/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002156, Accuracy_2: 78.7% Loss_2: 0.004143  [ 3525/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.004008, Accuracy_2: 74.5% Loss_2: 0.003440  [ 4089/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.003447, Accuracy_2: 80.9% Loss_2: 0.004836  [ 4653/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001765, Accuracy_2: 80.1% Loss_2: 0.001915  [ 5217/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002709, Accuracy_2: 75.2% Loss_2: 0.003520  [ 5781/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002918, Accuracy_2: 83.7% Loss_2: 0.002753  [ 6345/15250]\n",
      "Accuracy_1: 74.5%, Loss_1: 0.003768, Accuracy_2: 75.9% Loss_2: 0.002744  [ 6909/15250]\n",
      "Accuracy_1: 75.2%, Loss_1: 0.004617, Accuracy_2: 73.0% Loss_2: 0.005876  [ 7473/15250]\n",
      "Accuracy_1: 72.3%, Loss_1: 0.003802, Accuracy_2: 67.4% Loss_2: 0.006411  [ 8037/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003495, Accuracy_2: 76.6% Loss_2: 0.002991  [ 8601/15250]\n",
      "Accuracy_1: 73.0%, Loss_1: 0.005243, Accuracy_2: 78.0% Loss_2: 0.002463  [ 9165/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.003895, Accuracy_2: 77.3% Loss_2: 0.003282  [ 9729/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003662, Accuracy_2: 81.6% Loss_2: 0.002178  [10293/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001597, Accuracy_2: 79.4% Loss_2: 0.002542  [10857/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001877, Accuracy_2: 82.3% Loss_2: 0.000933  [11421/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001272, Accuracy_2: 75.9% Loss_2: 0.004193  [11985/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003463, Accuracy_2: 73.8% Loss_2: 0.005352  [12549/15250]\n",
      "Accuracy_1: 75.2%, Loss_1: 0.003455, Accuracy_2: 73.0% Loss_2: 0.003861  [13113/15250]\n",
      "Accuracy_1: 73.0%, Loss_1: 0.003306, Accuracy_2: 75.9% Loss_2: 0.003327  [13677/15250]\n",
      "Accuracy_1: 72.3%, Loss_1: 0.004512, Accuracy_2: 75.9% Loss_2: 0.003195  [14241/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.004666, Accuracy_2: 81.6% Loss_2: 0.002312  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 79.6%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 79.3%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Accuracy_1: 77.3%, Loss_1: 0.004658, Accuracy_2: 80.1% Loss_2: 0.004703  [  141/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002800, Accuracy_2: 87.9% Loss_2: 0.001366  [  705/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002402, Accuracy_2: 81.6% Loss_2: 0.002055  [ 1269/15250]\n",
      "Accuracy_1: 73.8%, Loss_1: 0.005587, Accuracy_2: 73.8% Loss_2: 0.006155  [ 1833/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.003336, Accuracy_2: 78.0% Loss_2: 0.004694  [ 2397/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002671, Accuracy_2: 79.4% Loss_2: 0.002170  [ 2961/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.003007, Accuracy_2: 72.3% Loss_2: 0.004476  [ 3525/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003221, Accuracy_2: 80.9% Loss_2: 0.002026  [ 4089/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001686, Accuracy_2: 78.0% Loss_2: 0.002881  [ 4653/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.003662, Accuracy_2: 78.7% Loss_2: 0.003521  [ 5217/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.003066, Accuracy_2: 74.5% Loss_2: 0.004162  [ 5781/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002669, Accuracy_2: 80.1% Loss_2: 0.002938  [ 6345/15250]\n",
      "Accuracy_1: 75.2%, Loss_1: 0.003316, Accuracy_2: 76.6% Loss_2: 0.003261  [ 6909/15250]\n",
      "Accuracy_1: 74.5%, Loss_1: 0.003377, Accuracy_2: 71.6% Loss_2: 0.004188  [ 7473/15250]\n",
      "Accuracy_1: 71.6%, Loss_1: 0.005105, Accuracy_2: 71.6% Loss_2: 0.003849  [ 8037/15250]\n",
      "Accuracy_1: 73.8%, Loss_1: 0.005360, Accuracy_2: 73.8% Loss_2: 0.004091  [ 8601/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002608, Accuracy_2: 78.7% Loss_2: 0.002802  [ 9165/15250]\n",
      "Accuracy_1: 73.0%, Loss_1: 0.003579, Accuracy_2: 76.6% Loss_2: 0.004034  [ 9729/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.002927, Accuracy_2: 75.9% Loss_2: 0.003936  [10293/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.002125, Accuracy_2: 78.7% Loss_2: 0.002465  [10857/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.003318, Accuracy_2: 80.1% Loss_2: 0.003405  [11421/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002010, Accuracy_2: 81.6% Loss_2: 0.002275  [11985/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001951, Accuracy_2: 83.7% Loss_2: 0.001895  [12549/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.004268, Accuracy_2: 78.7% Loss_2: 0.004158  [13113/15250]\n",
      "Accuracy_1: 74.5%, Loss_1: 0.003087, Accuracy_2: 75.2% Loss_2: 0.003074  [13677/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.002619, Accuracy_2: 83.0% Loss_2: 0.001254  [14241/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.004030, Accuracy_2: 79.4% Loss_2: 0.003546  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 78.5%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 79.2%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Accuracy_1: 83.0%, Loss_1: 0.005123, Accuracy_2: 84.4% Loss_2: 0.002591  [  141/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002782, Accuracy_2: 80.9% Loss_2: 0.003423  [  705/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003686, Accuracy_2: 79.4% Loss_2: 0.003538  [ 1269/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.003398, Accuracy_2: 80.9% Loss_2: 0.002165  [ 1833/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.002510, Accuracy_2: 75.9% Loss_2: 0.004083  [ 2397/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.003376, Accuracy_2: 80.9% Loss_2: 0.001405  [ 2961/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.002838, Accuracy_2: 77.3% Loss_2: 0.003168  [ 3525/15250]\n",
      "Accuracy_1: 75.2%, Loss_1: 0.004347, Accuracy_2: 82.3% Loss_2: 0.002679  [ 4089/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003097, Accuracy_2: 78.7% Loss_2: 0.003035  [ 4653/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001043, Accuracy_2: 83.0% Loss_2: 0.001360  [ 5217/15250]\n",
      "Accuracy_1: 74.5%, Loss_1: 0.004395, Accuracy_2: 75.2% Loss_2: 0.003584  [ 5781/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002321, Accuracy_2: 78.0% Loss_2: 0.003972  [ 6345/15250]\n",
      "Accuracy_1: 71.6%, Loss_1: 0.003892, Accuracy_2: 79.4% Loss_2: 0.002454  [ 6909/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.003138, Accuracy_2: 84.4% Loss_2: 0.004263  [ 7473/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002706, Accuracy_2: 77.3% Loss_2: 0.003511  [ 8037/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002791, Accuracy_2: 78.0% Loss_2: 0.003995  [ 8601/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002967, Accuracy_2: 83.7% Loss_2: 0.001579  [ 9165/15250]\n",
      "Accuracy_1: 74.5%, Loss_1: 0.003265, Accuracy_2: 79.4% Loss_2: 0.004085  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001691, Accuracy_2: 83.0% Loss_2: 0.002580  [10293/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.002951, Accuracy_2: 79.4% Loss_2: 0.003085  [10857/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002865, Accuracy_2: 75.9% Loss_2: 0.005109  [11421/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001571, Accuracy_2: 78.0% Loss_2: 0.002391  [11985/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001486, Accuracy_2: 78.0% Loss_2: 0.001280  [12549/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001413, Accuracy_2: 83.0% Loss_2: 0.002032  [13113/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.003810, Accuracy_2: 79.4% Loss_2: 0.003474  [13677/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.002968, Accuracy_2: 80.1% Loss_2: 0.002290  [14241/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.004445, Accuracy_2: 79.4% Loss_2: 0.002615  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 78.9%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 80.7%, Avg loss: 0.000000 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002148, Accuracy_2: 75.2% Loss_2: 0.005331  [  141/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.003671, Accuracy_2: 80.9% Loss_2: 0.001520  [  705/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002972, Accuracy_2: 87.9% Loss_2: 0.001443  [ 1269/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002914, Accuracy_2: 78.0% Loss_2: 0.004344  [ 1833/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002410, Accuracy_2: 82.3% Loss_2: 0.001338  [ 2397/15250]\n",
      "Accuracy_1: 72.3%, Loss_1: 0.005767, Accuracy_2: 78.7% Loss_2: 0.001944  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001142, Accuracy_2: 80.1% Loss_2: 0.003039  [ 3525/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002805, Accuracy_2: 77.3% Loss_2: 0.004920  [ 4089/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.003685, Accuracy_2: 80.1% Loss_2: 0.001967  [ 4653/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000865, Accuracy_2: 81.6% Loss_2: 0.001920  [ 5217/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001570, Accuracy_2: 80.1% Loss_2: 0.002106  [ 5781/15250]\n",
      "Accuracy_1: 73.8%, Loss_1: 0.003185, Accuracy_2: 79.4% Loss_2: 0.003393  [ 6345/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001692, Accuracy_2: 83.0% Loss_2: 0.001417  [ 6909/15250]\n",
      "Accuracy_1: 74.5%, Loss_1: 0.005176, Accuracy_2: 74.5% Loss_2: 0.006742  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001661, Accuracy_2: 83.0% Loss_2: 0.001179  [ 8037/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002295, Accuracy_2: 74.5% Loss_2: 0.003368  [ 8601/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002512, Accuracy_2: 78.7% Loss_2: 0.003659  [ 9165/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002505, Accuracy_2: 80.9% Loss_2: 0.002803  [ 9729/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001316, Accuracy_2: 81.6% Loss_2: 0.001132  [10293/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.003900, Accuracy_2: 78.0% Loss_2: 0.002566  [10857/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002929, Accuracy_2: 83.0% Loss_2: 0.003470  [11421/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003355, Accuracy_2: 82.3% Loss_2: 0.002286  [11985/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001415, Accuracy_2: 79.4% Loss_2: 0.002171  [12549/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002591, Accuracy_2: 83.7% Loss_2: 0.003206  [13113/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002459, Accuracy_2: 80.9% Loss_2: 0.003149  [13677/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.004658, Accuracy_2: 80.9% Loss_2: 0.002621  [14241/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001045, Accuracy_2: 86.5% Loss_2: 0.000223  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 79.9%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 80.2%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001552, Accuracy_2: 82.3% Loss_2: 0.002288  [  141/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002073, Accuracy_2: 82.3% Loss_2: 0.001662  [  705/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001235, Accuracy_2: 80.1% Loss_2: 0.003479  [ 1269/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001406, Accuracy_2: 83.7% Loss_2: 0.001425  [ 1833/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.002089, Accuracy_2: 74.5% Loss_2: 0.003355  [ 2397/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002090, Accuracy_2: 83.7% Loss_2: 0.002019  [ 2961/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000846, Accuracy_2: 87.2% Loss_2: 0.001574  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001226, Accuracy_2: 86.5% Loss_2: 0.001044  [ 4089/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001978, Accuracy_2: 85.1% Loss_2: 0.002094  [ 4653/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002349, Accuracy_2: 82.3% Loss_2: 0.003193  [ 5217/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.003369, Accuracy_2: 78.0% Loss_2: 0.002879  [ 5781/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001307, Accuracy_2: 82.3% Loss_2: 0.001971  [ 6345/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002897, Accuracy_2: 78.7% Loss_2: 0.003299  [ 6909/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001405, Accuracy_2: 76.6% Loss_2: 0.003458  [ 7473/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.006732, Accuracy_2: 82.3% Loss_2: 0.002515  [ 8037/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.002552, Accuracy_2: 81.6% Loss_2: 0.001447  [ 8601/15250]\n",
      "Accuracy_1: 74.5%, Loss_1: 0.003964, Accuracy_2: 76.6% Loss_2: 0.003381  [ 9165/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001626, Accuracy_2: 78.7% Loss_2: 0.003068  [ 9729/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002368, Accuracy_2: 83.7% Loss_2: 0.002961  [10293/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001448, Accuracy_2: 79.4% Loss_2: 0.001126  [10857/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.003294, Accuracy_2: 83.0% Loss_2: 0.001840  [11421/15250]\n",
      "Accuracy_1: 74.5%, Loss_1: 0.003002, Accuracy_2: 78.7% Loss_2: 0.001856  [11985/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001130, Accuracy_2: 81.6% Loss_2: 0.001214  [12549/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002208, Accuracy_2: 83.7% Loss_2: 0.003139  [13113/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.003010, Accuracy_2: 80.9% Loss_2: 0.002034  [13677/15250]\n",
      "Accuracy_1: 73.8%, Loss_1: 0.003132, Accuracy_2: 77.3% Loss_2: 0.001693  [14241/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001003, Accuracy_2: 78.7% Loss_2: 0.002440  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 80.3%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 80.4%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002226, Accuracy_2: 79.4% Loss_2: 0.005095  [  141/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.003370, Accuracy_2: 80.1% Loss_2: 0.002370  [  705/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000737, Accuracy_2: 83.0% Loss_2: 0.001529  [ 1269/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002636, Accuracy_2: 83.7% Loss_2: 0.001179  [ 1833/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001505, Accuracy_2: 78.7% Loss_2: 0.003883  [ 2397/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001856, Accuracy_2: 83.7% Loss_2: 0.002037  [ 2961/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002784, Accuracy_2: 82.3% Loss_2: 0.002081  [ 3525/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001788, Accuracy_2: 84.4% Loss_2: 0.003230  [ 4089/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003166, Accuracy_2: 84.4% Loss_2: 0.001505  [ 4653/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001775, Accuracy_2: 80.1% Loss_2: 0.003038  [ 5217/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001691, Accuracy_2: 80.9% Loss_2: 0.001979  [ 5781/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.003656, Accuracy_2: 81.6% Loss_2: 0.001981  [ 6345/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001507, Accuracy_2: 83.7% Loss_2: 0.002555  [ 6909/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001896, Accuracy_2: 82.3% Loss_2: 0.001348  [ 7473/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000849, Accuracy_2: 83.0% Loss_2: 0.001782  [ 8037/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.001954, Accuracy_2: 75.2% Loss_2: 0.002224  [ 8601/15250]\n",
      "Accuracy_1: 75.2%, Loss_1: 0.002501, Accuracy_2: 79.4% Loss_2: 0.001255  [ 9165/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001498, Accuracy_2: 82.3% Loss_2: 0.001144  [ 9729/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001366, Accuracy_2: 81.6% Loss_2: 0.002780  [10293/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.005016, Accuracy_2: 83.0% Loss_2: 0.002490  [10857/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003892, Accuracy_2: 80.1% Loss_2: 0.002598  [11421/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002446, Accuracy_2: 82.3% Loss_2: 0.002263  [11985/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.003136, Accuracy_2: 82.3% Loss_2: 0.001361  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001706, Accuracy_2: 85.1% Loss_2: 0.001069  [13113/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001921, Accuracy_2: 83.7% Loss_2: 0.001886  [13677/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003061, Accuracy_2: 79.4% Loss_2: 0.003693  [14241/15250]\n",
      "Accuracy_1: 73.0%, Loss_1: 0.005087, Accuracy_2: 74.5% Loss_2: 0.004484  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 80.2%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 80.7%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001947, Accuracy_2: 83.0% Loss_2: 0.002719  [  141/15250]\n",
      "Accuracy_1: 74.5%, Loss_1: 0.004647, Accuracy_2: 79.4% Loss_2: 0.004299  [  705/15250]\n",
      "Accuracy_1: 75.2%, Loss_1: 0.002580, Accuracy_2: 78.7% Loss_2: 0.002551  [ 1269/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001564, Accuracy_2: 80.9% Loss_2: 0.001300  [ 1833/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.003300, Accuracy_2: 80.1% Loss_2: 0.002015  [ 2397/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003226, Accuracy_2: 76.6% Loss_2: 0.003087  [ 2961/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002203, Accuracy_2: 78.7% Loss_2: 0.002148  [ 3525/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.003817, Accuracy_2: 70.9% Loss_2: 0.004578  [ 4089/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002682, Accuracy_2: 78.0% Loss_2: 0.003702  [ 4653/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001374, Accuracy_2: 79.4% Loss_2: 0.001768  [ 5217/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002817, Accuracy_2: 79.4% Loss_2: 0.002477  [ 5781/15250]\n",
      "Accuracy_1: 73.0%, Loss_1: 0.003301, Accuracy_2: 75.9% Loss_2: 0.003021  [ 6345/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003630, Accuracy_2: 78.7% Loss_2: 0.003496  [ 6909/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002057, Accuracy_2: 81.6% Loss_2: 0.002313  [ 7473/15250]\n",
      "Accuracy_1: 74.5%, Loss_1: 0.002935, Accuracy_2: 76.6% Loss_2: 0.002438  [ 8037/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.001953, Accuracy_2: 83.0% Loss_2: 0.001728  [ 8601/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.006575, Accuracy_2: 78.0% Loss_2: 0.003202  [ 9165/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002158, Accuracy_2: 78.7% Loss_2: 0.003953  [ 9729/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001639, Accuracy_2: 83.0% Loss_2: 0.003090  [10293/15250]\n",
      "Accuracy_1: 70.9%, Loss_1: 0.003641, Accuracy_2: 74.5% Loss_2: 0.003262  [10857/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003343, Accuracy_2: 74.5% Loss_2: 0.004371  [11421/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001567, Accuracy_2: 80.1% Loss_2: 0.003747  [11985/15250]\n",
      "Accuracy_1: 71.6%, Loss_1: 0.004317, Accuracy_2: 75.9% Loss_2: 0.001774  [12549/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002927, Accuracy_2: 76.6% Loss_2: 0.003194  [13113/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002929, Accuracy_2: 84.4% Loss_2: 0.002625  [13677/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001744, Accuracy_2: 81.6% Loss_2: 0.002777  [14241/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.003145, Accuracy_2: 82.3% Loss_2: 0.000601  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 80.3%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 80.8%, Avg loss: 0.000000 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Accuracy_1: 79.4%, Loss_1: 0.001956, Accuracy_2: 84.4% Loss_2: 0.002213  [  141/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001163, Accuracy_2: 79.4% Loss_2: 0.003252  [  705/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.003045, Accuracy_2: 80.1% Loss_2: 0.003676  [ 1269/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.004618, Accuracy_2: 78.0% Loss_2: 0.002578  [ 1833/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002773, Accuracy_2: 80.9% Loss_2: 0.003327  [ 2397/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002115, Accuracy_2: 83.7% Loss_2: 0.001566  [ 2961/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001623, Accuracy_2: 83.7% Loss_2: 0.002094  [ 3525/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001344, Accuracy_2: 83.7% Loss_2: 0.001730  [ 4089/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001883, Accuracy_2: 83.0% Loss_2: 0.003191  [ 4653/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001781, Accuracy_2: 83.0% Loss_2: 0.002234  [ 5217/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001140, Accuracy_2: 80.9% Loss_2: 0.002288  [ 5781/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.003235, Accuracy_2: 81.6% Loss_2: 0.001088  [ 6345/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002121, Accuracy_2: 79.4% Loss_2: 0.001645  [ 6909/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003381, Accuracy_2: 83.7% Loss_2: 0.001520  [ 7473/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001852, Accuracy_2: 84.4% Loss_2: 0.003706  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001379, Accuracy_2: 85.1% Loss_2: 0.001660  [ 8601/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001557, Accuracy_2: 88.7% Loss_2: 0.000800  [ 9165/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.003128, Accuracy_2: 80.9% Loss_2: 0.001041  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001450, Accuracy_2: 82.3% Loss_2: 0.004384  [10293/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.003617, Accuracy_2: 76.6% Loss_2: 0.004229  [10857/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001300, Accuracy_2: 83.0% Loss_2: 0.002324  [11421/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.005650, Accuracy_2: 78.7% Loss_2: 0.002319  [11985/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001392, Accuracy_2: 83.0% Loss_2: 0.001419  [12549/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.003789, Accuracy_2: 83.7% Loss_2: 0.001211  [13113/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001211, Accuracy_2: 80.9% Loss_2: 0.002285  [13677/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002458, Accuracy_2: 86.5% Loss_2: 0.001135  [14241/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002914, Accuracy_2: 85.1% Loss_2: 0.003205  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 80.5%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 80.0%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003118, Accuracy_2: 80.1% Loss_2: 0.003549  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001625, Accuracy_2: 87.2% Loss_2: 0.001036  [  705/15250]\n",
      "Accuracy_1: 75.2%, Loss_1: 0.003246, Accuracy_2: 75.2% Loss_2: 0.002107  [ 1269/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.003035, Accuracy_2: 81.6% Loss_2: 0.001086  [ 1833/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.003651, Accuracy_2: 75.2% Loss_2: 0.002972  [ 2397/15250]\n",
      "Accuracy_1: 75.2%, Loss_1: 0.002772, Accuracy_2: 79.4% Loss_2: 0.002970  [ 2961/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002392, Accuracy_2: 82.3% Loss_2: 0.001130  [ 3525/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001718, Accuracy_2: 82.3% Loss_2: 0.002270  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000363, Accuracy_2: 83.7% Loss_2: 0.000925  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002837, Accuracy_2: 83.7% Loss_2: 0.001303  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001362, Accuracy_2: 85.8% Loss_2: 0.001597  [ 5781/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001954, Accuracy_2: 80.9% Loss_2: 0.002889  [ 6345/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001760, Accuracy_2: 85.1% Loss_2: 0.001675  [ 6909/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001169, Accuracy_2: 82.3% Loss_2: 0.000978  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000906, Accuracy_2: 78.7% Loss_2: 0.002012  [ 8037/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003390, Accuracy_2: 83.0% Loss_2: 0.001717  [ 8601/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002140, Accuracy_2: 82.3% Loss_2: 0.002061  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001133, Accuracy_2: 85.1% Loss_2: 0.001480  [ 9729/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.005331, Accuracy_2: 75.2% Loss_2: 0.003552  [10293/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.002265, Accuracy_2: 78.7% Loss_2: 0.002287  [10857/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003394, Accuracy_2: 84.4% Loss_2: 0.000928  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000896, Accuracy_2: 86.5% Loss_2: 0.000878  [11985/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001253, Accuracy_2: 81.6% Loss_2: 0.001558  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001208, Accuracy_2: 85.1% Loss_2: 0.000711  [13113/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001028, Accuracy_2: 80.9% Loss_2: 0.003985  [13677/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001351, Accuracy_2: 81.6% Loss_2: 0.002264  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001419, Accuracy_2: 83.7% Loss_2: 0.001936  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.0%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.2%, Avg loss: 0.000000 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000846, Accuracy_2: 81.6% Loss_2: 0.001145  [  141/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002439, Accuracy_2: 73.8% Loss_2: 0.002943  [  705/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002394, Accuracy_2: 81.6% Loss_2: 0.002469  [ 1269/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.000972, Accuracy_2: 79.4% Loss_2: 0.001042  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000699, Accuracy_2: 90.1% Loss_2: 0.000861  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000652, Accuracy_2: 83.0% Loss_2: 0.001747  [ 2961/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001995, Accuracy_2: 87.2% Loss_2: 0.001446  [ 3525/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003316, Accuracy_2: 84.4% Loss_2: 0.004036  [ 4089/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002840, Accuracy_2: 78.7% Loss_2: 0.002075  [ 4653/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.000969, Accuracy_2: 83.0% Loss_2: 0.001670  [ 5217/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002966, Accuracy_2: 83.7% Loss_2: 0.001651  [ 5781/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002188, Accuracy_2: 81.6% Loss_2: 0.002228  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000465, Accuracy_2: 89.4% Loss_2: 0.002421  [ 6909/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002097, Accuracy_2: 80.9% Loss_2: 0.001535  [ 7473/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.001912, Accuracy_2: 78.7% Loss_2: 0.002928  [ 8037/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002205, Accuracy_2: 80.9% Loss_2: 0.004048  [ 8601/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001163, Accuracy_2: 82.3% Loss_2: 0.001833  [ 9165/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001858, Accuracy_2: 83.7% Loss_2: 0.002052  [ 9729/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.004484, Accuracy_2: 85.8% Loss_2: 0.001018  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001200, Accuracy_2: 84.4% Loss_2: 0.002229  [10857/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002453, Accuracy_2: 83.7% Loss_2: 0.003421  [11421/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001591, Accuracy_2: 81.6% Loss_2: 0.002384  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001613, Accuracy_2: 84.4% Loss_2: 0.003073  [12549/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001971, Accuracy_2: 79.4% Loss_2: 0.002494  [13113/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002279, Accuracy_2: 73.8% Loss_2: 0.005145  [13677/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.000905, Accuracy_2: 80.9% Loss_2: 0.001239  [14241/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001486, Accuracy_2: 81.6% Loss_2: 0.001114  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 80.5%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.5%, Avg loss: 0.000000 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001498, Accuracy_2: 84.4% Loss_2: 0.001996  [  141/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.002693, Accuracy_2: 79.4% Loss_2: 0.002472  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000547, Accuracy_2: 79.4% Loss_2: 0.003984  [ 1269/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.001333, Accuracy_2: 79.4% Loss_2: 0.002958  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002976, Accuracy_2: 87.9% Loss_2: 0.002027  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002539, Accuracy_2: 86.5% Loss_2: 0.001567  [ 2961/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001956, Accuracy_2: 83.0% Loss_2: 0.001790  [ 3525/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001055, Accuracy_2: 80.1% Loss_2: 0.001462  [ 4089/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001606, Accuracy_2: 82.3% Loss_2: 0.003138  [ 4653/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002555, Accuracy_2: 82.3% Loss_2: 0.002387  [ 5217/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.000790, Accuracy_2: 81.6% Loss_2: 0.001834  [ 5781/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001408, Accuracy_2: 85.1% Loss_2: 0.001706  [ 6345/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002498, Accuracy_2: 83.0% Loss_2: 0.001372  [ 6909/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002266, Accuracy_2: 84.4% Loss_2: 0.000676  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001699, Accuracy_2: 85.8% Loss_2: 0.002189  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000407, Accuracy_2: 90.1% Loss_2: 0.000485  [ 8601/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.004034, Accuracy_2: 76.6% Loss_2: 0.002586  [ 9165/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001950, Accuracy_2: 80.9% Loss_2: 0.001630  [ 9729/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.003472, Accuracy_2: 85.8% Loss_2: 0.000602  [10293/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.000772, Accuracy_2: 82.3% Loss_2: 0.002028  [10857/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001400, Accuracy_2: 79.4% Loss_2: 0.001580  [11421/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.001907, Accuracy_2: 79.4% Loss_2: 0.002547  [11985/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002386, Accuracy_2: 82.3% Loss_2: 0.000973  [12549/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003730, Accuracy_2: 83.7% Loss_2: 0.001823  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000723, Accuracy_2: 85.1% Loss_2: 0.001941  [13677/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001205, Accuracy_2: 78.0% Loss_2: 0.001883  [14241/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001069, Accuracy_2: 82.3% Loss_2: 0.002658  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.0%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 80.7%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001015, Accuracy_2: 87.9% Loss_2: 0.000507  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000994, Accuracy_2: 85.8% Loss_2: 0.002555  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001263, Accuracy_2: 83.7% Loss_2: 0.004048  [ 1269/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000486, Accuracy_2: 80.9% Loss_2: 0.002734  [ 1833/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002448, Accuracy_2: 78.7% Loss_2: 0.001891  [ 2397/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002974, Accuracy_2: 78.0% Loss_2: 0.002015  [ 2961/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001190, Accuracy_2: 80.1% Loss_2: 0.001292  [ 3525/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001736, Accuracy_2: 85.1% Loss_2: 0.000803  [ 4089/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002344, Accuracy_2: 74.5% Loss_2: 0.003823  [ 4653/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.003190, Accuracy_2: 84.4% Loss_2: 0.001352  [ 5217/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000551, Accuracy_2: 85.8% Loss_2: 0.001654  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001580, Accuracy_2: 84.4% Loss_2: 0.001549  [ 6345/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002019, Accuracy_2: 78.7% Loss_2: 0.003423  [ 6909/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.001553, Accuracy_2: 79.4% Loss_2: 0.002487  [ 7473/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001580, Accuracy_2: 84.4% Loss_2: 0.001207  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001096, Accuracy_2: 77.3% Loss_2: 0.003146  [ 8601/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001383, Accuracy_2: 79.4% Loss_2: 0.002325  [ 9165/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000770, Accuracy_2: 83.0% Loss_2: 0.001685  [ 9729/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002629, Accuracy_2: 78.0% Loss_2: 0.002937  [10293/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.003795, Accuracy_2: 84.4% Loss_2: 0.001553  [10857/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002539, Accuracy_2: 80.9% Loss_2: 0.002529  [11421/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.002370, Accuracy_2: 78.0% Loss_2: 0.001548  [11985/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002463, Accuracy_2: 83.0% Loss_2: 0.002351  [12549/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001623, Accuracy_2: 82.3% Loss_2: 0.002777  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001949, Accuracy_2: 85.1% Loss_2: 0.000935  [13677/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001773, Accuracy_2: 80.1% Loss_2: 0.003228  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001664, Accuracy_2: 86.5% Loss_2: 0.002339  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.7%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.8%, Avg loss: 0.000000 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Accuracy_1: 78.0%, Loss_1: 0.003738, Accuracy_2: 83.7% Loss_2: 0.000522  [  141/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002196, Accuracy_2: 78.0% Loss_2: 0.004908  [  705/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002346, Accuracy_2: 80.9% Loss_2: 0.002250  [ 1269/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002637, Accuracy_2: 86.5% Loss_2: 0.001353  [ 1833/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002554, Accuracy_2: 86.5% Loss_2: 0.002520  [ 2397/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002933, Accuracy_2: 82.3% Loss_2: 0.000910  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001220, Accuracy_2: 85.8% Loss_2: 0.002331  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000633, Accuracy_2: 85.1% Loss_2: 0.000602  [ 4089/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001512, Accuracy_2: 82.3% Loss_2: 0.000367  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000979, Accuracy_2: 87.9% Loss_2: 0.001208  [ 5217/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002648, Accuracy_2: 78.7% Loss_2: 0.003179  [ 5781/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000864, Accuracy_2: 87.2% Loss_2: 0.002195  [ 6345/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001752, Accuracy_2: 79.4% Loss_2: 0.001033  [ 6909/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001028, Accuracy_2: 84.4% Loss_2: 0.001029  [ 7473/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003141, Accuracy_2: 86.5% Loss_2: 0.001072  [ 8037/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001535, Accuracy_2: 82.3% Loss_2: 0.001318  [ 8601/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003255, Accuracy_2: 87.9% Loss_2: 0.000192  [ 9165/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001511, Accuracy_2: 83.7% Loss_2: 0.000990  [ 9729/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001806, Accuracy_2: 75.9% Loss_2: 0.003723  [10293/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001530, Accuracy_2: 85.1% Loss_2: 0.000714  [10857/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000701, Accuracy_2: 83.0% Loss_2: 0.000510  [11421/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.000791, Accuracy_2: 80.1% Loss_2: 0.000708  [11985/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001609, Accuracy_2: 82.3% Loss_2: 0.001127  [12549/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000630, Accuracy_2: 81.6% Loss_2: 0.001379  [13113/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000636, Accuracy_2: 83.0% Loss_2: 0.001038  [13677/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001875, Accuracy_2: 83.7% Loss_2: 0.001624  [14241/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.000867, Accuracy_2: 80.1% Loss_2: 0.002344  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 80.9%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000000 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001174, Accuracy_2: 84.4% Loss_2: 0.002587  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001125, Accuracy_2: 83.7% Loss_2: 0.001900  [  705/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001198, Accuracy_2: 85.1% Loss_2: 0.002688  [ 1269/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001456, Accuracy_2: 84.4% Loss_2: 0.001207  [ 1833/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.003493, Accuracy_2: 76.6% Loss_2: 0.002371  [ 2397/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002125, Accuracy_2: 82.3% Loss_2: 0.002740  [ 2961/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.002862, Accuracy_2: 81.6% Loss_2: 0.001431  [ 3525/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000418, Accuracy_2: 84.4% Loss_2: 0.000806  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000424, Accuracy_2: 88.7% Loss_2: 0.001256  [ 4653/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.003117, Accuracy_2: 73.8% Loss_2: 0.004462  [ 5217/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001610, Accuracy_2: 76.6% Loss_2: 0.002631  [ 5781/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002205, Accuracy_2: 87.2% Loss_2: 0.001084  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000816, Accuracy_2: 86.5% Loss_2: 0.001433  [ 6909/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001844, Accuracy_2: 80.1% Loss_2: 0.001257  [ 7473/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001191, Accuracy_2: 83.7% Loss_2: 0.003051  [ 8037/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.003685, Accuracy_2: 80.1% Loss_2: 0.002450  [ 8601/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002869, Accuracy_2: 81.6% Loss_2: 0.002186  [ 9165/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002683, Accuracy_2: 79.4% Loss_2: 0.002703  [ 9729/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.003425, Accuracy_2: 88.7% Loss_2: 0.001260  [10293/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.004697, Accuracy_2: 81.6% Loss_2: 0.001832  [10857/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002459, Accuracy_2: 78.7% Loss_2: 0.002471  [11421/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002631, Accuracy_2: 83.7% Loss_2: 0.001864  [11985/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002795, Accuracy_2: 83.7% Loss_2: 0.001647  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001375, Accuracy_2: 87.9% Loss_2: 0.001211  [13113/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.002335, Accuracy_2: 77.3% Loss_2: 0.002236  [13677/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.004404, Accuracy_2: 85.1% Loss_2: 0.002967  [14241/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.004272, Accuracy_2: 85.1% Loss_2: 0.001298  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.0%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000000 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001239, Accuracy_2: 85.8% Loss_2: 0.002932  [  141/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.001433, Accuracy_2: 81.6% Loss_2: 0.001919  [  705/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.003124, Accuracy_2: 81.6% Loss_2: 0.001590  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001265, Accuracy_2: 80.9% Loss_2: 0.003801  [ 1833/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001979, Accuracy_2: 83.0% Loss_2: 0.002080  [ 2397/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003529, Accuracy_2: 85.8% Loss_2: 0.001101  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000728, Accuracy_2: 85.8% Loss_2: 0.000623  [ 3525/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002052, Accuracy_2: 83.7% Loss_2: 0.001715  [ 4089/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001707, Accuracy_2: 80.1% Loss_2: 0.001635  [ 4653/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001388, Accuracy_2: 80.1% Loss_2: 0.002162  [ 5217/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001719, Accuracy_2: 82.3% Loss_2: 0.001467  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001764, Accuracy_2: 85.1% Loss_2: 0.002382  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000155, Accuracy_2: 85.8% Loss_2: 0.001100  [ 6909/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001318, Accuracy_2: 78.7% Loss_2: 0.004611  [ 7473/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002839, Accuracy_2: 87.9% Loss_2: 0.002764  [ 8037/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000582, Accuracy_2: 81.6% Loss_2: 0.001630  [ 8601/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003300, Accuracy_2: 84.4% Loss_2: 0.001112  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001277, Accuracy_2: 83.0% Loss_2: 0.002251  [ 9729/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.003067, Accuracy_2: 82.3% Loss_2: 0.001447  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000958, Accuracy_2: 87.9% Loss_2: 0.001714  [10857/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.004653, Accuracy_2: 81.6% Loss_2: 0.001873  [11421/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002840, Accuracy_2: 75.2% Loss_2: 0.002300  [11985/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001711, Accuracy_2: 82.3% Loss_2: 0.001827  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001781, Accuracy_2: 88.7% Loss_2: 0.000900  [13113/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002007, Accuracy_2: 83.7% Loss_2: 0.001278  [13677/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002546, Accuracy_2: 78.7% Loss_2: 0.002855  [14241/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001784, Accuracy_2: 83.7% Loss_2: 0.003006  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 80.7%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001720, Accuracy_2: 87.9% Loss_2: 0.001334  [  141/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002880, Accuracy_2: 86.5% Loss_2: 0.001684  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000880, Accuracy_2: 82.3% Loss_2: 0.002386  [ 1269/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002421, Accuracy_2: 82.3% Loss_2: 0.003654  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001236, Accuracy_2: 84.4% Loss_2: 0.001143  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000618, Accuracy_2: 80.1% Loss_2: 0.003737  [ 2961/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002317, Accuracy_2: 79.4% Loss_2: 0.002193  [ 3525/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000802, Accuracy_2: 85.8% Loss_2: 0.001197  [ 4089/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001806, Accuracy_2: 83.0% Loss_2: 0.002411  [ 4653/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.000935, Accuracy_2: 80.1% Loss_2: 0.001400  [ 5217/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000762, Accuracy_2: 84.4% Loss_2: 0.001367  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000936, Accuracy_2: 83.0% Loss_2: 0.002231  [ 6345/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001946, Accuracy_2: 83.7% Loss_2: 0.002350  [ 6909/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002615, Accuracy_2: 81.6% Loss_2: 0.002147  [ 7473/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002157, Accuracy_2: 87.9% Loss_2: 0.001405  [ 8037/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002559, Accuracy_2: 84.4% Loss_2: 0.001740  [ 8601/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002971, Accuracy_2: 78.0% Loss_2: 0.004479  [ 9165/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001846, Accuracy_2: 83.7% Loss_2: 0.001232  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001656, Accuracy_2: 86.5% Loss_2: 0.000813  [10293/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002225, Accuracy_2: 83.0% Loss_2: 0.002344  [10857/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.003770, Accuracy_2: 75.9% Loss_2: 0.002987  [11421/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001020, Accuracy_2: 83.7% Loss_2: 0.001537  [11985/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002880, Accuracy_2: 84.4% Loss_2: 0.001600  [12549/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001614, Accuracy_2: 85.8% Loss_2: 0.000739  [13113/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002237, Accuracy_2: 80.9% Loss_2: 0.000673  [13677/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002321, Accuracy_2: 85.1% Loss_2: 0.000669  [14241/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002373, Accuracy_2: 84.4% Loss_2: 0.001742  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.1%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000000 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000472, Accuracy_2: 83.7% Loss_2: 0.000826  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001114, Accuracy_2: 84.4% Loss_2: 0.000944  [  705/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002341, Accuracy_2: 87.9% Loss_2: 0.002036  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001977, Accuracy_2: 84.4% Loss_2: 0.001657  [ 1833/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.002488, Accuracy_2: 79.4% Loss_2: 0.002080  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001608, Accuracy_2: 82.3% Loss_2: 0.002900  [ 2961/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002600, Accuracy_2: 85.8% Loss_2: 0.000289  [ 3525/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000228, Accuracy_2: 82.3% Loss_2: 0.000761  [ 4089/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001183, Accuracy_2: 85.8% Loss_2: 0.000528  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000675, Accuracy_2: 89.4% Loss_2: 0.000940  [ 5217/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001431, Accuracy_2: 84.4% Loss_2: 0.001448  [ 5781/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000736, Accuracy_2: 82.3% Loss_2: 0.002737  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000663, Accuracy_2: 85.1% Loss_2: 0.000920  [ 6909/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003070, Accuracy_2: 85.8% Loss_2: 0.001146  [ 7473/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.003009, Accuracy_2: 77.3% Loss_2: 0.003704  [ 8037/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001589, Accuracy_2: 81.6% Loss_2: 0.002133  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001847, Accuracy_2: 88.7% Loss_2: 0.000266  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001132, Accuracy_2: 85.1% Loss_2: 0.002780  [ 9729/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.003548, Accuracy_2: 81.6% Loss_2: 0.002007  [10293/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001261, Accuracy_2: 84.4% Loss_2: 0.000761  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001905, Accuracy_2: 84.4% Loss_2: 0.002309  [11421/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001945, Accuracy_2: 83.7% Loss_2: 0.002838  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000420, Accuracy_2: 85.8% Loss_2: 0.001702  [12549/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002632, Accuracy_2: 85.8% Loss_2: 0.000734  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002692, Accuracy_2: 83.7% Loss_2: 0.001756  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001518, Accuracy_2: 85.8% Loss_2: 0.001467  [14241/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.004811, Accuracy_2: 85.1% Loss_2: 0.002727  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.0%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002855, Accuracy_2: 85.8% Loss_2: 0.001384  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000132, Accuracy_2: 84.4% Loss_2: 0.000914  [  705/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.001932, Accuracy_2: 77.3% Loss_2: 0.004626  [ 1269/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000952, Accuracy_2: 84.4% Loss_2: 0.001343  [ 1833/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003257, Accuracy_2: 83.7% Loss_2: 0.001738  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001236, Accuracy_2: 83.0% Loss_2: 0.002874  [ 2961/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001434, Accuracy_2: 83.7% Loss_2: 0.001887  [ 3525/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003062, Accuracy_2: 81.6% Loss_2: 0.002359  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001182, Accuracy_2: 83.7% Loss_2: 0.001230  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000680, Accuracy_2: 87.2% Loss_2: 0.000485  [ 5217/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000837, Accuracy_2: 87.2% Loss_2: 0.000924  [ 5781/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001111, Accuracy_2: 87.2% Loss_2: 0.000865  [ 6345/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002680, Accuracy_2: 82.3% Loss_2: 0.003261  [ 6909/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001501, Accuracy_2: 85.8% Loss_2: 0.001765  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001538, Accuracy_2: 87.9% Loss_2: 0.000562  [ 8037/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001621, Accuracy_2: 81.6% Loss_2: 0.001125  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001860, Accuracy_2: 83.0% Loss_2: 0.001529  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000723, Accuracy_2: 85.8% Loss_2: 0.000886  [ 9729/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.001450, Accuracy_2: 75.9% Loss_2: 0.002116  [10293/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002124, Accuracy_2: 87.9% Loss_2: 0.001400  [10857/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002548, Accuracy_2: 76.6% Loss_2: 0.001958  [11421/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002280, Accuracy_2: 83.0% Loss_2: 0.005133  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000107, Accuracy_2: 83.7% Loss_2: 0.000460  [12549/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000529, Accuracy_2: 86.5% Loss_2: 0.001064  [13113/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001750, Accuracy_2: 87.2% Loss_2: 0.000858  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000788, Accuracy_2: 82.3% Loss_2: 0.001653  [14241/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001531, Accuracy_2: 81.6% Loss_2: 0.001165  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000898, Accuracy_2: 82.3% Loss_2: 0.000808  [  141/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002240, Accuracy_2: 78.7% Loss_2: 0.004027  [  705/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002261, Accuracy_2: 80.1% Loss_2: 0.001815  [ 1269/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002405, Accuracy_2: 79.4% Loss_2: 0.002458  [ 1833/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001748, Accuracy_2: 83.0% Loss_2: 0.002126  [ 2397/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002156, Accuracy_2: 80.1% Loss_2: 0.001930  [ 2961/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001906, Accuracy_2: 82.3% Loss_2: 0.002623  [ 3525/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002566, Accuracy_2: 80.9% Loss_2: 0.002655  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000618, Accuracy_2: 85.1% Loss_2: 0.000955  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000830, Accuracy_2: 84.4% Loss_2: 0.000525  [ 5217/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.002894, Accuracy_2: 78.7% Loss_2: 0.004100  [ 5781/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001951, Accuracy_2: 84.4% Loss_2: 0.001677  [ 6345/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.004328, Accuracy_2: 91.5% Loss_2: 0.000506  [ 6909/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.003869, Accuracy_2: 77.3% Loss_2: 0.004080  [ 7473/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002668, Accuracy_2: 80.9% Loss_2: 0.001495  [ 8037/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002194, Accuracy_2: 83.0% Loss_2: 0.000981  [ 8601/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.005151, Accuracy_2: 82.3% Loss_2: 0.002325  [ 9165/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.003161, Accuracy_2: 81.6% Loss_2: 0.002536  [ 9729/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.001073, Accuracy_2: 84.4% Loss_2: 0.000740  [10293/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001837, Accuracy_2: 83.0% Loss_2: 0.002898  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002220, Accuracy_2: 89.4% Loss_2: 0.001978  [11421/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002183, Accuracy_2: 86.5% Loss_2: 0.000679  [11985/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001114, Accuracy_2: 84.4% Loss_2: 0.001147  [12549/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.004173, Accuracy_2: 82.3% Loss_2: 0.002355  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003144, Accuracy_2: 85.1% Loss_2: 0.002274  [13677/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001019, Accuracy_2: 83.0% Loss_2: 0.001139  [14241/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001783, Accuracy_2: 82.3% Loss_2: 0.002070  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.4%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.8%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000750, Accuracy_2: 85.1% Loss_2: 0.000414  [  141/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001731, Accuracy_2: 82.3% Loss_2: 0.001755  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002289, Accuracy_2: 86.5% Loss_2: 0.002024  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000617, Accuracy_2: 83.0% Loss_2: 0.003663  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002184, Accuracy_2: 84.4% Loss_2: 0.002604  [ 2397/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002587, Accuracy_2: 78.0% Loss_2: 0.006027  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000661, Accuracy_2: 80.9% Loss_2: 0.003355  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002401, Accuracy_2: 86.5% Loss_2: 0.002435  [ 4089/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001446, Accuracy_2: 79.4% Loss_2: 0.003145  [ 4653/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001028, Accuracy_2: 82.3% Loss_2: 0.000694  [ 5217/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002661, Accuracy_2: 83.7% Loss_2: 0.001916  [ 5781/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002560, Accuracy_2: 78.0% Loss_2: 0.004045  [ 6345/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.003559, Accuracy_2: 82.3% Loss_2: 0.002989  [ 6909/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000523, Accuracy_2: 80.9% Loss_2: 0.001883  [ 7473/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003359, Accuracy_2: 80.1% Loss_2: 0.004145  [ 8037/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002715, Accuracy_2: 80.9% Loss_2: 0.002007  [ 8601/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002055, Accuracy_2: 80.9% Loss_2: 0.003213  [ 9165/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001570, Accuracy_2: 84.4% Loss_2: 0.002378  [ 9729/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001212, Accuracy_2: 82.3% Loss_2: 0.002669  [10293/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001930, Accuracy_2: 83.0% Loss_2: 0.002409  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001246, Accuracy_2: 88.7% Loss_2: 0.000940  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002258, Accuracy_2: 90.1% Loss_2: 0.000576  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000147, Accuracy_2: 83.7% Loss_2: 0.001172  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001010, Accuracy_2: 87.9% Loss_2: 0.000626  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000788, Accuracy_2: 86.5% Loss_2: 0.000946  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000518, Accuracy_2: 85.1% Loss_2: 0.000774  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001006, Accuracy_2: 83.7% Loss_2: 0.001316  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.0%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001075, Accuracy_2: 85.8% Loss_2: 0.001534  [  141/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.002017, Accuracy_2: 80.1% Loss_2: 0.001069  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000613, Accuracy_2: 81.6% Loss_2: 0.002314  [ 1269/15250]\n",
      "Accuracy_1: 73.0%, Loss_1: 0.004741, Accuracy_2: 75.9% Loss_2: 0.002226  [ 1833/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.001375, Accuracy_2: 80.1% Loss_2: 0.002694  [ 2397/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001860, Accuracy_2: 85.1% Loss_2: 0.001962  [ 2961/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002673, Accuracy_2: 76.6% Loss_2: 0.002681  [ 3525/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.004661, Accuracy_2: 81.6% Loss_2: 0.002642  [ 4089/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.004661, Accuracy_2: 85.1% Loss_2: 0.001053  [ 4653/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000385, Accuracy_2: 87.2% Loss_2: 0.000424  [ 5217/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003019, Accuracy_2: 86.5% Loss_2: 0.000224  [ 5781/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001988, Accuracy_2: 85.8% Loss_2: 0.003571  [ 6345/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001924, Accuracy_2: 88.7% Loss_2: 0.000200  [ 6909/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002154, Accuracy_2: 83.0% Loss_2: 0.002602  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000517, Accuracy_2: 85.1% Loss_2: 0.001940  [ 8037/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.003286, Accuracy_2: 80.1% Loss_2: 0.003469  [ 8601/15250]\n",
      "Accuracy_1: 77.3%, Loss_1: 0.003881, Accuracy_2: 75.2% Loss_2: 0.004419  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000847, Accuracy_2: 86.5% Loss_2: 0.003614  [ 9729/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002007, Accuracy_2: 82.3% Loss_2: 0.001456  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000959, Accuracy_2: 87.2% Loss_2: 0.001296  [10857/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001572, Accuracy_2: 78.0% Loss_2: 0.003517  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000774, Accuracy_2: 83.7% Loss_2: 0.001526  [11985/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001359, Accuracy_2: 85.1% Loss_2: 0.001355  [12549/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001920, Accuracy_2: 83.0% Loss_2: 0.001338  [13113/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002659, Accuracy_2: 81.6% Loss_2: 0.002603  [13677/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.001784, Accuracy_2: 84.4% Loss_2: 0.000905  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000452, Accuracy_2: 89.4% Loss_2: 0.000657  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.2%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Accuracy_1: 77.3%, Loss_1: 0.003909, Accuracy_2: 78.0% Loss_2: 0.002031  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001616, Accuracy_2: 87.9% Loss_2: 0.001576  [  705/15250]\n",
      "Accuracy_1: 75.9%, Loss_1: 0.003464, Accuracy_2: 83.7% Loss_2: 0.003424  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000762, Accuracy_2: 88.7% Loss_2: 0.001682  [ 1833/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002432, Accuracy_2: 83.0% Loss_2: 0.002291  [ 2397/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001070, Accuracy_2: 82.3% Loss_2: 0.003780  [ 2961/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.004013, Accuracy_2: 83.0% Loss_2: 0.002842  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001919, Accuracy_2: 87.2% Loss_2: 0.002111  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000549, Accuracy_2: 85.1% Loss_2: 0.001231  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002319, Accuracy_2: 87.2% Loss_2: 0.001861  [ 5217/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002176, Accuracy_2: 79.4% Loss_2: 0.003015  [ 5781/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.003194, Accuracy_2: 83.0% Loss_2: 0.000480  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001329, Accuracy_2: 85.1% Loss_2: 0.004899  [ 6909/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001800, Accuracy_2: 83.0% Loss_2: 0.001701  [ 7473/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.003180, Accuracy_2: 79.4% Loss_2: 0.003519  [ 8037/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.001338, Accuracy_2: 84.4% Loss_2: 0.000990  [ 8601/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002121, Accuracy_2: 81.6% Loss_2: 0.001590  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000802, Accuracy_2: 87.9% Loss_2: 0.000625  [ 9729/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001882, Accuracy_2: 81.6% Loss_2: 0.001511  [10293/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001355, Accuracy_2: 82.3% Loss_2: 0.001388  [10857/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002677, Accuracy_2: 78.7% Loss_2: 0.002992  [11421/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002015, Accuracy_2: 82.3% Loss_2: 0.002890  [11985/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001607, Accuracy_2: 83.7% Loss_2: 0.001766  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000479, Accuracy_2: 92.9% Loss_2: 0.000811  [13113/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.000475, Accuracy_2: 77.3% Loss_2: 0.002920  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001740, Accuracy_2: 83.7% Loss_2: 0.003022  [14241/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000483, Accuracy_2: 83.0% Loss_2: 0.001218  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 80.9%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001489, Accuracy_2: 84.4% Loss_2: 0.001611  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003826, Accuracy_2: 87.2% Loss_2: 0.001025  [  705/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001668, Accuracy_2: 80.1% Loss_2: 0.001603  [ 1269/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001301, Accuracy_2: 81.6% Loss_2: 0.002167  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000535, Accuracy_2: 87.9% Loss_2: 0.001559  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000607, Accuracy_2: 81.6% Loss_2: 0.001166  [ 2961/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002778, Accuracy_2: 80.9% Loss_2: 0.003948  [ 3525/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002348, Accuracy_2: 84.4% Loss_2: 0.001218  [ 4089/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000611, Accuracy_2: 85.1% Loss_2: 0.000404  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002797, Accuracy_2: 90.1% Loss_2: 0.001883  [ 5217/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002468, Accuracy_2: 90.8% Loss_2: 0.000974  [ 5781/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001967, Accuracy_2: 88.7% Loss_2: 0.000924  [ 6345/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001895, Accuracy_2: 85.8% Loss_2: 0.001295  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002148, Accuracy_2: 83.7% Loss_2: 0.002003  [ 7473/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.003102, Accuracy_2: 83.7% Loss_2: 0.000567  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000393, Accuracy_2: 87.2% Loss_2: 0.001693  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000176, Accuracy_2: 90.1% Loss_2: 0.001701  [ 9165/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000815, Accuracy_2: 85.1% Loss_2: 0.002184  [ 9729/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001010, Accuracy_2: 87.2% Loss_2: 0.000897  [10293/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001826, Accuracy_2: 85.1% Loss_2: 0.000760  [10857/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002002, Accuracy_2: 86.5% Loss_2: 0.001324  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000121, Accuracy_2: 85.8% Loss_2: 0.001127  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001061, Accuracy_2: 83.7% Loss_2: 0.003007  [12549/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.003817, Accuracy_2: 84.4% Loss_2: 0.001303  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000145, Accuracy_2: 85.1% Loss_2: 0.001371  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001456, Accuracy_2: 90.8% Loss_2: 0.000760  [14241/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001030, Accuracy_2: 83.0% Loss_2: 0.001712  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.5%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.0%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002113, Accuracy_2: 80.1% Loss_2: 0.002866  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001368, Accuracy_2: 87.9% Loss_2: 0.001965  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002374, Accuracy_2: 85.1% Loss_2: 0.002467  [ 1269/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002519, Accuracy_2: 86.5% Loss_2: 0.000232  [ 1833/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.004040, Accuracy_2: 79.4% Loss_2: 0.003010  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001229, Accuracy_2: 88.7% Loss_2: 0.001119  [ 2961/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001004, Accuracy_2: 85.1% Loss_2: 0.001309  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000697, Accuracy_2: 87.2% Loss_2: 0.001676  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000734, Accuracy_2: 86.5% Loss_2: 0.001545  [ 4653/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002001, Accuracy_2: 85.8% Loss_2: 0.000320  [ 5217/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001286, Accuracy_2: 85.8% Loss_2: 0.000786  [ 5781/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001428, Accuracy_2: 90.8% Loss_2: 0.000172  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002239, Accuracy_2: 89.4% Loss_2: 0.001208  [ 6909/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003296, Accuracy_2: 80.9% Loss_2: 0.002432  [ 7473/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001009, Accuracy_2: 88.7% Loss_2: 0.000680  [ 8037/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002340, Accuracy_2: 85.8% Loss_2: 0.000445  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000710, Accuracy_2: 85.1% Loss_2: 0.001865  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001689, Accuracy_2: 90.1% Loss_2: 0.001409  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002095, Accuracy_2: 85.8% Loss_2: 0.001909  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001658, Accuracy_2: 86.5% Loss_2: 0.001403  [10857/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002255, Accuracy_2: 85.1% Loss_2: 0.000965  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001199, Accuracy_2: 89.4% Loss_2: 0.000705  [11985/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002647, Accuracy_2: 84.4% Loss_2: 0.001764  [12549/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002665, Accuracy_2: 83.0% Loss_2: 0.001832  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000680, Accuracy_2: 90.8% Loss_2: 0.000797  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000187, Accuracy_2: 87.9% Loss_2: 0.000274  [14241/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.004787, Accuracy_2: 85.1% Loss_2: 0.000961  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.7%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.5%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Accuracy_1: 79.4%, Loss_1: 0.001588, Accuracy_2: 82.3% Loss_2: 0.001585  [  141/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001690, Accuracy_2: 86.5% Loss_2: 0.001694  [  705/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000300, Accuracy_2: 84.4% Loss_2: 0.001749  [ 1269/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002100, Accuracy_2: 87.9% Loss_2: 0.001228  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001974, Accuracy_2: 87.9% Loss_2: 0.001080  [ 2397/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002485, Accuracy_2: 83.0% Loss_2: 0.001875  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001685, Accuracy_2: 87.2% Loss_2: 0.000603  [ 3525/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.000713, Accuracy_2: 80.1% Loss_2: 0.002129  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000658, Accuracy_2: 87.9% Loss_2: 0.000921  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000250, Accuracy_2: 86.5% Loss_2: 0.001717  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001798, Accuracy_2: 83.0% Loss_2: 0.001055  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000986, Accuracy_2: 88.7% Loss_2: 0.000755  [ 6345/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001397, Accuracy_2: 78.0% Loss_2: 0.002602  [ 6909/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000595, Accuracy_2: 85.1% Loss_2: 0.000706  [ 7473/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001381, Accuracy_2: 83.7% Loss_2: 0.001828  [ 8037/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003441, Accuracy_2: 85.8% Loss_2: 0.001207  [ 8601/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000958, Accuracy_2: 83.7% Loss_2: 0.000939  [ 9165/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002046, Accuracy_2: 84.4% Loss_2: 0.003069  [ 9729/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001803, Accuracy_2: 82.3% Loss_2: 0.002749  [10293/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003312, Accuracy_2: 83.7% Loss_2: 0.003193  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000089, Accuracy_2: 87.9% Loss_2: 0.001365  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000465, Accuracy_2: 87.2% Loss_2: 0.003578  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000501, Accuracy_2: 86.5% Loss_2: 0.001404  [12549/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001492, Accuracy_2: 79.4% Loss_2: 0.001792  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002029, Accuracy_2: 87.2% Loss_2: 0.001636  [13677/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001557, Accuracy_2: 83.0% Loss_2: 0.004478  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000435, Accuracy_2: 83.7% Loss_2: 0.002429  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.0%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.4%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001914, Accuracy_2: 83.0% Loss_2: 0.002092  [  141/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003506, Accuracy_2: 85.8% Loss_2: 0.001729  [  705/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001765, Accuracy_2: 85.8% Loss_2: 0.001430  [ 1269/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000977, Accuracy_2: 83.0% Loss_2: 0.002663  [ 1833/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002170, Accuracy_2: 82.3% Loss_2: 0.002701  [ 2397/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001918, Accuracy_2: 87.9% Loss_2: 0.001064  [ 2961/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.003959, Accuracy_2: 81.6% Loss_2: 0.002674  [ 3525/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001279, Accuracy_2: 86.5% Loss_2: 0.001162  [ 4089/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.004284, Accuracy_2: 77.3% Loss_2: 0.003445  [ 4653/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000933, Accuracy_2: 85.1% Loss_2: 0.000909  [ 5217/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001909, Accuracy_2: 82.3% Loss_2: 0.001058  [ 5781/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.004718, Accuracy_2: 78.7% Loss_2: 0.004739  [ 6345/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001329, Accuracy_2: 84.4% Loss_2: 0.000481  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001305, Accuracy_2: 93.6% Loss_2: 0.000170  [ 7473/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002160, Accuracy_2: 83.7% Loss_2: 0.001501  [ 8037/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002811, Accuracy_2: 83.0% Loss_2: 0.001635  [ 8601/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002477, Accuracy_2: 86.5% Loss_2: 0.000442  [ 9165/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001658, Accuracy_2: 83.7% Loss_2: 0.000927  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000859, Accuracy_2: 88.7% Loss_2: 0.000988  [10293/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002452, Accuracy_2: 79.4% Loss_2: 0.002208  [10857/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001689, Accuracy_2: 82.3% Loss_2: 0.000676  [11421/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001213, Accuracy_2: 83.7% Loss_2: 0.001574  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000807, Accuracy_2: 89.4% Loss_2: 0.000516  [12549/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000300, Accuracy_2: 84.4% Loss_2: 0.001041  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001160, Accuracy_2: 90.8% Loss_2: 0.000265  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000255, Accuracy_2: 87.9% Loss_2: 0.000179  [14241/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002129, Accuracy_2: 83.0% Loss_2: 0.001663  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.5%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000000 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000692, Accuracy_2: 85.1% Loss_2: 0.000897  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001286, Accuracy_2: 89.4% Loss_2: 0.001763  [  705/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002305, Accuracy_2: 83.7% Loss_2: 0.002955  [ 1269/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002130, Accuracy_2: 84.4% Loss_2: 0.001457  [ 1833/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000428, Accuracy_2: 83.7% Loss_2: 0.001311  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003602, Accuracy_2: 86.5% Loss_2: 0.000156  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000617, Accuracy_2: 85.1% Loss_2: 0.000437  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000459, Accuracy_2: 85.8% Loss_2: 0.001233  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002227, Accuracy_2: 87.9% Loss_2: 0.001806  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000036, Accuracy_2: 90.1% Loss_2: 0.000688  [ 5217/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000759, Accuracy_2: 77.3% Loss_2: 0.003598  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000636, Accuracy_2: 86.5% Loss_2: 0.000785  [ 6345/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000875, Accuracy_2: 83.7% Loss_2: 0.001264  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001303, Accuracy_2: 89.4% Loss_2: 0.000775  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002249, Accuracy_2: 87.9% Loss_2: 0.001658  [ 8037/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.003070, Accuracy_2: 76.6% Loss_2: 0.003090  [ 8601/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.002477, Accuracy_2: 77.3% Loss_2: 0.002053  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001266, Accuracy_2: 87.9% Loss_2: 0.001678  [ 9729/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001072, Accuracy_2: 82.3% Loss_2: 0.003627  [10293/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000697, Accuracy_2: 83.0% Loss_2: 0.001210  [10857/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003156, Accuracy_2: 84.4% Loss_2: 0.002669  [11421/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002873, Accuracy_2: 87.2% Loss_2: 0.001592  [11985/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001508, Accuracy_2: 82.3% Loss_2: 0.001160  [12549/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002696, Accuracy_2: 84.4% Loss_2: 0.001594  [13113/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001850, Accuracy_2: 88.7% Loss_2: 0.000149  [13677/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002193, Accuracy_2: 80.1% Loss_2: 0.002173  [14241/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.004635, Accuracy_2: 85.8% Loss_2: 0.001382  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 80.8%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.7%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001018, Accuracy_2: 89.4% Loss_2: 0.001000  [  141/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002247, Accuracy_2: 83.7% Loss_2: 0.000631  [  705/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000358, Accuracy_2: 85.1% Loss_2: 0.000594  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001703, Accuracy_2: 87.9% Loss_2: 0.002961  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000503, Accuracy_2: 84.4% Loss_2: 0.001069  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002598, Accuracy_2: 88.7% Loss_2: 0.000307  [ 2961/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001220, Accuracy_2: 86.5% Loss_2: 0.001144  [ 3525/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001307, Accuracy_2: 84.4% Loss_2: 0.000603  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000755, Accuracy_2: 83.7% Loss_2: 0.001535  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000573, Accuracy_2: 87.2% Loss_2: 0.000745  [ 5217/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002655, Accuracy_2: 80.1% Loss_2: 0.003312  [ 5781/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001854, Accuracy_2: 85.1% Loss_2: 0.001231  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001459, Accuracy_2: 83.0% Loss_2: 0.002477  [ 6909/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.000710, Accuracy_2: 80.1% Loss_2: 0.000994  [ 7473/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001038, Accuracy_2: 84.4% Loss_2: 0.002047  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001167, Accuracy_2: 89.4% Loss_2: 0.000251  [ 8601/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002091, Accuracy_2: 79.4% Loss_2: 0.003744  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000383, Accuracy_2: 87.9% Loss_2: 0.002328  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000674, Accuracy_2: 85.8% Loss_2: 0.001027  [10293/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001842, Accuracy_2: 89.4% Loss_2: 0.002156  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001537, Accuracy_2: 89.4% Loss_2: 0.002515  [11421/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.000953, Accuracy_2: 77.3% Loss_2: 0.002558  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001865, Accuracy_2: 85.8% Loss_2: 0.002441  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000481, Accuracy_2: 86.5% Loss_2: 0.001547  [13113/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001327, Accuracy_2: 85.1% Loss_2: 0.001324  [13677/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001028, Accuracy_2: 81.6% Loss_2: 0.003010  [14241/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.002351, Accuracy_2: 79.4% Loss_2: 0.005184  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.6%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000233, Accuracy_2: 81.6% Loss_2: 0.001785  [  141/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.000802, Accuracy_2: 80.9% Loss_2: 0.000689  [  705/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002116, Accuracy_2: 87.9% Loss_2: 0.000356  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000996, Accuracy_2: 90.1% Loss_2: 0.000203  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000804, Accuracy_2: 90.8% Loss_2: 0.001049  [ 2397/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001126, Accuracy_2: 83.0% Loss_2: 0.001123  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001134, Accuracy_2: 89.4% Loss_2: 0.001483  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000554, Accuracy_2: 86.5% Loss_2: 0.001423  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000764, Accuracy_2: 85.8% Loss_2: 0.001146  [ 4653/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001887, Accuracy_2: 80.1% Loss_2: 0.001561  [ 5217/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001307, Accuracy_2: 82.3% Loss_2: 0.000921  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000843, Accuracy_2: 92.2% Loss_2: 0.000098  [ 6345/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000951, Accuracy_2: 85.8% Loss_2: 0.000791  [ 6909/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002146, Accuracy_2: 83.7% Loss_2: 0.002804  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000288, Accuracy_2: 81.6% Loss_2: 0.004542  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001734, Accuracy_2: 90.1% Loss_2: 0.001940  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000574, Accuracy_2: 83.7% Loss_2: 0.002489  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000418, Accuracy_2: 84.4% Loss_2: 0.000270  [ 9729/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001156, Accuracy_2: 85.1% Loss_2: 0.000849  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000609, Accuracy_2: 85.8% Loss_2: 0.001339  [10857/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000332, Accuracy_2: 84.4% Loss_2: 0.000511  [11421/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000842, Accuracy_2: 81.6% Loss_2: 0.002732  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002048, Accuracy_2: 86.5% Loss_2: 0.003053  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001123, Accuracy_2: 88.7% Loss_2: 0.003621  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000241, Accuracy_2: 87.2% Loss_2: 0.000319  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001376, Accuracy_2: 85.8% Loss_2: 0.003153  [14241/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.004238, Accuracy_2: 82.3% Loss_2: 0.001746  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.1%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.2%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000510, Accuracy_2: 82.3% Loss_2: 0.003760  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001352, Accuracy_2: 87.2% Loss_2: 0.002082  [  705/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001740, Accuracy_2: 84.4% Loss_2: 0.000850  [ 1269/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002009, Accuracy_2: 83.0% Loss_2: 0.002306  [ 1833/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000488, Accuracy_2: 83.7% Loss_2: 0.000884  [ 2397/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002536, Accuracy_2: 84.4% Loss_2: 0.001525  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000267, Accuracy_2: 87.9% Loss_2: 0.001891  [ 3525/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.000975, Accuracy_2: 81.6% Loss_2: 0.002332  [ 4089/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000994, Accuracy_2: 83.7% Loss_2: 0.001614  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000077, Accuracy_2: 85.8% Loss_2: 0.001155  [ 5217/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001150, Accuracy_2: 81.6% Loss_2: 0.003078  [ 5781/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001065, Accuracy_2: 86.5% Loss_2: 0.002367  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000621, Accuracy_2: 87.2% Loss_2: 0.001312  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002137, Accuracy_2: 83.0% Loss_2: 0.003503  [ 7473/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.000415, Accuracy_2: 80.9% Loss_2: 0.001424  [ 8037/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.000917, Accuracy_2: 80.1% Loss_2: 0.001318  [ 8601/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000265, Accuracy_2: 83.7% Loss_2: 0.000417  [ 9165/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000879, Accuracy_2: 83.7% Loss_2: 0.000774  [ 9729/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.000952, Accuracy_2: 82.3% Loss_2: 0.001071  [10293/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.003166, Accuracy_2: 83.7% Loss_2: 0.002785  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000128, Accuracy_2: 85.8% Loss_2: 0.000605  [11421/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.003121, Accuracy_2: 83.0% Loss_2: 0.001532  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001429, Accuracy_2: 87.2% Loss_2: 0.000466  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000041, Accuracy_2: 91.5% Loss_2: 0.000326  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001048, Accuracy_2: 85.8% Loss_2: 0.001351  [13677/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001695, Accuracy_2: 84.4% Loss_2: 0.004369  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001049, Accuracy_2: 90.8% Loss_2: 0.000158  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.0%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.6%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002182, Accuracy_2: 85.8% Loss_2: 0.002284  [  141/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.000968, Accuracy_2: 82.3% Loss_2: 0.001067  [  705/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001291, Accuracy_2: 85.1% Loss_2: 0.001490  [ 1269/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002669, Accuracy_2: 81.6% Loss_2: 0.001909  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000873, Accuracy_2: 87.2% Loss_2: 0.000576  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001873, Accuracy_2: 88.7% Loss_2: 0.000488  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000312, Accuracy_2: 84.4% Loss_2: 0.000600  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000086, Accuracy_2: 83.7% Loss_2: 0.000436  [ 4089/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000775, Accuracy_2: 81.6% Loss_2: 0.002365  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000191, Accuracy_2: 89.4% Loss_2: 0.000471  [ 5217/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000484, Accuracy_2: 83.7% Loss_2: 0.003126  [ 5781/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001362, Accuracy_2: 83.7% Loss_2: 0.000336  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000439, Accuracy_2: 82.3% Loss_2: 0.002137  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000141, Accuracy_2: 92.2% Loss_2: 0.001239  [ 7473/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000741, Accuracy_2: 81.6% Loss_2: 0.002917  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000654, Accuracy_2: 87.9% Loss_2: 0.001638  [ 8601/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001788, Accuracy_2: 87.2% Loss_2: 0.000559  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001334, Accuracy_2: 85.1% Loss_2: 0.003302  [ 9729/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001197, Accuracy_2: 86.5% Loss_2: 0.002761  [10293/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000912, Accuracy_2: 93.6% Loss_2: 0.001179  [10857/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001389, Accuracy_2: 84.4% Loss_2: 0.000154  [11421/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003687, Accuracy_2: 86.5% Loss_2: 0.002263  [11985/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002656, Accuracy_2: 85.1% Loss_2: 0.001932  [12549/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002361, Accuracy_2: 89.4% Loss_2: 0.000122  [13113/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002368, Accuracy_2: 85.1% Loss_2: 0.000737  [13677/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000242, Accuracy_2: 86.5% Loss_2: 0.000501  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000525, Accuracy_2: 87.9% Loss_2: 0.000381  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.1%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.3%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001566, Accuracy_2: 84.4% Loss_2: 0.002091  [  141/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001273, Accuracy_2: 83.7% Loss_2: 0.001879  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001365, Accuracy_2: 89.4% Loss_2: 0.001957  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002046, Accuracy_2: 88.7% Loss_2: 0.000527  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002893, Accuracy_2: 86.5% Loss_2: 0.002305  [ 2397/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.002476, Accuracy_2: 78.0% Loss_2: 0.001593  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001213, Accuracy_2: 91.5% Loss_2: 0.000296  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000249, Accuracy_2: 85.8% Loss_2: 0.001083  [ 4089/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001400, Accuracy_2: 87.9% Loss_2: 0.001850  [ 4653/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000944, Accuracy_2: 82.3% Loss_2: 0.002908  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001006, Accuracy_2: 85.8% Loss_2: 0.001965  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001268, Accuracy_2: 90.1% Loss_2: 0.001078  [ 6345/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001844, Accuracy_2: 90.1% Loss_2: 0.001702  [ 6909/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001853, Accuracy_2: 87.2% Loss_2: 0.001736  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.003389, Accuracy_2: 85.1% Loss_2: 0.002597  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000172, Accuracy_2: 88.7% Loss_2: 0.000234  [ 8601/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.005169, Accuracy_2: 85.8% Loss_2: 0.001345  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001967, Accuracy_2: 87.2% Loss_2: 0.000421  [ 9729/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.004230, Accuracy_2: 81.6% Loss_2: 0.003630  [10293/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000329, Accuracy_2: 84.4% Loss_2: 0.000320  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000766, Accuracy_2: 89.4% Loss_2: 0.000991  [11421/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.002149, Accuracy_2: 87.2% Loss_2: 0.000721  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001315, Accuracy_2: 85.8% Loss_2: 0.002813  [12549/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001345, Accuracy_2: 86.5% Loss_2: 0.000900  [13113/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001844, Accuracy_2: 82.3% Loss_2: 0.001757  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000614, Accuracy_2: 85.8% Loss_2: 0.002985  [14241/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.000037, Accuracy_2: 80.1% Loss_2: 0.001157  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.8%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.7%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001393, Accuracy_2: 88.7% Loss_2: 0.001913  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000767, Accuracy_2: 85.1% Loss_2: 0.001197  [  705/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001776, Accuracy_2: 85.8% Loss_2: 0.001389  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001786, Accuracy_2: 87.9% Loss_2: 0.002640  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000408, Accuracy_2: 85.8% Loss_2: 0.001906  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000365, Accuracy_2: 91.5% Loss_2: 0.000949  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000390, Accuracy_2: 84.4% Loss_2: 0.001910  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000349, Accuracy_2: 85.8% Loss_2: 0.001415  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001449, Accuracy_2: 88.7% Loss_2: 0.000911  [ 4653/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003909, Accuracy_2: 85.8% Loss_2: 0.001272  [ 5217/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001827, Accuracy_2: 83.0% Loss_2: 0.001106  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000411, Accuracy_2: 85.1% Loss_2: 0.000308  [ 6345/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000209, Accuracy_2: 87.2% Loss_2: 0.000715  [ 6909/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001395, Accuracy_2: 90.1% Loss_2: 0.000181  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001667, Accuracy_2: 90.8% Loss_2: 0.002376  [ 8037/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003183, Accuracy_2: 87.2% Loss_2: 0.001701  [ 8601/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001711, Accuracy_2: 86.5% Loss_2: 0.000673  [ 9165/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.003022, Accuracy_2: 80.9% Loss_2: 0.000884  [ 9729/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000467, Accuracy_2: 83.0% Loss_2: 0.000730  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000170, Accuracy_2: 88.7% Loss_2: 0.000369  [10857/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002507, Accuracy_2: 87.2% Loss_2: 0.000288  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000988, Accuracy_2: 86.5% Loss_2: 0.000842  [11985/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001014, Accuracy_2: 85.8% Loss_2: 0.000172  [12549/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000903, Accuracy_2: 83.7% Loss_2: 0.000640  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000448, Accuracy_2: 93.6% Loss_2: 0.000032  [13677/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002290, Accuracy_2: 86.5% Loss_2: 0.000327  [14241/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000910, Accuracy_2: 85.8% Loss_2: 0.001740  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.7%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.5%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002469, Accuracy_2: 85.1% Loss_2: 0.000618  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000142, Accuracy_2: 85.1% Loss_2: 0.000766  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002387, Accuracy_2: 90.1% Loss_2: 0.001909  [ 1269/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002460, Accuracy_2: 87.9% Loss_2: 0.002286  [ 1833/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002252, Accuracy_2: 83.0% Loss_2: 0.001023  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000358, Accuracy_2: 88.7% Loss_2: 0.000208  [ 2961/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001572, Accuracy_2: 80.9% Loss_2: 0.001281  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000636, Accuracy_2: 87.9% Loss_2: 0.001996  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000894, Accuracy_2: 87.9% Loss_2: 0.000269  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001684, Accuracy_2: 86.5% Loss_2: 0.000957  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002133, Accuracy_2: 89.4% Loss_2: 0.002316  [ 5781/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.004087, Accuracy_2: 81.6% Loss_2: 0.002829  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002083, Accuracy_2: 88.7% Loss_2: 0.000579  [ 6909/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001198, Accuracy_2: 87.2% Loss_2: 0.001301  [ 7473/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000841, Accuracy_2: 90.8% Loss_2: 0.000720  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000774, Accuracy_2: 89.4% Loss_2: 0.002306  [ 8601/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000550, Accuracy_2: 84.4% Loss_2: 0.001050  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001881, Accuracy_2: 91.5% Loss_2: 0.000437  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002208, Accuracy_2: 83.7% Loss_2: 0.007126  [10293/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000952, Accuracy_2: 86.5% Loss_2: 0.001827  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002035, Accuracy_2: 85.1% Loss_2: 0.001437  [11421/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001639, Accuracy_2: 83.0% Loss_2: 0.001002  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000209, Accuracy_2: 86.5% Loss_2: 0.001828  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002670, Accuracy_2: 90.8% Loss_2: 0.000486  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000797, Accuracy_2: 83.7% Loss_2: 0.001422  [13677/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002406, Accuracy_2: 83.7% Loss_2: 0.000850  [14241/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002075, Accuracy_2: 84.4% Loss_2: 0.001442  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.8%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000749, Accuracy_2: 89.4% Loss_2: 0.001420  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003021, Accuracy_2: 90.8% Loss_2: 0.000784  [  705/15250]\n",
      "Accuracy_1: 76.6%, Loss_1: 0.003517, Accuracy_2: 83.7% Loss_2: 0.000999  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001024, Accuracy_2: 85.1% Loss_2: 0.001471  [ 1833/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000533, Accuracy_2: 83.0% Loss_2: 0.002661  [ 2397/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000531, Accuracy_2: 84.4% Loss_2: 0.001829  [ 2961/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.001342, Accuracy_2: 82.3% Loss_2: 0.000657  [ 3525/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001723, Accuracy_2: 85.8% Loss_2: 0.001399  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000945, Accuracy_2: 92.9% Loss_2: 0.000705  [ 4653/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000621, Accuracy_2: 86.5% Loss_2: 0.001259  [ 5217/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000467, Accuracy_2: 85.8% Loss_2: 0.001910  [ 5781/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002200, Accuracy_2: 86.5% Loss_2: 0.001612  [ 6345/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001559, Accuracy_2: 81.6% Loss_2: 0.001812  [ 6909/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000799, Accuracy_2: 85.8% Loss_2: 0.000910  [ 7473/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001488, Accuracy_2: 83.0% Loss_2: 0.001016  [ 8037/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000745, Accuracy_2: 84.4% Loss_2: 0.000134  [ 8601/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001244, Accuracy_2: 83.7% Loss_2: 0.000112  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000153, Accuracy_2: 87.9% Loss_2: 0.001254  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001921, Accuracy_2: 88.7% Loss_2: 0.000533  [10293/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001194, Accuracy_2: 83.7% Loss_2: 0.000997  [10857/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.004522, Accuracy_2: 83.0% Loss_2: 0.001185  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000575, Accuracy_2: 89.4% Loss_2: 0.000543  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002704, Accuracy_2: 91.5% Loss_2: 0.001056  [12549/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002765, Accuracy_2: 84.4% Loss_2: 0.000168  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000053, Accuracy_2: 90.8% Loss_2: 0.000570  [13677/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.003372, Accuracy_2: 80.1% Loss_2: 0.002043  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002001, Accuracy_2: 85.1% Loss_2: 0.001128  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.6%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000577, Accuracy_2: 87.9% Loss_2: 0.001354  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000894, Accuracy_2: 88.7% Loss_2: 0.000594  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002801, Accuracy_2: 90.1% Loss_2: 0.001588  [ 1269/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.001972, Accuracy_2: 80.1% Loss_2: 0.001907  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002280, Accuracy_2: 87.9% Loss_2: 0.000081  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000499, Accuracy_2: 85.8% Loss_2: 0.000345  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001394, Accuracy_2: 86.5% Loss_2: 0.000269  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001520, Accuracy_2: 90.8% Loss_2: 0.002168  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000939, Accuracy_2: 85.8% Loss_2: 0.001067  [ 4653/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001887, Accuracy_2: 84.4% Loss_2: 0.000462  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000815, Accuracy_2: 88.7% Loss_2: 0.001225  [ 5781/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000746, Accuracy_2: 81.6% Loss_2: 0.002778  [ 6345/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001992, Accuracy_2: 88.7% Loss_2: 0.000624  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000880, Accuracy_2: 90.8% Loss_2: 0.001331  [ 7473/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002051, Accuracy_2: 82.3% Loss_2: 0.000605  [ 8037/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001741, Accuracy_2: 86.5% Loss_2: 0.000498  [ 8601/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002198, Accuracy_2: 87.9% Loss_2: 0.000541  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000709, Accuracy_2: 89.4% Loss_2: 0.000696  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000090, Accuracy_2: 86.5% Loss_2: 0.000972  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000237, Accuracy_2: 86.5% Loss_2: 0.000073  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000629, Accuracy_2: 88.7% Loss_2: 0.000999  [11421/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001485, Accuracy_2: 82.3% Loss_2: 0.000878  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000523, Accuracy_2: 90.8% Loss_2: 0.001552  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000790, Accuracy_2: 86.5% Loss_2: 0.001949  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002172, Accuracy_2: 92.2% Loss_2: 0.000058  [13677/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.004400, Accuracy_2: 85.1% Loss_2: 0.003011  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000715, Accuracy_2: 87.9% Loss_2: 0.000247  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 80.8%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Accuracy_1: 84.4%, Loss_1: 0.004269, Accuracy_2: 87.2% Loss_2: 0.000487  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000461, Accuracy_2: 90.8% Loss_2: 0.000223  [  705/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002077, Accuracy_2: 83.0% Loss_2: 0.000969  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001078, Accuracy_2: 87.2% Loss_2: 0.001639  [ 1833/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002279, Accuracy_2: 86.5% Loss_2: 0.000273  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000441, Accuracy_2: 90.1% Loss_2: 0.000150  [ 2961/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000318, Accuracy_2: 81.6% Loss_2: 0.002556  [ 3525/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.003233, Accuracy_2: 80.9% Loss_2: 0.002177  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001377, Accuracy_2: 89.4% Loss_2: 0.000118  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001272, Accuracy_2: 88.7% Loss_2: 0.001353  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000081, Accuracy_2: 90.8% Loss_2: 0.000631  [ 5781/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001566, Accuracy_2: 82.3% Loss_2: 0.001953  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000444, Accuracy_2: 85.8% Loss_2: 0.001509  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001994, Accuracy_2: 87.9% Loss_2: 0.000603  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000687, Accuracy_2: 90.8% Loss_2: 0.001737  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000587, Accuracy_2: 90.1% Loss_2: 0.002368  [ 8601/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000113, Accuracy_2: 83.0% Loss_2: 0.000504  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000541, Accuracy_2: 87.2% Loss_2: 0.001629  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001127, Accuracy_2: 92.2% Loss_2: 0.000047  [10293/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000191, Accuracy_2: 79.4% Loss_2: 0.003843  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000175, Accuracy_2: 90.1% Loss_2: 0.000102  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000411, Accuracy_2: 87.2% Loss_2: 0.000526  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001133, Accuracy_2: 88.7% Loss_2: 0.000093  [12549/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000207, Accuracy_2: 83.0% Loss_2: 0.001045  [13113/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001796, Accuracy_2: 85.1% Loss_2: 0.000337  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000283, Accuracy_2: 86.5% Loss_2: 0.000461  [14241/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001467, Accuracy_2: 80.9% Loss_2: 0.001836  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.7%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.8%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000087, Accuracy_2: 88.7% Loss_2: 0.001185  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000815, Accuracy_2: 87.2% Loss_2: 0.001076  [  705/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000068, Accuracy_2: 83.0% Loss_2: 0.001024  [ 1269/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.002343, Accuracy_2: 79.4% Loss_2: 0.001443  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000562, Accuracy_2: 86.5% Loss_2: 0.002184  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000342, Accuracy_2: 85.8% Loss_2: 0.000135  [ 2961/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002854, Accuracy_2: 85.1% Loss_2: 0.001964  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000186, Accuracy_2: 85.8% Loss_2: 0.003087  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001570, Accuracy_2: 85.8% Loss_2: 0.000188  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000083, Accuracy_2: 87.9% Loss_2: 0.000739  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000443, Accuracy_2: 86.5% Loss_2: 0.001668  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001779, Accuracy_2: 87.2% Loss_2: 0.002056  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001878, Accuracy_2: 88.7% Loss_2: 0.000675  [ 6909/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001952, Accuracy_2: 82.3% Loss_2: 0.003032  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000948, Accuracy_2: 87.9% Loss_2: 0.000278  [ 8037/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000896, Accuracy_2: 83.0% Loss_2: 0.001096  [ 8601/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001845, Accuracy_2: 83.0% Loss_2: 0.001911  [ 9165/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000777, Accuracy_2: 83.7% Loss_2: 0.000163  [ 9729/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002679, Accuracy_2: 88.7% Loss_2: 0.001703  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001413, Accuracy_2: 85.8% Loss_2: 0.001352  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001821, Accuracy_2: 86.5% Loss_2: 0.001322  [11421/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003010, Accuracy_2: 86.5% Loss_2: 0.000658  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001322, Accuracy_2: 87.2% Loss_2: 0.002254  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001134, Accuracy_2: 87.2% Loss_2: 0.001871  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000565, Accuracy_2: 85.1% Loss_2: 0.002266  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003055, Accuracy_2: 87.9% Loss_2: 0.000725  [14241/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000394, Accuracy_2: 83.7% Loss_2: 0.001747  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.2%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002512, Accuracy_2: 83.0% Loss_2: 0.001912  [  141/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001648, Accuracy_2: 85.1% Loss_2: 0.000915  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002083, Accuracy_2: 87.9% Loss_2: 0.000832  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001258, Accuracy_2: 89.4% Loss_2: 0.001301  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001739, Accuracy_2: 89.4% Loss_2: 0.000659  [ 2397/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001948, Accuracy_2: 81.6% Loss_2: 0.001855  [ 2961/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001780, Accuracy_2: 85.1% Loss_2: 0.001803  [ 3525/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000339, Accuracy_2: 95.7% Loss_2: 0.000163  [ 4089/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000797, Accuracy_2: 85.8% Loss_2: 0.000783  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000482, Accuracy_2: 86.5% Loss_2: 0.003206  [ 5217/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001064, Accuracy_2: 82.3% Loss_2: 0.001045  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001603, Accuracy_2: 87.9% Loss_2: 0.001202  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000543, Accuracy_2: 86.5% Loss_2: 0.000126  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000184, Accuracy_2: 89.4% Loss_2: 0.000302  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000037, Accuracy_2: 89.4% Loss_2: 0.000560  [ 8037/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000225, Accuracy_2: 83.7% Loss_2: 0.001455  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001187, Accuracy_2: 85.1% Loss_2: 0.003188  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000161, Accuracy_2: 88.7% Loss_2: 0.000366  [ 9729/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001737, Accuracy_2: 83.0% Loss_2: 0.000696  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000218, Accuracy_2: 88.7% Loss_2: 0.001092  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000314, Accuracy_2: 87.2% Loss_2: 0.003183  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001274, Accuracy_2: 89.4% Loss_2: 0.000997  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000057, Accuracy_2: 89.4% Loss_2: 0.000890  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000623, Accuracy_2: 85.1% Loss_2: 0.002947  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000178, Accuracy_2: 83.7% Loss_2: 0.001247  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000645, Accuracy_2: 86.5% Loss_2: 0.001088  [14241/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000373, Accuracy_2: 85.8% Loss_2: 0.002297  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002224, Accuracy_2: 85.8% Loss_2: 0.000688  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002130, Accuracy_2: 89.4% Loss_2: 0.001320  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001133, Accuracy_2: 86.5% Loss_2: 0.001084  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000206, Accuracy_2: 86.5% Loss_2: 0.000323  [ 1833/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000346, Accuracy_2: 83.7% Loss_2: 0.000344  [ 2397/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001430, Accuracy_2: 80.9% Loss_2: 0.001370  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001358, Accuracy_2: 90.1% Loss_2: 0.001335  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001086, Accuracy_2: 90.1% Loss_2: 0.000180  [ 4089/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002811, Accuracy_2: 85.8% Loss_2: 0.003484  [ 4653/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000787, Accuracy_2: 82.3% Loss_2: 0.000443  [ 5217/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001228, Accuracy_2: 83.7% Loss_2: 0.000250  [ 5781/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000479, Accuracy_2: 86.5% Loss_2: 0.000164  [ 6345/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002730, Accuracy_2: 86.5% Loss_2: 0.000165  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000160, Accuracy_2: 91.5% Loss_2: 0.000139  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000047, Accuracy_2: 85.1% Loss_2: 0.001248  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000539, Accuracy_2: 84.4% Loss_2: 0.000640  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000284, Accuracy_2: 82.3% Loss_2: 0.003564  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000049, Accuracy_2: 87.2% Loss_2: 0.000916  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000889, Accuracy_2: 87.2% Loss_2: 0.001464  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000691, Accuracy_2: 87.2% Loss_2: 0.000620  [10857/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001331, Accuracy_2: 83.7% Loss_2: 0.001299  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000778, Accuracy_2: 85.8% Loss_2: 0.003715  [11985/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000752, Accuracy_2: 85.1% Loss_2: 0.000117  [12549/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001196, Accuracy_2: 88.7% Loss_2: 0.000610  [13113/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.000529, Accuracy_2: 80.1% Loss_2: 0.000524  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000043, Accuracy_2: 86.5% Loss_2: 0.000270  [14241/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001871, Accuracy_2: 82.3% Loss_2: 0.002615  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.5%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000146, Accuracy_2: 87.2% Loss_2: 0.001571  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001783, Accuracy_2: 86.5% Loss_2: 0.001130  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000776, Accuracy_2: 92.9% Loss_2: 0.000361  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001499, Accuracy_2: 90.1% Loss_2: 0.000088  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003208, Accuracy_2: 87.2% Loss_2: 0.001431  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000939, Accuracy_2: 90.1% Loss_2: 0.000117  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000230, Accuracy_2: 90.8% Loss_2: 0.000125  [ 3525/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002649, Accuracy_2: 83.0% Loss_2: 0.002164  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000677, Accuracy_2: 94.3% Loss_2: 0.000577  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001089, Accuracy_2: 85.8% Loss_2: 0.001897  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000565, Accuracy_2: 85.8% Loss_2: 0.001066  [ 5781/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000064, Accuracy_2: 80.1% Loss_2: 0.001881  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001174, Accuracy_2: 89.4% Loss_2: 0.001189  [ 6909/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001426, Accuracy_2: 87.2% Loss_2: 0.000255  [ 7473/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001385, Accuracy_2: 83.0% Loss_2: 0.001183  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000753, Accuracy_2: 86.5% Loss_2: 0.000260  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000694, Accuracy_2: 88.7% Loss_2: 0.000922  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001433, Accuracy_2: 89.4% Loss_2: 0.001964  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001282, Accuracy_2: 87.2% Loss_2: 0.000550  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000711, Accuracy_2: 87.2% Loss_2: 0.001292  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002076, Accuracy_2: 87.9% Loss_2: 0.000632  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000668, Accuracy_2: 88.7% Loss_2: 0.000809  [11985/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001187, Accuracy_2: 86.5% Loss_2: 0.001325  [12549/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001058, Accuracy_2: 87.2% Loss_2: 0.001680  [13113/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000469, Accuracy_2: 80.9% Loss_2: 0.004675  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001289, Accuracy_2: 84.4% Loss_2: 0.003554  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001237, Accuracy_2: 88.7% Loss_2: 0.000126  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001024, Accuracy_2: 86.5% Loss_2: 0.001512  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001539, Accuracy_2: 87.9% Loss_2: 0.001423  [  705/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000184, Accuracy_2: 81.6% Loss_2: 0.003157  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003017, Accuracy_2: 89.4% Loss_2: 0.001370  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000568, Accuracy_2: 86.5% Loss_2: 0.001745  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001441, Accuracy_2: 83.0% Loss_2: 0.002535  [ 2961/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001554, Accuracy_2: 87.9% Loss_2: 0.000546  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003015, Accuracy_2: 85.8% Loss_2: 0.003128  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000127, Accuracy_2: 82.3% Loss_2: 0.002382  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000837, Accuracy_2: 90.8% Loss_2: 0.001901  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001297, Accuracy_2: 90.8% Loss_2: 0.000238  [ 5781/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000234, Accuracy_2: 87.2% Loss_2: 0.000070  [ 6345/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002984, Accuracy_2: 81.6% Loss_2: 0.002593  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002885, Accuracy_2: 87.2% Loss_2: 0.000707  [ 7473/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000388, Accuracy_2: 80.1% Loss_2: 0.002635  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001113, Accuracy_2: 92.2% Loss_2: 0.000255  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001714, Accuracy_2: 83.7% Loss_2: 0.002572  [ 9165/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002396, Accuracy_2: 85.8% Loss_2: 0.001490  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000923, Accuracy_2: 88.7% Loss_2: 0.000514  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000256, Accuracy_2: 89.4% Loss_2: 0.001147  [10857/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000960, Accuracy_2: 85.1% Loss_2: 0.000161  [11421/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002217, Accuracy_2: 84.4% Loss_2: 0.001938  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000646, Accuracy_2: 85.8% Loss_2: 0.001456  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001010, Accuracy_2: 84.4% Loss_2: 0.001119  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001356, Accuracy_2: 84.4% Loss_2: 0.000468  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000868, Accuracy_2: 85.1% Loss_2: 0.002445  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000179, Accuracy_2: 90.8% Loss_2: 0.000154  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.8%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000622, Accuracy_2: 87.2% Loss_2: 0.001193  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001265, Accuracy_2: 87.2% Loss_2: 0.000248  [  705/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001589, Accuracy_2: 83.0% Loss_2: 0.001140  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000519, Accuracy_2: 85.8% Loss_2: 0.001583  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001275, Accuracy_2: 89.4% Loss_2: 0.000467  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001314, Accuracy_2: 84.4% Loss_2: 0.000412  [ 2961/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002114, Accuracy_2: 83.0% Loss_2: 0.002031  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000120, Accuracy_2: 87.2% Loss_2: 0.001675  [ 4089/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.004580, Accuracy_2: 86.5% Loss_2: 0.000688  [ 4653/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001650, Accuracy_2: 83.7% Loss_2: 0.001022  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000090, Accuracy_2: 90.1% Loss_2: 0.000601  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001424, Accuracy_2: 87.9% Loss_2: 0.000108  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000681, Accuracy_2: 90.8% Loss_2: 0.000685  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000171, Accuracy_2: 90.1% Loss_2: 0.000663  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000574, Accuracy_2: 85.1% Loss_2: 0.002184  [ 8037/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001492, Accuracy_2: 85.1% Loss_2: 0.001916  [ 8601/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002644, Accuracy_2: 85.1% Loss_2: 0.001123  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000898, Accuracy_2: 88.7% Loss_2: 0.000568  [ 9729/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001974, Accuracy_2: 85.8% Loss_2: 0.001135  [10293/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001516, Accuracy_2: 83.7% Loss_2: 0.003531  [10857/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002277, Accuracy_2: 87.2% Loss_2: 0.000223  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000927, Accuracy_2: 88.7% Loss_2: 0.001174  [11985/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002285, Accuracy_2: 87.2% Loss_2: 0.000053  [12549/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000581, Accuracy_2: 86.5% Loss_2: 0.000029  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001094, Accuracy_2: 90.8% Loss_2: 0.001857  [13677/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002247, Accuracy_2: 86.5% Loss_2: 0.001744  [14241/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001647, Accuracy_2: 85.8% Loss_2: 0.003451  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.7%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001562, Accuracy_2: 87.2% Loss_2: 0.000575  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000198, Accuracy_2: 89.4% Loss_2: 0.000012  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000025, Accuracy_2: 85.8% Loss_2: 0.001399  [ 1269/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000935, Accuracy_2: 93.6% Loss_2: 0.000233  [ 1833/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000794, Accuracy_2: 86.5% Loss_2: 0.000426  [ 2397/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.003309, Accuracy_2: 89.4% Loss_2: 0.000614  [ 2961/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002812, Accuracy_2: 87.2% Loss_2: 0.001176  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001001, Accuracy_2: 84.4% Loss_2: 0.004537  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000445, Accuracy_2: 91.5% Loss_2: 0.000679  [ 4653/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001191, Accuracy_2: 83.7% Loss_2: 0.001848  [ 5217/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000766, Accuracy_2: 83.0% Loss_2: 0.001795  [ 5781/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000267, Accuracy_2: 81.6% Loss_2: 0.002123  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001640, Accuracy_2: 84.4% Loss_2: 0.001168  [ 6909/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000551, Accuracy_2: 83.7% Loss_2: 0.000866  [ 7473/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.000495, Accuracy_2: 78.7% Loss_2: 0.001876  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000076, Accuracy_2: 86.5% Loss_2: 0.000566  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000395, Accuracy_2: 90.1% Loss_2: 0.001370  [ 9165/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000497, Accuracy_2: 85.1% Loss_2: 0.000158  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001756, Accuracy_2: 86.5% Loss_2: 0.000255  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001534, Accuracy_2: 91.5% Loss_2: 0.002246  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001491, Accuracy_2: 90.1% Loss_2: 0.000166  [11421/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001064, Accuracy_2: 85.1% Loss_2: 0.001178  [11985/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002991, Accuracy_2: 87.2% Loss_2: 0.000082  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002334, Accuracy_2: 87.9% Loss_2: 0.000337  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000780, Accuracy_2: 87.2% Loss_2: 0.000358  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000729, Accuracy_2: 88.7% Loss_2: 0.000233  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000617, Accuracy_2: 89.4% Loss_2: 0.001065  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.6%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000402, Accuracy_2: 88.7% Loss_2: 0.000251  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000473, Accuracy_2: 87.9% Loss_2: 0.001366  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000221, Accuracy_2: 90.1% Loss_2: 0.000018  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000417, Accuracy_2: 87.9% Loss_2: 0.001871  [ 1833/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000329, Accuracy_2: 83.0% Loss_2: 0.000860  [ 2397/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.003385, Accuracy_2: 86.5% Loss_2: 0.001582  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002766, Accuracy_2: 92.2% Loss_2: 0.000145  [ 3525/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000877, Accuracy_2: 86.5% Loss_2: 0.000808  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000371, Accuracy_2: 86.5% Loss_2: 0.001295  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001359, Accuracy_2: 91.5% Loss_2: 0.000707  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001505, Accuracy_2: 87.9% Loss_2: 0.000433  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000367, Accuracy_2: 89.4% Loss_2: 0.000112  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001318, Accuracy_2: 87.2% Loss_2: 0.002808  [ 6909/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001660, Accuracy_2: 86.5% Loss_2: 0.002926  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000523, Accuracy_2: 87.2% Loss_2: 0.000423  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000522, Accuracy_2: 88.7% Loss_2: 0.000583  [ 8601/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000845, Accuracy_2: 86.5% Loss_2: 0.000109  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001429, Accuracy_2: 87.2% Loss_2: 0.001743  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000817, Accuracy_2: 87.9% Loss_2: 0.000888  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003821, Accuracy_2: 89.4% Loss_2: 0.000989  [10857/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001757, Accuracy_2: 82.3% Loss_2: 0.001709  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000671, Accuracy_2: 87.9% Loss_2: 0.000447  [11985/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001927, Accuracy_2: 87.2% Loss_2: 0.000377  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002123, Accuracy_2: 89.4% Loss_2: 0.001085  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002637, Accuracy_2: 85.8% Loss_2: 0.001498  [13677/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000288, Accuracy_2: 82.3% Loss_2: 0.000662  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003647, Accuracy_2: 83.7% Loss_2: 0.002266  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 80.4%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000210, Accuracy_2: 89.4% Loss_2: 0.002440  [  141/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002587, Accuracy_2: 84.4% Loss_2: 0.000626  [  705/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000975, Accuracy_2: 87.2% Loss_2: 0.000042  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002842, Accuracy_2: 89.4% Loss_2: 0.000137  [ 1833/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002149, Accuracy_2: 81.6% Loss_2: 0.003056  [ 2397/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003652, Accuracy_2: 87.9% Loss_2: 0.001004  [ 2961/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001297, Accuracy_2: 86.5% Loss_2: 0.000436  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001893, Accuracy_2: 87.9% Loss_2: 0.002255  [ 4089/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.003270, Accuracy_2: 85.8% Loss_2: 0.001594  [ 4653/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002882, Accuracy_2: 84.4% Loss_2: 0.000942  [ 5217/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003352, Accuracy_2: 85.8% Loss_2: 0.003458  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001018, Accuracy_2: 88.7% Loss_2: 0.003428  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001926, Accuracy_2: 85.8% Loss_2: 0.002395  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000335, Accuracy_2: 86.5% Loss_2: 0.004134  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003006, Accuracy_2: 92.2% Loss_2: 0.001344  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000224, Accuracy_2: 87.9% Loss_2: 0.001418  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000606, Accuracy_2: 85.8% Loss_2: 0.001833  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001195, Accuracy_2: 91.5% Loss_2: 0.000154  [ 9729/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003244, Accuracy_2: 84.4% Loss_2: 0.003549  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000540, Accuracy_2: 88.7% Loss_2: 0.000335  [10857/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000770, Accuracy_2: 85.8% Loss_2: 0.002584  [11421/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.004111, Accuracy_2: 87.9% Loss_2: 0.000995  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000329, Accuracy_2: 84.4% Loss_2: 0.001650  [12549/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.003647, Accuracy_2: 80.9% Loss_2: 0.002156  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001394, Accuracy_2: 89.4% Loss_2: 0.000559  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001364, Accuracy_2: 87.2% Loss_2: 0.000093  [14241/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000791, Accuracy_2: 84.4% Loss_2: 0.001063  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.1%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001536, Accuracy_2: 85.1% Loss_2: 0.001233  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002688, Accuracy_2: 87.9% Loss_2: 0.000943  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001196, Accuracy_2: 90.1% Loss_2: 0.000056  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001056, Accuracy_2: 87.9% Loss_2: 0.000557  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000276, Accuracy_2: 88.7% Loss_2: 0.000151  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000699, Accuracy_2: 85.8% Loss_2: 0.002668  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000293, Accuracy_2: 85.1% Loss_2: 0.002891  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001465, Accuracy_2: 91.5% Loss_2: 0.002001  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000338, Accuracy_2: 86.5% Loss_2: 0.001709  [ 4653/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000539, Accuracy_2: 83.0% Loss_2: 0.000730  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000532, Accuracy_2: 87.9% Loss_2: 0.000462  [ 5781/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000180, Accuracy_2: 85.1% Loss_2: 0.002016  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000234, Accuracy_2: 89.4% Loss_2: 0.002215  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000285, Accuracy_2: 86.5% Loss_2: 0.000574  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000563, Accuracy_2: 90.1% Loss_2: 0.000243  [ 8037/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002285, Accuracy_2: 80.9% Loss_2: 0.003323  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001181, Accuracy_2: 88.7% Loss_2: 0.000812  [ 9165/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000559, Accuracy_2: 87.2% Loss_2: 0.000935  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001609, Accuracy_2: 87.9% Loss_2: 0.000400  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000273, Accuracy_2: 91.5% Loss_2: 0.000063  [10857/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000777, Accuracy_2: 87.2% Loss_2: 0.000992  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000928, Accuracy_2: 87.9% Loss_2: 0.000011  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002392, Accuracy_2: 87.9% Loss_2: 0.001418  [12549/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002372, Accuracy_2: 84.4% Loss_2: 0.000772  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001092, Accuracy_2: 93.6% Loss_2: 0.000011  [13677/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000974, Accuracy_2: 85.1% Loss_2: 0.000699  [14241/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000269, Accuracy_2: 85.1% Loss_2: 0.000971  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.2%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000083, Accuracy_2: 92.9% Loss_2: 0.000498  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000530, Accuracy_2: 90.1% Loss_2: 0.000657  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000017, Accuracy_2: 85.1% Loss_2: 0.000764  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000166, Accuracy_2: 92.9% Loss_2: 0.000019  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000259, Accuracy_2: 87.9% Loss_2: 0.001623  [ 2397/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001924, Accuracy_2: 85.1% Loss_2: 0.001483  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000203, Accuracy_2: 89.4% Loss_2: 0.001953  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000822, Accuracy_2: 88.7% Loss_2: 0.001058  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000088, Accuracy_2: 85.1% Loss_2: 0.001308  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000446, Accuracy_2: 86.5% Loss_2: 0.000573  [ 5217/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002149, Accuracy_2: 87.2% Loss_2: 0.001722  [ 5781/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001578, Accuracy_2: 83.0% Loss_2: 0.001049  [ 6345/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002656, Accuracy_2: 83.7% Loss_2: 0.002480  [ 6909/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001790, Accuracy_2: 85.8% Loss_2: 0.000990  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001667, Accuracy_2: 87.2% Loss_2: 0.001194  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000317, Accuracy_2: 87.2% Loss_2: 0.003139  [ 8601/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001182, Accuracy_2: 81.6% Loss_2: 0.000542  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000987, Accuracy_2: 86.5% Loss_2: 0.001058  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001459, Accuracy_2: 90.8% Loss_2: 0.000438  [10293/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001881, Accuracy_2: 84.4% Loss_2: 0.000525  [10857/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000599, Accuracy_2: 87.2% Loss_2: 0.000190  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000629, Accuracy_2: 83.7% Loss_2: 0.002809  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000142, Accuracy_2: 87.2% Loss_2: 0.000247  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000624, Accuracy_2: 86.5% Loss_2: 0.000150  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002898, Accuracy_2: 90.8% Loss_2: 0.000610  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000262, Accuracy_2: 89.4% Loss_2: 0.001277  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001084, Accuracy_2: 90.8% Loss_2: 0.000324  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Accuracy_1: 79.4%, Loss_1: 0.001217, Accuracy_2: 80.1% Loss_2: 0.001419  [  141/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002622, Accuracy_2: 83.0% Loss_2: 0.002354  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001127, Accuracy_2: 83.7% Loss_2: 0.003102  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000808, Accuracy_2: 89.4% Loss_2: 0.001118  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000014, Accuracy_2: 92.2% Loss_2: 0.000226  [ 2397/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002144, Accuracy_2: 86.5% Loss_2: 0.000089  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001905, Accuracy_2: 87.2% Loss_2: 0.000511  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001184, Accuracy_2: 87.2% Loss_2: 0.001085  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001012, Accuracy_2: 88.7% Loss_2: 0.001125  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001115, Accuracy_2: 90.1% Loss_2: 0.000174  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002194, Accuracy_2: 86.5% Loss_2: 0.001030  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.004048, Accuracy_2: 89.4% Loss_2: 0.001449  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000085, Accuracy_2: 90.8% Loss_2: 0.000922  [ 6909/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000655, Accuracy_2: 87.9% Loss_2: 0.002096  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000296, Accuracy_2: 90.8% Loss_2: 0.000463  [ 8037/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001209, Accuracy_2: 87.2% Loss_2: 0.001023  [ 8601/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001759, Accuracy_2: 85.8% Loss_2: 0.000220  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002394, Accuracy_2: 86.5% Loss_2: 0.000921  [ 9729/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001645, Accuracy_2: 87.2% Loss_2: 0.001383  [10293/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001682, Accuracy_2: 86.5% Loss_2: 0.001606  [10857/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000817, Accuracy_2: 87.9% Loss_2: 0.000206  [11421/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000394, Accuracy_2: 86.5% Loss_2: 0.000026  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000007, Accuracy_2: 83.7% Loss_2: 0.001554  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001908, Accuracy_2: 85.1% Loss_2: 0.000963  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000768, Accuracy_2: 89.4% Loss_2: 0.000119  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000388, Accuracy_2: 89.4% Loss_2: 0.000372  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000758, Accuracy_2: 86.5% Loss_2: 0.000350  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.6%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000000 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000518, Accuracy_2: 89.4% Loss_2: 0.001794  [  141/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000853, Accuracy_2: 83.7% Loss_2: 0.001686  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000080, Accuracy_2: 90.8% Loss_2: 0.000040  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001486, Accuracy_2: 90.8% Loss_2: 0.000071  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000017, Accuracy_2: 87.9% Loss_2: 0.001224  [ 2397/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001746, Accuracy_2: 77.3% Loss_2: 0.006956  [ 2961/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.000457, Accuracy_2: 83.0% Loss_2: 0.003315  [ 3525/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000114, Accuracy_2: 83.7% Loss_2: 0.000557  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000124, Accuracy_2: 85.8% Loss_2: 0.001386  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001835, Accuracy_2: 90.1% Loss_2: 0.001108  [ 5217/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000794, Accuracy_2: 85.8% Loss_2: 0.000381  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000262, Accuracy_2: 86.5% Loss_2: 0.001384  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000687, Accuracy_2: 87.2% Loss_2: 0.000234  [ 6909/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000383, Accuracy_2: 84.4% Loss_2: 0.001098  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000850, Accuracy_2: 90.1% Loss_2: 0.000600  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000659, Accuracy_2: 83.0% Loss_2: 0.002296  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000814, Accuracy_2: 90.1% Loss_2: 0.000522  [ 9165/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001128, Accuracy_2: 87.2% Loss_2: 0.000119  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000590, Accuracy_2: 88.7% Loss_2: 0.000041  [10293/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000544, Accuracy_2: 85.8% Loss_2: 0.000599  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001599, Accuracy_2: 89.4% Loss_2: 0.000937  [11421/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.005741, Accuracy_2: 80.1% Loss_2: 0.004977  [11985/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002896, Accuracy_2: 84.4% Loss_2: 0.001113  [12549/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000753, Accuracy_2: 83.7% Loss_2: 0.002027  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001191, Accuracy_2: 87.2% Loss_2: 0.000239  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000183, Accuracy_2: 86.5% Loss_2: 0.001481  [14241/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.004301, Accuracy_2: 81.6% Loss_2: 0.002091  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.0%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.5%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001752, Accuracy_2: 86.5% Loss_2: 0.000602  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000384, Accuracy_2: 89.4% Loss_2: 0.001010  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000692, Accuracy_2: 85.8% Loss_2: 0.000198  [ 1269/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002149, Accuracy_2: 82.3% Loss_2: 0.004258  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000327, Accuracy_2: 87.9% Loss_2: 0.001935  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.004010, Accuracy_2: 90.1% Loss_2: 0.000971  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000537, Accuracy_2: 86.5% Loss_2: 0.000190  [ 3525/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001622, Accuracy_2: 85.8% Loss_2: 0.000418  [ 4089/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000598, Accuracy_2: 87.2% Loss_2: 0.000106  [ 4653/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000240, Accuracy_2: 83.0% Loss_2: 0.001819  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001494, Accuracy_2: 88.7% Loss_2: 0.001402  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001392, Accuracy_2: 86.5% Loss_2: 0.002057  [ 6345/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001457, Accuracy_2: 87.2% Loss_2: 0.000053  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001741, Accuracy_2: 87.2% Loss_2: 0.003414  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001267, Accuracy_2: 92.2% Loss_2: 0.002507  [ 8037/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001329, Accuracy_2: 85.8% Loss_2: 0.001139  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000047, Accuracy_2: 89.4% Loss_2: 0.000669  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001053, Accuracy_2: 88.7% Loss_2: 0.001386  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001672, Accuracy_2: 90.1% Loss_2: 0.000187  [10293/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000741, Accuracy_2: 86.5% Loss_2: 0.001527  [10857/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.004475, Accuracy_2: 84.4% Loss_2: 0.003768  [11421/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000056, Accuracy_2: 87.2% Loss_2: 0.000076  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001518, Accuracy_2: 90.8% Loss_2: 0.002745  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000034, Accuracy_2: 83.7% Loss_2: 0.000881  [13113/15250]\n",
      "Accuracy_1: 78.0%, Loss_1: 0.001379, Accuracy_2: 77.3% Loss_2: 0.001942  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000100, Accuracy_2: 84.4% Loss_2: 0.001342  [14241/15250]\n",
      "Accuracy_1: 78.7%, Loss_1: 0.001659, Accuracy_2: 80.9% Loss_2: 0.002150  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.2%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.7%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001289, Accuracy_2: 82.3% Loss_2: 0.002356  [  141/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003368, Accuracy_2: 85.8% Loss_2: 0.001720  [  705/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.004338, Accuracy_2: 83.7% Loss_2: 0.000170  [ 1269/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000961, Accuracy_2: 85.8% Loss_2: 0.001407  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002526, Accuracy_2: 88.7% Loss_2: 0.000642  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003184, Accuracy_2: 85.1% Loss_2: 0.003079  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001319, Accuracy_2: 86.5% Loss_2: 0.000685  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000832, Accuracy_2: 89.4% Loss_2: 0.002626  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000180, Accuracy_2: 90.1% Loss_2: 0.000396  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002564, Accuracy_2: 91.5% Loss_2: 0.000790  [ 5217/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.004974, Accuracy_2: 83.0% Loss_2: 0.001281  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001033, Accuracy_2: 87.9% Loss_2: 0.000388  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000410, Accuracy_2: 87.2% Loss_2: 0.002736  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001401, Accuracy_2: 87.9% Loss_2: 0.002388  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000699, Accuracy_2: 90.1% Loss_2: 0.001662  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000791, Accuracy_2: 85.8% Loss_2: 0.001894  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000942, Accuracy_2: 88.7% Loss_2: 0.000407  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000976, Accuracy_2: 90.1% Loss_2: 0.000540  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000322, Accuracy_2: 92.9% Loss_2: 0.000067  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001492, Accuracy_2: 87.9% Loss_2: 0.001416  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000382, Accuracy_2: 87.9% Loss_2: 0.001037  [11421/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001326, Accuracy_2: 85.1% Loss_2: 0.001475  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001390, Accuracy_2: 87.9% Loss_2: 0.001943  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000957, Accuracy_2: 85.8% Loss_2: 0.000747  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001682, Accuracy_2: 87.2% Loss_2: 0.001852  [13677/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001200, Accuracy_2: 82.3% Loss_2: 0.003387  [14241/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001676, Accuracy_2: 83.0% Loss_2: 0.003799  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.8%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003219, Accuracy_2: 86.5% Loss_2: 0.002285  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000367, Accuracy_2: 89.4% Loss_2: 0.000784  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000819, Accuracy_2: 90.8% Loss_2: 0.000691  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000432, Accuracy_2: 85.8% Loss_2: 0.003139  [ 1833/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001712, Accuracy_2: 86.5% Loss_2: 0.001478  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000772, Accuracy_2: 89.4% Loss_2: 0.000161  [ 2961/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001064, Accuracy_2: 88.7% Loss_2: 0.000841  [ 3525/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002746, Accuracy_2: 83.7% Loss_2: 0.001003  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001092, Accuracy_2: 85.8% Loss_2: 0.000917  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001132, Accuracy_2: 87.2% Loss_2: 0.000548  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000957, Accuracy_2: 87.9% Loss_2: 0.000900  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000628, Accuracy_2: 92.2% Loss_2: 0.000281  [ 6345/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001050, Accuracy_2: 88.7% Loss_2: 0.000072  [ 6909/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000083, Accuracy_2: 83.7% Loss_2: 0.001163  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000715, Accuracy_2: 90.1% Loss_2: 0.000379  [ 8037/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001832, Accuracy_2: 87.2% Loss_2: 0.001261  [ 8601/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003041, Accuracy_2: 86.5% Loss_2: 0.000983  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000075, Accuracy_2: 86.5% Loss_2: 0.001498  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000299, Accuracy_2: 86.5% Loss_2: 0.000765  [10293/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000854, Accuracy_2: 83.7% Loss_2: 0.001018  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000372, Accuracy_2: 86.5% Loss_2: 0.001608  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000776, Accuracy_2: 85.8% Loss_2: 0.001191  [11985/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002439, Accuracy_2: 85.1% Loss_2: 0.001228  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001161, Accuracy_2: 89.4% Loss_2: 0.000012  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000880, Accuracy_2: 87.9% Loss_2: 0.000039  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000760, Accuracy_2: 88.7% Loss_2: 0.000189  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000890, Accuracy_2: 87.2% Loss_2: 0.000073  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000272, Accuracy_2: 89.4% Loss_2: 0.000730  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001533, Accuracy_2: 87.2% Loss_2: 0.000205  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000250, Accuracy_2: 86.5% Loss_2: 0.002858  [ 1269/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.004097, Accuracy_2: 89.4% Loss_2: 0.000164  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002661, Accuracy_2: 83.7% Loss_2: 0.001753  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000249, Accuracy_2: 91.5% Loss_2: 0.000004  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002703, Accuracy_2: 89.4% Loss_2: 0.000153  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001280, Accuracy_2: 87.9% Loss_2: 0.000336  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000369, Accuracy_2: 84.4% Loss_2: 0.002736  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000495, Accuracy_2: 84.4% Loss_2: 0.001085  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002098, Accuracy_2: 93.6% Loss_2: 0.000952  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000669, Accuracy_2: 87.9% Loss_2: 0.001568  [ 6345/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001148, Accuracy_2: 85.1% Loss_2: 0.001604  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000968, Accuracy_2: 86.5% Loss_2: 0.002296  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000568, Accuracy_2: 89.4% Loss_2: 0.002496  [ 8037/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001572, Accuracy_2: 86.5% Loss_2: 0.001280  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001110, Accuracy_2: 92.2% Loss_2: 0.000266  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000852, Accuracy_2: 85.1% Loss_2: 0.000557  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000998, Accuracy_2: 85.8% Loss_2: 0.001110  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000587, Accuracy_2: 93.6% Loss_2: 0.000164  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000417, Accuracy_2: 84.4% Loss_2: 0.003693  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001974, Accuracy_2: 86.5% Loss_2: 0.001367  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000510, Accuracy_2: 89.4% Loss_2: 0.000953  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001621, Accuracy_2: 87.2% Loss_2: 0.001978  [13113/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002562, Accuracy_2: 83.7% Loss_2: 0.001083  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000688, Accuracy_2: 87.2% Loss_2: 0.001629  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000868, Accuracy_2: 90.8% Loss_2: 0.000428  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001505, Accuracy_2: 87.9% Loss_2: 0.002208  [  141/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000600, Accuracy_2: 84.4% Loss_2: 0.000216  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000303, Accuracy_2: 90.8% Loss_2: 0.000234  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000116, Accuracy_2: 85.8% Loss_2: 0.000255  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000448, Accuracy_2: 90.8% Loss_2: 0.002113  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000228, Accuracy_2: 87.9% Loss_2: 0.002310  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001089, Accuracy_2: 87.2% Loss_2: 0.003416  [ 3525/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000972, Accuracy_2: 85.8% Loss_2: 0.002796  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001505, Accuracy_2: 90.8% Loss_2: 0.000189  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000747, Accuracy_2: 88.7% Loss_2: 0.000184  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000424, Accuracy_2: 85.8% Loss_2: 0.001831  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001036, Accuracy_2: 90.8% Loss_2: 0.000048  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001708, Accuracy_2: 85.8% Loss_2: 0.001668  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000371, Accuracy_2: 86.5% Loss_2: 0.000587  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000685, Accuracy_2: 87.9% Loss_2: 0.000321  [ 8037/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001424, Accuracy_2: 85.8% Loss_2: 0.000114  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000159, Accuracy_2: 84.4% Loss_2: 0.000472  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000318, Accuracy_2: 90.1% Loss_2: 0.001197  [ 9729/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001928, Accuracy_2: 85.8% Loss_2: 0.000418  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000212, Accuracy_2: 90.1% Loss_2: 0.002104  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003935, Accuracy_2: 92.9% Loss_2: 0.000553  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001938, Accuracy_2: 90.1% Loss_2: 0.000144  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.005563, Accuracy_2: 89.4% Loss_2: 0.000779  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001624, Accuracy_2: 87.9% Loss_2: 0.000324  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000419, Accuracy_2: 90.1% Loss_2: 0.000032  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003795, Accuracy_2: 88.7% Loss_2: 0.000006  [14241/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000353, Accuracy_2: 85.1% Loss_2: 0.000887  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.1%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000207, Accuracy_2: 87.9% Loss_2: 0.000469  [  141/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.003364, Accuracy_2: 86.5% Loss_2: 0.001213  [  705/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000508, Accuracy_2: 81.6% Loss_2: 0.001262  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000015, Accuracy_2: 90.1% Loss_2: 0.002427  [ 1833/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000690, Accuracy_2: 84.4% Loss_2: 0.000793  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001375, Accuracy_2: 86.5% Loss_2: 0.001219  [ 2961/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001953, Accuracy_2: 91.5% Loss_2: 0.000318  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000460, Accuracy_2: 85.1% Loss_2: 0.002211  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000148, Accuracy_2: 92.2% Loss_2: 0.000571  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000094, Accuracy_2: 90.1% Loss_2: 0.000872  [ 5217/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001145, Accuracy_2: 85.8% Loss_2: 0.001408  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000541, Accuracy_2: 86.5% Loss_2: 0.002047  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002994, Accuracy_2: 89.4% Loss_2: 0.000434  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000832, Accuracy_2: 87.9% Loss_2: 0.000872  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002621, Accuracy_2: 89.4% Loss_2: 0.002542  [ 8037/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002022, Accuracy_2: 83.7% Loss_2: 0.000861  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000278, Accuracy_2: 92.9% Loss_2: 0.000040  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001662, Accuracy_2: 87.2% Loss_2: 0.000731  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003051, Accuracy_2: 89.4% Loss_2: 0.000990  [10293/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001427, Accuracy_2: 85.8% Loss_2: 0.001397  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001719, Accuracy_2: 86.5% Loss_2: 0.000129  [11421/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002640, Accuracy_2: 88.7% Loss_2: 0.000190  [11985/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000441, Accuracy_2: 83.7% Loss_2: 0.000532  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000143, Accuracy_2: 87.9% Loss_2: 0.001838  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001458, Accuracy_2: 86.5% Loss_2: 0.000243  [13677/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001498, Accuracy_2: 87.2% Loss_2: 0.000077  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000289, Accuracy_2: 89.4% Loss_2: 0.000757  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.4%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.7%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000431, Accuracy_2: 92.2% Loss_2: 0.000101  [  141/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002258, Accuracy_2: 82.3% Loss_2: 0.002334  [  705/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.006199, Accuracy_2: 83.7% Loss_2: 0.001668  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000743, Accuracy_2: 87.9% Loss_2: 0.000097  [ 1833/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000706, Accuracy_2: 85.1% Loss_2: 0.002820  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000912, Accuracy_2: 90.8% Loss_2: 0.001383  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000192, Accuracy_2: 87.2% Loss_2: 0.002104  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002686, Accuracy_2: 90.8% Loss_2: 0.001735  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000259, Accuracy_2: 91.5% Loss_2: 0.000724  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001254, Accuracy_2: 91.5% Loss_2: 0.000886  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001505, Accuracy_2: 85.8% Loss_2: 0.000431  [ 5781/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001330, Accuracy_2: 83.7% Loss_2: 0.001790  [ 6345/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000006, Accuracy_2: 81.6% Loss_2: 0.001631  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000334, Accuracy_2: 87.9% Loss_2: 0.000162  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000024, Accuracy_2: 88.7% Loss_2: 0.001286  [ 8037/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001759, Accuracy_2: 83.0% Loss_2: 0.002950  [ 8601/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.003798, Accuracy_2: 84.4% Loss_2: 0.002422  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000258, Accuracy_2: 85.1% Loss_2: 0.001650  [ 9729/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000805, Accuracy_2: 80.9% Loss_2: 0.001848  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001933, Accuracy_2: 89.4% Loss_2: 0.001889  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002189, Accuracy_2: 92.2% Loss_2: 0.000044  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.004274, Accuracy_2: 90.8% Loss_2: 0.003155  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001792, Accuracy_2: 90.1% Loss_2: 0.001138  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001810, Accuracy_2: 87.2% Loss_2: 0.000419  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001800, Accuracy_2: 85.1% Loss_2: 0.002310  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000534, Accuracy_2: 83.7% Loss_2: 0.000671  [14241/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002889, Accuracy_2: 87.2% Loss_2: 0.000375  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.8%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001254, Accuracy_2: 91.5% Loss_2: 0.001741  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000060, Accuracy_2: 90.1% Loss_2: 0.001010  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001762, Accuracy_2: 90.1% Loss_2: 0.000931  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000122, Accuracy_2: 85.8% Loss_2: 0.002389  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000514, Accuracy_2: 88.7% Loss_2: 0.000129  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002115, Accuracy_2: 87.9% Loss_2: 0.002705  [ 2961/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002014, Accuracy_2: 88.7% Loss_2: 0.000126  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001286, Accuracy_2: 87.9% Loss_2: 0.000081  [ 4089/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002786, Accuracy_2: 88.7% Loss_2: 0.000042  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001284, Accuracy_2: 90.1% Loss_2: 0.000006  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000206, Accuracy_2: 86.5% Loss_2: 0.001039  [ 5781/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000279, Accuracy_2: 85.1% Loss_2: 0.000492  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001501, Accuracy_2: 85.8% Loss_2: 0.002688  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001198, Accuracy_2: 88.7% Loss_2: 0.000372  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000948, Accuracy_2: 81.6% Loss_2: 0.001083  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000578, Accuracy_2: 87.2% Loss_2: 0.004076  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000078, Accuracy_2: 89.4% Loss_2: 0.000062  [ 9165/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000914, Accuracy_2: 85.8% Loss_2: 0.000452  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000785, Accuracy_2: 87.2% Loss_2: 0.001824  [10293/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000161, Accuracy_2: 83.7% Loss_2: 0.001217  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000260, Accuracy_2: 90.1% Loss_2: 0.000186  [11421/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000775, Accuracy_2: 83.0% Loss_2: 0.001048  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000197, Accuracy_2: 92.2% Loss_2: 0.001602  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000360, Accuracy_2: 91.5% Loss_2: 0.000054  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000744, Accuracy_2: 87.9% Loss_2: 0.000033  [13677/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001549, Accuracy_2: 86.5% Loss_2: 0.000468  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000783, Accuracy_2: 85.8% Loss_2: 0.001316  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001764, Accuracy_2: 87.2% Loss_2: 0.001211  [  141/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000063, Accuracy_2: 85.8% Loss_2: 0.000152  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000580, Accuracy_2: 90.8% Loss_2: 0.000679  [ 1269/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000980, Accuracy_2: 84.4% Loss_2: 0.001256  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000925, Accuracy_2: 85.8% Loss_2: 0.001992  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000723, Accuracy_2: 89.4% Loss_2: 0.001471  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000490, Accuracy_2: 89.4% Loss_2: 0.002659  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000641, Accuracy_2: 88.7% Loss_2: 0.000317  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000948, Accuracy_2: 91.5% Loss_2: 0.001656  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000746, Accuracy_2: 86.5% Loss_2: 0.001101  [ 5217/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000591, Accuracy_2: 92.9% Loss_2: 0.001612  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000806, Accuracy_2: 87.2% Loss_2: 0.002974  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000289, Accuracy_2: 90.1% Loss_2: 0.000047  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002880, Accuracy_2: 86.5% Loss_2: 0.001261  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000005, Accuracy_2: 91.5% Loss_2: 0.000031  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000850, Accuracy_2: 85.8% Loss_2: 0.001062  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000385, Accuracy_2: 90.8% Loss_2: 0.000154  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000050, Accuracy_2: 90.8% Loss_2: 0.000616  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000674, Accuracy_2: 87.9% Loss_2: 0.000430  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000723, Accuracy_2: 87.2% Loss_2: 0.001255  [10857/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.003107, Accuracy_2: 80.9% Loss_2: 0.002017  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000109, Accuracy_2: 88.7% Loss_2: 0.000295  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001736, Accuracy_2: 90.1% Loss_2: 0.000192  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001242, Accuracy_2: 86.5% Loss_2: 0.001545  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001100, Accuracy_2: 87.9% Loss_2: 0.000280  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000619, Accuracy_2: 87.9% Loss_2: 0.000790  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003425, Accuracy_2: 90.8% Loss_2: 0.000566  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.1%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002965, Accuracy_2: 92.9% Loss_2: 0.000685  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003230, Accuracy_2: 90.1% Loss_2: 0.000056  [  705/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002479, Accuracy_2: 90.1% Loss_2: 0.000222  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000269, Accuracy_2: 90.1% Loss_2: 0.000347  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000188, Accuracy_2: 83.7% Loss_2: 0.001585  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000308, Accuracy_2: 87.9% Loss_2: 0.001401  [ 2961/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002037, Accuracy_2: 88.7% Loss_2: 0.001344  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001218, Accuracy_2: 87.9% Loss_2: 0.001515  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001389, Accuracy_2: 87.2% Loss_2: 0.001968  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003768, Accuracy_2: 87.2% Loss_2: 0.003048  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001385, Accuracy_2: 86.5% Loss_2: 0.001044  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001023, Accuracy_2: 87.9% Loss_2: 0.003874  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000491, Accuracy_2: 91.5% Loss_2: 0.000605  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000133, Accuracy_2: 91.5% Loss_2: 0.000063  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001551, Accuracy_2: 88.7% Loss_2: 0.000200  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000476, Accuracy_2: 90.1% Loss_2: 0.002309  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001679, Accuracy_2: 89.4% Loss_2: 0.002879  [ 9165/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002159, Accuracy_2: 85.8% Loss_2: 0.000205  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000583, Accuracy_2: 87.2% Loss_2: 0.000575  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001715, Accuracy_2: 90.8% Loss_2: 0.001212  [10857/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003431, Accuracy_2: 85.1% Loss_2: 0.000819  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003214, Accuracy_2: 86.5% Loss_2: 0.002151  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000239, Accuracy_2: 87.2% Loss_2: 0.000572  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002386, Accuracy_2: 89.4% Loss_2: 0.002901  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000997, Accuracy_2: 91.5% Loss_2: 0.000129  [13677/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000219, Accuracy_2: 83.7% Loss_2: 0.001309  [14241/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000991, Accuracy_2: 83.7% Loss_2: 0.002934  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.8%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Accuracy_1: 82.3%, Loss_1: 0.000715, Accuracy_2: 84.4% Loss_2: 0.000575  [  141/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.002535, Accuracy_2: 80.1% Loss_2: 0.001272  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000751, Accuracy_2: 86.5% Loss_2: 0.000750  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000738, Accuracy_2: 88.7% Loss_2: 0.000342  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000076, Accuracy_2: 86.5% Loss_2: 0.000856  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002090, Accuracy_2: 84.4% Loss_2: 0.001021  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000766, Accuracy_2: 87.2% Loss_2: 0.000771  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000120, Accuracy_2: 93.6% Loss_2: 0.002312  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000361, Accuracy_2: 86.5% Loss_2: 0.002452  [ 4653/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001484, Accuracy_2: 87.2% Loss_2: 0.001324  [ 5217/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001306, Accuracy_2: 87.9% Loss_2: 0.002345  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000811, Accuracy_2: 87.9% Loss_2: 0.002406  [ 6345/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002028, Accuracy_2: 84.4% Loss_2: 0.000941  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000131, Accuracy_2: 91.5% Loss_2: 0.000385  [ 7473/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001296, Accuracy_2: 85.8% Loss_2: 0.000158  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000359, Accuracy_2: 92.2% Loss_2: 0.002130  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000110, Accuracy_2: 87.2% Loss_2: 0.000899  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000004, Accuracy_2: 85.1% Loss_2: 0.003232  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000198, Accuracy_2: 91.5% Loss_2: 0.001386  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000875, Accuracy_2: 87.9% Loss_2: 0.000384  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002836, Accuracy_2: 87.9% Loss_2: 0.000693  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000036, Accuracy_2: 86.5% Loss_2: 0.000911  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000563, Accuracy_2: 88.7% Loss_2: 0.000039  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001015, Accuracy_2: 87.9% Loss_2: 0.000959  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000801, Accuracy_2: 84.4% Loss_2: 0.000877  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001605, Accuracy_2: 89.4% Loss_2: 0.001777  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002433, Accuracy_2: 87.9% Loss_2: 0.001610  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001920, Accuracy_2: 80.1% Loss_2: 0.002484  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003727, Accuracy_2: 86.5% Loss_2: 0.001255  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000259, Accuracy_2: 90.8% Loss_2: 0.001122  [ 1269/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001872, Accuracy_2: 85.8% Loss_2: 0.002795  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000018, Accuracy_2: 92.2% Loss_2: 0.000029  [ 2397/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.000528, Accuracy_2: 82.3% Loss_2: 0.002989  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001575, Accuracy_2: 84.4% Loss_2: 0.001513  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000396, Accuracy_2: 89.4% Loss_2: 0.000447  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000020, Accuracy_2: 87.2% Loss_2: 0.001062  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000943, Accuracy_2: 88.7% Loss_2: 0.002111  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000103, Accuracy_2: 90.1% Loss_2: 0.000303  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000414, Accuracy_2: 92.2% Loss_2: 0.000036  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000036, Accuracy_2: 87.2% Loss_2: 0.000136  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000477, Accuracy_2: 90.1% Loss_2: 0.000125  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001307, Accuracy_2: 90.1% Loss_2: 0.000052  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000894, Accuracy_2: 89.4% Loss_2: 0.000537  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001701, Accuracy_2: 90.1% Loss_2: 0.000888  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002609, Accuracy_2: 92.2% Loss_2: 0.000086  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000969, Accuracy_2: 87.2% Loss_2: 0.000473  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000679, Accuracy_2: 90.1% Loss_2: 0.000067  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000365, Accuracy_2: 90.8% Loss_2: 0.000004  [11421/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000124, Accuracy_2: 86.5% Loss_2: 0.000631  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001403, Accuracy_2: 83.7% Loss_2: 0.002537  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000028, Accuracy_2: 89.4% Loss_2: 0.002085  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000333, Accuracy_2: 85.8% Loss_2: 0.001196  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000638, Accuracy_2: 83.7% Loss_2: 0.002560  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000158, Accuracy_2: 85.1% Loss_2: 0.000056  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.5%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000801, Accuracy_2: 94.3% Loss_2: 0.000055  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001014, Accuracy_2: 87.9% Loss_2: 0.000257  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.003971, Accuracy_2: 87.9% Loss_2: 0.000494  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000015, Accuracy_2: 87.2% Loss_2: 0.001797  [ 1833/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.000338, Accuracy_2: 83.7% Loss_2: 0.000049  [ 2397/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002010, Accuracy_2: 86.5% Loss_2: 0.004521  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002623, Accuracy_2: 85.1% Loss_2: 0.000809  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002823, Accuracy_2: 88.7% Loss_2: 0.000043  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001205, Accuracy_2: 90.8% Loss_2: 0.002142  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000331, Accuracy_2: 85.8% Loss_2: 0.001350  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000310, Accuracy_2: 87.2% Loss_2: 0.001057  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001965, Accuracy_2: 85.8% Loss_2: 0.004761  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001167, Accuracy_2: 89.4% Loss_2: 0.000602  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000529, Accuracy_2: 87.2% Loss_2: 0.002777  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000684, Accuracy_2: 89.4% Loss_2: 0.003229  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000237, Accuracy_2: 89.4% Loss_2: 0.001021  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000727, Accuracy_2: 90.1% Loss_2: 0.001423  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001038, Accuracy_2: 92.2% Loss_2: 0.000162  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001072, Accuracy_2: 86.5% Loss_2: 0.002183  [10293/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000646, Accuracy_2: 87.2% Loss_2: 0.000504  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000664, Accuracy_2: 90.8% Loss_2: 0.001631  [11421/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001194, Accuracy_2: 85.1% Loss_2: 0.000654  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000330, Accuracy_2: 88.7% Loss_2: 0.000116  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000162, Accuracy_2: 87.9% Loss_2: 0.000642  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000401, Accuracy_2: 86.5% Loss_2: 0.002617  [13677/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001465, Accuracy_2: 85.8% Loss_2: 0.000722  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000973, Accuracy_2: 87.2% Loss_2: 0.000957  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Accuracy_1: 83.7%, Loss_1: 0.004632, Accuracy_2: 87.9% Loss_2: 0.001350  [  141/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000728, Accuracy_2: 83.0% Loss_2: 0.003177  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000830, Accuracy_2: 90.8% Loss_2: 0.002778  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000062, Accuracy_2: 87.2% Loss_2: 0.000529  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000265, Accuracy_2: 88.7% Loss_2: 0.003857  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001453, Accuracy_2: 87.9% Loss_2: 0.000105  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000350, Accuracy_2: 91.5% Loss_2: 0.000039  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000554, Accuracy_2: 92.9% Loss_2: 0.000911  [ 4089/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000203, Accuracy_2: 87.2% Loss_2: 0.000389  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002868, Accuracy_2: 92.2% Loss_2: 0.000002  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001032, Accuracy_2: 90.8% Loss_2: 0.001788  [ 5781/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002559, Accuracy_2: 87.9% Loss_2: 0.000659  [ 6345/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002214, Accuracy_2: 86.5% Loss_2: 0.000544  [ 6909/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001734, Accuracy_2: 85.8% Loss_2: 0.001164  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000808, Accuracy_2: 87.2% Loss_2: 0.001049  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000366, Accuracy_2: 85.8% Loss_2: 0.000489  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001174, Accuracy_2: 87.9% Loss_2: 0.002925  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000234, Accuracy_2: 87.9% Loss_2: 0.000678  [ 9729/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000691, Accuracy_2: 95.7% Loss_2: 0.000447  [10293/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000418, Accuracy_2: 85.1% Loss_2: 0.000092  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000021, Accuracy_2: 94.3% Loss_2: 0.000019  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000217, Accuracy_2: 88.7% Loss_2: 0.001676  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000058, Accuracy_2: 89.4% Loss_2: 0.000054  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000642, Accuracy_2: 90.1% Loss_2: 0.000983  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000067, Accuracy_2: 87.9% Loss_2: 0.001321  [13677/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002107, Accuracy_2: 84.4% Loss_2: 0.000889  [14241/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000677, Accuracy_2: 87.9% Loss_2: 0.001497  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001396, Accuracy_2: 90.1% Loss_2: 0.000053  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000489, Accuracy_2: 91.5% Loss_2: 0.000532  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001715, Accuracy_2: 87.9% Loss_2: 0.000313  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000091, Accuracy_2: 88.7% Loss_2: 0.000378  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002277, Accuracy_2: 88.7% Loss_2: 0.005108  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001154, Accuracy_2: 90.8% Loss_2: 0.001718  [ 2961/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000362, Accuracy_2: 85.8% Loss_2: 0.001102  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000013, Accuracy_2: 85.8% Loss_2: 0.000005  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001146, Accuracy_2: 89.4% Loss_2: 0.000245  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000081, Accuracy_2: 88.7% Loss_2: 0.001727  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001248, Accuracy_2: 88.7% Loss_2: 0.001449  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001753, Accuracy_2: 85.8% Loss_2: 0.000899  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001242, Accuracy_2: 91.5% Loss_2: 0.000019  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000958, Accuracy_2: 91.5% Loss_2: 0.002324  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001394, Accuracy_2: 85.1% Loss_2: 0.001595  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000809, Accuracy_2: 85.8% Loss_2: 0.002988  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000549, Accuracy_2: 87.2% Loss_2: 0.000465  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000285, Accuracy_2: 88.7% Loss_2: 0.000321  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000112, Accuracy_2: 87.9% Loss_2: 0.000688  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000239, Accuracy_2: 86.5% Loss_2: 0.000744  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001246, Accuracy_2: 90.8% Loss_2: 0.000471  [11421/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.003620, Accuracy_2: 81.6% Loss_2: 0.001106  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002121, Accuracy_2: 87.9% Loss_2: 0.001220  [12549/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000053, Accuracy_2: 82.3% Loss_2: 0.000670  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000358, Accuracy_2: 89.4% Loss_2: 0.002716  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000151, Accuracy_2: 89.4% Loss_2: 0.000241  [14241/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001266, Accuracy_2: 87.2% Loss_2: 0.001713  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000259, Accuracy_2: 91.5% Loss_2: 0.000481  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001062, Accuracy_2: 89.4% Loss_2: 0.000137  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001182, Accuracy_2: 89.4% Loss_2: 0.002772  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000042, Accuracy_2: 87.2% Loss_2: 0.000919  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001752, Accuracy_2: 87.9% Loss_2: 0.002424  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000307, Accuracy_2: 88.7% Loss_2: 0.000653  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.005930, Accuracy_2: 86.5% Loss_2: 0.002860  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000077, Accuracy_2: 90.8% Loss_2: 0.001960  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001537, Accuracy_2: 87.2% Loss_2: 0.000635  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001745, Accuracy_2: 85.1% Loss_2: 0.004909  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001925, Accuracy_2: 92.2% Loss_2: 0.000214  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000425, Accuracy_2: 87.9% Loss_2: 0.001657  [ 6345/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000572, Accuracy_2: 86.5% Loss_2: 0.000290  [ 6909/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001028, Accuracy_2: 84.4% Loss_2: 0.001059  [ 7473/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001484, Accuracy_2: 88.7% Loss_2: 0.000145  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000294, Accuracy_2: 88.7% Loss_2: 0.001723  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000175, Accuracy_2: 85.1% Loss_2: 0.001364  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000155, Accuracy_2: 87.9% Loss_2: 0.001165  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000404, Accuracy_2: 90.8% Loss_2: 0.000206  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000105, Accuracy_2: 90.8% Loss_2: 0.000312  [10857/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001742, Accuracy_2: 83.7% Loss_2: 0.001493  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001073, Accuracy_2: 87.9% Loss_2: 0.002359  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000085, Accuracy_2: 85.1% Loss_2: 0.000533  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003110, Accuracy_2: 90.8% Loss_2: 0.000029  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002694, Accuracy_2: 87.9% Loss_2: 0.001151  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001452, Accuracy_2: 87.2% Loss_2: 0.002034  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000185, Accuracy_2: 89.4% Loss_2: 0.000051  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001404, Accuracy_2: 85.8% Loss_2: 0.001437  [  141/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000333, Accuracy_2: 86.5% Loss_2: 0.001156  [  705/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002569, Accuracy_2: 85.8% Loss_2: 0.001346  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000085, Accuracy_2: 85.8% Loss_2: 0.001664  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000208, Accuracy_2: 87.9% Loss_2: 0.001152  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003002, Accuracy_2: 87.2% Loss_2: 0.003020  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000829, Accuracy_2: 84.4% Loss_2: 0.003473  [ 3525/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002933, Accuracy_2: 87.2% Loss_2: 0.001230  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000117, Accuracy_2: 85.1% Loss_2: 0.000929  [ 4653/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.004085, Accuracy_2: 88.7% Loss_2: 0.002342  [ 5217/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003327, Accuracy_2: 87.2% Loss_2: 0.000444  [ 5781/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001583, Accuracy_2: 80.9% Loss_2: 0.000316  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001017, Accuracy_2: 85.8% Loss_2: 0.001291  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000194, Accuracy_2: 85.8% Loss_2: 0.001736  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000381, Accuracy_2: 85.8% Loss_2: 0.001489  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002435, Accuracy_2: 88.7% Loss_2: 0.003961  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000404, Accuracy_2: 92.2% Loss_2: 0.000096  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001734, Accuracy_2: 91.5% Loss_2: 0.000478  [ 9729/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001355, Accuracy_2: 95.0% Loss_2: 0.000219  [10293/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002567, Accuracy_2: 83.7% Loss_2: 0.000237  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001083, Accuracy_2: 91.5% Loss_2: 0.000842  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003690, Accuracy_2: 92.9% Loss_2: 0.000040  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000566, Accuracy_2: 87.2% Loss_2: 0.002696  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000205, Accuracy_2: 86.5% Loss_2: 0.000557  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001571, Accuracy_2: 92.2% Loss_2: 0.002899  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000983, Accuracy_2: 89.4% Loss_2: 0.000677  [14241/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000546, Accuracy_2: 84.4% Loss_2: 0.000889  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.5%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000013, Accuracy_2: 87.9% Loss_2: 0.001133  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000922, Accuracy_2: 87.2% Loss_2: 0.000053  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000829, Accuracy_2: 86.5% Loss_2: 0.002201  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000155, Accuracy_2: 87.9% Loss_2: 0.001268  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000038, Accuracy_2: 87.9% Loss_2: 0.000034  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000876, Accuracy_2: 87.2% Loss_2: 0.000383  [ 2961/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000373, Accuracy_2: 83.0% Loss_2: 0.001573  [ 3525/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002671, Accuracy_2: 87.9% Loss_2: 0.000847  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000610, Accuracy_2: 89.4% Loss_2: 0.000820  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000406, Accuracy_2: 92.9% Loss_2: 0.000806  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000340, Accuracy_2: 85.1% Loss_2: 0.003244  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000555, Accuracy_2: 89.4% Loss_2: 0.000067  [ 6345/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000520, Accuracy_2: 83.0% Loss_2: 0.001465  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002566, Accuracy_2: 89.4% Loss_2: 0.000214  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001620, Accuracy_2: 86.5% Loss_2: 0.000110  [ 8037/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000591, Accuracy_2: 81.6% Loss_2: 0.001169  [ 8601/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002409, Accuracy_2: 81.6% Loss_2: 0.000623  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001072, Accuracy_2: 92.9% Loss_2: 0.000005  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000220, Accuracy_2: 89.4% Loss_2: 0.000115  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001283, Accuracy_2: 88.7% Loss_2: 0.001151  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000244, Accuracy_2: 89.4% Loss_2: 0.001460  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000380, Accuracy_2: 88.7% Loss_2: 0.000132  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000190, Accuracy_2: 90.8% Loss_2: 0.000408  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000957, Accuracy_2: 87.2% Loss_2: 0.000450  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000744, Accuracy_2: 88.7% Loss_2: 0.003064  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000042, Accuracy_2: 88.7% Loss_2: 0.000986  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001101, Accuracy_2: 91.5% Loss_2: 0.000094  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.1%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000885, Accuracy_2: 89.4% Loss_2: 0.000202  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000985, Accuracy_2: 81.6% Loss_2: 0.002789  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002283, Accuracy_2: 85.1% Loss_2: 0.000507  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001446, Accuracy_2: 93.6% Loss_2: 0.001075  [ 1833/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002449, Accuracy_2: 83.7% Loss_2: 0.001375  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000864, Accuracy_2: 83.7% Loss_2: 0.000971  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000025, Accuracy_2: 88.7% Loss_2: 0.001028  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003176, Accuracy_2: 85.1% Loss_2: 0.001585  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.004102, Accuracy_2: 89.4% Loss_2: 0.002611  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000710, Accuracy_2: 86.5% Loss_2: 0.003477  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000058, Accuracy_2: 87.9% Loss_2: 0.003124  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000133, Accuracy_2: 89.4% Loss_2: 0.002748  [ 6345/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002704, Accuracy_2: 86.5% Loss_2: 0.000509  [ 6909/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001253, Accuracy_2: 84.4% Loss_2: 0.000640  [ 7473/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002651, Accuracy_2: 84.4% Loss_2: 0.001637  [ 8037/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003083, Accuracy_2: 83.7% Loss_2: 0.002359  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000907, Accuracy_2: 89.4% Loss_2: 0.000200  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000398, Accuracy_2: 87.2% Loss_2: 0.002530  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000221, Accuracy_2: 93.6% Loss_2: 0.000401  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000193, Accuracy_2: 89.4% Loss_2: 0.001741  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001071, Accuracy_2: 91.5% Loss_2: 0.000309  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002969, Accuracy_2: 85.1% Loss_2: 0.001522  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000649, Accuracy_2: 84.4% Loss_2: 0.002306  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000014, Accuracy_2: 84.4% Loss_2: 0.000810  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000506, Accuracy_2: 85.1% Loss_2: 0.000421  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002203, Accuracy_2: 92.2% Loss_2: 0.000445  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001424, Accuracy_2: 85.1% Loss_2: 0.002619  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002621, Accuracy_2: 90.1% Loss_2: 0.000904  [  141/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001861, Accuracy_2: 86.5% Loss_2: 0.000224  [  705/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001091, Accuracy_2: 85.1% Loss_2: 0.000309  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001091, Accuracy_2: 90.1% Loss_2: 0.002453  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000769, Accuracy_2: 87.2% Loss_2: 0.001621  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000111, Accuracy_2: 90.8% Loss_2: 0.000044  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000051, Accuracy_2: 87.2% Loss_2: 0.001794  [ 3525/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000374, Accuracy_2: 84.4% Loss_2: 0.001329  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000820, Accuracy_2: 87.9% Loss_2: 0.000221  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000636, Accuracy_2: 86.5% Loss_2: 0.003598  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000044, Accuracy_2: 86.5% Loss_2: 0.002432  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000428, Accuracy_2: 88.7% Loss_2: 0.001786  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000312, Accuracy_2: 83.7% Loss_2: 0.002869  [ 6909/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002566, Accuracy_2: 86.5% Loss_2: 0.000044  [ 7473/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000324, Accuracy_2: 92.9% Loss_2: 0.000219  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000300, Accuracy_2: 92.2% Loss_2: 0.000065  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001031, Accuracy_2: 87.9% Loss_2: 0.001173  [ 9165/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000640, Accuracy_2: 84.4% Loss_2: 0.002747  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000426, Accuracy_2: 90.1% Loss_2: 0.000621  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001211, Accuracy_2: 87.2% Loss_2: 0.001959  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 85.1% Loss_2: 0.001487  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000069, Accuracy_2: 87.2% Loss_2: 0.001180  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000728, Accuracy_2: 89.4% Loss_2: 0.001537  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000338, Accuracy_2: 92.2% Loss_2: 0.000224  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000500, Accuracy_2: 86.5% Loss_2: 0.000207  [13677/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000561, Accuracy_2: 84.4% Loss_2: 0.000610  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000497, Accuracy_2: 87.9% Loss_2: 0.000021  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000642, Accuracy_2: 89.4% Loss_2: 0.000470  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002127, Accuracy_2: 86.5% Loss_2: 0.001336  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000279, Accuracy_2: 92.2% Loss_2: 0.002440  [ 1269/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000371, Accuracy_2: 83.7% Loss_2: 0.004783  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000533, Accuracy_2: 88.7% Loss_2: 0.000414  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.000245  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001374, Accuracy_2: 89.4% Loss_2: 0.000443  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002051, Accuracy_2: 90.1% Loss_2: 0.000308  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000796, Accuracy_2: 85.1% Loss_2: 0.000663  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.001317  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000253, Accuracy_2: 85.1% Loss_2: 0.000888  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001398, Accuracy_2: 91.5% Loss_2: 0.000011  [ 6345/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000036, Accuracy_2: 85.8% Loss_2: 0.000173  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000046, Accuracy_2: 87.9% Loss_2: 0.000056  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000007, Accuracy_2: 87.2% Loss_2: 0.000047  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000489, Accuracy_2: 85.1% Loss_2: 0.001438  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000380, Accuracy_2: 87.2% Loss_2: 0.000249  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001070, Accuracy_2: 90.8% Loss_2: 0.000004  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000016, Accuracy_2: 90.1% Loss_2: 0.000600  [10293/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001114, Accuracy_2: 87.2% Loss_2: 0.000276  [10857/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000265, Accuracy_2: 86.5% Loss_2: 0.000530  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000033, Accuracy_2: 90.1% Loss_2: 0.000036  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000555, Accuracy_2: 89.4% Loss_2: 0.000590  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000480, Accuracy_2: 87.2% Loss_2: 0.001989  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000060, Accuracy_2: 87.2% Loss_2: 0.000653  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000339, Accuracy_2: 89.4% Loss_2: 0.000384  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000233, Accuracy_2: 85.1% Loss_2: 0.000649  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000206, Accuracy_2: 89.4% Loss_2: 0.000318  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000119, Accuracy_2: 86.5% Loss_2: 0.001573  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000895, Accuracy_2: 91.5% Loss_2: 0.000168  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000035, Accuracy_2: 87.9% Loss_2: 0.000063  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001728, Accuracy_2: 87.9% Loss_2: 0.000451  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002285, Accuracy_2: 87.9% Loss_2: 0.001966  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001604, Accuracy_2: 87.9% Loss_2: 0.002483  [ 3525/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000573, Accuracy_2: 86.5% Loss_2: 0.000003  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.004183, Accuracy_2: 90.8% Loss_2: 0.000778  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000820, Accuracy_2: 88.7% Loss_2: 0.000343  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000400, Accuracy_2: 89.4% Loss_2: 0.000006  [ 5781/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000092, Accuracy_2: 85.1% Loss_2: 0.000345  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000348, Accuracy_2: 90.1% Loss_2: 0.000952  [ 6909/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000418, Accuracy_2: 85.1% Loss_2: 0.000594  [ 7473/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000572, Accuracy_2: 87.2% Loss_2: 0.000049  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001814, Accuracy_2: 90.1% Loss_2: 0.000048  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001456, Accuracy_2: 92.2% Loss_2: 0.000023  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000828, Accuracy_2: 85.8% Loss_2: 0.001311  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000017, Accuracy_2: 90.1% Loss_2: 0.001102  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002986, Accuracy_2: 88.7% Loss_2: 0.001022  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000933, Accuracy_2: 90.1% Loss_2: 0.000820  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000269, Accuracy_2: 92.9% Loss_2: 0.000337  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000085, Accuracy_2: 90.1% Loss_2: 0.000347  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000733, Accuracy_2: 90.1% Loss_2: 0.001572  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001946, Accuracy_2: 90.8% Loss_2: 0.003811  [13677/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.003435, Accuracy_2: 84.4% Loss_2: 0.001076  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001196, Accuracy_2: 88.7% Loss_2: 0.000568  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000694, Accuracy_2: 90.1% Loss_2: 0.000204  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000105, Accuracy_2: 86.5% Loss_2: 0.002501  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000288, Accuracy_2: 90.1% Loss_2: 0.000753  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002331, Accuracy_2: 90.8% Loss_2: 0.000397  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000007, Accuracy_2: 89.4% Loss_2: 0.002027  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000107, Accuracy_2: 90.1% Loss_2: 0.000026  [ 2961/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001848, Accuracy_2: 86.5% Loss_2: 0.001128  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000022, Accuracy_2: 87.2% Loss_2: 0.000933  [ 4089/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000421, Accuracy_2: 86.5% Loss_2: 0.003444  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001181, Accuracy_2: 87.9% Loss_2: 0.001069  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000017, Accuracy_2: 87.9% Loss_2: 0.000098  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000107, Accuracy_2: 90.1% Loss_2: 0.001107  [ 6345/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001047, Accuracy_2: 86.5% Loss_2: 0.000176  [ 6909/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.000635, Accuracy_2: 78.7% Loss_2: 0.002605  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001430, Accuracy_2: 86.5% Loss_2: 0.000820  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002020, Accuracy_2: 94.3% Loss_2: 0.000107  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001040, Accuracy_2: 90.8% Loss_2: 0.000031  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000005, Accuracy_2: 91.5% Loss_2: 0.000035  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002359, Accuracy_2: 91.5% Loss_2: 0.000422  [10293/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000207, Accuracy_2: 81.6% Loss_2: 0.005392  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000817, Accuracy_2: 88.7% Loss_2: 0.001437  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000926, Accuracy_2: 93.6% Loss_2: 0.000187  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001608, Accuracy_2: 90.8% Loss_2: 0.001802  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001289, Accuracy_2: 87.9% Loss_2: 0.000690  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000155, Accuracy_2: 90.1% Loss_2: 0.000382  [13677/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000068, Accuracy_2: 83.7% Loss_2: 0.001054  [14241/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000068, Accuracy_2: 93.6% Loss_2: 0.000001  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000049, Accuracy_2: 92.9% Loss_2: 0.001411  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001424, Accuracy_2: 88.7% Loss_2: 0.003025  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001426, Accuracy_2: 87.2% Loss_2: 0.000934  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002668, Accuracy_2: 88.7% Loss_2: 0.001851  [ 1833/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.000218, Accuracy_2: 80.1% Loss_2: 0.000132  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000528, Accuracy_2: 90.1% Loss_2: 0.001269  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001616, Accuracy_2: 93.6% Loss_2: 0.000094  [ 3525/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002065, Accuracy_2: 84.4% Loss_2: 0.002152  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000245, Accuracy_2: 89.4% Loss_2: 0.001581  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002977, Accuracy_2: 89.4% Loss_2: 0.000561  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001068, Accuracy_2: 88.7% Loss_2: 0.000563  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000346, Accuracy_2: 86.5% Loss_2: 0.000905  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000563, Accuracy_2: 88.7% Loss_2: 0.000976  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000833, Accuracy_2: 87.2% Loss_2: 0.000263  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000952, Accuracy_2: 87.9% Loss_2: 0.000151  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001003, Accuracy_2: 86.5% Loss_2: 0.002352  [ 8601/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000839, Accuracy_2: 85.8% Loss_2: 0.000853  [ 9165/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000616, Accuracy_2: 83.7% Loss_2: 0.003000  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001554, Accuracy_2: 90.8% Loss_2: 0.000040  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001486, Accuracy_2: 88.7% Loss_2: 0.001158  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000846, Accuracy_2: 86.5% Loss_2: 0.000503  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001650, Accuracy_2: 92.9% Loss_2: 0.000225  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.004828, Accuracy_2: 87.9% Loss_2: 0.002049  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000266, Accuracy_2: 88.7% Loss_2: 0.001546  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000621, Accuracy_2: 90.1% Loss_2: 0.001265  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.004108, Accuracy_2: 92.9% Loss_2: 0.000342  [14241/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000668, Accuracy_2: 85.1% Loss_2: 0.001127  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002543, Accuracy_2: 87.9% Loss_2: 0.001737  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001275, Accuracy_2: 89.4% Loss_2: 0.000891  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000187, Accuracy_2: 89.4% Loss_2: 0.000103  [ 1269/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000069, Accuracy_2: 84.4% Loss_2: 0.001342  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000123, Accuracy_2: 87.9% Loss_2: 0.001302  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000859, Accuracy_2: 87.9% Loss_2: 0.000189  [ 2961/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000032, Accuracy_2: 85.1% Loss_2: 0.000032  [ 3525/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002266, Accuracy_2: 87.2% Loss_2: 0.001647  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000045, Accuracy_2: 91.5% Loss_2: 0.000500  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000456, Accuracy_2: 89.4% Loss_2: 0.002152  [ 5217/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000003, Accuracy_2: 83.7% Loss_2: 0.000278  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000072, Accuracy_2: 89.4% Loss_2: 0.001509  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001607, Accuracy_2: 87.9% Loss_2: 0.001218  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001663, Accuracy_2: 86.5% Loss_2: 0.000451  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000607, Accuracy_2: 89.4% Loss_2: 0.002619  [ 8037/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002599, Accuracy_2: 85.8% Loss_2: 0.000165  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000067, Accuracy_2: 88.7% Loss_2: 0.002919  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000154, Accuracy_2: 87.9% Loss_2: 0.000973  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000087, Accuracy_2: 85.1% Loss_2: 0.001209  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001351, Accuracy_2: 92.2% Loss_2: 0.001836  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000016, Accuracy_2: 92.9% Loss_2: 0.000302  [11421/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001610, Accuracy_2: 86.5% Loss_2: 0.000156  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000642, Accuracy_2: 89.4% Loss_2: 0.002220  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001243, Accuracy_2: 92.2% Loss_2: 0.000023  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001049, Accuracy_2: 89.4% Loss_2: 0.000078  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000004, Accuracy_2: 87.2% Loss_2: 0.001696  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001037, Accuracy_2: 90.1% Loss_2: 0.000340  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.5%, Avg loss: 0.000001 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001979, Accuracy_2: 88.7% Loss_2: 0.000234  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000782, Accuracy_2: 91.5% Loss_2: 0.002012  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000476, Accuracy_2: 91.5% Loss_2: 0.001690  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000257, Accuracy_2: 90.1% Loss_2: 0.000979  [ 1833/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001234, Accuracy_2: 85.8% Loss_2: 0.000005  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000637, Accuracy_2: 87.2% Loss_2: 0.000963  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000009, Accuracy_2: 90.1% Loss_2: 0.001566  [ 3525/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000928, Accuracy_2: 86.5% Loss_2: 0.000973  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000066, Accuracy_2: 83.7% Loss_2: 0.000214  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001245, Accuracy_2: 90.1% Loss_2: 0.000004  [ 5217/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003688, Accuracy_2: 88.7% Loss_2: 0.001212  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000007, Accuracy_2: 90.1% Loss_2: 0.000170  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000075, Accuracy_2: 89.4% Loss_2: 0.000619  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000827, Accuracy_2: 89.4% Loss_2: 0.001266  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000610, Accuracy_2: 88.7% Loss_2: 0.000097  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002232, Accuracy_2: 88.7% Loss_2: 0.000565  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000046, Accuracy_2: 86.5% Loss_2: 0.000414  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001415, Accuracy_2: 88.7% Loss_2: 0.000939  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000340, Accuracy_2: 88.7% Loss_2: 0.001283  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000153, Accuracy_2: 86.5% Loss_2: 0.000718  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000629, Accuracy_2: 91.5% Loss_2: 0.000610  [11421/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001059, Accuracy_2: 86.5% Loss_2: 0.000331  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000188, Accuracy_2: 88.7% Loss_2: 0.001017  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001840, Accuracy_2: 90.1% Loss_2: 0.000020  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000136, Accuracy_2: 90.1% Loss_2: 0.000369  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000004, Accuracy_2: 86.5% Loss_2: 0.000841  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000184, Accuracy_2: 85.8% Loss_2: 0.000615  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002080, Accuracy_2: 85.1% Loss_2: 0.001592  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001028, Accuracy_2: 90.8% Loss_2: 0.000699  [  705/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002405, Accuracy_2: 84.4% Loss_2: 0.001075  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000735, Accuracy_2: 85.1% Loss_2: 0.001701  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000396, Accuracy_2: 85.1% Loss_2: 0.001557  [ 2397/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002277, Accuracy_2: 85.1% Loss_2: 0.000121  [ 2961/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000002, Accuracy_2: 92.9% Loss_2: 0.000325  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002431, Accuracy_2: 90.1% Loss_2: 0.000349  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000946, Accuracy_2: 84.4% Loss_2: 0.000325  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000056, Accuracy_2: 86.5% Loss_2: 0.003336  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001047, Accuracy_2: 87.2% Loss_2: 0.000838  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000134, Accuracy_2: 87.2% Loss_2: 0.001975  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000092, Accuracy_2: 86.5% Loss_2: 0.000127  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002023, Accuracy_2: 88.7% Loss_2: 0.000937  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000643, Accuracy_2: 90.8% Loss_2: 0.000007  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001939, Accuracy_2: 90.1% Loss_2: 0.000954  [ 8601/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000562, Accuracy_2: 81.6% Loss_2: 0.002354  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000007, Accuracy_2: 85.8% Loss_2: 0.001898  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001165, Accuracy_2: 87.2% Loss_2: 0.001056  [10293/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000652, Accuracy_2: 87.9% Loss_2: 0.000003  [10857/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000874, Accuracy_2: 90.8% Loss_2: 0.001868  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000037, Accuracy_2: 87.2% Loss_2: 0.001596  [11985/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001763, Accuracy_2: 87.9% Loss_2: 0.002164  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000200, Accuracy_2: 92.2% Loss_2: 0.001064  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000214, Accuracy_2: 86.5% Loss_2: 0.000313  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001132, Accuracy_2: 87.2% Loss_2: 0.000491  [14241/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001470, Accuracy_2: 85.1% Loss_2: 0.001839  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000004, Accuracy_2: 87.2% Loss_2: 0.000793  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001709, Accuracy_2: 86.5% Loss_2: 0.001063  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000041, Accuracy_2: 92.2% Loss_2: 0.000008  [ 1269/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002087, Accuracy_2: 85.8% Loss_2: 0.000142  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001603, Accuracy_2: 89.4% Loss_2: 0.000003  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000490, Accuracy_2: 88.7% Loss_2: 0.000654  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001420, Accuracy_2: 90.8% Loss_2: 0.000360  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001364, Accuracy_2: 87.2% Loss_2: 0.002002  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000418, Accuracy_2: 90.8% Loss_2: 0.000001  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000215, Accuracy_2: 89.4% Loss_2: 0.000379  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000439, Accuracy_2: 87.2% Loss_2: 0.000344  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000995, Accuracy_2: 87.9% Loss_2: 0.001539  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003071, Accuracy_2: 88.7% Loss_2: 0.000594  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000629, Accuracy_2: 90.1% Loss_2: 0.000379  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001698, Accuracy_2: 89.4% Loss_2: 0.001311  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000010, Accuracy_2: 89.4% Loss_2: 0.002505  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000562, Accuracy_2: 91.5% Loss_2: 0.000385  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000256, Accuracy_2: 90.1% Loss_2: 0.001249  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001212, Accuracy_2: 87.2% Loss_2: 0.001423  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001701, Accuracy_2: 92.9% Loss_2: 0.000102  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001892, Accuracy_2: 87.2% Loss_2: 0.002590  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002912, Accuracy_2: 90.1% Loss_2: 0.000316  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000711, Accuracy_2: 89.4% Loss_2: 0.002044  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000981, Accuracy_2: 87.9% Loss_2: 0.000990  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000018, Accuracy_2: 87.9% Loss_2: 0.000463  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000883, Accuracy_2: 87.9% Loss_2: 0.001456  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000065, Accuracy_2: 87.2% Loss_2: 0.002145  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000546, Accuracy_2: 90.1% Loss_2: 0.000617  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003875, Accuracy_2: 86.5% Loss_2: 0.001495  [  705/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000306, Accuracy_2: 86.5% Loss_2: 0.000735  [ 1269/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001159, Accuracy_2: 87.9% Loss_2: 0.001084  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000005, Accuracy_2: 84.4% Loss_2: 0.002167  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002124, Accuracy_2: 84.4% Loss_2: 0.000558  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000981, Accuracy_2: 91.5% Loss_2: 0.000369  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000681, Accuracy_2: 88.7% Loss_2: 0.001861  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000053, Accuracy_2: 89.4% Loss_2: 0.000121  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000946, Accuracy_2: 89.4% Loss_2: 0.000960  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001217, Accuracy_2: 90.1% Loss_2: 0.000134  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000008, Accuracy_2: 83.0% Loss_2: 0.000861  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000199, Accuracy_2: 90.8% Loss_2: 0.000017  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000141, Accuracy_2: 92.9% Loss_2: 0.000098  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.003027, Accuracy_2: 86.5% Loss_2: 0.000681  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000133, Accuracy_2: 87.2% Loss_2: 0.000272  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000006, Accuracy_2: 91.5% Loss_2: 0.000234  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001977, Accuracy_2: 91.5% Loss_2: 0.000039  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000044, Accuracy_2: 87.2% Loss_2: 0.000315  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001644, Accuracy_2: 88.7% Loss_2: 0.000776  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000113, Accuracy_2: 85.8% Loss_2: 0.000082  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002345, Accuracy_2: 87.9% Loss_2: 0.001465  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000244, Accuracy_2: 87.9% Loss_2: 0.000269  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001176, Accuracy_2: 90.8% Loss_2: 0.000127  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001002, Accuracy_2: 88.7% Loss_2: 0.000402  [13677/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001068, Accuracy_2: 87.2% Loss_2: 0.000407  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001570, Accuracy_2: 90.1% Loss_2: 0.000480  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001136, Accuracy_2: 90.1% Loss_2: 0.002455  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002027, Accuracy_2: 87.9% Loss_2: 0.002583  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001050, Accuracy_2: 84.4% Loss_2: 0.001628  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000207, Accuracy_2: 92.9% Loss_2: 0.000931  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000330, Accuracy_2: 89.4% Loss_2: 0.000077  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001469, Accuracy_2: 90.1% Loss_2: 0.000282  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000029, Accuracy_2: 87.2% Loss_2: 0.002309  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001396, Accuracy_2: 85.1% Loss_2: 0.002750  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000803, Accuracy_2: 87.2% Loss_2: 0.000762  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001250, Accuracy_2: 92.9% Loss_2: 0.002902  [ 5217/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002605, Accuracy_2: 85.8% Loss_2: 0.000627  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000061, Accuracy_2: 89.4% Loss_2: 0.001194  [ 6345/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002771, Accuracy_2: 85.1% Loss_2: 0.000018  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003475, Accuracy_2: 91.5% Loss_2: 0.000003  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000696, Accuracy_2: 86.5% Loss_2: 0.000329  [ 8037/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000269, Accuracy_2: 93.6% Loss_2: 0.000337  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000446, Accuracy_2: 89.4% Loss_2: 0.000946  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000025, Accuracy_2: 85.1% Loss_2: 0.002596  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.004834, Accuracy_2: 86.5% Loss_2: 0.000714  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001524, Accuracy_2: 91.5% Loss_2: 0.001831  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001454, Accuracy_2: 85.8% Loss_2: 0.002168  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001289, Accuracy_2: 87.9% Loss_2: 0.000703  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000031, Accuracy_2: 90.1% Loss_2: 0.001189  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003467, Accuracy_2: 89.4% Loss_2: 0.000023  [13113/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001542, Accuracy_2: 83.0% Loss_2: 0.002620  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000986, Accuracy_2: 90.1% Loss_2: 0.002050  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003250, Accuracy_2: 89.4% Loss_2: 0.001236  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000392, Accuracy_2: 90.8% Loss_2: 0.000705  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003069, Accuracy_2: 88.7% Loss_2: 0.000709  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000061, Accuracy_2: 87.2% Loss_2: 0.002597  [ 1269/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002991, Accuracy_2: 84.4% Loss_2: 0.001243  [ 1833/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.000595, Accuracy_2: 80.9% Loss_2: 0.000071  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001027, Accuracy_2: 86.5% Loss_2: 0.002675  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000698, Accuracy_2: 91.5% Loss_2: 0.001129  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000326, Accuracy_2: 86.5% Loss_2: 0.000172  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000908, Accuracy_2: 90.1% Loss_2: 0.001423  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000584, Accuracy_2: 89.4% Loss_2: 0.000842  [ 5217/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001317, Accuracy_2: 83.7% Loss_2: 0.000028  [ 5781/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001152, Accuracy_2: 87.2% Loss_2: 0.000004  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001702, Accuracy_2: 84.4% Loss_2: 0.001337  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001299, Accuracy_2: 88.7% Loss_2: 0.000326  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000319, Accuracy_2: 85.8% Loss_2: 0.002912  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002331, Accuracy_2: 87.9% Loss_2: 0.001577  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001252, Accuracy_2: 87.2% Loss_2: 0.004940  [ 9165/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003588, Accuracy_2: 86.5% Loss_2: 0.001882  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000526, Accuracy_2: 90.1% Loss_2: 0.000009  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002660, Accuracy_2: 90.8% Loss_2: 0.001262  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000907, Accuracy_2: 92.2% Loss_2: 0.002115  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000028, Accuracy_2: 88.7% Loss_2: 0.000532  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000908, Accuracy_2: 87.9% Loss_2: 0.002055  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001135, Accuracy_2: 90.1% Loss_2: 0.000287  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000350, Accuracy_2: 87.9% Loss_2: 0.000569  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000223, Accuracy_2: 89.4% Loss_2: 0.001154  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000006, Accuracy_2: 87.2% Loss_2: 0.000002  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.2%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000020, Accuracy_2: 81.6% Loss_2: 0.001807  [  141/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000214, Accuracy_2: 85.8% Loss_2: 0.002155  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000524, Accuracy_2: 87.2% Loss_2: 0.000158  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000314, Accuracy_2: 93.6% Loss_2: 0.000196  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000377, Accuracy_2: 87.9% Loss_2: 0.000004  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001310, Accuracy_2: 87.9% Loss_2: 0.000441  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000282, Accuracy_2: 89.4% Loss_2: 0.001399  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000142, Accuracy_2: 85.8% Loss_2: 0.001669  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000085, Accuracy_2: 87.9% Loss_2: 0.003616  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000554, Accuracy_2: 85.8% Loss_2: 0.000318  [ 5217/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000886, Accuracy_2: 83.0% Loss_2: 0.001217  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000002, Accuracy_2: 86.5% Loss_2: 0.000466  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000757, Accuracy_2: 89.4% Loss_2: 0.000870  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000734, Accuracy_2: 87.9% Loss_2: 0.000559  [ 7473/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001559, Accuracy_2: 86.5% Loss_2: 0.002703  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000007, Accuracy_2: 88.7% Loss_2: 0.000134  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000060, Accuracy_2: 89.4% Loss_2: 0.000005  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000595, Accuracy_2: 90.1% Loss_2: 0.000384  [ 9729/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001204, Accuracy_2: 85.1% Loss_2: 0.000230  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000591, Accuracy_2: 88.7% Loss_2: 0.000196  [10857/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000842, Accuracy_2: 85.8% Loss_2: 0.001778  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002105, Accuracy_2: 88.7% Loss_2: 0.000124  [11985/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003261, Accuracy_2: 85.1% Loss_2: 0.000780  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000213, Accuracy_2: 85.8% Loss_2: 0.000880  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000315, Accuracy_2: 86.5% Loss_2: 0.000637  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000927, Accuracy_2: 87.2% Loss_2: 0.001740  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001147, Accuracy_2: 90.8% Loss_2: 0.000056  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001271, Accuracy_2: 85.8% Loss_2: 0.000998  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003681, Accuracy_2: 88.7% Loss_2: 0.000344  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001105, Accuracy_2: 87.9% Loss_2: 0.001096  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000694, Accuracy_2: 89.4% Loss_2: 0.000092  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002750, Accuracy_2: 89.4% Loss_2: 0.001074  [ 2397/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000536, Accuracy_2: 85.8% Loss_2: 0.001936  [ 2961/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001522, Accuracy_2: 84.4% Loss_2: 0.000048  [ 3525/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002438, Accuracy_2: 85.1% Loss_2: 0.000480  [ 4089/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001918, Accuracy_2: 80.9% Loss_2: 0.002457  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000019, Accuracy_2: 87.2% Loss_2: 0.001173  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000085, Accuracy_2: 90.1% Loss_2: 0.004969  [ 5781/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000415, Accuracy_2: 83.0% Loss_2: 0.000606  [ 6345/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000990, Accuracy_2: 93.6% Loss_2: 0.000408  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001536, Accuracy_2: 88.7% Loss_2: 0.002412  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001982, Accuracy_2: 92.9% Loss_2: 0.001849  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000902, Accuracy_2: 89.4% Loss_2: 0.001068  [ 8601/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000764, Accuracy_2: 85.1% Loss_2: 0.000027  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000389, Accuracy_2: 85.1% Loss_2: 0.001262  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001596, Accuracy_2: 89.4% Loss_2: 0.000075  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000915, Accuracy_2: 85.8% Loss_2: 0.001831  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000135, Accuracy_2: 87.2% Loss_2: 0.001748  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000014, Accuracy_2: 87.9% Loss_2: 0.001771  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003108, Accuracy_2: 86.5% Loss_2: 0.000754  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001161, Accuracy_2: 88.7% Loss_2: 0.000704  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000514, Accuracy_2: 90.1% Loss_2: 0.000004  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001436, Accuracy_2: 88.7% Loss_2: 0.000927  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003365, Accuracy_2: 90.1% Loss_2: 0.000102  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000900, Accuracy_2: 90.1% Loss_2: 0.001042  [  141/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000754, Accuracy_2: 93.6% Loss_2: 0.000736  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000879, Accuracy_2: 89.4% Loss_2: 0.000039  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001814, Accuracy_2: 87.9% Loss_2: 0.000976  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001560, Accuracy_2: 92.2% Loss_2: 0.000012  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002014, Accuracy_2: 88.7% Loss_2: 0.000730  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000441, Accuracy_2: 90.8% Loss_2: 0.000978  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001495, Accuracy_2: 88.7% Loss_2: 0.000480  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000787, Accuracy_2: 87.2% Loss_2: 0.001612  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001164, Accuracy_2: 92.2% Loss_2: 0.000103  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002434, Accuracy_2: 87.9% Loss_2: 0.002391  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000015, Accuracy_2: 92.9% Loss_2: 0.000049  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000347, Accuracy_2: 89.4% Loss_2: 0.000028  [ 6909/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001585, Accuracy_2: 81.6% Loss_2: 0.004050  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002040, Accuracy_2: 89.4% Loss_2: 0.001599  [ 8037/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001668, Accuracy_2: 85.1% Loss_2: 0.000508  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001154, Accuracy_2: 85.8% Loss_2: 0.002008  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000419, Accuracy_2: 88.7% Loss_2: 0.002606  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000682, Accuracy_2: 86.5% Loss_2: 0.000313  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001470, Accuracy_2: 90.1% Loss_2: 0.000420  [10857/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000191, Accuracy_2: 83.0% Loss_2: 0.002121  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000081, Accuracy_2: 88.7% Loss_2: 0.001518  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000389, Accuracy_2: 89.4% Loss_2: 0.000484  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000008, Accuracy_2: 90.1% Loss_2: 0.001317  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001514, Accuracy_2: 89.4% Loss_2: 0.000245  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000487, Accuracy_2: 91.5% Loss_2: 0.001484  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000726, Accuracy_2: 86.5% Loss_2: 0.001149  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000023, Accuracy_2: 87.2% Loss_2: 0.001113  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001064, Accuracy_2: 89.4% Loss_2: 0.000947  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000067, Accuracy_2: 88.7% Loss_2: 0.001522  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000221, Accuracy_2: 92.2% Loss_2: 0.000603  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002597, Accuracy_2: 88.7% Loss_2: 0.000166  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000747, Accuracy_2: 88.7% Loss_2: 0.001226  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001546, Accuracy_2: 89.4% Loss_2: 0.000278  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000009, Accuracy_2: 88.7% Loss_2: 0.000930  [ 4089/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000700, Accuracy_2: 85.1% Loss_2: 0.000003  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000437, Accuracy_2: 87.2% Loss_2: 0.002060  [ 5217/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000876, Accuracy_2: 92.9% Loss_2: 0.000529  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000704, Accuracy_2: 91.5% Loss_2: 0.000008  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000693  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000004, Accuracy_2: 90.1% Loss_2: 0.001027  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000283, Accuracy_2: 91.5% Loss_2: 0.001305  [ 8037/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001595, Accuracy_2: 87.2% Loss_2: 0.000908  [ 8601/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002448, Accuracy_2: 85.8% Loss_2: 0.000449  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001254, Accuracy_2: 94.3% Loss_2: 0.000138  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001982, Accuracy_2: 85.1% Loss_2: 0.000210  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001192, Accuracy_2: 89.4% Loss_2: 0.000883  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000531, Accuracy_2: 87.9% Loss_2: 0.000006  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000638, Accuracy_2: 91.5% Loss_2: 0.002674  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001134, Accuracy_2: 88.7% Loss_2: 0.000054  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000087, Accuracy_2: 91.5% Loss_2: 0.000754  [13113/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000708, Accuracy_2: 83.7% Loss_2: 0.000807  [13677/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.000259, Accuracy_2: 83.0% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000641, Accuracy_2: 89.4% Loss_2: 0.000630  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000005, Accuracy_2: 87.9% Loss_2: 0.000662  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002550, Accuracy_2: 87.9% Loss_2: 0.001667  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002746, Accuracy_2: 88.7% Loss_2: 0.000012  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000211, Accuracy_2: 90.1% Loss_2: 0.000150  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001840, Accuracy_2: 87.9% Loss_2: 0.001509  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001247, Accuracy_2: 87.9% Loss_2: 0.000711  [ 2961/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002416, Accuracy_2: 83.7% Loss_2: 0.000009  [ 3525/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000567, Accuracy_2: 85.1% Loss_2: 0.000035  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000398, Accuracy_2: 86.5% Loss_2: 0.001091  [ 4653/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001790, Accuracy_2: 86.5% Loss_2: 0.000915  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000029, Accuracy_2: 88.7% Loss_2: 0.001181  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000363, Accuracy_2: 85.1% Loss_2: 0.003554  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002292, Accuracy_2: 85.1% Loss_2: 0.000020  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000090, Accuracy_2: 90.8% Loss_2: 0.000011  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000004, Accuracy_2: 90.8% Loss_2: 0.000937  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001531, Accuracy_2: 87.2% Loss_2: 0.001278  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000463, Accuracy_2: 87.2% Loss_2: 0.000110  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001702, Accuracy_2: 87.9% Loss_2: 0.001066  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000433, Accuracy_2: 88.7% Loss_2: 0.000391  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001332, Accuracy_2: 87.9% Loss_2: 0.002030  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000484, Accuracy_2: 87.9% Loss_2: 0.000026  [11421/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002892, Accuracy_2: 86.5% Loss_2: 0.000835  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000744, Accuracy_2: 88.7% Loss_2: 0.000173  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000107, Accuracy_2: 90.8% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002822, Accuracy_2: 90.1% Loss_2: 0.002887  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000550, Accuracy_2: 90.1% Loss_2: 0.000067  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000099, Accuracy_2: 91.5% Loss_2: 0.001825  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001318, Accuracy_2: 90.1% Loss_2: 0.000607  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.004014, Accuracy_2: 90.8% Loss_2: 0.001629  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001648, Accuracy_2: 87.2% Loss_2: 0.000290  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001023, Accuracy_2: 88.7% Loss_2: 0.003510  [ 1833/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000338, Accuracy_2: 83.7% Loss_2: 0.001995  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000007, Accuracy_2: 90.8% Loss_2: 0.000769  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000542, Accuracy_2: 89.4% Loss_2: 0.001327  [ 3525/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001595, Accuracy_2: 80.9% Loss_2: 0.002204  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001712, Accuracy_2: 87.2% Loss_2: 0.000554  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003142, Accuracy_2: 90.1% Loss_2: 0.000001  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000016, Accuracy_2: 90.1% Loss_2: 0.000102  [ 5781/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002971, Accuracy_2: 85.8% Loss_2: 0.005832  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000027, Accuracy_2: 90.8% Loss_2: 0.000005  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000423, Accuracy_2: 88.7% Loss_2: 0.004012  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000434, Accuracy_2: 90.8% Loss_2: 0.000183  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001511, Accuracy_2: 87.9% Loss_2: 0.001349  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001055, Accuracy_2: 85.8% Loss_2: 0.000636  [ 9165/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000003, Accuracy_2: 91.5% Loss_2: 0.001272  [ 9729/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000014, Accuracy_2: 82.3% Loss_2: 0.000752  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001847, Accuracy_2: 92.9% Loss_2: 0.000004  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002370, Accuracy_2: 90.1% Loss_2: 0.000550  [11421/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000003, Accuracy_2: 95.7% Loss_2: 0.000013  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000164, Accuracy_2: 88.7% Loss_2: 0.000660  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000843, Accuracy_2: 88.7% Loss_2: 0.001043  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.003069, Accuracy_2: 89.4% Loss_2: 0.000170  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000122, Accuracy_2: 89.4% Loss_2: 0.000482  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000067, Accuracy_2: 88.7% Loss_2: 0.002078  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002888, Accuracy_2: 92.2% Loss_2: 0.001304  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000762, Accuracy_2: 90.1% Loss_2: 0.000006  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001141, Accuracy_2: 89.4% Loss_2: 0.000366  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001015, Accuracy_2: 85.8% Loss_2: 0.001920  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000907, Accuracy_2: 89.4% Loss_2: 0.000709  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000728, Accuracy_2: 87.2% Loss_2: 0.001482  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000787, Accuracy_2: 87.9% Loss_2: 0.000722  [ 3525/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.004135, Accuracy_2: 84.4% Loss_2: 0.003302  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000383, Accuracy_2: 88.7% Loss_2: 0.000174  [ 4653/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002626, Accuracy_2: 84.4% Loss_2: 0.000477  [ 5217/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001309, Accuracy_2: 86.5% Loss_2: 0.002361  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000027, Accuracy_2: 85.1% Loss_2: 0.002479  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001208, Accuracy_2: 88.7% Loss_2: 0.004207  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002593, Accuracy_2: 93.6% Loss_2: 0.000095  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001044, Accuracy_2: 92.9% Loss_2: 0.000690  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001206, Accuracy_2: 85.8% Loss_2: 0.002257  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000265, Accuracy_2: 89.4% Loss_2: 0.001053  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000266, Accuracy_2: 88.7% Loss_2: 0.000106  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001189, Accuracy_2: 95.0% Loss_2: 0.000062  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000020, Accuracy_2: 87.2% Loss_2: 0.000375  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000053, Accuracy_2: 90.8% Loss_2: 0.000128  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002493, Accuracy_2: 92.2% Loss_2: 0.000073  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000612, Accuracy_2: 90.8% Loss_2: 0.000239  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000200, Accuracy_2: 90.1% Loss_2: 0.000068  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000123, Accuracy_2: 87.2% Loss_2: 0.002440  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000099, Accuracy_2: 92.2% Loss_2: 0.000491  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000474, Accuracy_2: 90.1% Loss_2: 0.000830  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001532, Accuracy_2: 83.0% Loss_2: 0.000180  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001716, Accuracy_2: 91.5% Loss_2: 0.000035  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000132, Accuracy_2: 88.7% Loss_2: 0.002269  [ 1269/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000427, Accuracy_2: 87.9% Loss_2: 0.001726  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000885, Accuracy_2: 92.2% Loss_2: 0.000013  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000715  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000151, Accuracy_2: 92.2% Loss_2: 0.000797  [ 3525/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001198, Accuracy_2: 85.8% Loss_2: 0.002077  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000057, Accuracy_2: 90.1% Loss_2: 0.000264  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001573, Accuracy_2: 87.9% Loss_2: 0.000060  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000069, Accuracy_2: 88.7% Loss_2: 0.000903  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000258, Accuracy_2: 87.2% Loss_2: 0.000036  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000526, Accuracy_2: 87.9% Loss_2: 0.003740  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000131, Accuracy_2: 90.1% Loss_2: 0.000089  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000176, Accuracy_2: 91.5% Loss_2: 0.000109  [ 8037/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000459, Accuracy_2: 83.7% Loss_2: 0.001407  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000007, Accuracy_2: 87.9% Loss_2: 0.000326  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.004639, Accuracy_2: 93.6% Loss_2: 0.000258  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000365, Accuracy_2: 85.8% Loss_2: 0.001591  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001082, Accuracy_2: 87.9% Loss_2: 0.000333  [10857/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000776, Accuracy_2: 85.8% Loss_2: 0.001277  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000459, Accuracy_2: 90.8% Loss_2: 0.000677  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000501, Accuracy_2: 89.4% Loss_2: 0.000358  [12549/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000103, Accuracy_2: 83.7% Loss_2: 0.001070  [13113/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000503, Accuracy_2: 85.8% Loss_2: 0.000002  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001556, Accuracy_2: 88.7% Loss_2: 0.000147  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000654, Accuracy_2: 93.6% Loss_2: 0.000035  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000546, Accuracy_2: 91.5% Loss_2: 0.000836  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000262, Accuracy_2: 87.9% Loss_2: 0.000389  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000364, Accuracy_2: 92.9% Loss_2: 0.000003  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001286, Accuracy_2: 92.2% Loss_2: 0.000022  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000304, Accuracy_2: 89.4% Loss_2: 0.001649  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000060, Accuracy_2: 90.1% Loss_2: 0.000018  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000424, Accuracy_2: 88.7% Loss_2: 0.001667  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000833, Accuracy_2: 92.9% Loss_2: 0.000387  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000185, Accuracy_2: 91.5% Loss_2: 0.001368  [ 4653/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002385, Accuracy_2: 84.4% Loss_2: 0.002121  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000668  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000031, Accuracy_2: 90.1% Loss_2: 0.000152  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001571, Accuracy_2: 91.5% Loss_2: 0.001146  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000002, Accuracy_2: 84.4% Loss_2: 0.002689  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000185, Accuracy_2: 88.7% Loss_2: 0.000143  [ 8037/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000007, Accuracy_2: 80.1% Loss_2: 0.001763  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000409, Accuracy_2: 92.9% Loss_2: 0.000012  [ 9165/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000662, Accuracy_2: 87.2% Loss_2: 0.000448  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000027, Accuracy_2: 91.5% Loss_2: 0.000538  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000007, Accuracy_2: 94.3% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000726, Accuracy_2: 87.2% Loss_2: 0.000028  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000552, Accuracy_2: 88.7% Loss_2: 0.002707  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001416, Accuracy_2: 88.7% Loss_2: 0.000876  [12549/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002180, Accuracy_2: 85.8% Loss_2: 0.001620  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000639, Accuracy_2: 86.5% Loss_2: 0.000354  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.003211, Accuracy_2: 95.0% Loss_2: 0.000093  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001937, Accuracy_2: 92.2% Loss_2: 0.000136  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001814, Accuracy_2: 87.2% Loss_2: 0.001127  [  141/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000184, Accuracy_2: 92.9% Loss_2: 0.000065  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000224, Accuracy_2: 84.4% Loss_2: 0.002172  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001881, Accuracy_2: 87.2% Loss_2: 0.000713  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000835, Accuracy_2: 88.7% Loss_2: 0.000968  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000806, Accuracy_2: 91.5% Loss_2: 0.000496  [ 2961/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000340, Accuracy_2: 87.2% Loss_2: 0.000253  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000815, Accuracy_2: 89.4% Loss_2: 0.000586  [ 4089/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000431, Accuracy_2: 82.3% Loss_2: 0.002199  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000452, Accuracy_2: 87.9% Loss_2: 0.000034  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000104, Accuracy_2: 92.9% Loss_2: 0.000024  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000163, Accuracy_2: 90.8% Loss_2: 0.000105  [ 6345/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000443, Accuracy_2: 83.0% Loss_2: 0.000654  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.000340  [ 7473/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002755, Accuracy_2: 83.7% Loss_2: 0.000826  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001928, Accuracy_2: 86.5% Loss_2: 0.000686  [ 8601/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001200, Accuracy_2: 86.5% Loss_2: 0.000977  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000214, Accuracy_2: 90.8% Loss_2: 0.001271  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000707, Accuracy_2: 87.9% Loss_2: 0.000365  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000927, Accuracy_2: 88.7% Loss_2: 0.003429  [10857/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002116, Accuracy_2: 87.2% Loss_2: 0.000130  [11421/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000021, Accuracy_2: 93.6% Loss_2: 0.001865  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001956, Accuracy_2: 92.9% Loss_2: 0.000107  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000875, Accuracy_2: 89.4% Loss_2: 0.000551  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000105, Accuracy_2: 87.2% Loss_2: 0.001602  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001359, Accuracy_2: 91.5% Loss_2: 0.000262  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001417, Accuracy_2: 89.4% Loss_2: 0.001526  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 80.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000607, Accuracy_2: 87.9% Loss_2: 0.002164  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003052, Accuracy_2: 91.5% Loss_2: 0.000867  [  705/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001775, Accuracy_2: 83.7% Loss_2: 0.003675  [ 1269/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003157, Accuracy_2: 87.2% Loss_2: 0.000209  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000036, Accuracy_2: 90.1% Loss_2: 0.000146  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000003, Accuracy_2: 87.9% Loss_2: 0.000249  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000363, Accuracy_2: 84.4% Loss_2: 0.001649  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000372, Accuracy_2: 88.7% Loss_2: 0.001463  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003601, Accuracy_2: 92.2% Loss_2: 0.000165  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000058, Accuracy_2: 90.1% Loss_2: 0.000023  [ 5217/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000490, Accuracy_2: 81.6% Loss_2: 0.001026  [ 5781/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.000120, Accuracy_2: 82.3% Loss_2: 0.000988  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000007, Accuracy_2: 87.9% Loss_2: 0.001394  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000177, Accuracy_2: 87.2% Loss_2: 0.002843  [ 7473/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000693, Accuracy_2: 83.7% Loss_2: 0.000604  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000359, Accuracy_2: 90.8% Loss_2: 0.000018  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000731, Accuracy_2: 92.2% Loss_2: 0.000204  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001655, Accuracy_2: 93.6% Loss_2: 0.003283  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002055, Accuracy_2: 90.8% Loss_2: 0.000027  [10293/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002227, Accuracy_2: 87.2% Loss_2: 0.000504  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.004089, Accuracy_2: 93.6% Loss_2: 0.001514  [11421/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001247, Accuracy_2: 85.8% Loss_2: 0.001207  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000045, Accuracy_2: 90.8% Loss_2: 0.000002  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000481, Accuracy_2: 92.2% Loss_2: 0.000057  [13113/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000861, Accuracy_2: 84.4% Loss_2: 0.001844  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001414, Accuracy_2: 89.4% Loss_2: 0.000439  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002610, Accuracy_2: 88.7% Loss_2: 0.001383  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000940, Accuracy_2: 91.5% Loss_2: 0.002198  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000898, Accuracy_2: 88.7% Loss_2: 0.000247  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000003, Accuracy_2: 92.9% Loss_2: 0.000043  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000696, Accuracy_2: 92.2% Loss_2: 0.000002  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000997, Accuracy_2: 90.1% Loss_2: 0.001565  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000686, Accuracy_2: 86.5% Loss_2: 0.001544  [ 2961/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000708, Accuracy_2: 85.8% Loss_2: 0.000344  [ 3525/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002469, Accuracy_2: 86.5% Loss_2: 0.001446  [ 4089/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000200, Accuracy_2: 92.9% Loss_2: 0.000103  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000239, Accuracy_2: 93.6% Loss_2: 0.001840  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000005, Accuracy_2: 90.8% Loss_2: 0.000063  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000066, Accuracy_2: 94.3% Loss_2: 0.000632  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000171, Accuracy_2: 88.7% Loss_2: 0.001011  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000003, Accuracy_2: 89.4% Loss_2: 0.000411  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000385, Accuracy_2: 87.2% Loss_2: 0.000295  [ 8037/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002410, Accuracy_2: 87.9% Loss_2: 0.000028  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001400, Accuracy_2: 85.8% Loss_2: 0.000938  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000624, Accuracy_2: 86.5% Loss_2: 0.002318  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003080, Accuracy_2: 85.8% Loss_2: 0.002851  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000213, Accuracy_2: 84.4% Loss_2: 0.001133  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000786, Accuracy_2: 92.2% Loss_2: 0.000100  [11421/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001175, Accuracy_2: 82.3% Loss_2: 0.001006  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001079, Accuracy_2: 85.8% Loss_2: 0.000614  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000025, Accuracy_2: 92.9% Loss_2: 0.001561  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000082, Accuracy_2: 87.2% Loss_2: 0.000728  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000778, Accuracy_2: 88.7% Loss_2: 0.000737  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000558, Accuracy_2: 90.8% Loss_2: 0.000301  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002593, Accuracy_2: 88.7% Loss_2: 0.001216  [  141/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002858, Accuracy_2: 80.9% Loss_2: 0.001884  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000698, Accuracy_2: 89.4% Loss_2: 0.000229  [ 1269/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001861, Accuracy_2: 86.5% Loss_2: 0.001622  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000313, Accuracy_2: 87.2% Loss_2: 0.000149  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000418, Accuracy_2: 90.1% Loss_2: 0.000102  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001246, Accuracy_2: 91.5% Loss_2: 0.000064  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000013, Accuracy_2: 89.4% Loss_2: 0.000247  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000011, Accuracy_2: 89.4% Loss_2: 0.000051  [ 4653/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000457, Accuracy_2: 85.8% Loss_2: 0.000747  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001836, Accuracy_2: 92.2% Loss_2: 0.000001  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001267, Accuracy_2: 89.4% Loss_2: 0.000027  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000613, Accuracy_2: 91.5% Loss_2: 0.000008  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000664, Accuracy_2: 87.2% Loss_2: 0.002169  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000599, Accuracy_2: 87.9% Loss_2: 0.000016  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001120, Accuracy_2: 86.5% Loss_2: 0.003501  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001441, Accuracy_2: 89.4% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 85.8% Loss_2: 0.000374  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000045, Accuracy_2: 87.9% Loss_2: 0.000619  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000144, Accuracy_2: 87.9% Loss_2: 0.001096  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000040, Accuracy_2: 89.4% Loss_2: 0.000780  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000202, Accuracy_2: 87.9% Loss_2: 0.001123  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003654, Accuracy_2: 86.5% Loss_2: 0.000548  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000812, Accuracy_2: 90.8% Loss_2: 0.002096  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001585, Accuracy_2: 90.8% Loss_2: 0.000615  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003062, Accuracy_2: 90.8% Loss_2: 0.001258  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001440, Accuracy_2: 90.8% Loss_2: 0.000298  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000821  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000777, Accuracy_2: 89.4% Loss_2: 0.002164  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.002022  [ 1269/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000552, Accuracy_2: 85.8% Loss_2: 0.000857  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000242, Accuracy_2: 88.7% Loss_2: 0.000035  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000512, Accuracy_2: 92.2% Loss_2: 0.000070  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000001  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001045, Accuracy_2: 89.4% Loss_2: 0.000895  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000137, Accuracy_2: 89.4% Loss_2: 0.001152  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001501, Accuracy_2: 90.1% Loss_2: 0.000657  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000509, Accuracy_2: 87.9% Loss_2: 0.000628  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000651, Accuracy_2: 88.7% Loss_2: 0.001368  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000258, Accuracy_2: 88.7% Loss_2: 0.001920  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000047, Accuracy_2: 88.7% Loss_2: 0.002280  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000814, Accuracy_2: 89.4% Loss_2: 0.000208  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000083, Accuracy_2: 88.7% Loss_2: 0.001032  [ 8601/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.002814, Accuracy_2: 83.7% Loss_2: 0.000192  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002334, Accuracy_2: 89.4% Loss_2: 0.001103  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001403, Accuracy_2: 85.1% Loss_2: 0.001162  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000996, Accuracy_2: 90.8% Loss_2: 0.000006  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000272, Accuracy_2: 87.9% Loss_2: 0.000519  [11421/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001517, Accuracy_2: 83.7% Loss_2: 0.001493  [11985/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000365, Accuracy_2: 93.6% Loss_2: 0.001679  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001353, Accuracy_2: 90.1% Loss_2: 0.001068  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000026, Accuracy_2: 85.8% Loss_2: 0.000349  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000004, Accuracy_2: 86.5% Loss_2: 0.001423  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.001125  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001169, Accuracy_2: 89.4% Loss_2: 0.000882  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000207, Accuracy_2: 92.9% Loss_2: 0.000062  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000372, Accuracy_2: 88.7% Loss_2: 0.000014  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000242, Accuracy_2: 91.5% Loss_2: 0.000030  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000081  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000458, Accuracy_2: 87.9% Loss_2: 0.000318  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000877  [ 3525/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000656, Accuracy_2: 94.3% Loss_2: 0.001817  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000088, Accuracy_2: 89.4% Loss_2: 0.002603  [ 4653/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000559, Accuracy_2: 85.1% Loss_2: 0.000544  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001418, Accuracy_2: 88.7% Loss_2: 0.000625  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000756, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000041, Accuracy_2: 94.3% Loss_2: 0.001959  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000344, Accuracy_2: 87.2% Loss_2: 0.001493  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.000030  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001292, Accuracy_2: 92.2% Loss_2: 0.000538  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002442, Accuracy_2: 86.5% Loss_2: 0.004469  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000464, Accuracy_2: 87.2% Loss_2: 0.002666  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000610, Accuracy_2: 87.9% Loss_2: 0.001690  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000276, Accuracy_2: 89.4% Loss_2: 0.000025  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000252, Accuracy_2: 86.5% Loss_2: 0.001115  [11421/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002811, Accuracy_2: 87.2% Loss_2: 0.000288  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000070, Accuracy_2: 90.1% Loss_2: 0.001680  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001398, Accuracy_2: 88.7% Loss_2: 0.000225  [13113/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000173, Accuracy_2: 92.9% Loss_2: 0.002178  [13677/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003493, Accuracy_2: 87.2% Loss_2: 0.000002  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000272, Accuracy_2: 86.5% Loss_2: 0.000410  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000220, Accuracy_2: 91.5% Loss_2: 0.000009  [  141/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001260, Accuracy_2: 85.8% Loss_2: 0.000870  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000842, Accuracy_2: 94.3% Loss_2: 0.000156  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002179, Accuracy_2: 90.1% Loss_2: 0.000030  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001256, Accuracy_2: 93.6% Loss_2: 0.000019  [ 2397/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003119, Accuracy_2: 85.8% Loss_2: 0.001371  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000035, Accuracy_2: 86.5% Loss_2: 0.000242  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000193, Accuracy_2: 90.1% Loss_2: 0.000055  [ 4089/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002877, Accuracy_2: 87.9% Loss_2: 0.000581  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000057  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000401, Accuracy_2: 87.9% Loss_2: 0.000893  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000006, Accuracy_2: 90.8% Loss_2: 0.000149  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000755, Accuracy_2: 92.9% Loss_2: 0.000057  [ 6909/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000600, Accuracy_2: 87.9% Loss_2: 0.000261  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000860, Accuracy_2: 92.2% Loss_2: 0.000001  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000523, Accuracy_2: 92.2% Loss_2: 0.000396  [ 8601/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000118, Accuracy_2: 83.0% Loss_2: 0.000579  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002689, Accuracy_2: 90.8% Loss_2: 0.000486  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000350, Accuracy_2: 91.5% Loss_2: 0.000118  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000025, Accuracy_2: 91.5% Loss_2: 0.002018  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002591, Accuracy_2: 90.8% Loss_2: 0.000105  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001084, Accuracy_2: 90.1% Loss_2: 0.000285  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000337, Accuracy_2: 88.7% Loss_2: 0.000281  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000023, Accuracy_2: 90.8% Loss_2: 0.000014  [13113/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.004379, Accuracy_2: 87.2% Loss_2: 0.000249  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001170, Accuracy_2: 89.4% Loss_2: 0.000085  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000276, Accuracy_2: 89.4% Loss_2: 0.001153  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000740, Accuracy_2: 92.9% Loss_2: 0.000074  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000122, Accuracy_2: 90.8% Loss_2: 0.000002  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001871, Accuracy_2: 91.5% Loss_2: 0.001273  [ 1269/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001714, Accuracy_2: 88.7% Loss_2: 0.000011  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000009, Accuracy_2: 88.7% Loss_2: 0.000040  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002181, Accuracy_2: 89.4% Loss_2: 0.000661  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000490, Accuracy_2: 87.2% Loss_2: 0.001487  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000016, Accuracy_2: 87.2% Loss_2: 0.000992  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001108, Accuracy_2: 90.1% Loss_2: 0.000077  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000090, Accuracy_2: 90.1% Loss_2: 0.000357  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000362, Accuracy_2: 92.2% Loss_2: 0.000064  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000062, Accuracy_2: 87.2% Loss_2: 0.000316  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002486, Accuracy_2: 91.5% Loss_2: 0.000227  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000866, Accuracy_2: 92.2% Loss_2: 0.000611  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000230, Accuracy_2: 91.5% Loss_2: 0.000007  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003022, Accuracy_2: 88.7% Loss_2: 0.000746  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003335, Accuracy_2: 89.4% Loss_2: 0.000153  [ 9165/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000018, Accuracy_2: 92.9% Loss_2: 0.000451  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001044, Accuracy_2: 92.2% Loss_2: 0.000548  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000417, Accuracy_2: 91.5% Loss_2: 0.001876  [10857/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001291, Accuracy_2: 86.5% Loss_2: 0.001161  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000659, Accuracy_2: 90.8% Loss_2: 0.000335  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000522, Accuracy_2: 85.8% Loss_2: 0.002329  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000132, Accuracy_2: 89.4% Loss_2: 0.000027  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000827, Accuracy_2: 87.9% Loss_2: 0.000238  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000051, Accuracy_2: 92.2% Loss_2: 0.000010  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000746, Accuracy_2: 90.1% Loss_2: 0.001347  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000292, Accuracy_2: 88.7% Loss_2: 0.000414  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000043, Accuracy_2: 90.8% Loss_2: 0.000075  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000117, Accuracy_2: 90.8% Loss_2: 0.000593  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001216, Accuracy_2: 87.2% Loss_2: 0.000056  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001372, Accuracy_2: 90.1% Loss_2: 0.000131  [ 2397/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002357, Accuracy_2: 83.0% Loss_2: 0.000951  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001468, Accuracy_2: 85.8% Loss_2: 0.000908  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000015, Accuracy_2: 86.5% Loss_2: 0.000960  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000377, Accuracy_2: 92.2% Loss_2: 0.000342  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000027, Accuracy_2: 89.4% Loss_2: 0.000560  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001280, Accuracy_2: 91.5% Loss_2: 0.000107  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001197, Accuracy_2: 88.7% Loss_2: 0.000866  [ 6345/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001390, Accuracy_2: 84.4% Loss_2: 0.003211  [ 6909/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.003836, Accuracy_2: 84.4% Loss_2: 0.000322  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000705, Accuracy_2: 87.9% Loss_2: 0.000292  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001256, Accuracy_2: 87.2% Loss_2: 0.000043  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000519, Accuracy_2: 88.7% Loss_2: 0.001719  [ 9165/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001913, Accuracy_2: 87.2% Loss_2: 0.000167  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.005865, Accuracy_2: 91.5% Loss_2: 0.000539  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000077, Accuracy_2: 89.4% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000358, Accuracy_2: 89.4% Loss_2: 0.000826  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000298, Accuracy_2: 89.4% Loss_2: 0.001744  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000283, Accuracy_2: 91.5% Loss_2: 0.000003  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002005, Accuracy_2: 90.1% Loss_2: 0.000397  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.004243, Accuracy_2: 89.4% Loss_2: 0.001432  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000311, Accuracy_2: 91.5% Loss_2: 0.000014  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001516, Accuracy_2: 85.8% Loss_2: 0.000234  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000061, Accuracy_2: 92.9% Loss_2: 0.000433  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000420, Accuracy_2: 90.8% Loss_2: 0.000648  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000531, Accuracy_2: 90.8% Loss_2: 0.002441  [ 1269/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000633, Accuracy_2: 92.2% Loss_2: 0.000518  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001471, Accuracy_2: 89.4% Loss_2: 0.000161  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001581, Accuracy_2: 90.1% Loss_2: 0.000121  [ 2961/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002212, Accuracy_2: 85.1% Loss_2: 0.000328  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000913, Accuracy_2: 90.1% Loss_2: 0.000014  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000112, Accuracy_2: 88.7% Loss_2: 0.000207  [ 4653/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002613, Accuracy_2: 87.2% Loss_2: 0.000012  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000972, Accuracy_2: 92.9% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000007, Accuracy_2: 90.8% Loss_2: 0.002022  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000178, Accuracy_2: 92.2% Loss_2: 0.000607  [ 6909/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002478, Accuracy_2: 83.7% Loss_2: 0.000469  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000126, Accuracy_2: 90.8% Loss_2: 0.000010  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001674, Accuracy_2: 91.5% Loss_2: 0.002426  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000185, Accuracy_2: 90.8% Loss_2: 0.000014  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001798, Accuracy_2: 90.8% Loss_2: 0.000004  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001741, Accuracy_2: 94.3% Loss_2: 0.000684  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000435, Accuracy_2: 87.9% Loss_2: 0.001592  [10857/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001410, Accuracy_2: 82.3% Loss_2: 0.000256  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001946, Accuracy_2: 92.9% Loss_2: 0.000336  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000778, Accuracy_2: 87.9% Loss_2: 0.000002  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000339, Accuracy_2: 89.4% Loss_2: 0.001580  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001096, Accuracy_2: 91.5% Loss_2: 0.001424  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000159, Accuracy_2: 91.5% Loss_2: 0.000195  [14241/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001725, Accuracy_2: 89.4% Loss_2: 0.000705  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000275, Accuracy_2: 87.9% Loss_2: 0.000399  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002105, Accuracy_2: 85.8% Loss_2: 0.002232  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001996, Accuracy_2: 88.7% Loss_2: 0.001277  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002306, Accuracy_2: 92.2% Loss_2: 0.001911  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000899, Accuracy_2: 92.2% Loss_2: 0.000020  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000031, Accuracy_2: 92.2% Loss_2: 0.000975  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000721, Accuracy_2: 92.2% Loss_2: 0.000007  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000382, Accuracy_2: 89.4% Loss_2: 0.001793  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 85.8% Loss_2: 0.001965  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000532, Accuracy_2: 85.1% Loss_2: 0.001189  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000002, Accuracy_2: 85.1% Loss_2: 0.002969  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000639, Accuracy_2: 90.8% Loss_2: 0.000002  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000809, Accuracy_2: 90.1% Loss_2: 0.001939  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002486, Accuracy_2: 92.9% Loss_2: 0.000086  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000857, Accuracy_2: 90.8% Loss_2: 0.000374  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000074, Accuracy_2: 91.5% Loss_2: 0.000259  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000029, Accuracy_2: 88.7% Loss_2: 0.000496  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000016, Accuracy_2: 87.2% Loss_2: 0.000342  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000820  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000212, Accuracy_2: 88.7% Loss_2: 0.000007  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001264, Accuracy_2: 85.8% Loss_2: 0.001211  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000902, Accuracy_2: 88.7% Loss_2: 0.001684  [11985/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000955, Accuracy_2: 85.1% Loss_2: 0.001597  [12549/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001546, Accuracy_2: 84.4% Loss_2: 0.001427  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002381, Accuracy_2: 90.1% Loss_2: 0.000296  [13677/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000507, Accuracy_2: 84.4% Loss_2: 0.000378  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002697, Accuracy_2: 85.8% Loss_2: 0.000280  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000192, Accuracy_2: 85.8% Loss_2: 0.001637  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 89.4% Loss_2: 0.001065  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000391, Accuracy_2: 87.9% Loss_2: 0.000404  [ 1269/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002568, Accuracy_2: 86.5% Loss_2: 0.000074  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000681, Accuracy_2: 93.6% Loss_2: 0.000663  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000509, Accuracy_2: 87.9% Loss_2: 0.000088  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000014, Accuracy_2: 92.2% Loss_2: 0.000086  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000456, Accuracy_2: 90.1% Loss_2: 0.000247  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000086, Accuracy_2: 87.2% Loss_2: 0.000061  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000066, Accuracy_2: 90.8% Loss_2: 0.000731  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000710, Accuracy_2: 91.5% Loss_2: 0.000007  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000059, Accuracy_2: 84.4% Loss_2: 0.000231  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000677, Accuracy_2: 90.1% Loss_2: 0.000187  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000857, Accuracy_2: 89.4% Loss_2: 0.000273  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000895, Accuracy_2: 86.5% Loss_2: 0.001413  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000805, Accuracy_2: 89.4% Loss_2: 0.000027  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000007, Accuracy_2: 85.8% Loss_2: 0.000593  [ 9165/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001017, Accuracy_2: 86.5% Loss_2: 0.001693  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001361, Accuracy_2: 94.3% Loss_2: 0.000315  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000200, Accuracy_2: 90.1% Loss_2: 0.002364  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000287, Accuracy_2: 87.2% Loss_2: 0.000433  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000208, Accuracy_2: 91.5% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000828, Accuracy_2: 94.3% Loss_2: 0.000301  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000108, Accuracy_2: 88.7% Loss_2: 0.000817  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000705, Accuracy_2: 85.8% Loss_2: 0.000560  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000006, Accuracy_2: 90.8% Loss_2: 0.001176  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000079, Accuracy_2: 90.8% Loss_2: 0.000469  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000359, Accuracy_2: 85.8% Loss_2: 0.000186  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000020, Accuracy_2: 87.9% Loss_2: 0.001097  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001113, Accuracy_2: 87.9% Loss_2: 0.000001  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001071, Accuracy_2: 90.8% Loss_2: 0.001281  [ 1833/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.004651, Accuracy_2: 85.8% Loss_2: 0.001048  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000681, Accuracy_2: 90.1% Loss_2: 0.000052  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000385  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000374, Accuracy_2: 89.4% Loss_2: 0.000794  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001489, Accuracy_2: 85.8% Loss_2: 0.001366  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000003, Accuracy_2: 87.9% Loss_2: 0.000150  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000267, Accuracy_2: 91.5% Loss_2: 0.000694  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000281  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000027, Accuracy_2: 87.2% Loss_2: 0.001297  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002280, Accuracy_2: 85.8% Loss_2: 0.003023  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000010, Accuracy_2: 92.2% Loss_2: 0.000381  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002497, Accuracy_2: 92.2% Loss_2: 0.001266  [ 8601/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000519, Accuracy_2: 91.5% Loss_2: 0.000953  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000909, Accuracy_2: 86.5% Loss_2: 0.000494  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002841, Accuracy_2: 85.8% Loss_2: 0.000242  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000130, Accuracy_2: 90.8% Loss_2: 0.000003  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000519, Accuracy_2: 87.9% Loss_2: 0.000726  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000122, Accuracy_2: 90.8% Loss_2: 0.002390  [11985/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001944, Accuracy_2: 85.8% Loss_2: 0.000771  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000004, Accuracy_2: 88.7% Loss_2: 0.000432  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000464, Accuracy_2: 90.8% Loss_2: 0.000099  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000010, Accuracy_2: 90.1% Loss_2: 0.000003  [14241/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001774, Accuracy_2: 84.4% Loss_2: 0.000323  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000186, Accuracy_2: 85.1% Loss_2: 0.001639  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000350, Accuracy_2: 92.9% Loss_2: 0.000025  [  705/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000034, Accuracy_2: 92.2% Loss_2: 0.000331  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000101, Accuracy_2: 90.1% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001144, Accuracy_2: 92.9% Loss_2: 0.000021  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000960, Accuracy_2: 91.5% Loss_2: 0.000709  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002690, Accuracy_2: 86.5% Loss_2: 0.002278  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000057, Accuracy_2: 88.7% Loss_2: 0.000438  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000003, Accuracy_2: 87.9% Loss_2: 0.001297  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002436, Accuracy_2: 92.2% Loss_2: 0.000004  [ 5217/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.003302, Accuracy_2: 85.8% Loss_2: 0.003035  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000741, Accuracy_2: 86.5% Loss_2: 0.000923  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000730, Accuracy_2: 91.5% Loss_2: 0.000124  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002204, Accuracy_2: 88.7% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000047, Accuracy_2: 85.8% Loss_2: 0.001484  [ 8037/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000203, Accuracy_2: 83.0% Loss_2: 0.000866  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000004, Accuracy_2: 88.7% Loss_2: 0.001171  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000034  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000006, Accuracy_2: 87.2% Loss_2: 0.001192  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000029, Accuracy_2: 87.9% Loss_2: 0.000800  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000069, Accuracy_2: 88.7% Loss_2: 0.000849  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000150, Accuracy_2: 89.4% Loss_2: 0.000480  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001280, Accuracy_2: 85.8% Loss_2: 0.001039  [12549/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000007, Accuracy_2: 92.9% Loss_2: 0.002815  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000551, Accuracy_2: 90.1% Loss_2: 0.000023  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001751, Accuracy_2: 88.7% Loss_2: 0.000521  [14241/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000304, Accuracy_2: 85.8% Loss_2: 0.001372  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001253, Accuracy_2: 82.3% Loss_2: 0.002253  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000071, Accuracy_2: 92.2% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001854, Accuracy_2: 90.8% Loss_2: 0.000001  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000004, Accuracy_2: 90.1% Loss_2: 0.000108  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001901, Accuracy_2: 94.3% Loss_2: 0.000204  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001389, Accuracy_2: 88.7% Loss_2: 0.000482  [ 2961/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001894, Accuracy_2: 84.4% Loss_2: 0.002034  [ 3525/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000144, Accuracy_2: 92.9% Loss_2: 0.000377  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000779, Accuracy_2: 90.1% Loss_2: 0.000065  [ 4653/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000945, Accuracy_2: 94.3% Loss_2: 0.000511  [ 5217/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002710, Accuracy_2: 87.2% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001223, Accuracy_2: 88.7% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000173, Accuracy_2: 87.9% Loss_2: 0.000725  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000161, Accuracy_2: 86.5% Loss_2: 0.001336  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001189, Accuracy_2: 90.1% Loss_2: 0.001479  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000770, Accuracy_2: 91.5% Loss_2: 0.000448  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000104, Accuracy_2: 94.3% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000473, Accuracy_2: 86.5% Loss_2: 0.000890  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001988, Accuracy_2: 92.9% Loss_2: 0.000019  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000070, Accuracy_2: 87.9% Loss_2: 0.000015  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001657, Accuracy_2: 85.8% Loss_2: 0.001385  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000247, Accuracy_2: 87.9% Loss_2: 0.001170  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000324  [12549/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000002, Accuracy_2: 94.3% Loss_2: 0.001483  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000069, Accuracy_2: 90.1% Loss_2: 0.001829  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000605, Accuracy_2: 90.8% Loss_2: 0.005688  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000314, Accuracy_2: 87.2% Loss_2: 0.001098  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.1%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000717, Accuracy_2: 87.9% Loss_2: 0.001619  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000709, Accuracy_2: 91.5% Loss_2: 0.000025  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003032, Accuracy_2: 92.2% Loss_2: 0.000041  [ 1269/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000001, Accuracy_2: 84.4% Loss_2: 0.000508  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000035, Accuracy_2: 90.1% Loss_2: 0.000001  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000003  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000471, Accuracy_2: 87.9% Loss_2: 0.000525  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003030, Accuracy_2: 88.7% Loss_2: 0.000148  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000271, Accuracy_2: 89.4% Loss_2: 0.000994  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000263, Accuracy_2: 87.2% Loss_2: 0.000046  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000003, Accuracy_2: 87.2% Loss_2: 0.001756  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000804, Accuracy_2: 92.9% Loss_2: 0.000231  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002050, Accuracy_2: 85.1% Loss_2: 0.003529  [ 6909/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000463, Accuracy_2: 84.4% Loss_2: 0.000345  [ 7473/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000304, Accuracy_2: 84.4% Loss_2: 0.001306  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000549, Accuracy_2: 90.1% Loss_2: 0.000921  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000509, Accuracy_2: 92.2% Loss_2: 0.002038  [ 9165/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000792, Accuracy_2: 84.4% Loss_2: 0.000227  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000974, Accuracy_2: 91.5% Loss_2: 0.002560  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001681, Accuracy_2: 86.5% Loss_2: 0.002564  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000255, Accuracy_2: 90.8% Loss_2: 0.001231  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002018, Accuracy_2: 88.7% Loss_2: 0.000407  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000049, Accuracy_2: 87.9% Loss_2: 0.002110  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000217, Accuracy_2: 88.7% Loss_2: 0.000701  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000182, Accuracy_2: 86.5% Loss_2: 0.000581  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003327, Accuracy_2: 87.2% Loss_2: 0.000024  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000213, Accuracy_2: 89.4% Loss_2: 0.000538  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002029, Accuracy_2: 91.5% Loss_2: 0.001176  [  141/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002351, Accuracy_2: 83.0% Loss_2: 0.001006  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000318, Accuracy_2: 87.9% Loss_2: 0.000283  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002410, Accuracy_2: 90.8% Loss_2: 0.001861  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001372, Accuracy_2: 86.5% Loss_2: 0.002314  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000429, Accuracy_2: 87.9% Loss_2: 0.000661  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001941, Accuracy_2: 88.7% Loss_2: 0.002343  [ 3525/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000967, Accuracy_2: 85.1% Loss_2: 0.003587  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000693, Accuracy_2: 89.4% Loss_2: 0.000579  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000027, Accuracy_2: 88.7% Loss_2: 0.001987  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001929, Accuracy_2: 88.7% Loss_2: 0.001597  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000089, Accuracy_2: 90.1% Loss_2: 0.000320  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000401, Accuracy_2: 88.7% Loss_2: 0.001725  [ 6909/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000698, Accuracy_2: 87.9% Loss_2: 0.000050  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001145, Accuracy_2: 88.7% Loss_2: 0.000946  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000509, Accuracy_2: 95.7% Loss_2: 0.000006  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003032, Accuracy_2: 92.9% Loss_2: 0.000118  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000347, Accuracy_2: 90.8% Loss_2: 0.004408  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000975, Accuracy_2: 87.2% Loss_2: 0.000025  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002142, Accuracy_2: 90.1% Loss_2: 0.000382  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000335, Accuracy_2: 88.7% Loss_2: 0.005055  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002492, Accuracy_2: 88.7% Loss_2: 0.003103  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000024, Accuracy_2: 90.1% Loss_2: 0.000287  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001735, Accuracy_2: 89.4% Loss_2: 0.000065  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000164, Accuracy_2: 87.2% Loss_2: 0.000042  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000518, Accuracy_2: 89.4% Loss_2: 0.000094  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000452, Accuracy_2: 90.1% Loss_2: 0.000100  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "Accuracy_1: 81.6%, Loss_1: 0.000757, Accuracy_2: 84.4% Loss_2: 0.000005  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000292, Accuracy_2: 90.8% Loss_2: 0.000732  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000005, Accuracy_2: 86.5% Loss_2: 0.001418  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000933, Accuracy_2: 90.8% Loss_2: 0.000005  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001833, Accuracy_2: 86.5% Loss_2: 0.000748  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001391, Accuracy_2: 91.5% Loss_2: 0.000011  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000017, Accuracy_2: 90.8% Loss_2: 0.000493  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000300, Accuracy_2: 89.4% Loss_2: 0.001760  [ 4089/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000643, Accuracy_2: 86.5% Loss_2: 0.001000  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000260, Accuracy_2: 92.9% Loss_2: 0.000016  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000867, Accuracy_2: 87.2% Loss_2: 0.000007  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000094, Accuracy_2: 92.2% Loss_2: 0.000027  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000230, Accuracy_2: 90.8% Loss_2: 0.000042  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000456, Accuracy_2: 92.2% Loss_2: 0.000118  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002606, Accuracy_2: 87.9% Loss_2: 0.001602  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001747, Accuracy_2: 90.1% Loss_2: 0.000526  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000275, Accuracy_2: 95.0% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001468, Accuracy_2: 87.2% Loss_2: 0.001505  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000826, Accuracy_2: 88.7% Loss_2: 0.003713  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001059, Accuracy_2: 95.0% Loss_2: 0.000258  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002852, Accuracy_2: 90.8% Loss_2: 0.000009  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000474, Accuracy_2: 90.1% Loss_2: 0.000797  [11985/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002280, Accuracy_2: 85.1% Loss_2: 0.000079  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000745, Accuracy_2: 90.1% Loss_2: 0.000171  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000122, Accuracy_2: 88.7% Loss_2: 0.001865  [13677/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002777, Accuracy_2: 84.4% Loss_2: 0.001477  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000008, Accuracy_2: 93.6% Loss_2: 0.000005  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000289, Accuracy_2: 92.2% Loss_2: 0.000252  [  141/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.005535, Accuracy_2: 82.3% Loss_2: 0.000499  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001377, Accuracy_2: 89.4% Loss_2: 0.000919  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000130, Accuracy_2: 91.5% Loss_2: 0.000209  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000455  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000694, Accuracy_2: 87.9% Loss_2: 0.001138  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002294, Accuracy_2: 87.9% Loss_2: 0.000647  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000377, Accuracy_2: 90.8% Loss_2: 0.002213  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000036, Accuracy_2: 87.9% Loss_2: 0.002083  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000369, Accuracy_2: 84.4% Loss_2: 0.002498  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000023, Accuracy_2: 90.1% Loss_2: 0.000776  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001835, Accuracy_2: 92.9% Loss_2: 0.000045  [ 6345/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001518, Accuracy_2: 85.1% Loss_2: 0.001428  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000007, Accuracy_2: 90.1% Loss_2: 0.000038  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002158, Accuracy_2: 90.8% Loss_2: 0.001758  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000102, Accuracy_2: 87.9% Loss_2: 0.000003  [ 8601/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000013, Accuracy_2: 85.8% Loss_2: 0.000204  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000099, Accuracy_2: 88.7% Loss_2: 0.000380  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000005, Accuracy_2: 90.1% Loss_2: 0.000026  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000194, Accuracy_2: 86.5% Loss_2: 0.000891  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000344, Accuracy_2: 88.7% Loss_2: 0.000033  [11421/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001419, Accuracy_2: 84.4% Loss_2: 0.000017  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000305  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001922, Accuracy_2: 93.6% Loss_2: 0.000004  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000100, Accuracy_2: 86.5% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003147, Accuracy_2: 90.8% Loss_2: 0.000015  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000023  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.4%, Avg loss: 0.000000 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000160, Accuracy_2: 89.4% Loss_2: 0.000740  [  141/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000123, Accuracy_2: 92.9% Loss_2: 0.001331  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001219, Accuracy_2: 94.3% Loss_2: 0.000062  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001015, Accuracy_2: 90.1% Loss_2: 0.000263  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000496, Accuracy_2: 85.8% Loss_2: 0.001653  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001596, Accuracy_2: 87.9% Loss_2: 0.000814  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003603, Accuracy_2: 87.2% Loss_2: 0.001856  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001655, Accuracy_2: 92.9% Loss_2: 0.000106  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000951  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000071, Accuracy_2: 91.5% Loss_2: 0.000002  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001539, Accuracy_2: 91.5% Loss_2: 0.000011  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000005, Accuracy_2: 90.1% Loss_2: 0.001011  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000915, Accuracy_2: 90.1% Loss_2: 0.000115  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000013, Accuracy_2: 87.9% Loss_2: 0.000310  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001549, Accuracy_2: 90.1% Loss_2: 0.001477  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000452, Accuracy_2: 90.8% Loss_2: 0.001492  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001308, Accuracy_2: 87.2% Loss_2: 0.000162  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000256, Accuracy_2: 85.8% Loss_2: 0.000850  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000803, Accuracy_2: 83.7% Loss_2: 0.004278  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001879, Accuracy_2: 89.4% Loss_2: 0.001285  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000080, Accuracy_2: 88.7% Loss_2: 0.000270  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000752, Accuracy_2: 92.2% Loss_2: 0.001158  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002486, Accuracy_2: 90.1% Loss_2: 0.000046  [12549/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002549, Accuracy_2: 85.8% Loss_2: 0.000008  [13113/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000132, Accuracy_2: 85.8% Loss_2: 0.000185  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.004177, Accuracy_2: 87.9% Loss_2: 0.002631  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000457, Accuracy_2: 86.5% Loss_2: 0.000102  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001915, Accuracy_2: 90.8% Loss_2: 0.000362  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001056, Accuracy_2: 87.9% Loss_2: 0.000004  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000506, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000042, Accuracy_2: 88.7% Loss_2: 0.001294  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000369, Accuracy_2: 93.6% Loss_2: 0.001752  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000008, Accuracy_2: 89.4% Loss_2: 0.001283  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001095, Accuracy_2: 92.2% Loss_2: 0.000085  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000388, Accuracy_2: 87.9% Loss_2: 0.001369  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001684, Accuracy_2: 89.4% Loss_2: 0.002199  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000983, Accuracy_2: 91.5% Loss_2: 0.000007  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001032, Accuracy_2: 85.8% Loss_2: 0.000164  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002220, Accuracy_2: 90.1% Loss_2: 0.000096  [ 6909/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001426, Accuracy_2: 85.1% Loss_2: 0.000618  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.000378  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001088, Accuracy_2: 87.9% Loss_2: 0.000079  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000353, Accuracy_2: 88.7% Loss_2: 0.000158  [ 9165/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000084, Accuracy_2: 95.0% Loss_2: 0.000459  [ 9729/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001499, Accuracy_2: 93.6% Loss_2: 0.000605  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000962, Accuracy_2: 88.7% Loss_2: 0.000168  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000049, Accuracy_2: 89.4% Loss_2: 0.000394  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002285, Accuracy_2: 90.8% Loss_2: 0.000029  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.000168  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000007, Accuracy_2: 87.2% Loss_2: 0.001455  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000007, Accuracy_2: 86.5% Loss_2: 0.002090  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000063, Accuracy_2: 92.9% Loss_2: 0.000710  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000183, Accuracy_2: 89.4% Loss_2: 0.000004  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000089, Accuracy_2: 91.5% Loss_2: 0.000012  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000512, Accuracy_2: 90.1% Loss_2: 0.000061  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002053, Accuracy_2: 90.1% Loss_2: 0.000038  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000250, Accuracy_2: 88.7% Loss_2: 0.001319  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000765, Accuracy_2: 92.2% Loss_2: 0.000161  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.004673, Accuracy_2: 85.8% Loss_2: 0.002801  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000840, Accuracy_2: 90.1% Loss_2: 0.000322  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000010, Accuracy_2: 93.6% Loss_2: 0.000010  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000040, Accuracy_2: 87.9% Loss_2: 0.001289  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002189, Accuracy_2: 89.4% Loss_2: 0.000760  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002522, Accuracy_2: 90.1% Loss_2: 0.000239  [ 5781/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000481, Accuracy_2: 87.9% Loss_2: 0.000009  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000025, Accuracy_2: 87.9% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001360, Accuracy_2: 91.5% Loss_2: 0.000360  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000766, Accuracy_2: 90.8% Loss_2: 0.000073  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000508, Accuracy_2: 89.4% Loss_2: 0.000204  [ 8601/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000711, Accuracy_2: 86.5% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000877, Accuracy_2: 90.1% Loss_2: 0.001981  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000651, Accuracy_2: 87.2% Loss_2: 0.000258  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000222, Accuracy_2: 89.4% Loss_2: 0.002534  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000662, Accuracy_2: 88.7% Loss_2: 0.000591  [11421/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.003721, Accuracy_2: 87.9% Loss_2: 0.003551  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000670, Accuracy_2: 85.8% Loss_2: 0.000818  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000009, Accuracy_2: 92.2% Loss_2: 0.001822  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000380, Accuracy_2: 90.8% Loss_2: 0.001262  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000116, Accuracy_2: 87.2% Loss_2: 0.003108  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003525, Accuracy_2: 88.7% Loss_2: 0.000001  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000646, Accuracy_2: 89.4% Loss_2: 0.001244  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000013, Accuracy_2: 85.1% Loss_2: 0.003644  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000457, Accuracy_2: 85.8% Loss_2: 0.001342  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000965, Accuracy_2: 90.8% Loss_2: 0.000499  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000332, Accuracy_2: 88.7% Loss_2: 0.000693  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000808, Accuracy_2: 87.2% Loss_2: 0.000135  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000293, Accuracy_2: 90.1% Loss_2: 0.000291  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.004884, Accuracy_2: 90.1% Loss_2: 0.001180  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000017  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001376, Accuracy_2: 90.8% Loss_2: 0.002336  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001612, Accuracy_2: 89.4% Loss_2: 0.000856  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000787, Accuracy_2: 87.2% Loss_2: 0.001361  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000410, Accuracy_2: 87.9% Loss_2: 0.001078  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000739, Accuracy_2: 92.2% Loss_2: 0.000025  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000004, Accuracy_2: 90.8% Loss_2: 0.000041  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001683, Accuracy_2: 89.4% Loss_2: 0.000251  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000868, Accuracy_2: 91.5% Loss_2: 0.000301  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002106, Accuracy_2: 89.4% Loss_2: 0.000020  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000267, Accuracy_2: 88.7% Loss_2: 0.002685  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000873, Accuracy_2: 90.8% Loss_2: 0.000601  [10857/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003367, Accuracy_2: 87.9% Loss_2: 0.000975  [11421/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000272, Accuracy_2: 95.0% Loss_2: 0.000002  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000847, Accuracy_2: 92.9% Loss_2: 0.000898  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000026, Accuracy_2: 89.4% Loss_2: 0.000006  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000958, Accuracy_2: 92.2% Loss_2: 0.000011  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000251, Accuracy_2: 89.4% Loss_2: 0.001903  [14241/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000651, Accuracy_2: 85.1% Loss_2: 0.003517  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000015, Accuracy_2: 92.2% Loss_2: 0.001318  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000543  [  705/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000298, Accuracy_2: 85.8% Loss_2: 0.000605  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001112, Accuracy_2: 90.8% Loss_2: 0.000199  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000090, Accuracy_2: 90.1% Loss_2: 0.000340  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000031, Accuracy_2: 90.8% Loss_2: 0.000672  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000588, Accuracy_2: 87.9% Loss_2: 0.003057  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000838, Accuracy_2: 86.5% Loss_2: 0.000105  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000816, Accuracy_2: 94.3% Loss_2: 0.000025  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002653, Accuracy_2: 89.4% Loss_2: 0.000386  [ 5217/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000435, Accuracy_2: 85.1% Loss_2: 0.001054  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000773, Accuracy_2: 88.7% Loss_2: 0.000438  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.000516  [ 6909/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000006, Accuracy_2: 93.6% Loss_2: 0.001658  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000621, Accuracy_2: 89.4% Loss_2: 0.000004  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002706, Accuracy_2: 90.8% Loss_2: 0.001931  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000167, Accuracy_2: 93.6% Loss_2: 0.000002  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000018  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000153, Accuracy_2: 91.5% Loss_2: 0.000649  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000917, Accuracy_2: 92.2% Loss_2: 0.000774  [10857/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001654, Accuracy_2: 79.4% Loss_2: 0.006132  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000244, Accuracy_2: 92.2% Loss_2: 0.000023  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000263  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001335, Accuracy_2: 90.8% Loss_2: 0.000249  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000470, Accuracy_2: 84.4% Loss_2: 0.001718  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.004410, Accuracy_2: 92.2% Loss_2: 0.000004  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000543  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000048, Accuracy_2: 90.1% Loss_2: 0.001174  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002256, Accuracy_2: 87.9% Loss_2: 0.000587  [  705/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001500, Accuracy_2: 83.0% Loss_2: 0.000429  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000266, Accuracy_2: 88.7% Loss_2: 0.000022  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000006, Accuracy_2: 87.2% Loss_2: 0.002500  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000830, Accuracy_2: 92.2% Loss_2: 0.001351  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000082, Accuracy_2: 87.2% Loss_2: 0.000466  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000491, Accuracy_2: 90.8% Loss_2: 0.000059  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002187, Accuracy_2: 88.7% Loss_2: 0.000306  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000004, Accuracy_2: 90.1% Loss_2: 0.000074  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002196, Accuracy_2: 87.2% Loss_2: 0.000068  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000043, Accuracy_2: 87.9% Loss_2: 0.001788  [ 6345/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001001, Accuracy_2: 85.1% Loss_2: 0.003618  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000855, Accuracy_2: 90.8% Loss_2: 0.001233  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000247, Accuracy_2: 90.8% Loss_2: 0.000112  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000230, Accuracy_2: 90.8% Loss_2: 0.000260  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000007, Accuracy_2: 87.2% Loss_2: 0.000189  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000537, Accuracy_2: 88.7% Loss_2: 0.001433  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002392, Accuracy_2: 90.8% Loss_2: 0.003754  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000502, Accuracy_2: 88.7% Loss_2: 0.002231  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000015, Accuracy_2: 91.5% Loss_2: 0.000971  [11421/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000005, Accuracy_2: 92.9% Loss_2: 0.000422  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.003489, Accuracy_2: 88.7% Loss_2: 0.000011  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000186, Accuracy_2: 85.8% Loss_2: 0.000420  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000371, Accuracy_2: 87.9% Loss_2: 0.000662  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000141, Accuracy_2: 91.5% Loss_2: 0.000435  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.001876  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000974, Accuracy_2: 88.7% Loss_2: 0.000437  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000284  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000157, Accuracy_2: 89.4% Loss_2: 0.006646  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000684, Accuracy_2: 95.0% Loss_2: 0.000387  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000481, Accuracy_2: 90.1% Loss_2: 0.002635  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000839, Accuracy_2: 89.4% Loss_2: 0.000631  [ 2961/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000550, Accuracy_2: 88.7% Loss_2: 0.000011  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000456, Accuracy_2: 90.1% Loss_2: 0.001548  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000299, Accuracy_2: 90.8% Loss_2: 0.003066  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000350, Accuracy_2: 86.5% Loss_2: 0.000583  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000148, Accuracy_2: 90.8% Loss_2: 0.000026  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000066, Accuracy_2: 88.7% Loss_2: 0.000740  [ 6345/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001251, Accuracy_2: 87.2% Loss_2: 0.000984  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.004267, Accuracy_2: 90.1% Loss_2: 0.000051  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000067, Accuracy_2: 85.8% Loss_2: 0.001378  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000020, Accuracy_2: 87.2% Loss_2: 0.001549  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002751, Accuracy_2: 91.5% Loss_2: 0.000539  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000909, Accuracy_2: 85.8% Loss_2: 0.001170  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001049, Accuracy_2: 92.2% Loss_2: 0.002161  [10293/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000961, Accuracy_2: 86.5% Loss_2: 0.000066  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000854, Accuracy_2: 90.8% Loss_2: 0.000254  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000190, Accuracy_2: 92.2% Loss_2: 0.000464  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001646, Accuracy_2: 89.4% Loss_2: 0.001236  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003166, Accuracy_2: 89.4% Loss_2: 0.001126  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000799, Accuracy_2: 89.4% Loss_2: 0.000020  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000854  [14241/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000995, Accuracy_2: 86.5% Loss_2: 0.001230  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001970, Accuracy_2: 87.2% Loss_2: 0.000422  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000166, Accuracy_2: 86.5% Loss_2: 0.003448  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000006, Accuracy_2: 85.8% Loss_2: 0.000279  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000450, Accuracy_2: 89.4% Loss_2: 0.000218  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001236, Accuracy_2: 92.2% Loss_2: 0.000002  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000822, Accuracy_2: 86.5% Loss_2: 0.000804  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000024, Accuracy_2: 90.8% Loss_2: 0.000744  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001349, Accuracy_2: 87.2% Loss_2: 0.002177  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000905, Accuracy_2: 84.4% Loss_2: 0.000069  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000259, Accuracy_2: 87.2% Loss_2: 0.000907  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000374, Accuracy_2: 91.5% Loss_2: 0.000059  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000163, Accuracy_2: 88.7% Loss_2: 0.001165  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000026, Accuracy_2: 87.9% Loss_2: 0.000466  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002485  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002454, Accuracy_2: 88.7% Loss_2: 0.000594  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001838, Accuracy_2: 92.2% Loss_2: 0.000157  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000063  [ 9165/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000043, Accuracy_2: 95.0% Loss_2: 0.000991  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000062, Accuracy_2: 87.2% Loss_2: 0.000531  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001964, Accuracy_2: 91.5% Loss_2: 0.000005  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000635, Accuracy_2: 89.4% Loss_2: 0.000012  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000063, Accuracy_2: 87.9% Loss_2: 0.000218  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000560, Accuracy_2: 90.1% Loss_2: 0.000476  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000009, Accuracy_2: 87.2% Loss_2: 0.002105  [13113/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000233, Accuracy_2: 92.9% Loss_2: 0.000345  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000513, Accuracy_2: 90.1% Loss_2: 0.001156  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000004, Accuracy_2: 87.2% Loss_2: 0.000085  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000000\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000063, Accuracy_2: 90.1% Loss_2: 0.000715  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000264, Accuracy_2: 90.8% Loss_2: 0.000006  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003074, Accuracy_2: 90.1% Loss_2: 0.000182  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000003, Accuracy_2: 94.3% Loss_2: 0.000002  [ 1833/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000360, Accuracy_2: 82.3% Loss_2: 0.001299  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001984, Accuracy_2: 90.1% Loss_2: 0.000856  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000275, Accuracy_2: 90.1% Loss_2: 0.001021  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000223, Accuracy_2: 90.8% Loss_2: 0.000871  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001414, Accuracy_2: 84.4% Loss_2: 0.001242  [ 4653/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001374, Accuracy_2: 93.6% Loss_2: 0.001805  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003224, Accuracy_2: 89.4% Loss_2: 0.000768  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001111, Accuracy_2: 87.9% Loss_2: 0.000585  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.004545, Accuracy_2: 89.4% Loss_2: 0.001803  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003343, Accuracy_2: 88.7% Loss_2: 0.000443  [ 7473/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001389, Accuracy_2: 85.8% Loss_2: 0.000021  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000089, Accuracy_2: 90.8% Loss_2: 0.001860  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000839, Accuracy_2: 90.1% Loss_2: 0.001796  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000574, Accuracy_2: 92.2% Loss_2: 0.000001  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000469, Accuracy_2: 90.8% Loss_2: 0.000515  [10293/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.002282, Accuracy_2: 84.4% Loss_2: 0.000048  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000020, Accuracy_2: 88.7% Loss_2: 0.001743  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000576, Accuracy_2: 90.8% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001955, Accuracy_2: 86.5% Loss_2: 0.000264  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000434, Accuracy_2: 90.1% Loss_2: 0.001188  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000048, Accuracy_2: 92.2% Loss_2: 0.001850  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000389, Accuracy_2: 87.9% Loss_2: 0.000684  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001063, Accuracy_2: 91.5% Loss_2: 0.000006  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.004792, Accuracy_2: 92.9% Loss_2: 0.001447  [  141/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002093, Accuracy_2: 85.8% Loss_2: 0.000577  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002795, Accuracy_2: 89.4% Loss_2: 0.000100  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000004, Accuracy_2: 90.1% Loss_2: 0.000065  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000012, Accuracy_2: 91.5% Loss_2: 0.000002  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001138, Accuracy_2: 90.8% Loss_2: 0.000706  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000051, Accuracy_2: 89.4% Loss_2: 0.000098  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000399, Accuracy_2: 87.9% Loss_2: 0.001158  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000692, Accuracy_2: 87.2% Loss_2: 0.000411  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001046, Accuracy_2: 87.2% Loss_2: 0.000006  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002825, Accuracy_2: 87.9% Loss_2: 0.000059  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000805, Accuracy_2: 92.2% Loss_2: 0.002214  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000012, Accuracy_2: 89.4% Loss_2: 0.002305  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000477, Accuracy_2: 87.9% Loss_2: 0.000008  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000211, Accuracy_2: 92.9% Loss_2: 0.000686  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000192, Accuracy_2: 91.5% Loss_2: 0.001774  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001605, Accuracy_2: 92.2% Loss_2: 0.000006  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000756, Accuracy_2: 90.1% Loss_2: 0.000600  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002340, Accuracy_2: 87.9% Loss_2: 0.001231  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001815, Accuracy_2: 89.4% Loss_2: 0.001163  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000995, Accuracy_2: 89.4% Loss_2: 0.000023  [11421/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001635, Accuracy_2: 95.0% Loss_2: 0.000003  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.000004  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000930, Accuracy_2: 89.4% Loss_2: 0.000896  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 87.2% Loss_2: 0.001673  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002005, Accuracy_2: 93.6% Loss_2: 0.000052  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000012, Accuracy_2: 91.5% Loss_2: 0.000001  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000229, Accuracy_2: 91.5% Loss_2: 0.000492  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000391, Accuracy_2: 87.9% Loss_2: 0.001182  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000613, Accuracy_2: 91.5% Loss_2: 0.001128  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000121, Accuracy_2: 87.2% Loss_2: 0.000933  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000583, Accuracy_2: 87.2% Loss_2: 0.000009  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000413, Accuracy_2: 85.8% Loss_2: 0.001889  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000034, Accuracy_2: 84.4% Loss_2: 0.000536  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002092, Accuracy_2: 91.5% Loss_2: 0.000615  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000212, Accuracy_2: 89.4% Loss_2: 0.000051  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000008, Accuracy_2: 89.4% Loss_2: 0.001932  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000009, Accuracy_2: 92.9% Loss_2: 0.000077  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000012, Accuracy_2: 92.2% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000826, Accuracy_2: 84.4% Loss_2: 0.003618  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000113, Accuracy_2: 87.2% Loss_2: 0.001774  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000127, Accuracy_2: 88.7% Loss_2: 0.002902  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000340, Accuracy_2: 92.9% Loss_2: 0.001063  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000027, Accuracy_2: 88.7% Loss_2: 0.000183  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001521, Accuracy_2: 92.9% Loss_2: 0.000538  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000059, Accuracy_2: 90.8% Loss_2: 0.000131  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001144, Accuracy_2: 89.4% Loss_2: 0.000006  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000844, Accuracy_2: 87.9% Loss_2: 0.002089  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000014, Accuracy_2: 90.8% Loss_2: 0.000657  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000694, Accuracy_2: 88.7% Loss_2: 0.000080  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001366, Accuracy_2: 90.8% Loss_2: 0.000847  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001881, Accuracy_2: 89.4% Loss_2: 0.000965  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001242, Accuracy_2: 87.9% Loss_2: 0.001958  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000688, Accuracy_2: 89.4% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002099, Accuracy_2: 87.9% Loss_2: 0.002034  [ 1269/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000968, Accuracy_2: 85.1% Loss_2: 0.000003  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000571, Accuracy_2: 86.5% Loss_2: 0.000542  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000377, Accuracy_2: 90.1% Loss_2: 0.000573  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000501  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000004, Accuracy_2: 90.8% Loss_2: 0.000184  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000681, Accuracy_2: 91.5% Loss_2: 0.000213  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001287, Accuracy_2: 90.8% Loss_2: 0.001165  [ 5217/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002678, Accuracy_2: 85.8% Loss_2: 0.000483  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003462, Accuracy_2: 92.9% Loss_2: 0.000001  [ 6345/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000736, Accuracy_2: 87.2% Loss_2: 0.000439  [ 6909/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001971, Accuracy_2: 87.9% Loss_2: 0.000287  [ 7473/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002064, Accuracy_2: 85.1% Loss_2: 0.005859  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002018, Accuracy_2: 87.2% Loss_2: 0.002375  [ 8601/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000760, Accuracy_2: 87.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000198, Accuracy_2: 92.2% Loss_2: 0.000632  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000648, Accuracy_2: 85.8% Loss_2: 0.001801  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000019, Accuracy_2: 85.1% Loss_2: 0.001593  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000873, Accuracy_2: 88.7% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000007, Accuracy_2: 87.9% Loss_2: 0.000273  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000151, Accuracy_2: 90.8% Loss_2: 0.000280  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000626, Accuracy_2: 88.7% Loss_2: 0.001151  [13113/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000175, Accuracy_2: 92.2% Loss_2: 0.000083  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000144, Accuracy_2: 87.2% Loss_2: 0.001125  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001763, Accuracy_2: 87.9% Loss_2: 0.000276  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000047, Accuracy_2: 87.2% Loss_2: 0.001927  [  141/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000027, Accuracy_2: 83.7% Loss_2: 0.000039  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000095, Accuracy_2: 87.2% Loss_2: 0.000194  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000007, Accuracy_2: 91.5% Loss_2: 0.000038  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000811, Accuracy_2: 90.1% Loss_2: 0.000028  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000208, Accuracy_2: 87.9% Loss_2: 0.000612  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000128, Accuracy_2: 88.7% Loss_2: 0.000385  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000222, Accuracy_2: 92.9% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001306, Accuracy_2: 90.1% Loss_2: 0.000153  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000042, Accuracy_2: 90.1% Loss_2: 0.004002  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000697, Accuracy_2: 89.4% Loss_2: 0.000002  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000162, Accuracy_2: 92.9% Loss_2: 0.000111  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000805, Accuracy_2: 93.6% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000655, Accuracy_2: 90.8% Loss_2: 0.000060  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000692, Accuracy_2: 88.7% Loss_2: 0.004273  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001790, Accuracy_2: 91.5% Loss_2: 0.001172  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001866, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001829, Accuracy_2: 87.2% Loss_2: 0.000834  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001410, Accuracy_2: 90.8% Loss_2: 0.002195  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.001373  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000004, Accuracy_2: 89.4% Loss_2: 0.000740  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000015, Accuracy_2: 91.5% Loss_2: 0.001617  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000360, Accuracy_2: 87.9% Loss_2: 0.000711  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000785, Accuracy_2: 88.7% Loss_2: 0.001152  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001683, Accuracy_2: 90.1% Loss_2: 0.000837  [13677/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000267, Accuracy_2: 84.4% Loss_2: 0.001654  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001913, Accuracy_2: 90.8% Loss_2: 0.000306  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000337, Accuracy_2: 87.9% Loss_2: 0.001877  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001019, Accuracy_2: 85.1% Loss_2: 0.000279  [  705/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000444, Accuracy_2: 85.1% Loss_2: 0.000028  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001974, Accuracy_2: 90.8% Loss_2: 0.001566  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000562  [ 2397/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.001368, Accuracy_2: 95.0% Loss_2: 0.000139  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001642, Accuracy_2: 84.4% Loss_2: 0.001169  [ 3525/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001980, Accuracy_2: 87.2% Loss_2: 0.000011  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001213, Accuracy_2: 94.3% Loss_2: 0.000767  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000628, Accuracy_2: 88.7% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000283, Accuracy_2: 92.2% Loss_2: 0.000170  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000468, Accuracy_2: 91.5% Loss_2: 0.001912  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000553, Accuracy_2: 91.5% Loss_2: 0.000507  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000205, Accuracy_2: 91.5% Loss_2: 0.000043  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000046, Accuracy_2: 83.7% Loss_2: 0.002588  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002688, Accuracy_2: 90.8% Loss_2: 0.002306  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000360, Accuracy_2: 93.6% Loss_2: 0.000395  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000136, Accuracy_2: 92.9% Loss_2: 0.000212  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000836, Accuracy_2: 89.4% Loss_2: 0.000539  [10293/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001035, Accuracy_2: 85.1% Loss_2: 0.000583  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000902, Accuracy_2: 86.5% Loss_2: 0.002741  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002025, Accuracy_2: 86.5% Loss_2: 0.001993  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000010, Accuracy_2: 90.8% Loss_2: 0.000614  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002505, Accuracy_2: 90.8% Loss_2: 0.000660  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000299, Accuracy_2: 90.1% Loss_2: 0.000005  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000012, Accuracy_2: 91.5% Loss_2: 0.001076  [14241/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000862, Accuracy_2: 85.1% Loss_2: 0.000025  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001889, Accuracy_2: 90.8% Loss_2: 0.000006  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000004, Accuracy_2: 85.1% Loss_2: 0.002775  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000022, Accuracy_2: 90.1% Loss_2: 0.000596  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000003, Accuracy_2: 87.9% Loss_2: 0.000261  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000094  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000026, Accuracy_2: 91.5% Loss_2: 0.001917  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000863, Accuracy_2: 85.8% Loss_2: 0.001036  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002089, Accuracy_2: 86.5% Loss_2: 0.002135  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000132, Accuracy_2: 86.5% Loss_2: 0.001673  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000038, Accuracy_2: 92.2% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.001293  [ 5781/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000458, Accuracy_2: 83.0% Loss_2: 0.000388  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000037, Accuracy_2: 92.2% Loss_2: 0.000068  [ 6909/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000661, Accuracy_2: 85.1% Loss_2: 0.000022  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001122, Accuracy_2: 90.8% Loss_2: 0.001878  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001694, Accuracy_2: 92.2% Loss_2: 0.001377  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002168, Accuracy_2: 90.1% Loss_2: 0.001978  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001766, Accuracy_2: 88.7% Loss_2: 0.000020  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000418, Accuracy_2: 86.5% Loss_2: 0.001495  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000666, Accuracy_2: 91.5% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000059, Accuracy_2: 87.9% Loss_2: 0.000025  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.003458  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003816, Accuracy_2: 85.1% Loss_2: 0.000498  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000101, Accuracy_2: 82.3% Loss_2: 0.005754  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000323, Accuracy_2: 90.8% Loss_2: 0.003820  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001443, Accuracy_2: 92.2% Loss_2: 0.000001  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.001854  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000600, Accuracy_2: 87.2% Loss_2: 0.001258  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001489, Accuracy_2: 90.1% Loss_2: 0.002654  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000048, Accuracy_2: 93.6% Loss_2: 0.000005  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003881, Accuracy_2: 88.7% Loss_2: 0.000922  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.004793, Accuracy_2: 86.5% Loss_2: 0.001568  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002030, Accuracy_2: 90.1% Loss_2: 0.000969  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000646, Accuracy_2: 90.1% Loss_2: 0.000536  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000468, Accuracy_2: 92.2% Loss_2: 0.000098  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003322, Accuracy_2: 88.7% Loss_2: 0.001558  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000753, Accuracy_2: 90.8% Loss_2: 0.002379  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000692, Accuracy_2: 86.5% Loss_2: 0.001819  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000067  [ 6909/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000148, Accuracy_2: 82.3% Loss_2: 0.000563  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001107, Accuracy_2: 88.7% Loss_2: 0.001332  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000214, Accuracy_2: 89.4% Loss_2: 0.000244  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000012, Accuracy_2: 90.8% Loss_2: 0.000733  [ 9165/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001459, Accuracy_2: 83.0% Loss_2: 0.001919  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000002  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000010, Accuracy_2: 87.2% Loss_2: 0.000039  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000002, Accuracy_2: 92.9% Loss_2: 0.000344  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001217, Accuracy_2: 88.7% Loss_2: 0.000092  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000966, Accuracy_2: 92.9% Loss_2: 0.000003  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000630, Accuracy_2: 90.8% Loss_2: 0.000169  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000134, Accuracy_2: 91.5% Loss_2: 0.000465  [13677/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000025, Accuracy_2: 94.3% Loss_2: 0.000013  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000388, Accuracy_2: 91.5% Loss_2: 0.000205  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000020, Accuracy_2: 91.5% Loss_2: 0.000050  [  141/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001207, Accuracy_2: 83.7% Loss_2: 0.000753  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001761, Accuracy_2: 87.2% Loss_2: 0.000057  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001937, Accuracy_2: 87.9% Loss_2: 0.000059  [ 1833/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000002, Accuracy_2: 95.0% Loss_2: 0.002989  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001924, Accuracy_2: 87.2% Loss_2: 0.000387  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000964, Accuracy_2: 90.1% Loss_2: 0.000061  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000050, Accuracy_2: 87.9% Loss_2: 0.000316  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001311, Accuracy_2: 88.7% Loss_2: 0.000012  [ 4653/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000156, Accuracy_2: 85.1% Loss_2: 0.000002  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000688, Accuracy_2: 91.5% Loss_2: 0.000138  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000746, Accuracy_2: 90.1% Loss_2: 0.000002  [ 6345/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002402, Accuracy_2: 85.8% Loss_2: 0.000386  [ 6909/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000580, Accuracy_2: 86.5% Loss_2: 0.000014  [ 7473/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001031, Accuracy_2: 83.7% Loss_2: 0.001493  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000984, Accuracy_2: 89.4% Loss_2: 0.000548  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001522, Accuracy_2: 94.3% Loss_2: 0.000002  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000036, Accuracy_2: 87.9% Loss_2: 0.000011  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000789, Accuracy_2: 90.8% Loss_2: 0.004667  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000246, Accuracy_2: 87.9% Loss_2: 0.000891  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000650, Accuracy_2: 89.4% Loss_2: 0.000292  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000391  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000076, Accuracy_2: 86.5% Loss_2: 0.002021  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000189, Accuracy_2: 93.6% Loss_2: 0.000004  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000018, Accuracy_2: 88.7% Loss_2: 0.001976  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001734, Accuracy_2: 90.1% Loss_2: 0.000113  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002622, Accuracy_2: 92.2% Loss_2: 0.000027  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000022, Accuracy_2: 87.2% Loss_2: 0.000081  [  705/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000500, Accuracy_2: 85.1% Loss_2: 0.000455  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000108, Accuracy_2: 94.3% Loss_2: 0.000061  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001005, Accuracy_2: 90.8% Loss_2: 0.000767  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000040, Accuracy_2: 85.1% Loss_2: 0.001193  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000159, Accuracy_2: 89.4% Loss_2: 0.000626  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.009224, Accuracy_2: 90.8% Loss_2: 0.000733  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000024, Accuracy_2: 89.4% Loss_2: 0.000470  [ 4653/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000116  [ 5217/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000002, Accuracy_2: 91.5% Loss_2: 0.002494  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002927, Accuracy_2: 92.9% Loss_2: 0.000854  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000602, Accuracy_2: 88.7% Loss_2: 0.004462  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002393, Accuracy_2: 90.1% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.002041, Accuracy_2: 83.0% Loss_2: 0.001259  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002365, Accuracy_2: 89.4% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000496, Accuracy_2: 90.1% Loss_2: 0.000024  [ 9165/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000348, Accuracy_2: 85.1% Loss_2: 0.000423  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000033, Accuracy_2: 85.1% Loss_2: 0.000003  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001116, Accuracy_2: 88.7% Loss_2: 0.000828  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000706, Accuracy_2: 90.8% Loss_2: 0.000001  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003861, Accuracy_2: 93.6% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000053, Accuracy_2: 87.9% Loss_2: 0.001296  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001315, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000311, Accuracy_2: 90.1% Loss_2: 0.000199  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000160, Accuracy_2: 87.2% Loss_2: 0.002194  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000463, Accuracy_2: 92.2% Loss_2: 0.000079  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000084, Accuracy_2: 89.4% Loss_2: 0.000603  [  141/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.000380, Accuracy_2: 83.7% Loss_2: 0.000009  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000255, Accuracy_2: 85.8% Loss_2: 0.001427  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001118, Accuracy_2: 88.7% Loss_2: 0.000005  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001592, Accuracy_2: 92.2% Loss_2: 0.005179  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000677, Accuracy_2: 87.2% Loss_2: 0.000323  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000440, Accuracy_2: 89.4% Loss_2: 0.000064  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000293, Accuracy_2: 89.4% Loss_2: 0.001396  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000006, Accuracy_2: 85.8% Loss_2: 0.000005  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001317, Accuracy_2: 91.5% Loss_2: 0.000965  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001566, Accuracy_2: 87.2% Loss_2: 0.000230  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000101, Accuracy_2: 89.4% Loss_2: 0.000045  [ 6345/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000752, Accuracy_2: 85.8% Loss_2: 0.002315  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000118  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002297, Accuracy_2: 89.4% Loss_2: 0.000562  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001659, Accuracy_2: 88.7% Loss_2: 0.002430  [ 8601/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000062, Accuracy_2: 84.4% Loss_2: 0.000403  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000811, Accuracy_2: 89.4% Loss_2: 0.000164  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003696, Accuracy_2: 89.4% Loss_2: 0.002555  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000599, Accuracy_2: 90.1% Loss_2: 0.002124  [10857/15250]\n",
      "Accuracy_1: 79.4%, Loss_1: 0.003984, Accuracy_2: 80.9% Loss_2: 0.001732  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001457, Accuracy_2: 90.1% Loss_2: 0.001928  [11985/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003797, Accuracy_2: 87.2% Loss_2: 0.000319  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001735, Accuracy_2: 93.6% Loss_2: 0.001133  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000485, Accuracy_2: 91.5% Loss_2: 0.001486  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000631, Accuracy_2: 89.4% Loss_2: 0.000782  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000327, Accuracy_2: 90.8% Loss_2: 0.001697  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000252, Accuracy_2: 90.8% Loss_2: 0.000879  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003879, Accuracy_2: 94.3% Loss_2: 0.002128  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000991, Accuracy_2: 88.7% Loss_2: 0.000190  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002601, Accuracy_2: 92.2% Loss_2: 0.000368  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000033, Accuracy_2: 88.7% Loss_2: 0.002637  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000734, Accuracy_2: 87.2% Loss_2: 0.000211  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001030, Accuracy_2: 88.7% Loss_2: 0.000090  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000012, Accuracy_2: 89.4% Loss_2: 0.000890  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000259, Accuracy_2: 88.7% Loss_2: 0.001584  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000030, Accuracy_2: 86.5% Loss_2: 0.000891  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000825, Accuracy_2: 88.7% Loss_2: 0.000430  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000621, Accuracy_2: 88.7% Loss_2: 0.001672  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000875, Accuracy_2: 87.9% Loss_2: 0.001167  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000081, Accuracy_2: 87.9% Loss_2: 0.000003  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002084, Accuracy_2: 93.6% Loss_2: 0.000488  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000703, Accuracy_2: 87.9% Loss_2: 0.000007  [ 9165/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.004356, Accuracy_2: 88.7% Loss_2: 0.000035  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000081, Accuracy_2: 87.2% Loss_2: 0.000065  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000074, Accuracy_2: 87.2% Loss_2: 0.000617  [10857/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000094, Accuracy_2: 95.7% Loss_2: 0.000077  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000748, Accuracy_2: 92.2% Loss_2: 0.001188  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000460, Accuracy_2: 88.7% Loss_2: 0.000370  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001888, Accuracy_2: 90.1% Loss_2: 0.002331  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.005002, Accuracy_2: 88.7% Loss_2: 0.000026  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000092, Accuracy_2: 85.1% Loss_2: 0.002398  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000535, Accuracy_2: 90.1% Loss_2: 0.001596  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000120, Accuracy_2: 88.7% Loss_2: 0.000110  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001689, Accuracy_2: 89.4% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000665, Accuracy_2: 89.4% Loss_2: 0.000471  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002798, Accuracy_2: 95.7% Loss_2: 0.001173  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000016, Accuracy_2: 89.4% Loss_2: 0.002165  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000860, Accuracy_2: 89.4% Loss_2: 0.000166  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000073, Accuracy_2: 90.8% Loss_2: 0.000282  [ 3525/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000964  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.001833  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000012, Accuracy_2: 91.5% Loss_2: 0.000001  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001599, Accuracy_2: 87.2% Loss_2: 0.000398  [ 5781/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000529, Accuracy_2: 94.3% Loss_2: 0.000627  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000793  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000045, Accuracy_2: 91.5% Loss_2: 0.000383  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000805, Accuracy_2: 90.1% Loss_2: 0.000025  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000012, Accuracy_2: 90.1% Loss_2: 0.001324  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000201, Accuracy_2: 88.7% Loss_2: 0.000396  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000033, Accuracy_2: 87.9% Loss_2: 0.000040  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001209, Accuracy_2: 90.8% Loss_2: 0.001814  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000081, Accuracy_2: 88.7% Loss_2: 0.001040  [10857/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000608, Accuracy_2: 87.2% Loss_2: 0.000062  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000534, Accuracy_2: 92.9% Loss_2: 0.000001  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003455, Accuracy_2: 92.2% Loss_2: 0.001413  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000365, Accuracy_2: 90.8% Loss_2: 0.000472  [13113/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.002059, Accuracy_2: 80.1% Loss_2: 0.004677  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000939, Accuracy_2: 86.5% Loss_2: 0.001415  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001063, Accuracy_2: 88.7% Loss_2: 0.000019  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000000 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000254, Accuracy_2: 90.1% Loss_2: 0.001066  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.001212  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000108, Accuracy_2: 87.2% Loss_2: 0.000018  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000040, Accuracy_2: 90.1% Loss_2: 0.003635  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001157, Accuracy_2: 87.9% Loss_2: 0.000245  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000632, Accuracy_2: 86.5% Loss_2: 0.000113  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000970, Accuracy_2: 89.4% Loss_2: 0.000342  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002391, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000173, Accuracy_2: 92.2% Loss_2: 0.000192  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000073, Accuracy_2: 90.1% Loss_2: 0.000347  [ 5217/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001438, Accuracy_2: 87.2% Loss_2: 0.000046  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000008, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.004131, Accuracy_2: 92.9% Loss_2: 0.000013  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000648, Accuracy_2: 84.4% Loss_2: 0.003786  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000034, Accuracy_2: 90.1% Loss_2: 0.001067  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000413, Accuracy_2: 88.7% Loss_2: 0.000077  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000373, Accuracy_2: 91.5% Loss_2: 0.000722  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001334, Accuracy_2: 90.8% Loss_2: 0.000038  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000125  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000044, Accuracy_2: 89.4% Loss_2: 0.000005  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.004514, Accuracy_2: 87.9% Loss_2: 0.000794  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003874, Accuracy_2: 90.1% Loss_2: 0.000987  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000005, Accuracy_2: 91.5% Loss_2: 0.000179  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000701, Accuracy_2: 89.4% Loss_2: 0.000011  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000535, Accuracy_2: 88.7% Loss_2: 0.000063  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000740, Accuracy_2: 87.9% Loss_2: 0.000864  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000802, Accuracy_2: 93.6% Loss_2: 0.000004  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.004270, Accuracy_2: 92.9% Loss_2: 0.000004  [  141/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001219, Accuracy_2: 87.2% Loss_2: 0.000934  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002159, Accuracy_2: 93.6% Loss_2: 0.000225  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001224, Accuracy_2: 89.4% Loss_2: 0.000255  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000563  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000007, Accuracy_2: 87.2% Loss_2: 0.000310  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000319, Accuracy_2: 90.8% Loss_2: 0.000009  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000103  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000013, Accuracy_2: 88.7% Loss_2: 0.001091  [ 4653/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003251, Accuracy_2: 85.1% Loss_2: 0.000348  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000003, Accuracy_2: 87.2% Loss_2: 0.000890  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000273, Accuracy_2: 92.2% Loss_2: 0.000011  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001363, Accuracy_2: 90.1% Loss_2: 0.000052  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000893, Accuracy_2: 87.2% Loss_2: 0.000095  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001394, Accuracy_2: 86.5% Loss_2: 0.000022  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000311, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000204, Accuracy_2: 91.5% Loss_2: 0.000217  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001273, Accuracy_2: 89.4% Loss_2: 0.000962  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001252, Accuracy_2: 86.5% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001138, Accuracy_2: 86.5% Loss_2: 0.001291  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000540, Accuracy_2: 84.4% Loss_2: 0.002364  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000008, Accuracy_2: 90.8% Loss_2: 0.000014  [11985/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000020, Accuracy_2: 92.9% Loss_2: 0.000882  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000001, Accuracy_2: 84.4% Loss_2: 0.003257  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000005, Accuracy_2: 90.1% Loss_2: 0.000176  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000798, Accuracy_2: 87.9% Loss_2: 0.000039  [14241/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001087, Accuracy_2: 87.2% Loss_2: 0.000106  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000487  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000104, Accuracy_2: 92.2% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000995, Accuracy_2: 91.5% Loss_2: 0.001309  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000810  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000038  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000760, Accuracy_2: 88.7% Loss_2: 0.000100  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000021, Accuracy_2: 90.8% Loss_2: 0.000897  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000895, Accuracy_2: 90.8% Loss_2: 0.000476  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000330, Accuracy_2: 89.4% Loss_2: 0.002098  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000307, Accuracy_2: 92.9% Loss_2: 0.000032  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000269, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000196, Accuracy_2: 89.4% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000533, Accuracy_2: 85.8% Loss_2: 0.000786  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000313, Accuracy_2: 90.1% Loss_2: 0.002069  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000013, Accuracy_2: 85.8% Loss_2: 0.002926  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000451, Accuracy_2: 89.4% Loss_2: 0.000356  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000339, Accuracy_2: 91.5% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000248  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000533, Accuracy_2: 90.1% Loss_2: 0.001668  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000351  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002798, Accuracy_2: 92.2% Loss_2: 0.000380  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000017, Accuracy_2: 92.9% Loss_2: 0.000010  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001175, Accuracy_2: 90.8% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000186, Accuracy_2: 85.8% Loss_2: 0.000001  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001205, Accuracy_2: 87.2% Loss_2: 0.000005  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000475, Accuracy_2: 93.6% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000005, Accuracy_2: 90.8% Loss_2: 0.000007  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001271, Accuracy_2: 90.8% Loss_2: 0.000509  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003436, Accuracy_2: 90.1% Loss_2: 0.004077  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000459, Accuracy_2: 91.5% Loss_2: 0.000010  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000051  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000051, Accuracy_2: 89.4% Loss_2: 0.000046  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000002, Accuracy_2: 87.9% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003069, Accuracy_2: 90.8% Loss_2: 0.000034  [ 4089/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000091, Accuracy_2: 95.7% Loss_2: 0.001901  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002340, Accuracy_2: 91.5% Loss_2: 0.001376  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000024, Accuracy_2: 87.2% Loss_2: 0.000253  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001100, Accuracy_2: 89.4% Loss_2: 0.000102  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000084, Accuracy_2: 87.9% Loss_2: 0.000652  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003371, Accuracy_2: 92.2% Loss_2: 0.001158  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000438, Accuracy_2: 85.8% Loss_2: 0.000532  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000516, Accuracy_2: 87.9% Loss_2: 0.002541  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001456, Accuracy_2: 94.3% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000105, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000367, Accuracy_2: 85.1% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000230, Accuracy_2: 87.2% Loss_2: 0.000501  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000006, Accuracy_2: 90.8% Loss_2: 0.000019  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001283, Accuracy_2: 88.7% Loss_2: 0.000017  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000870, Accuracy_2: 88.7% Loss_2: 0.000560  [12549/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001353, Accuracy_2: 87.9% Loss_2: 0.000164  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001562, Accuracy_2: 93.6% Loss_2: 0.000064  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001520, Accuracy_2: 86.5% Loss_2: 0.000900  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001806, Accuracy_2: 92.9% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000811, Accuracy_2: 91.5% Loss_2: 0.000291  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001182, Accuracy_2: 85.8% Loss_2: 0.000781  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001841, Accuracy_2: 94.3% Loss_2: 0.000546  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001954, Accuracy_2: 88.7% Loss_2: 0.001659  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000001, Accuracy_2: 85.8% Loss_2: 0.000940  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001520, Accuracy_2: 87.9% Loss_2: 0.002451  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000190, Accuracy_2: 90.1% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000003  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000415  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001234, Accuracy_2: 85.8% Loss_2: 0.000180  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002320, Accuracy_2: 93.6% Loss_2: 0.000074  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000964, Accuracy_2: 94.3% Loss_2: 0.002008  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002018, Accuracy_2: 87.9% Loss_2: 0.002032  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000017, Accuracy_2: 87.9% Loss_2: 0.002823  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003248, Accuracy_2: 90.8% Loss_2: 0.003290  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000043, Accuracy_2: 85.8% Loss_2: 0.002641  [ 8601/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003684, Accuracy_2: 85.1% Loss_2: 0.003317  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002287, Accuracy_2: 89.4% Loss_2: 0.001227  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002496, Accuracy_2: 87.9% Loss_2: 0.003822  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000028, Accuracy_2: 87.2% Loss_2: 0.001276  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000030  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.003343, Accuracy_2: 88.7% Loss_2: 0.002999  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000239, Accuracy_2: 91.5% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001161, Accuracy_2: 91.5% Loss_2: 0.000123  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001663, Accuracy_2: 90.8% Loss_2: 0.000557  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000793, Accuracy_2: 89.4% Loss_2: 0.002305  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000083, Accuracy_2: 87.9% Loss_2: 0.000846  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000972, Accuracy_2: 92.9% Loss_2: 0.000787  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000521, Accuracy_2: 87.9% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001505, Accuracy_2: 92.2% Loss_2: 0.001299  [ 1269/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000780, Accuracy_2: 86.5% Loss_2: 0.000001  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001958, Accuracy_2: 86.5% Loss_2: 0.000044  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001638, Accuracy_2: 90.8% Loss_2: 0.000126  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001306, Accuracy_2: 94.3% Loss_2: 0.000475  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000475, Accuracy_2: 88.7% Loss_2: 0.002703  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000147, Accuracy_2: 86.5% Loss_2: 0.000529  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000525, Accuracy_2: 89.4% Loss_2: 0.000449  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000004  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000032, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 87.9% Loss_2: 0.001048  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000035, Accuracy_2: 87.2% Loss_2: 0.000136  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002508, Accuracy_2: 90.1% Loss_2: 0.000694  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000006, Accuracy_2: 89.4% Loss_2: 0.001957  [ 9165/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001435, Accuracy_2: 87.2% Loss_2: 0.002265  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000037, Accuracy_2: 85.1% Loss_2: 0.002347  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002694, Accuracy_2: 91.5% Loss_2: 0.000233  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000073, Accuracy_2: 92.9% Loss_2: 0.000730  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000042, Accuracy_2: 87.9% Loss_2: 0.000020  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000074, Accuracy_2: 88.7% Loss_2: 0.001402  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000014, Accuracy_2: 90.1% Loss_2: 0.000294  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000116, Accuracy_2: 88.7% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000842, Accuracy_2: 91.5% Loss_2: 0.001445  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001439, Accuracy_2: 90.8% Loss_2: 0.001220  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000011  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001756, Accuracy_2: 90.1% Loss_2: 0.002051  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000280, Accuracy_2: 87.2% Loss_2: 0.000710  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000817, Accuracy_2: 91.5% Loss_2: 0.000506  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001563, Accuracy_2: 89.4% Loss_2: 0.000266  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000258, Accuracy_2: 91.5% Loss_2: 0.001325  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000023  [ 3525/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000568, Accuracy_2: 93.6% Loss_2: 0.000583  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000858  [ 4653/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000981, Accuracy_2: 86.5% Loss_2: 0.000001  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000766, Accuracy_2: 90.8% Loss_2: 0.000011  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000017  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000131, Accuracy_2: 90.8% Loss_2: 0.001299  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001227, Accuracy_2: 89.4% Loss_2: 0.000182  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000228  [ 8037/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000704, Accuracy_2: 83.7% Loss_2: 0.002445  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000078, Accuracy_2: 87.9% Loss_2: 0.000356  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000033, Accuracy_2: 92.2% Loss_2: 0.002139  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000056, Accuracy_2: 93.6% Loss_2: 0.000015  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001306, Accuracy_2: 90.1% Loss_2: 0.002204  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000272, Accuracy_2: 92.9% Loss_2: 0.000055  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000656, Accuracy_2: 87.2% Loss_2: 0.003119  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000394, Accuracy_2: 87.9% Loss_2: 0.001721  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000782, Accuracy_2: 91.5% Loss_2: 0.000306  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000242, Accuracy_2: 88.7% Loss_2: 0.001125  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000181  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002761, Accuracy_2: 88.7% Loss_2: 0.001958  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000187, Accuracy_2: 89.4% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 86.5% Loss_2: 0.002775  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000430, Accuracy_2: 87.2% Loss_2: 0.000849  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000008, Accuracy_2: 87.2% Loss_2: 0.001193  [ 1833/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000315, Accuracy_2: 95.0% Loss_2: 0.000052  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000755, Accuracy_2: 93.6% Loss_2: 0.000624  [ 2961/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001264, Accuracy_2: 85.1% Loss_2: 0.000190  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000564, Accuracy_2: 88.7% Loss_2: 0.000084  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.006253, Accuracy_2: 89.4% Loss_2: 0.000051  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000921, Accuracy_2: 87.2% Loss_2: 0.001747  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002184, Accuracy_2: 94.3% Loss_2: 0.001031  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000436, Accuracy_2: 90.8% Loss_2: 0.001117  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002079, Accuracy_2: 87.2% Loss_2: 0.000001  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.001783  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001149, Accuracy_2: 91.5% Loss_2: 0.000001  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001123, Accuracy_2: 86.5% Loss_2: 0.003044  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000226  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001482, Accuracy_2: 92.9% Loss_2: 0.001519  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000743, Accuracy_2: 88.7% Loss_2: 0.002089  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.001289  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000531, Accuracy_2: 86.5% Loss_2: 0.003859  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000071, Accuracy_2: 92.9% Loss_2: 0.000012  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.004049, Accuracy_2: 86.5% Loss_2: 0.006520  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000059, Accuracy_2: 86.5% Loss_2: 0.004475  [13113/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003388, Accuracy_2: 86.5% Loss_2: 0.000187  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000160, Accuracy_2: 90.8% Loss_2: 0.000069  [14241/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002598, Accuracy_2: 87.9% Loss_2: 0.000576  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.003171  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000088, Accuracy_2: 87.2% Loss_2: 0.000024  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002282, Accuracy_2: 92.2% Loss_2: 0.000727  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000806, Accuracy_2: 91.5% Loss_2: 0.000277  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 86.5% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001206, Accuracy_2: 86.5% Loss_2: 0.002345  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000812, Accuracy_2: 90.8% Loss_2: 0.000051  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000639, Accuracy_2: 90.8% Loss_2: 0.001720  [ 4653/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001938, Accuracy_2: 86.5% Loss_2: 0.000828  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000064, Accuracy_2: 85.8% Loss_2: 0.000621  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000142, Accuracy_2: 92.9% Loss_2: 0.001140  [ 6345/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000001  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000727  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001769, Accuracy_2: 88.7% Loss_2: 0.000315  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002658, Accuracy_2: 90.8% Loss_2: 0.000156  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000009, Accuracy_2: 89.4% Loss_2: 0.000323  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000251, Accuracy_2: 89.4% Loss_2: 0.000003  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000459, Accuracy_2: 86.5% Loss_2: 0.001871  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000014, Accuracy_2: 88.7% Loss_2: 0.000005  [10857/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000015, Accuracy_2: 93.6% Loss_2: 0.000654  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000439, Accuracy_2: 88.7% Loss_2: 0.000947  [11985/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001723, Accuracy_2: 95.0% Loss_2: 0.000002  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000261  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000071, Accuracy_2: 92.2% Loss_2: 0.000501  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000013, Accuracy_2: 90.1% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000130, Accuracy_2: 87.9% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000040, Accuracy_2: 87.9% Loss_2: 0.000516  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000840, Accuracy_2: 83.0% Loss_2: 0.004335  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000657, Accuracy_2: 85.1% Loss_2: 0.002543  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000063, Accuracy_2: 87.2% Loss_2: 0.000712  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000046  [ 2961/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000440, Accuracy_2: 94.3% Loss_2: 0.000235  [ 3525/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000040, Accuracy_2: 93.6% Loss_2: 0.000003  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001722, Accuracy_2: 92.9% Loss_2: 0.000010  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000014, Accuracy_2: 89.4% Loss_2: 0.000003  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000498, Accuracy_2: 90.1% Loss_2: 0.000144  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001717, Accuracy_2: 91.5% Loss_2: 0.000049  [ 6345/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002456, Accuracy_2: 86.5% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000501, Accuracy_2: 87.2% Loss_2: 0.000003  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000100, Accuracy_2: 90.1% Loss_2: 0.001264  [ 8037/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003662, Accuracy_2: 87.9% Loss_2: 0.001391  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000001, Accuracy_2: 85.8% Loss_2: 0.001722  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000745, Accuracy_2: 92.2% Loss_2: 0.000003  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000008, Accuracy_2: 88.7% Loss_2: 0.000530  [10857/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000156, Accuracy_2: 84.4% Loss_2: 0.001458  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001414, Accuracy_2: 89.4% Loss_2: 0.001516  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000408, Accuracy_2: 91.5% Loss_2: 0.001604  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000239, Accuracy_2: 85.1% Loss_2: 0.000276  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000008, Accuracy_2: 89.4% Loss_2: 0.001337  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000352, Accuracy_2: 87.9% Loss_2: 0.001083  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.002249  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003021, Accuracy_2: 87.2% Loss_2: 0.000001  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001099, Accuracy_2: 87.9% Loss_2: 0.001440  [  705/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002963, Accuracy_2: 87.2% Loss_2: 0.000001  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000001, Accuracy_2: 85.1% Loss_2: 0.001089  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000011, Accuracy_2: 91.5% Loss_2: 0.001396  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001569, Accuracy_2: 89.4% Loss_2: 0.001009  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001548, Accuracy_2: 90.8% Loss_2: 0.000047  [ 3525/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.003983, Accuracy_2: 83.7% Loss_2: 0.002084  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000592, Accuracy_2: 89.4% Loss_2: 0.000229  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002165, Accuracy_2: 87.9% Loss_2: 0.000293  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001365, Accuracy_2: 92.2% Loss_2: 0.001204  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000007, Accuracy_2: 90.8% Loss_2: 0.002987  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000559, Accuracy_2: 91.5% Loss_2: 0.000355  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001469, Accuracy_2: 90.8% Loss_2: 0.001407  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000690, Accuracy_2: 85.8% Loss_2: 0.000079  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000012, Accuracy_2: 88.7% Loss_2: 0.000076  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000005, Accuracy_2: 87.2% Loss_2: 0.004056  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001642, Accuracy_2: 89.4% Loss_2: 0.000124  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000553, Accuracy_2: 90.1% Loss_2: 0.000684  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001258, Accuracy_2: 87.9% Loss_2: 0.000012  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001708, Accuracy_2: 90.8% Loss_2: 0.000230  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000012, Accuracy_2: 87.9% Loss_2: 0.001424  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002642, Accuracy_2: 87.9% Loss_2: 0.000427  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000248  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001312, Accuracy_2: 85.1% Loss_2: 0.001148  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001400, Accuracy_2: 89.4% Loss_2: 0.000675  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001182, Accuracy_2: 86.5% Loss_2: 0.001123  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000217, Accuracy_2: 92.2% Loss_2: 0.000233  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000303, Accuracy_2: 89.4% Loss_2: 0.000004  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000362, Accuracy_2: 91.5% Loss_2: 0.001116  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001166, Accuracy_2: 90.8% Loss_2: 0.000001  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000290, Accuracy_2: 91.5% Loss_2: 0.000010  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000199, Accuracy_2: 85.8% Loss_2: 0.000821  [ 2961/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001097, Accuracy_2: 85.1% Loss_2: 0.000440  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002948, Accuracy_2: 87.9% Loss_2: 0.000219  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000413, Accuracy_2: 89.4% Loss_2: 0.000070  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000045, Accuracy_2: 87.9% Loss_2: 0.001253  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001523, Accuracy_2: 88.7% Loss_2: 0.001563  [ 5781/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000035, Accuracy_2: 93.6% Loss_2: 0.000255  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000016, Accuracy_2: 89.4% Loss_2: 0.002198  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000008, Accuracy_2: 89.4% Loss_2: 0.000319  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000095, Accuracy_2: 88.7% Loss_2: 0.000227  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000719, Accuracy_2: 89.4% Loss_2: 0.000046  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000035  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000470, Accuracy_2: 92.9% Loss_2: 0.004805  [ 9729/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001675, Accuracy_2: 96.5% Loss_2: 0.000001  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000952, Accuracy_2: 89.4% Loss_2: 0.000043  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000268, Accuracy_2: 95.0% Loss_2: 0.000002  [11421/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000129, Accuracy_2: 82.3% Loss_2: 0.003088  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000187, Accuracy_2: 89.4% Loss_2: 0.000586  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000014, Accuracy_2: 89.4% Loss_2: 0.001819  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000713, Accuracy_2: 87.2% Loss_2: 0.000144  [13677/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001563, Accuracy_2: 85.8% Loss_2: 0.001576  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000008, Accuracy_2: 87.9% Loss_2: 0.001113  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000012  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001416, Accuracy_2: 87.9% Loss_2: 0.002079  [  705/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002061, Accuracy_2: 85.1% Loss_2: 0.000205  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000156, Accuracy_2: 89.4% Loss_2: 0.000577  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000009, Accuracy_2: 90.1% Loss_2: 0.000320  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000120, Accuracy_2: 90.1% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000135, Accuracy_2: 87.2% Loss_2: 0.000340  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001102, Accuracy_2: 91.5% Loss_2: 0.000082  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000125, Accuracy_2: 89.4% Loss_2: 0.000048  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000946, Accuracy_2: 87.9% Loss_2: 0.000363  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001353, Accuracy_2: 88.7% Loss_2: 0.000170  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000041  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001955, Accuracy_2: 88.7% Loss_2: 0.000014  [ 6909/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000003, Accuracy_2: 92.2% Loss_2: 0.000247  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000340, Accuracy_2: 87.9% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.004384, Accuracy_2: 87.9% Loss_2: 0.001937  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000377, Accuracy_2: 93.6% Loss_2: 0.000005  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000012, Accuracy_2: 85.8% Loss_2: 0.002324  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000418, Accuracy_2: 88.7% Loss_2: 0.001895  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003382, Accuracy_2: 90.8% Loss_2: 0.000148  [10857/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002628, Accuracy_2: 86.5% Loss_2: 0.000033  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000568, Accuracy_2: 91.5% Loss_2: 0.003376  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000004, Accuracy_2: 85.8% Loss_2: 0.000082  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002486, Accuracy_2: 89.4% Loss_2: 0.000085  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000214, Accuracy_2: 90.1% Loss_2: 0.001556  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001335, Accuracy_2: 90.8% Loss_2: 0.000259  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002434, Accuracy_2: 92.2% Loss_2: 0.000035  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000350, Accuracy_2: 88.7% Loss_2: 0.001014  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001046, Accuracy_2: 87.9% Loss_2: 0.000727  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000970, Accuracy_2: 90.1% Loss_2: 0.000517  [ 1269/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001240, Accuracy_2: 87.9% Loss_2: 0.001971  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000070, Accuracy_2: 91.5% Loss_2: 0.001199  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000232, Accuracy_2: 87.2% Loss_2: 0.002316  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000797, Accuracy_2: 85.1% Loss_2: 0.001881  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.003798  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001712, Accuracy_2: 91.5% Loss_2: 0.000170  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000904  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000006, Accuracy_2: 92.9% Loss_2: 0.000167  [ 5781/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000356, Accuracy_2: 85.1% Loss_2: 0.001427  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000182, Accuracy_2: 89.4% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000760, Accuracy_2: 90.8% Loss_2: 0.001235  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001330, Accuracy_2: 92.9% Loss_2: 0.000018  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000016, Accuracy_2: 88.7% Loss_2: 0.000003  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000191, Accuracy_2: 92.2% Loss_2: 0.000047  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000514, Accuracy_2: 92.2% Loss_2: 0.000116  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000116, Accuracy_2: 89.4% Loss_2: 0.000387  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.001023  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000011, Accuracy_2: 94.3% Loss_2: 0.000007  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003497, Accuracy_2: 90.1% Loss_2: 0.000596  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002206, Accuracy_2: 93.6% Loss_2: 0.000002  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000708, Accuracy_2: 90.8% Loss_2: 0.000004  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000009, Accuracy_2: 89.4% Loss_2: 0.000072  [13677/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000005  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002848, Accuracy_2: 89.4% Loss_2: 0.000105  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000568, Accuracy_2: 91.5% Loss_2: 0.001830  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000811, Accuracy_2: 92.2% Loss_2: 0.000003  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000277, Accuracy_2: 90.1% Loss_2: 0.000258  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000016, Accuracy_2: 91.5% Loss_2: 0.000644  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001059, Accuracy_2: 93.6% Loss_2: 0.000021  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002991, Accuracy_2: 92.2% Loss_2: 0.000012  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000506, Accuracy_2: 89.4% Loss_2: 0.000004  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000883, Accuracy_2: 87.9% Loss_2: 0.001113  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003092, Accuracy_2: 87.2% Loss_2: 0.001026  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001490, Accuracy_2: 87.2% Loss_2: 0.000623  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000460, Accuracy_2: 89.4% Loss_2: 0.001918  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000805, Accuracy_2: 87.2% Loss_2: 0.002979  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000920, Accuracy_2: 89.4% Loss_2: 0.001361  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000062, Accuracy_2: 89.4% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000001  [ 8037/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000002, Accuracy_2: 92.9% Loss_2: 0.002782  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000023, Accuracy_2: 90.1% Loss_2: 0.002223  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000740, Accuracy_2: 85.8% Loss_2: 0.002222  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000146, Accuracy_2: 89.4% Loss_2: 0.000011  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000012  [10857/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000124, Accuracy_2: 85.1% Loss_2: 0.001167  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000190, Accuracy_2: 86.5% Loss_2: 0.000474  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000014, Accuracy_2: 86.5% Loss_2: 0.000399  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000717, Accuracy_2: 90.1% Loss_2: 0.000545  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.003977  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000224  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000012, Accuracy_2: 89.4% Loss_2: 0.000003  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002977, Accuracy_2: 91.5% Loss_2: 0.000001  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000390, Accuracy_2: 90.8% Loss_2: 0.000013  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000982  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000428, Accuracy_2: 93.6% Loss_2: 0.000813  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001207, Accuracy_2: 91.5% Loss_2: 0.000014  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000001, Accuracy_2: 86.5% Loss_2: 0.000263  [ 2961/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001839, Accuracy_2: 89.4% Loss_2: 0.000029  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000003, Accuracy_2: 89.4% Loss_2: 0.000260  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000925, Accuracy_2: 89.4% Loss_2: 0.002341  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000004, Accuracy_2: 85.8% Loss_2: 0.000721  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000227  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000260, Accuracy_2: 87.2% Loss_2: 0.003148  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000688, Accuracy_2: 90.8% Loss_2: 0.001703  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.003391  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000003, Accuracy_2: 87.2% Loss_2: 0.000389  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 86.5% Loss_2: 0.000238  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001756, Accuracy_2: 90.8% Loss_2: 0.000140  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000003, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000829, Accuracy_2: 87.9% Loss_2: 0.000003  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000637, Accuracy_2: 90.8% Loss_2: 0.000895  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000004, Accuracy_2: 87.2% Loss_2: 0.000010  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001012, Accuracy_2: 90.8% Loss_2: 0.001187  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000515, Accuracy_2: 90.1% Loss_2: 0.000024  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000210, Accuracy_2: 87.2% Loss_2: 0.000007  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000029, Accuracy_2: 85.8% Loss_2: 0.000184  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000005, Accuracy_2: 90.8% Loss_2: 0.001045  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001135, Accuracy_2: 89.4% Loss_2: 0.001405  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.6%, Avg loss: 0.000001 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000153, Accuracy_2: 90.1% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000245, Accuracy_2: 90.8% Loss_2: 0.000220  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000385, Accuracy_2: 90.8% Loss_2: 0.000276  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000426, Accuracy_2: 85.1% Loss_2: 0.004380  [ 1833/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000229, Accuracy_2: 95.0% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.007420, Accuracy_2: 89.4% Loss_2: 0.002757  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001798, Accuracy_2: 88.7% Loss_2: 0.000464  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.004665, Accuracy_2: 90.8% Loss_2: 0.001661  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000003, Accuracy_2: 87.9% Loss_2: 0.000643  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000649  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000316, Accuracy_2: 92.2% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000914  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000575, Accuracy_2: 86.5% Loss_2: 0.001904  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000874, Accuracy_2: 93.6% Loss_2: 0.000502  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000011, Accuracy_2: 92.2% Loss_2: 0.000318  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000017, Accuracy_2: 89.4% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000858, Accuracy_2: 92.9% Loss_2: 0.000003  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000036, Accuracy_2: 91.5% Loss_2: 0.000202  [ 9729/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000390, Accuracy_2: 82.3% Loss_2: 0.004047  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002343, Accuracy_2: 92.9% Loss_2: 0.001432  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001580, Accuracy_2: 90.1% Loss_2: 0.000568  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000108, Accuracy_2: 92.2% Loss_2: 0.001099  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001146, Accuracy_2: 87.9% Loss_2: 0.000169  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000541, Accuracy_2: 91.5% Loss_2: 0.000107  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000045, Accuracy_2: 84.4% Loss_2: 0.001866  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000140, Accuracy_2: 90.1% Loss_2: 0.000195  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.004584, Accuracy_2: 90.8% Loss_2: 0.000001  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000515, Accuracy_2: 87.2% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000652  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000026, Accuracy_2: 90.1% Loss_2: 0.000204  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003111, Accuracy_2: 91.5% Loss_2: 0.001696  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000580, Accuracy_2: 92.2% Loss_2: 0.001213  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000024, Accuracy_2: 92.2% Loss_2: 0.000004  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000181, Accuracy_2: 90.8% Loss_2: 0.000670  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001037, Accuracy_2: 90.1% Loss_2: 0.000011  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000053, Accuracy_2: 94.3% Loss_2: 0.000008  [ 4653/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001801, Accuracy_2: 87.9% Loss_2: 0.000480  [ 5217/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000012, Accuracy_2: 93.6% Loss_2: 0.000749  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000065, Accuracy_2: 89.4% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001024, Accuracy_2: 87.9% Loss_2: 0.001320  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000010, Accuracy_2: 89.4% Loss_2: 0.002663  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001253, Accuracy_2: 87.9% Loss_2: 0.000567  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000784, Accuracy_2: 91.5% Loss_2: 0.001859  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001707, Accuracy_2: 90.1% Loss_2: 0.000256  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.001482  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000190, Accuracy_2: 91.5% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000003  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000076, Accuracy_2: 95.0% Loss_2: 0.000008  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001003, Accuracy_2: 88.7% Loss_2: 0.000001  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000296, Accuracy_2: 91.5% Loss_2: 0.000921  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000006, Accuracy_2: 92.9% Loss_2: 0.000178  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001627, Accuracy_2: 90.1% Loss_2: 0.003472  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.001763  [14241/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000026, Accuracy_2: 92.9% Loss_2: 0.000565  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000028, Accuracy_2: 93.6% Loss_2: 0.000463  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000685, Accuracy_2: 86.5% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000306, Accuracy_2: 90.1% Loss_2: 0.000079  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000767, Accuracy_2: 88.7% Loss_2: 0.000781  [ 1833/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001387, Accuracy_2: 87.2% Loss_2: 0.000002  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.000003  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002107, Accuracy_2: 89.4% Loss_2: 0.002404  [ 3525/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000757, Accuracy_2: 85.1% Loss_2: 0.003181  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.002157  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000132, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000386, Accuracy_2: 86.5% Loss_2: 0.000259  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001331, Accuracy_2: 90.1% Loss_2: 0.000542  [ 6345/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000296, Accuracy_2: 87.9% Loss_2: 0.000823  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003577, Accuracy_2: 87.9% Loss_2: 0.000766  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000008, Accuracy_2: 89.4% Loss_2: 0.001157  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001394, Accuracy_2: 90.1% Loss_2: 0.000410  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000079, Accuracy_2: 92.9% Loss_2: 0.000696  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001237, Accuracy_2: 90.8% Loss_2: 0.001375  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.002278  [10857/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000026, Accuracy_2: 85.1% Loss_2: 0.000159  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.001325  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000152, Accuracy_2: 90.8% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000002  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000812, Accuracy_2: 88.7% Loss_2: 0.000599  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000155, Accuracy_2: 89.4% Loss_2: 0.000157  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.002976  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000471, Accuracy_2: 85.8% Loss_2: 0.000186  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003441, Accuracy_2: 88.7% Loss_2: 0.000853  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000014, Accuracy_2: 91.5% Loss_2: 0.001634  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000160, Accuracy_2: 90.8% Loss_2: 0.000236  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001633, Accuracy_2: 93.6% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002873, Accuracy_2: 92.9% Loss_2: 0.000003  [ 2961/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001087, Accuracy_2: 87.2% Loss_2: 0.002258  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001803, Accuracy_2: 90.1% Loss_2: 0.000130  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000114, Accuracy_2: 88.7% Loss_2: 0.000002  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001125, Accuracy_2: 91.5% Loss_2: 0.000434  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000853  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002105, Accuracy_2: 88.7% Loss_2: 0.000801  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000999, Accuracy_2: 90.8% Loss_2: 0.000483  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000953, Accuracy_2: 90.8% Loss_2: 0.000002  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001383, Accuracy_2: 90.1% Loss_2: 0.000224  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001269, Accuracy_2: 87.2% Loss_2: 0.000469  [ 8601/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.004413, Accuracy_2: 87.9% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000461  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001273, Accuracy_2: 92.9% Loss_2: 0.001610  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000002, Accuracy_2: 87.2% Loss_2: 0.000077  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000560, Accuracy_2: 87.9% Loss_2: 0.001858  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000927, Accuracy_2: 88.7% Loss_2: 0.000002  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000048, Accuracy_2: 90.8% Loss_2: 0.000932  [12549/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000688, Accuracy_2: 85.8% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001190, Accuracy_2: 83.7% Loss_2: 0.000143  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001137, Accuracy_2: 87.9% Loss_2: 0.001623  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000001  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001726, Accuracy_2: 91.5% Loss_2: 0.001986  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000010, Accuracy_2: 87.9% Loss_2: 0.000297  [  705/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000418, Accuracy_2: 83.7% Loss_2: 0.001236  [ 1269/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001213, Accuracy_2: 85.1% Loss_2: 0.000660  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001353, Accuracy_2: 90.1% Loss_2: 0.000004  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000025, Accuracy_2: 87.9% Loss_2: 0.000392  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001101, Accuracy_2: 88.7% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000367, Accuracy_2: 90.1% Loss_2: 0.000352  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000249, Accuracy_2: 90.1% Loss_2: 0.000058  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000500, Accuracy_2: 88.7% Loss_2: 0.002094  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000386, Accuracy_2: 87.9% Loss_2: 0.003019  [ 5781/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001885, Accuracy_2: 84.4% Loss_2: 0.001809  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000002  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000462, Accuracy_2: 88.7% Loss_2: 0.001293  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.000146  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000378, Accuracy_2: 87.9% Loss_2: 0.000259  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000679, Accuracy_2: 91.5% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001192, Accuracy_2: 89.4% Loss_2: 0.000425  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000486, Accuracy_2: 88.7% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002243, Accuracy_2: 92.2% Loss_2: 0.000014  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000212, Accuracy_2: 90.1% Loss_2: 0.000007  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.002514  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000013, Accuracy_2: 90.8% Loss_2: 0.000136  [12549/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000376, Accuracy_2: 85.1% Loss_2: 0.001151  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000622, Accuracy_2: 92.2% Loss_2: 0.000051  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000039, Accuracy_2: 87.2% Loss_2: 0.001456  [14241/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001018, Accuracy_2: 87.9% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000251, Accuracy_2: 88.7% Loss_2: 0.000373  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001361, Accuracy_2: 91.5% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 85.1% Loss_2: 0.000804  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000785, Accuracy_2: 90.8% Loss_2: 0.001105  [ 1833/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000011, Accuracy_2: 93.6% Loss_2: 0.000688  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000414, Accuracy_2: 90.1% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000012, Accuracy_2: 86.5% Loss_2: 0.000001  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000048, Accuracy_2: 89.4% Loss_2: 0.000100  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002284, Accuracy_2: 86.5% Loss_2: 0.003981  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000026, Accuracy_2: 89.4% Loss_2: 0.000044  [ 5217/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000089, Accuracy_2: 93.6% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000249  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000829  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000699, Accuracy_2: 89.4% Loss_2: 0.001521  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000008, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000256, Accuracy_2: 89.4% Loss_2: 0.000364  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000004, Accuracy_2: 92.2% Loss_2: 0.000148  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000001, Accuracy_2: 83.7% Loss_2: 0.002422  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000053, Accuracy_2: 92.9% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002173, Accuracy_2: 90.1% Loss_2: 0.000382  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000507  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000280, Accuracy_2: 92.2% Loss_2: 0.003757  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000744, Accuracy_2: 89.4% Loss_2: 0.000907  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000506, Accuracy_2: 90.1% Loss_2: 0.000116  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000047, Accuracy_2: 86.5% Loss_2: 0.001590  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000795, Accuracy_2: 91.5% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.003297  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000023, Accuracy_2: 89.4% Loss_2: 0.000618  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000062  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000864, Accuracy_2: 85.8% Loss_2: 0.000788  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000014, Accuracy_2: 90.8% Loss_2: 0.000002  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001178, Accuracy_2: 92.9% Loss_2: 0.000276  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000041, Accuracy_2: 88.7% Loss_2: 0.000005  [ 4089/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000879, Accuracy_2: 92.9% Loss_2: 0.000233  [ 4653/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000003, Accuracy_2: 95.0% Loss_2: 0.001701  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000853, Accuracy_2: 86.5% Loss_2: 0.003566  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000175  [ 6345/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000194, Accuracy_2: 86.5% Loss_2: 0.000517  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000552, Accuracy_2: 91.5% Loss_2: 0.000127  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000504, Accuracy_2: 92.9% Loss_2: 0.002355  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000233, Accuracy_2: 93.6% Loss_2: 0.000016  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000086, Accuracy_2: 90.8% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 92.9% Loss_2: 0.000002  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000003, Accuracy_2: 92.9% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000289, Accuracy_2: 90.8% Loss_2: 0.000086  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000348, Accuracy_2: 92.9% Loss_2: 0.000003  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000024, Accuracy_2: 89.4% Loss_2: 0.002708  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002295, Accuracy_2: 91.5% Loss_2: 0.001138  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000090, Accuracy_2: 88.7% Loss_2: 0.000968  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.000451  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000586, Accuracy_2: 88.7% Loss_2: 0.000502  [14241/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003312, Accuracy_2: 87.9% Loss_2: 0.000302  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000006, Accuracy_2: 94.3% Loss_2: 0.000005  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000644, Accuracy_2: 85.1% Loss_2: 0.006764  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000023, Accuracy_2: 92.2% Loss_2: 0.001133  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003814, Accuracy_2: 92.2% Loss_2: 0.000504  [ 1833/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000095, Accuracy_2: 93.6% Loss_2: 0.001019  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002165, Accuracy_2: 90.1% Loss_2: 0.001909  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000056, Accuracy_2: 87.2% Loss_2: 0.000374  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000012, Accuracy_2: 90.8% Loss_2: 0.003372  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001126, Accuracy_2: 90.1% Loss_2: 0.000018  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.004260, Accuracy_2: 89.4% Loss_2: 0.004082  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001743, Accuracy_2: 91.5% Loss_2: 0.002563  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.000004  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001523, Accuracy_2: 92.9% Loss_2: 0.000622  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000164, Accuracy_2: 87.9% Loss_2: 0.001746  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000031, Accuracy_2: 90.8% Loss_2: 0.000089  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.001492  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002345, Accuracy_2: 90.1% Loss_2: 0.001898  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000185, Accuracy_2: 91.5% Loss_2: 0.002626  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000838, Accuracy_2: 92.2% Loss_2: 0.000152  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002070, Accuracy_2: 93.6% Loss_2: 0.000249  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000002  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000762, Accuracy_2: 87.2% Loss_2: 0.001867  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000467, Accuracy_2: 89.4% Loss_2: 0.000242  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000307, Accuracy_2: 85.1% Loss_2: 0.001425  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001286, Accuracy_2: 91.5% Loss_2: 0.000281  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000010, Accuracy_2: 87.9% Loss_2: 0.001936  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000004, Accuracy_2: 90.1% Loss_2: 0.000148  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000210, Accuracy_2: 88.7% Loss_2: 0.000991  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000002, Accuracy_2: 92.9% Loss_2: 0.000004  [ 1269/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000529, Accuracy_2: 95.0% Loss_2: 0.000019  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002645, Accuracy_2: 90.8% Loss_2: 0.000001  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001517, Accuracy_2: 92.9% Loss_2: 0.000041  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000906, Accuracy_2: 89.4% Loss_2: 0.000954  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000010  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000769, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000591, Accuracy_2: 92.9% Loss_2: 0.001118  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002252, Accuracy_2: 88.7% Loss_2: 0.000004  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000519, Accuracy_2: 87.2% Loss_2: 0.000257  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000075, Accuracy_2: 84.4% Loss_2: 0.000272  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001878, Accuracy_2: 90.1% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001322, Accuracy_2: 90.1% Loss_2: 0.000292  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000052, Accuracy_2: 90.8% Loss_2: 0.000063  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000002, Accuracy_2: 87.2% Loss_2: 0.000005  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000047, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000649, Accuracy_2: 89.4% Loss_2: 0.000572  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000182, Accuracy_2: 91.5% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000360, Accuracy_2: 92.2% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.006096, Accuracy_2: 87.2% Loss_2: 0.000482  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000004, Accuracy_2: 90.1% Loss_2: 0.003566  [12549/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002097, Accuracy_2: 87.9% Loss_2: 0.000262  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000030, Accuracy_2: 90.8% Loss_2: 0.000148  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000004  [14241/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000030, Accuracy_2: 95.0% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001014, Accuracy_2: 92.2% Loss_2: 0.000038  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000006, Accuracy_2: 87.9% Loss_2: 0.001189  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000069, Accuracy_2: 87.2% Loss_2: 0.000083  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000057  [ 1833/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000719, Accuracy_2: 85.1% Loss_2: 0.000079  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000408, Accuracy_2: 91.5% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001235, Accuracy_2: 91.5% Loss_2: 0.001767  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000074, Accuracy_2: 90.1% Loss_2: 0.000463  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000005, Accuracy_2: 90.8% Loss_2: 0.001689  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000042, Accuracy_2: 90.8% Loss_2: 0.000095  [ 5217/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000384  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000152, Accuracy_2: 91.5% Loss_2: 0.000140  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000092, Accuracy_2: 88.7% Loss_2: 0.000007  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000016, Accuracy_2: 87.2% Loss_2: 0.000264  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001008, Accuracy_2: 85.8% Loss_2: 0.000003  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000472  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001052, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002651  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001701, Accuracy_2: 85.8% Loss_2: 0.001144  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000034, Accuracy_2: 84.4% Loss_2: 0.001434  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001193, Accuracy_2: 87.2% Loss_2: 0.000020  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000013, Accuracy_2: 87.2% Loss_2: 0.002317  [11985/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000060, Accuracy_2: 83.7% Loss_2: 0.001011  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001175, Accuracy_2: 92.2% Loss_2: 0.001016  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000363, Accuracy_2: 88.7% Loss_2: 0.003289  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000437, Accuracy_2: 95.0% Loss_2: 0.000001  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000901, Accuracy_2: 87.9% Loss_2: 0.000461  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000423, Accuracy_2: 88.7% Loss_2: 0.000113  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.001567  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000187, Accuracy_2: 89.4% Loss_2: 0.001912  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000263, Accuracy_2: 89.4% Loss_2: 0.000003  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000061, Accuracy_2: 92.2% Loss_2: 0.000829  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000045, Accuracy_2: 91.5% Loss_2: 0.000241  [ 3525/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000641, Accuracy_2: 93.6% Loss_2: 0.001564  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000476, Accuracy_2: 91.5% Loss_2: 0.000341  [ 4653/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001548, Accuracy_2: 87.2% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002071, Accuracy_2: 90.1% Loss_2: 0.001682  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000943, Accuracy_2: 91.5% Loss_2: 0.000656  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000505, Accuracy_2: 90.1% Loss_2: 0.000219  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003091, Accuracy_2: 92.2% Loss_2: 0.000260  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000388  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 84.4% Loss_2: 0.000747  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001454, Accuracy_2: 90.8% Loss_2: 0.000015  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002229, Accuracy_2: 91.5% Loss_2: 0.000724  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003647, Accuracy_2: 91.5% Loss_2: 0.000859  [10293/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000035, Accuracy_2: 83.7% Loss_2: 0.000838  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000438, Accuracy_2: 90.8% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000133, Accuracy_2: 90.1% Loss_2: 0.001355  [11985/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001788, Accuracy_2: 87.2% Loss_2: 0.001093  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001290, Accuracy_2: 89.4% Loss_2: 0.001086  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.002053  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000448, Accuracy_2: 91.5% Loss_2: 0.000023  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000422, Accuracy_2: 87.9% Loss_2: 0.000209  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001507  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000198, Accuracy_2: 86.5% Loss_2: 0.001268  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000007, Accuracy_2: 89.4% Loss_2: 0.000234  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001667, Accuracy_2: 88.7% Loss_2: 0.000615  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000048, Accuracy_2: 88.7% Loss_2: 0.000432  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000419, Accuracy_2: 88.7% Loss_2: 0.000680  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 87.2% Loss_2: 0.000736  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002172, Accuracy_2: 92.9% Loss_2: 0.000037  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003197, Accuracy_2: 90.8% Loss_2: 0.000002  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000033, Accuracy_2: 83.7% Loss_2: 0.002113  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000379, Accuracy_2: 88.7% Loss_2: 0.000002  [ 5781/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001874, Accuracy_2: 87.2% Loss_2: 0.000566  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001919, Accuracy_2: 89.4% Loss_2: 0.000079  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000035, Accuracy_2: 88.7% Loss_2: 0.000017  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000012, Accuracy_2: 88.7% Loss_2: 0.002924  [ 8037/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000544, Accuracy_2: 82.3% Loss_2: 0.002987  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000202  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.002457  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000282, Accuracy_2: 83.7% Loss_2: 0.000483  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.007984, Accuracy_2: 90.1% Loss_2: 0.000960  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.001633  [11985/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000020, Accuracy_2: 94.3% Loss_2: 0.000219  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000012  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001119, Accuracy_2: 88.7% Loss_2: 0.002062  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000740, Accuracy_2: 90.1% Loss_2: 0.000778  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.001042  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001334, Accuracy_2: 89.4% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000213, Accuracy_2: 87.9% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001364, Accuracy_2: 91.5% Loss_2: 0.002476  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000090, Accuracy_2: 92.2% Loss_2: 0.001191  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000290, Accuracy_2: 92.9% Loss_2: 0.000019  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000014, Accuracy_2: 90.1% Loss_2: 0.000005  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000119, Accuracy_2: 87.2% Loss_2: 0.000658  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000069, Accuracy_2: 89.4% Loss_2: 0.001974  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000245, Accuracy_2: 86.5% Loss_2: 0.001172  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002481, Accuracy_2: 90.1% Loss_2: 0.000071  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000007, Accuracy_2: 89.4% Loss_2: 0.000013  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000004, Accuracy_2: 85.8% Loss_2: 0.000823  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000323, Accuracy_2: 90.1% Loss_2: 0.000002  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000366, Accuracy_2: 90.8% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000042, Accuracy_2: 86.5% Loss_2: 0.001772  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.004450, Accuracy_2: 88.7% Loss_2: 0.000339  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001031, Accuracy_2: 90.1% Loss_2: 0.001480  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001182, Accuracy_2: 86.5% Loss_2: 0.000620  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002796, Accuracy_2: 92.9% Loss_2: 0.000295  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000726, Accuracy_2: 90.8% Loss_2: 0.000669  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000416, Accuracy_2: 90.1% Loss_2: 0.001134  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002503, Accuracy_2: 92.2% Loss_2: 0.000051  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000209, Accuracy_2: 91.5% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000247  [13113/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001170, Accuracy_2: 87.2% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002834, Accuracy_2: 90.8% Loss_2: 0.000022  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000513, Accuracy_2: 90.8% Loss_2: 0.000566  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001150, Accuracy_2: 90.1% Loss_2: 0.000008  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000673, Accuracy_2: 90.1% Loss_2: 0.000434  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001295, Accuracy_2: 87.2% Loss_2: 0.000424  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000215, Accuracy_2: 91.5% Loss_2: 0.001291  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001452, Accuracy_2: 89.4% Loss_2: 0.000089  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000879, Accuracy_2: 85.8% Loss_2: 0.000009  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000013, Accuracy_2: 87.2% Loss_2: 0.000473  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001827, Accuracy_2: 90.1% Loss_2: 0.000002  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000342  [ 4653/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.002355  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002845, Accuracy_2: 90.1% Loss_2: 0.001356  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000008, Accuracy_2: 91.5% Loss_2: 0.000110  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001081, Accuracy_2: 89.4% Loss_2: 0.001591  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000003, Accuracy_2: 89.4% Loss_2: 0.000144  [ 7473/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000895, Accuracy_2: 86.5% Loss_2: 0.000322  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000094  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003483, Accuracy_2: 92.9% Loss_2: 0.000070  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001230, Accuracy_2: 93.6% Loss_2: 0.000002  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000020  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000108, Accuracy_2: 90.1% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000644, Accuracy_2: 90.1% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.005605, Accuracy_2: 90.1% Loss_2: 0.000798  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000330, Accuracy_2: 88.7% Loss_2: 0.001506  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000008, Accuracy_2: 87.9% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002597, Accuracy_2: 91.5% Loss_2: 0.000001  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000023, Accuracy_2: 87.2% Loss_2: 0.001208  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000017, Accuracy_2: 88.7% Loss_2: 0.000109  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.005953  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000065, Accuracy_2: 87.9% Loss_2: 0.001234  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 91.5% Loss_2: 0.000004  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000010, Accuracy_2: 89.4% Loss_2: 0.000001  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000310, Accuracy_2: 89.4% Loss_2: 0.000413  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000615, Accuracy_2: 94.3% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000003, Accuracy_2: 91.5% Loss_2: 0.000434  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003023, Accuracy_2: 89.4% Loss_2: 0.000771  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002113, Accuracy_2: 93.6% Loss_2: 0.000178  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000623  [ 5217/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000938, Accuracy_2: 95.0% Loss_2: 0.000694  [ 5781/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000231  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000851, Accuracy_2: 90.8% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000889, Accuracy_2: 93.6% Loss_2: 0.000002  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000217, Accuracy_2: 93.6% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000445, Accuracy_2: 89.4% Loss_2: 0.001666  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000012, Accuracy_2: 84.4% Loss_2: 0.004632  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000021, Accuracy_2: 87.2% Loss_2: 0.000041  [ 9729/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000146, Accuracy_2: 95.7% Loss_2: 0.000098  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000004, Accuracy_2: 92.9% Loss_2: 0.000008  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000354, Accuracy_2: 90.1% Loss_2: 0.001034  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001021, Accuracy_2: 87.2% Loss_2: 0.001177  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002641, Accuracy_2: 87.9% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000702  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001898, Accuracy_2: 90.1% Loss_2: 0.000006  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000013, Accuracy_2: 90.8% Loss_2: 0.001153  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.003570  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000799, Accuracy_2: 90.1% Loss_2: 0.004140  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.003048, Accuracy_2: 93.6% Loss_2: 0.000020  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000132, Accuracy_2: 86.5% Loss_2: 0.000002  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001944, Accuracy_2: 89.4% Loss_2: 0.000253  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000015, Accuracy_2: 87.9% Loss_2: 0.000761  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001555, Accuracy_2: 89.4% Loss_2: 0.000257  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000956, Accuracy_2: 85.1% Loss_2: 0.000189  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000213  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000064, Accuracy_2: 85.8% Loss_2: 0.001393  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000934, Accuracy_2: 90.1% Loss_2: 0.001000  [ 6345/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002036, Accuracy_2: 89.4% Loss_2: 0.000030  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001119, Accuracy_2: 92.2% Loss_2: 0.000009  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001443, Accuracy_2: 92.2% Loss_2: 0.001596  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000999, Accuracy_2: 90.1% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001414, Accuracy_2: 91.5% Loss_2: 0.000107  [ 9165/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.000123, Accuracy_2: 83.0% Loss_2: 0.000045  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001929, Accuracy_2: 92.2% Loss_2: 0.000010  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000487, Accuracy_2: 92.9% Loss_2: 0.000011  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000004, Accuracy_2: 90.1% Loss_2: 0.000516  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000693, Accuracy_2: 90.1% Loss_2: 0.001323  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000144, Accuracy_2: 92.2% Loss_2: 0.000783  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000020, Accuracy_2: 88.7% Loss_2: 0.004112  [13113/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000541, Accuracy_2: 85.8% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000316, Accuracy_2: 91.5% Loss_2: 0.002916  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000008, Accuracy_2: 89.4% Loss_2: 0.000025  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001339, Accuracy_2: 92.2% Loss_2: 0.001095  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.005108, Accuracy_2: 89.4% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 92.2% Loss_2: 0.000047  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000304, Accuracy_2: 91.5% Loss_2: 0.000003  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001897, Accuracy_2: 87.9% Loss_2: 0.001014  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002047, Accuracy_2: 89.4% Loss_2: 0.001979  [ 2961/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001065, Accuracy_2: 89.4% Loss_2: 0.000277  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000513, Accuracy_2: 94.3% Loss_2: 0.000004  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000203  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000638, Accuracy_2: 83.7% Loss_2: 0.006038  [ 5781/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000041  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000220, Accuracy_2: 90.1% Loss_2: 0.000001  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000020, Accuracy_2: 90.8% Loss_2: 0.000087  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000193, Accuracy_2: 92.2% Loss_2: 0.000039  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000962  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.001107  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000100, Accuracy_2: 87.9% Loss_2: 0.000149  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000033, Accuracy_2: 91.5% Loss_2: 0.000113  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001479, Accuracy_2: 87.2% Loss_2: 0.003151  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000070, Accuracy_2: 86.5% Loss_2: 0.001342  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001813, Accuracy_2: 87.9% Loss_2: 0.000022  [12549/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000785  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000003, Accuracy_2: 90.1% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000501  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001212, Accuracy_2: 87.2% Loss_2: 0.000008  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000007, Accuracy_2: 88.7% Loss_2: 0.003818  [  141/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000427, Accuracy_2: 83.7% Loss_2: 0.000459  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000084, Accuracy_2: 85.8% Loss_2: 0.000516  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001687, Accuracy_2: 86.5% Loss_2: 0.001497  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000007, Accuracy_2: 90.1% Loss_2: 0.001937  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000394  [ 4089/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000085  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002410, Accuracy_2: 90.8% Loss_2: 0.000107  [ 5217/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000527, Accuracy_2: 95.0% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001278, Accuracy_2: 85.1% Loss_2: 0.000482  [ 6345/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000533, Accuracy_2: 94.3% Loss_2: 0.000734  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000827, Accuracy_2: 90.8% Loss_2: 0.001401  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000032, Accuracy_2: 87.9% Loss_2: 0.000293  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001572, Accuracy_2: 89.4% Loss_2: 0.001287  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000937, Accuracy_2: 88.7% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001872, Accuracy_2: 90.8% Loss_2: 0.000376  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000216, Accuracy_2: 88.7% Loss_2: 0.000699  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002240, Accuracy_2: 85.1% Loss_2: 0.003158  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000030, Accuracy_2: 92.9% Loss_2: 0.000001  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000003  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000641, Accuracy_2: 89.4% Loss_2: 0.000234  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000477, Accuracy_2: 90.1% Loss_2: 0.000002  [13113/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000878, Accuracy_2: 93.6% Loss_2: 0.000333  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.004280, Accuracy_2: 91.5% Loss_2: 0.000007  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000378, Accuracy_2: 89.4% Loss_2: 0.001279  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000086, Accuracy_2: 87.9% Loss_2: 0.001422  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000516, Accuracy_2: 88.7% Loss_2: 0.000880  [  705/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001214, Accuracy_2: 87.9% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002499, Accuracy_2: 92.9% Loss_2: 0.000564  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000475, Accuracy_2: 90.1% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000008, Accuracy_2: 90.1% Loss_2: 0.001453  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000009, Accuracy_2: 90.1% Loss_2: 0.000441  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000062, Accuracy_2: 87.9% Loss_2: 0.000025  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001020, Accuracy_2: 92.9% Loss_2: 0.000009  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000109, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000898, Accuracy_2: 87.2% Loss_2: 0.000002  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000080, Accuracy_2: 92.9% Loss_2: 0.000095  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000487, Accuracy_2: 90.1% Loss_2: 0.000284  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000004  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002891, Accuracy_2: 88.7% Loss_2: 0.000029  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001289, Accuracy_2: 87.2% Loss_2: 0.000946  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000730, Accuracy_2: 91.5% Loss_2: 0.001499  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000458, Accuracy_2: 90.8% Loss_2: 0.000019  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000207, Accuracy_2: 86.5% Loss_2: 0.001640  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000666  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000209  [11421/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003122, Accuracy_2: 86.5% Loss_2: 0.000907  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000009, Accuracy_2: 85.8% Loss_2: 0.002640  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000019, Accuracy_2: 93.6% Loss_2: 0.000010  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000476, Accuracy_2: 91.5% Loss_2: 0.002082  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001292, Accuracy_2: 86.5% Loss_2: 0.002681  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000041, Accuracy_2: 87.2% Loss_2: 0.001510  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000924, Accuracy_2: 91.5% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000040, Accuracy_2: 90.8% Loss_2: 0.000153  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000099, Accuracy_2: 90.1% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000117, Accuracy_2: 92.2% Loss_2: 0.000021  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000920, Accuracy_2: 92.2% Loss_2: 0.000035  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000006, Accuracy_2: 90.1% Loss_2: 0.000491  [ 2961/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.003665, Accuracy_2: 80.1% Loss_2: 0.001367  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000044, Accuracy_2: 87.2% Loss_2: 0.003609  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000007, Accuracy_2: 90.1% Loss_2: 0.000018  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000577, Accuracy_2: 88.7% Loss_2: 0.000097  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001082, Accuracy_2: 87.9% Loss_2: 0.001889  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000043  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.001170  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000854, Accuracy_2: 90.8% Loss_2: 0.000233  [ 7473/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000006, Accuracy_2: 95.0% Loss_2: 0.000293  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000405, Accuracy_2: 90.1% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000002  [ 9165/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000447, Accuracy_2: 97.2% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000808, Accuracy_2: 88.7% Loss_2: 0.001686  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000010, Accuracy_2: 92.9% Loss_2: 0.000011  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000162, Accuracy_2: 89.4% Loss_2: 0.000736  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000183, Accuracy_2: 85.8% Loss_2: 0.001331  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001475, Accuracy_2: 89.4% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000562, Accuracy_2: 90.1% Loss_2: 0.001358  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000001, Accuracy_2: 86.5% Loss_2: 0.000663  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000495, Accuracy_2: 93.6% Loss_2: 0.000004  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000088, Accuracy_2: 94.3% Loss_2: 0.000409  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000006, Accuracy_2: 90.1% Loss_2: 0.000015  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003316, Accuracy_2: 92.2% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003448, Accuracy_2: 92.2% Loss_2: 0.000774  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000068, Accuracy_2: 89.4% Loss_2: 0.002392  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000887, Accuracy_2: 90.1% Loss_2: 0.001294  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001277, Accuracy_2: 89.4% Loss_2: 0.000038  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000302, Accuracy_2: 90.8% Loss_2: 0.000005  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000537, Accuracy_2: 88.7% Loss_2: 0.000394  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000010, Accuracy_2: 86.5% Loss_2: 0.000094  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000206, Accuracy_2: 88.7% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000546, Accuracy_2: 89.4% Loss_2: 0.001993  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000017, Accuracy_2: 91.5% Loss_2: 0.000079  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002562, Accuracy_2: 91.5% Loss_2: 0.000018  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001314  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000477, Accuracy_2: 92.2% Loss_2: 0.000119  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000272  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001094, Accuracy_2: 85.8% Loss_2: 0.000117  [ 9165/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000692, Accuracy_2: 95.7% Loss_2: 0.000011  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000255, Accuracy_2: 85.8% Loss_2: 0.000094  [10293/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003387, Accuracy_2: 86.5% Loss_2: 0.001118  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002740, Accuracy_2: 92.2% Loss_2: 0.000366  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000754  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001141, Accuracy_2: 92.2% Loss_2: 0.000051  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000014, Accuracy_2: 90.8% Loss_2: 0.002183  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001541, Accuracy_2: 91.5% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000983, Accuracy_2: 86.5% Loss_2: 0.000196  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000002, Accuracy_2: 87.9% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000468  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000409, Accuracy_2: 86.5% Loss_2: 0.001457  [  705/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000001, Accuracy_2: 94.3% Loss_2: 0.001798  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001138, Accuracy_2: 89.4% Loss_2: 0.001752  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000014  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.001004  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 91.5% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.001572  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000054, Accuracy_2: 92.9% Loss_2: 0.000013  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002661, Accuracy_2: 92.2% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.004712, Accuracy_2: 93.6% Loss_2: 0.000004  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000793, Accuracy_2: 92.2% Loss_2: 0.000004  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000038, Accuracy_2: 90.8% Loss_2: 0.004577  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000061, Accuracy_2: 90.1% Loss_2: 0.000016  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000162, Accuracy_2: 89.4% Loss_2: 0.000435  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000049, Accuracy_2: 93.6% Loss_2: 0.000006  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002240, Accuracy_2: 88.7% Loss_2: 0.001317  [ 9165/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000006, Accuracy_2: 92.2% Loss_2: 0.000412  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.004860, Accuracy_2: 90.8% Loss_2: 0.000100  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000195  [10857/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000045, Accuracy_2: 93.6% Loss_2: 0.001926  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000923, Accuracy_2: 91.5% Loss_2: 0.000002  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000002, Accuracy_2: 86.5% Loss_2: 0.001732  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000020, Accuracy_2: 90.8% Loss_2: 0.000302  [13113/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000019, Accuracy_2: 94.3% Loss_2: 0.000255  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.001215  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000012, Accuracy_2: 88.7% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.5%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000767, Accuracy_2: 88.7% Loss_2: 0.000079  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000595, Accuracy_2: 91.5% Loss_2: 0.000670  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000388, Accuracy_2: 88.7% Loss_2: 0.002170  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000315, Accuracy_2: 89.4% Loss_2: 0.001628  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001635, Accuracy_2: 89.4% Loss_2: 0.001019  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002737, Accuracy_2: 89.4% Loss_2: 0.000032  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000504, Accuracy_2: 91.5% Loss_2: 0.000176  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000062, Accuracy_2: 91.5% Loss_2: 0.000001  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000450, Accuracy_2: 87.9% Loss_2: 0.001524  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000537  [ 5217/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001103, Accuracy_2: 86.5% Loss_2: 0.002300  [ 5781/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003187, Accuracy_2: 89.4% Loss_2: 0.000290  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000125, Accuracy_2: 87.9% Loss_2: 0.002450  [ 6909/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.001022, Accuracy_2: 94.3% Loss_2: 0.001297  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001984, Accuracy_2: 88.7% Loss_2: 0.000950  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000780  [ 8601/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000700, Accuracy_2: 85.8% Loss_2: 0.000026  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001574, Accuracy_2: 91.5% Loss_2: 0.000802  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001012, Accuracy_2: 88.7% Loss_2: 0.000218  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000630, Accuracy_2: 90.8% Loss_2: 0.001215  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000017, Accuracy_2: 91.5% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001183, Accuracy_2: 83.0% Loss_2: 0.000143  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000005, Accuracy_2: 86.5% Loss_2: 0.001649  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001077, Accuracy_2: 91.5% Loss_2: 0.000016  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.000363  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002877, Accuracy_2: 91.5% Loss_2: 0.003025  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002848, Accuracy_2: 88.7% Loss_2: 0.000001  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000321, Accuracy_2: 89.4% Loss_2: 0.000279  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000339, Accuracy_2: 91.5% Loss_2: 0.000031  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002065, Accuracy_2: 88.7% Loss_2: 0.001807  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000860, Accuracy_2: 88.7% Loss_2: 0.000086  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000194, Accuracy_2: 90.1% Loss_2: 0.000002  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000354, Accuracy_2: 86.5% Loss_2: 0.000872  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000002  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000007, Accuracy_2: 92.9% Loss_2: 0.000001  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002732, Accuracy_2: 90.1% Loss_2: 0.000056  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000001  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000091, Accuracy_2: 88.7% Loss_2: 0.002657  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001556, Accuracy_2: 90.1% Loss_2: 0.000022  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000095, Accuracy_2: 85.1% Loss_2: 0.002328  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000002  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000013, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001138, Accuracy_2: 87.2% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000996, Accuracy_2: 89.4% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003789, Accuracy_2: 90.1% Loss_2: 0.000673  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000047, Accuracy_2: 88.7% Loss_2: 0.000765  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002622, Accuracy_2: 92.2% Loss_2: 0.000046  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001647, Accuracy_2: 92.9% Loss_2: 0.000294  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.003272  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002785, Accuracy_2: 90.8% Loss_2: 0.005851  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.000011  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002271, Accuracy_2: 86.5% Loss_2: 0.000532  [13677/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003503, Accuracy_2: 85.8% Loss_2: 0.000095  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001739, Accuracy_2: 90.8% Loss_2: 0.000366  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000078, Accuracy_2: 87.2% Loss_2: 0.000462  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002694, Accuracy_2: 87.9% Loss_2: 0.003151  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001694, Accuracy_2: 87.9% Loss_2: 0.001259  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000014  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000932, Accuracy_2: 87.2% Loss_2: 0.000001  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000185, Accuracy_2: 86.5% Loss_2: 0.002804  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000468, Accuracy_2: 87.2% Loss_2: 0.000457  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000045, Accuracy_2: 89.4% Loss_2: 0.000004  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000076, Accuracy_2: 90.8% Loss_2: 0.000094  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000005, Accuracy_2: 88.7% Loss_2: 0.000235  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002160, Accuracy_2: 87.9% Loss_2: 0.000879  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000542, Accuracy_2: 87.2% Loss_2: 0.000007  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002877, Accuracy_2: 93.6% Loss_2: 0.000002  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000044, Accuracy_2: 93.6% Loss_2: 0.000069  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000100, Accuracy_2: 92.9% Loss_2: 0.000001  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000005  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000006, Accuracy_2: 90.8% Loss_2: 0.000224  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001777  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000929, Accuracy_2: 88.7% Loss_2: 0.000004  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000364, Accuracy_2: 89.4% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.001114  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000002, Accuracy_2: 85.8% Loss_2: 0.002356  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000244, Accuracy_2: 88.7% Loss_2: 0.001664  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.001424  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000002, Accuracy_2: 93.6% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.004405, Accuracy_2: 92.2% Loss_2: 0.000227  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000571  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000016, Accuracy_2: 91.5% Loss_2: 0.000850  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000178, Accuracy_2: 92.2% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000669, Accuracy_2: 90.8% Loss_2: 0.000001  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000005, Accuracy_2: 83.7% Loss_2: 0.002889  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 89.4% Loss_2: 0.000864  [ 2397/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002964, Accuracy_2: 85.8% Loss_2: 0.000002  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001272, Accuracy_2: 89.4% Loss_2: 0.000920  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001403, Accuracy_2: 87.9% Loss_2: 0.000855  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000035  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000033, Accuracy_2: 86.5% Loss_2: 0.001370  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000480, Accuracy_2: 89.4% Loss_2: 0.000017  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000090, Accuracy_2: 85.1% Loss_2: 0.000005  [ 6345/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000232, Accuracy_2: 85.1% Loss_2: 0.000062  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001253, Accuracy_2: 90.8% Loss_2: 0.000223  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000923, Accuracy_2: 92.2% Loss_2: 0.000721  [ 8601/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000090, Accuracy_2: 95.7% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000118, Accuracy_2: 92.2% Loss_2: 0.000894  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000390, Accuracy_2: 86.5% Loss_2: 0.004554  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001447, Accuracy_2: 92.9% Loss_2: 0.000366  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002201, Accuracy_2: 92.2% Loss_2: 0.000012  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 87.9% Loss_2: 0.007784  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000393, Accuracy_2: 87.9% Loss_2: 0.002502  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000120, Accuracy_2: 90.8% Loss_2: 0.000009  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000572, Accuracy_2: 93.6% Loss_2: 0.000021  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000867  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.004462, Accuracy_2: 86.5% Loss_2: 0.000001  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000313, Accuracy_2: 92.9% Loss_2: 0.000403  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001191, Accuracy_2: 89.4% Loss_2: 0.000765  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000004, Accuracy_2: 88.7% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002918, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000017  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001200, Accuracy_2: 91.5% Loss_2: 0.000683  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002826  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001662, Accuracy_2: 89.4% Loss_2: 0.000993  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000157  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000919  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000540, Accuracy_2: 93.6% Loss_2: 0.001551  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000838, Accuracy_2: 87.9% Loss_2: 0.003746  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000183  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000027, Accuracy_2: 88.7% Loss_2: 0.001595  [ 7473/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000010, Accuracy_2: 92.9% Loss_2: 0.000071  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001128, Accuracy_2: 90.8% Loss_2: 0.000162  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000030, Accuracy_2: 92.2% Loss_2: 0.000068  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001056  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000003, Accuracy_2: 85.1% Loss_2: 0.000818  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000003  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000158, Accuracy_2: 89.4% Loss_2: 0.000458  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000009, Accuracy_2: 92.2% Loss_2: 0.000001  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003484, Accuracy_2: 85.8% Loss_2: 0.001070  [12549/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000023, Accuracy_2: 95.0% Loss_2: 0.000310  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000744, Accuracy_2: 90.1% Loss_2: 0.000929  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000028, Accuracy_2: 88.7% Loss_2: 0.001180  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000430, Accuracy_2: 88.7% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000011, Accuracy_2: 96.5% Loss_2: 0.000005  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000005, Accuracy_2: 90.8% Loss_2: 0.000381  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001434, Accuracy_2: 90.8% Loss_2: 0.000001  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000300, Accuracy_2: 90.8% Loss_2: 0.000279  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001077, Accuracy_2: 90.1% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000023, Accuracy_2: 90.8% Loss_2: 0.000001  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000219, Accuracy_2: 93.6% Loss_2: 0.000003  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002037, Accuracy_2: 87.2% Loss_2: 0.000933  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000405, Accuracy_2: 91.5% Loss_2: 0.002533  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000005, Accuracy_2: 90.8% Loss_2: 0.000107  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000687, Accuracy_2: 87.2% Loss_2: 0.000391  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.002868, Accuracy_2: 95.7% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000031, Accuracy_2: 92.9% Loss_2: 0.000005  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000088, Accuracy_2: 92.2% Loss_2: 0.000012  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002110, Accuracy_2: 88.7% Loss_2: 0.000733  [ 9165/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000352, Accuracy_2: 85.1% Loss_2: 0.001339  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000686, Accuracy_2: 92.2% Loss_2: 0.001356  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003634, Accuracy_2: 91.5% Loss_2: 0.001427  [10857/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000014, Accuracy_2: 95.0% Loss_2: 0.000013  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000487, Accuracy_2: 91.5% Loss_2: 0.000172  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000415, Accuracy_2: 92.9% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000046, Accuracy_2: 95.0% Loss_2: 0.000004  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000258, Accuracy_2: 90.1% Loss_2: 0.001410  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000086, Accuracy_2: 87.2% Loss_2: 0.000365  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000668, Accuracy_2: 88.7% Loss_2: 0.000009  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000585, Accuracy_2: 90.1% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000039, Accuracy_2: 86.5% Loss_2: 0.000707  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000294, Accuracy_2: 91.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.001573  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.004541  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 92.2% Loss_2: 0.001936  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001379, Accuracy_2: 90.8% Loss_2: 0.000011  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 90.1% Loss_2: 0.000001  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000615, Accuracy_2: 91.5% Loss_2: 0.000824  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001727, Accuracy_2: 87.9% Loss_2: 0.001266  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000010  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000980, Accuracy_2: 93.6% Loss_2: 0.000021  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000105, Accuracy_2: 90.8% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003781, Accuracy_2: 89.4% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000874, Accuracy_2: 94.3% Loss_2: 0.000165  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000011, Accuracy_2: 87.9% Loss_2: 0.000843  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000022, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000021, Accuracy_2: 89.4% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000706  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000068, Accuracy_2: 90.8% Loss_2: 0.001542  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.004623, Accuracy_2: 93.6% Loss_2: 0.000006  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000180, Accuracy_2: 88.7% Loss_2: 0.000669  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001252, Accuracy_2: 90.1% Loss_2: 0.000009  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000020, Accuracy_2: 92.9% Loss_2: 0.000016  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000010, Accuracy_2: 90.1% Loss_2: 0.000656  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000623, Accuracy_2: 89.4% Loss_2: 0.000699  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001084, Accuracy_2: 89.4% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001849, Accuracy_2: 88.7% Loss_2: 0.003418  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000739, Accuracy_2: 90.8% Loss_2: 0.001027  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000246, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001637, Accuracy_2: 85.8% Loss_2: 0.000988  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000010  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000788, Accuracy_2: 91.5% Loss_2: 0.000091  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000014, Accuracy_2: 87.9% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000001, Accuracy_2: 86.5% Loss_2: 0.001198  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000051  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001791, Accuracy_2: 94.3% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000863, Accuracy_2: 92.9% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000014, Accuracy_2: 90.8% Loss_2: 0.000390  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000846  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000192  [ 8037/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000335  [ 8601/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002526, Accuracy_2: 84.4% Loss_2: 0.000296  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.001280  [ 9729/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.002599  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000554, Accuracy_2: 90.1% Loss_2: 0.000692  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000142, Accuracy_2: 90.1% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000212, Accuracy_2: 91.5% Loss_2: 0.000197  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000014  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000429, Accuracy_2: 86.5% Loss_2: 0.001210  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000007, Accuracy_2: 91.5% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001097, Accuracy_2: 88.7% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000540  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002831, Accuracy_2: 91.5% Loss_2: 0.002024  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.002883  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000143, Accuracy_2: 90.8% Loss_2: 0.003618  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000001  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001208, Accuracy_2: 91.5% Loss_2: 0.001359  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001006, Accuracy_2: 92.9% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001064, Accuracy_2: 89.4% Loss_2: 0.001391  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000817, Accuracy_2: 89.4% Loss_2: 0.000013  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000799  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000016, Accuracy_2: 92.2% Loss_2: 0.000116  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000065, Accuracy_2: 88.7% Loss_2: 0.002737  [ 5781/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000220, Accuracy_2: 93.6% Loss_2: 0.000833  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001628, Accuracy_2: 89.4% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000095  [ 7473/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000387, Accuracy_2: 94.3% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000026, Accuracy_2: 89.4% Loss_2: 0.000865  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000534, Accuracy_2: 90.1% Loss_2: 0.000445  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.004162, Accuracy_2: 92.2% Loss_2: 0.000020  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002447, Accuracy_2: 90.1% Loss_2: 0.000119  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000885  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000283, Accuracy_2: 88.7% Loss_2: 0.001232  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000162  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000922, Accuracy_2: 90.8% Loss_2: 0.000181  [12549/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000009, Accuracy_2: 94.3% Loss_2: 0.003226  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001231, Accuracy_2: 87.2% Loss_2: 0.001192  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002008, Accuracy_2: 89.4% Loss_2: 0.000002  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000061  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001393, Accuracy_2: 90.1% Loss_2: 0.000278  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000013  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000325  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001033, Accuracy_2: 87.9% Loss_2: 0.000556  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001594, Accuracy_2: 92.9% Loss_2: 0.000016  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000529, Accuracy_2: 90.1% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000214, Accuracy_2: 85.1% Loss_2: 0.003736  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000298, Accuracy_2: 90.8% Loss_2: 0.002393  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000240, Accuracy_2: 90.8% Loss_2: 0.001266  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002582, Accuracy_2: 90.8% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001569, Accuracy_2: 87.2% Loss_2: 0.002288  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000009, Accuracy_2: 88.7% Loss_2: 0.000004  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000343, Accuracy_2: 87.9% Loss_2: 0.000002  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 91.5% Loss_2: 0.000001  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000828, Accuracy_2: 92.2% Loss_2: 0.000286  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002085, Accuracy_2: 89.4% Loss_2: 0.000602  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002522, Accuracy_2: 90.1% Loss_2: 0.002387  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002384, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000849, Accuracy_2: 88.7% Loss_2: 0.001800  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.004293, Accuracy_2: 87.9% Loss_2: 0.000500  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000730, Accuracy_2: 91.5% Loss_2: 0.000007  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000523, Accuracy_2: 88.7% Loss_2: 0.001340  [11985/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002808, Accuracy_2: 87.2% Loss_2: 0.000072  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000037, Accuracy_2: 91.5% Loss_2: 0.000003  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000722, Accuracy_2: 91.5% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000071, Accuracy_2: 94.3% Loss_2: 0.001818  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000751, Accuracy_2: 88.7% Loss_2: 0.001783  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.004722, Accuracy_2: 92.2% Loss_2: 0.000103  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001197, Accuracy_2: 87.9% Loss_2: 0.000664  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000391, Accuracy_2: 87.9% Loss_2: 0.000714  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000971, Accuracy_2: 92.9% Loss_2: 0.000004  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000928  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000090, Accuracy_2: 90.1% Loss_2: 0.000192  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.001663  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000073  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000737, Accuracy_2: 86.5% Loss_2: 0.000068  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000909  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000015, Accuracy_2: 90.1% Loss_2: 0.000249  [ 6345/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001327, Accuracy_2: 87.9% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001255, Accuracy_2: 91.5% Loss_2: 0.000198  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000004, Accuracy_2: 86.5% Loss_2: 0.000422  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.002245  [ 8601/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000441, Accuracy_2: 85.1% Loss_2: 0.001173  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000075  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000899, Accuracy_2: 93.6% Loss_2: 0.000001  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000617, Accuracy_2: 90.1% Loss_2: 0.000777  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.001159  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000679, Accuracy_2: 88.7% Loss_2: 0.002968  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000092, Accuracy_2: 87.9% Loss_2: 0.000005  [12549/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000437, Accuracy_2: 86.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000121, Accuracy_2: 92.9% Loss_2: 0.001838  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000040, Accuracy_2: 93.6% Loss_2: 0.000333  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000870, Accuracy_2: 87.9% Loss_2: 0.000120  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000141, Accuracy_2: 89.4% Loss_2: 0.000180  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001291, Accuracy_2: 87.9% Loss_2: 0.000879  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000238, Accuracy_2: 90.8% Loss_2: 0.001275  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000717  [ 1833/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000013, Accuracy_2: 83.7% Loss_2: 0.000003  [ 2397/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000002  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000411, Accuracy_2: 90.1% Loss_2: 0.000516  [ 3525/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000718, Accuracy_2: 83.0% Loss_2: 0.001790  [ 4089/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.001865, Accuracy_2: 83.7% Loss_2: 0.000001  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000013, Accuracy_2: 91.5% Loss_2: 0.000007  [ 5217/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000002, Accuracy_2: 93.6% Loss_2: 0.004638  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000835, Accuracy_2: 86.5% Loss_2: 0.000411  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000386  [ 6909/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000378, Accuracy_2: 83.0% Loss_2: 0.002053  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000203  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000236, Accuracy_2: 90.1% Loss_2: 0.003669  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000666, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002891, Accuracy_2: 88.7% Loss_2: 0.000443  [ 9729/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000002  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000174, Accuracy_2: 91.5% Loss_2: 0.000178  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001040, Accuracy_2: 87.2% Loss_2: 0.000647  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000503, Accuracy_2: 90.8% Loss_2: 0.002122  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003741, Accuracy_2: 95.0% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002850, Accuracy_2: 88.7% Loss_2: 0.001155  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000651, Accuracy_2: 92.2% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000012, Accuracy_2: 92.9% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000006, Accuracy_2: 90.8% Loss_2: 0.000247  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000011  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000692, Accuracy_2: 88.7% Loss_2: 0.001213  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000242, Accuracy_2: 91.5% Loss_2: 0.000171  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000004, Accuracy_2: 83.7% Loss_2: 0.005332  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000667, Accuracy_2: 90.8% Loss_2: 0.001338  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.002678  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001378, Accuracy_2: 91.5% Loss_2: 0.000177  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.000006  [ 4089/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000003, Accuracy_2: 94.3% Loss_2: 0.000006  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002652, Accuracy_2: 89.4% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000056, Accuracy_2: 87.9% Loss_2: 0.000008  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000031, Accuracy_2: 89.4% Loss_2: 0.003808  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000498, Accuracy_2: 87.9% Loss_2: 0.001300  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000429, Accuracy_2: 87.9% Loss_2: 0.000285  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001789, Accuracy_2: 91.5% Loss_2: 0.000670  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000530, Accuracy_2: 92.2% Loss_2: 0.000189  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000010, Accuracy_2: 91.5% Loss_2: 0.000202  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000397, Accuracy_2: 91.5% Loss_2: 0.000731  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.003417, Accuracy_2: 95.0% Loss_2: 0.000185  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001694, Accuracy_2: 90.8% Loss_2: 0.000007  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001630, Accuracy_2: 92.2% Loss_2: 0.000036  [11421/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002021, Accuracy_2: 86.5% Loss_2: 0.000066  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001015, Accuracy_2: 85.8% Loss_2: 0.000888  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000238, Accuracy_2: 90.1% Loss_2: 0.000511  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001888, Accuracy_2: 89.4% Loss_2: 0.000174  [13677/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.002054  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000013, Accuracy_2: 87.9% Loss_2: 0.000893  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002390, Accuracy_2: 92.9% Loss_2: 0.000027  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001289, Accuracy_2: 90.8% Loss_2: 0.000002  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.002273  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000003  [ 2961/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000061, Accuracy_2: 87.2% Loss_2: 0.000001  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000414, Accuracy_2: 88.7% Loss_2: 0.002295  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000029  [ 4653/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001098, Accuracy_2: 86.5% Loss_2: 0.000901  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000022, Accuracy_2: 89.4% Loss_2: 0.000001  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000570, Accuracy_2: 87.9% Loss_2: 0.000510  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000115, Accuracy_2: 88.7% Loss_2: 0.002357  [ 6909/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000001, Accuracy_2: 81.6% Loss_2: 0.000460  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000874, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000111, Accuracy_2: 91.5% Loss_2: 0.001674  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000052, Accuracy_2: 90.1% Loss_2: 0.002517  [ 9165/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000136, Accuracy_2: 95.7% Loss_2: 0.000004  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000118  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.001323  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000289, Accuracy_2: 92.9% Loss_2: 0.000045  [11421/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000011, Accuracy_2: 94.3% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000095  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000018  [13113/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.001048  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000706, Accuracy_2: 90.1% Loss_2: 0.000340  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002548, Accuracy_2: 88.7% Loss_2: 0.004788  [  141/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000457, Accuracy_2: 95.0% Loss_2: 0.000008  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000834, Accuracy_2: 86.5% Loss_2: 0.002977  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.002765, Accuracy_2: 92.9% Loss_2: 0.003786  [ 1833/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001726, Accuracy_2: 92.2% Loss_2: 0.001263  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000412, Accuracy_2: 92.9% Loss_2: 0.000429  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.001102  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000878, Accuracy_2: 87.9% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001391, Accuracy_2: 87.9% Loss_2: 0.000452  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.003115  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000003, Accuracy_2: 87.9% Loss_2: 0.000487  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002270, Accuracy_2: 91.5% Loss_2: 0.000003  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000044  [ 6909/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001944, Accuracy_2: 93.6% Loss_2: 0.001501  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 86.5% Loss_2: 0.001716  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001444, Accuracy_2: 94.3% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000108, Accuracy_2: 88.7% Loss_2: 0.001160  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000415, Accuracy_2: 87.9% Loss_2: 0.000007  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000536, Accuracy_2: 89.4% Loss_2: 0.003233  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001686, Accuracy_2: 87.2% Loss_2: 0.000121  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000007, Accuracy_2: 89.4% Loss_2: 0.000482  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000004  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002570, Accuracy_2: 87.2% Loss_2: 0.000090  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000005, Accuracy_2: 92.2% Loss_2: 0.000007  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002544, Accuracy_2: 90.1% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000020, Accuracy_2: 93.6% Loss_2: 0.000029  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000339  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.8%, Avg loss: 0.000001 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000058, Accuracy_2: 90.1% Loss_2: 0.000307  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000209  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000019, Accuracy_2: 90.1% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000303  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001776, Accuracy_2: 89.4% Loss_2: 0.000376  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000044, Accuracy_2: 93.6% Loss_2: 0.000829  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000427, Accuracy_2: 92.2% Loss_2: 0.000610  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000011, Accuracy_2: 88.7% Loss_2: 0.001323  [ 4089/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000572, Accuracy_2: 95.7% Loss_2: 0.000002  [ 4653/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.001601, Accuracy_2: 95.7% Loss_2: 0.000001  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002008, Accuracy_2: 94.3% Loss_2: 0.000001  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000174, Accuracy_2: 89.4% Loss_2: 0.000042  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000637, Accuracy_2: 93.6% Loss_2: 0.000003  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000779, Accuracy_2: 90.1% Loss_2: 0.000192  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.006683, Accuracy_2: 90.1% Loss_2: 0.000373  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000088, Accuracy_2: 89.4% Loss_2: 0.000313  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001570, Accuracy_2: 91.5% Loss_2: 0.002391  [ 9165/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000180, Accuracy_2: 93.6% Loss_2: 0.007187  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000112, Accuracy_2: 87.9% Loss_2: 0.001588  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001628, Accuracy_2: 89.4% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000911, Accuracy_2: 92.2% Loss_2: 0.000001  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000216, Accuracy_2: 85.8% Loss_2: 0.002156  [11985/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.009431, Accuracy_2: 84.4% Loss_2: 0.000726  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001395, Accuracy_2: 87.9% Loss_2: 0.000142  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001671, Accuracy_2: 89.4% Loss_2: 0.000881  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001033, Accuracy_2: 89.4% Loss_2: 0.000116  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002050, Accuracy_2: 88.7% Loss_2: 0.000684  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000037, Accuracy_2: 91.5% Loss_2: 0.001708  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000098, Accuracy_2: 87.2% Loss_2: 0.000136  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000020  [ 1269/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000248, Accuracy_2: 95.0% Loss_2: 0.001173  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000030, Accuracy_2: 88.7% Loss_2: 0.000335  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001404, Accuracy_2: 90.1% Loss_2: 0.000139  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000120, Accuracy_2: 85.8% Loss_2: 0.000371  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000091  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000008, Accuracy_2: 90.1% Loss_2: 0.001621  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.000057  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001194, Accuracy_2: 91.5% Loss_2: 0.001400  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000011, Accuracy_2: 90.8% Loss_2: 0.000001  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000018, Accuracy_2: 84.4% Loss_2: 0.000283  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000880, Accuracy_2: 93.6% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001173, Accuracy_2: 89.4% Loss_2: 0.002315  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.000648  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000921, Accuracy_2: 89.4% Loss_2: 0.000399  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000044, Accuracy_2: 88.7% Loss_2: 0.004852  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000118, Accuracy_2: 89.4% Loss_2: 0.000140  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000006, Accuracy_2: 85.8% Loss_2: 0.007004  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000973, Accuracy_2: 90.1% Loss_2: 0.000027  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000075, Accuracy_2: 86.5% Loss_2: 0.000290  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001721, Accuracy_2: 90.8% Loss_2: 0.001040  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000291, Accuracy_2: 90.1% Loss_2: 0.002156  [13113/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.003139  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000450  [14241/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000002, Accuracy_2: 95.0% Loss_2: 0.000300  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000305, Accuracy_2: 93.6% Loss_2: 0.001158  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000017, Accuracy_2: 91.5% Loss_2: 0.000002  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000005, Accuracy_2: 87.9% Loss_2: 0.000004  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001969, Accuracy_2: 88.7% Loss_2: 0.000360  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 87.2% Loss_2: 0.002827  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000951, Accuracy_2: 86.5% Loss_2: 0.001046  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000003  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000005, Accuracy_2: 86.5% Loss_2: 0.000021  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001624, Accuracy_2: 90.8% Loss_2: 0.000906  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000026, Accuracy_2: 89.4% Loss_2: 0.001864  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000627, Accuracy_2: 90.1% Loss_2: 0.000011  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000014, Accuracy_2: 89.4% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001324, Accuracy_2: 90.1% Loss_2: 0.000220  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000160, Accuracy_2: 88.7% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001048, Accuracy_2: 83.7% Loss_2: 0.001767  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000066, Accuracy_2: 89.4% Loss_2: 0.000766  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000015  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000024  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001232, Accuracy_2: 89.4% Loss_2: 0.000792  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002628, Accuracy_2: 92.9% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000006  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000241, Accuracy_2: 87.9% Loss_2: 0.000002  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000695, Accuracy_2: 92.9% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.003848, Accuracy_2: 87.2% Loss_2: 0.003219  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001939, Accuracy_2: 90.8% Loss_2: 0.000456  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000406, Accuracy_2: 91.5% Loss_2: 0.000952  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000220, Accuracy_2: 88.7% Loss_2: 0.002911  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000246, Accuracy_2: 90.1% Loss_2: 0.001068  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000066, Accuracy_2: 86.5% Loss_2: 0.002302  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000004, Accuracy_2: 86.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.004393, Accuracy_2: 86.5% Loss_2: 0.001735  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000005, Accuracy_2: 86.5% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000014  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000164, Accuracy_2: 91.5% Loss_2: 0.000150  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000981, Accuracy_2: 92.2% Loss_2: 0.000009  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000002, Accuracy_2: 87.2% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000023, Accuracy_2: 92.2% Loss_2: 0.000021  [ 5781/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000007, Accuracy_2: 93.6% Loss_2: 0.000464  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000030  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000685, Accuracy_2: 95.0% Loss_2: 0.000001  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002664, Accuracy_2: 90.1% Loss_2: 0.000002  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000385, Accuracy_2: 90.1% Loss_2: 0.000195  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001507, Accuracy_2: 92.2% Loss_2: 0.000259  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000510, Accuracy_2: 87.2% Loss_2: 0.000731  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001014, Accuracy_2: 86.5% Loss_2: 0.000217  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000004  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000040  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000315, Accuracy_2: 87.2% Loss_2: 0.000358  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000236, Accuracy_2: 92.9% Loss_2: 0.000003  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001495, Accuracy_2: 90.1% Loss_2: 0.002724  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000003  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003293, Accuracy_2: 91.5% Loss_2: 0.000038  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000001, Accuracy_2: 85.8% Loss_2: 0.000001  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000116, Accuracy_2: 94.3% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.001533, Accuracy_2: 80.9% Loss_2: 0.000542  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000049, Accuracy_2: 85.1% Loss_2: 0.001787  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.001713  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000023, Accuracy_2: 87.9% Loss_2: 0.001093  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001526, Accuracy_2: 90.1% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000986  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000445, Accuracy_2: 91.5% Loss_2: 0.000027  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000204, Accuracy_2: 92.2% Loss_2: 0.000235  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000050, Accuracy_2: 90.8% Loss_2: 0.000639  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001197, Accuracy_2: 87.2% Loss_2: 0.001326  [ 5781/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000000, Accuracy_2: 81.6% Loss_2: 0.004907  [ 6345/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000252, Accuracy_2: 96.5% Loss_2: 0.000009  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000063, Accuracy_2: 92.9% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000039  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000385, Accuracy_2: 90.8% Loss_2: 0.000532  [ 8601/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003183, Accuracy_2: 87.2% Loss_2: 0.000012  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000465, Accuracy_2: 93.6% Loss_2: 0.000078  [10293/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000199, Accuracy_2: 94.3% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000066, Accuracy_2: 90.8% Loss_2: 0.000049  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.003215  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000041, Accuracy_2: 92.2% Loss_2: 0.000010  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000403, Accuracy_2: 90.1% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001763, Accuracy_2: 90.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000003, Accuracy_2: 89.4% Loss_2: 0.000065  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000153, Accuracy_2: 90.8% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000629, Accuracy_2: 87.9% Loss_2: 0.000443  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000032  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000614, Accuracy_2: 92.2% Loss_2: 0.000014  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001182, Accuracy_2: 89.4% Loss_2: 0.000001  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000010, Accuracy_2: 89.4% Loss_2: 0.000201  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000788, Accuracy_2: 87.2% Loss_2: 0.002517  [ 3525/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002876, Accuracy_2: 85.1% Loss_2: 0.000943  [ 4089/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000012, Accuracy_2: 92.9% Loss_2: 0.000264  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000253, Accuracy_2: 90.1% Loss_2: 0.002147  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.001352  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000324, Accuracy_2: 87.9% Loss_2: 0.002125  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000891  [ 7473/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003118, Accuracy_2: 85.8% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.004338, Accuracy_2: 87.2% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000004, Accuracy_2: 89.4% Loss_2: 0.000678  [ 9165/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000474, Accuracy_2: 94.3% Loss_2: 0.001336  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002698, Accuracy_2: 86.5% Loss_2: 0.000901  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001284, Accuracy_2: 87.9% Loss_2: 0.001013  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000199, Accuracy_2: 90.1% Loss_2: 0.000874  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000013  [11985/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000031, Accuracy_2: 94.3% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002715, Accuracy_2: 90.8% Loss_2: 0.001711  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000004, Accuracy_2: 85.8% Loss_2: 0.000941  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000006, Accuracy_2: 90.1% Loss_2: 0.000402  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000075, Accuracy_2: 84.4% Loss_2: 0.001311  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002112, Accuracy_2: 87.9% Loss_2: 0.000008  [  141/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000033, Accuracy_2: 93.6% Loss_2: 0.000158  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003664, Accuracy_2: 88.7% Loss_2: 0.000010  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001127, Accuracy_2: 92.2% Loss_2: 0.000201  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000025  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000024, Accuracy_2: 93.6% Loss_2: 0.000512  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001035, Accuracy_2: 92.2% Loss_2: 0.000003  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001471, Accuracy_2: 90.1% Loss_2: 0.001380  [ 4089/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000460, Accuracy_2: 95.0% Loss_2: 0.000001  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002772, Accuracy_2: 89.4% Loss_2: 0.001186  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000509, Accuracy_2: 90.8% Loss_2: 0.001199  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001732, Accuracy_2: 92.9% Loss_2: 0.001977  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001767, Accuracy_2: 90.8% Loss_2: 0.000871  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000907, Accuracy_2: 87.2% Loss_2: 0.000016  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000002  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000193, Accuracy_2: 86.5% Loss_2: 0.000359  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000172, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000034, Accuracy_2: 93.6% Loss_2: 0.000007  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000672, Accuracy_2: 93.6% Loss_2: 0.000100  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000902, Accuracy_2: 85.8% Loss_2: 0.001197  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000064, Accuracy_2: 92.2% Loss_2: 0.001543  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000001, Accuracy_2: 85.1% Loss_2: 0.002233  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000061, Accuracy_2: 90.8% Loss_2: 0.000022  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.004312, Accuracy_2: 87.9% Loss_2: 0.000456  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000015, Accuracy_2: 89.4% Loss_2: 0.000077  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000109, Accuracy_2: 87.9% Loss_2: 0.003782  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000728, Accuracy_2: 85.8% Loss_2: 0.000374  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001720, Accuracy_2: 90.1% Loss_2: 0.000017  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000013, Accuracy_2: 90.1% Loss_2: 0.000868  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000599, Accuracy_2: 93.6% Loss_2: 0.000032  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000525, Accuracy_2: 91.5% Loss_2: 0.000652  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.005009, Accuracy_2: 88.7% Loss_2: 0.002070  [ 2961/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000221, Accuracy_2: 85.1% Loss_2: 0.000686  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000014, Accuracy_2: 88.7% Loss_2: 0.000299  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002832, Accuracy_2: 89.4% Loss_2: 0.000945  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000504, Accuracy_2: 93.6% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001312, Accuracy_2: 83.7% Loss_2: 0.000048  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000095, Accuracy_2: 93.6% Loss_2: 0.000024  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000243, Accuracy_2: 88.7% Loss_2: 0.000825  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000185, Accuracy_2: 90.1% Loss_2: 0.000001  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000812, Accuracy_2: 90.8% Loss_2: 0.000431  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001859, Accuracy_2: 91.5% Loss_2: 0.000014  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.001219  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000004  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002073, Accuracy_2: 92.9% Loss_2: 0.000244  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000084, Accuracy_2: 92.2% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000032, Accuracy_2: 94.3% Loss_2: 0.000002  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002124, Accuracy_2: 90.1% Loss_2: 0.000749  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000069, Accuracy_2: 88.7% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000347  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000721, Accuracy_2: 92.9% Loss_2: 0.000073  [14241/15250]\n",
      "Accuracy_1: 80.1%, Loss_1: 0.001751, Accuracy_2: 84.4% Loss_2: 0.001221  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000846, Accuracy_2: 95.0% Loss_2: 0.000002  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002498, Accuracy_2: 89.4% Loss_2: 0.000256  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001508, Accuracy_2: 90.8% Loss_2: 0.000939  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000505, Accuracy_2: 88.7% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001814, Accuracy_2: 88.7% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000104, Accuracy_2: 89.4% Loss_2: 0.001120  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000003, Accuracy_2: 92.9% Loss_2: 0.000054  [ 4089/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.001492  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000898, Accuracy_2: 92.9% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001525, Accuracy_2: 92.2% Loss_2: 0.000002  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000788, Accuracy_2: 87.9% Loss_2: 0.004503  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000023, Accuracy_2: 91.5% Loss_2: 0.000834  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.001883  [ 7473/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000266, Accuracy_2: 85.8% Loss_2: 0.000005  [ 8037/15250]\n",
      "Accuracy_1: 80.9%, Loss_1: 0.005778, Accuracy_2: 83.7% Loss_2: 0.000453  [ 8601/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000001, Accuracy_2: 95.0% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001011, Accuracy_2: 90.8% Loss_2: 0.000519  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000261, Accuracy_2: 91.5% Loss_2: 0.002781  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000585, Accuracy_2: 89.4% Loss_2: 0.000124  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001883, Accuracy_2: 93.6% Loss_2: 0.000220  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000001  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.000063  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000190  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000368  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000199, Accuracy_2: 90.8% Loss_2: 0.000001  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000166, Accuracy_2: 87.9% Loss_2: 0.000717  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000397, Accuracy_2: 90.8% Loss_2: 0.000584  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000699, Accuracy_2: 90.8% Loss_2: 0.000081  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000006, Accuracy_2: 90.1% Loss_2: 0.000386  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000004  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000003  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000031, Accuracy_2: 87.9% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000085, Accuracy_2: 92.2% Loss_2: 0.000061  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001763, Accuracy_2: 90.1% Loss_2: 0.000020  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001836, Accuracy_2: 92.9% Loss_2: 0.001061  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002806, Accuracy_2: 90.1% Loss_2: 0.000013  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000734, Accuracy_2: 89.4% Loss_2: 0.001319  [ 6345/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000570, Accuracy_2: 95.0% Loss_2: 0.000643  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000010  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000013, Accuracy_2: 92.9% Loss_2: 0.000276  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.001075  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000007, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000651  [ 9729/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001537, Accuracy_2: 95.0% Loss_2: 0.000120  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001050, Accuracy_2: 92.2% Loss_2: 0.001362  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000029, Accuracy_2: 91.5% Loss_2: 0.000039  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000950, Accuracy_2: 88.7% Loss_2: 0.000920  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000021, Accuracy_2: 87.2% Loss_2: 0.000889  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000002  [13113/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002035, Accuracy_2: 85.1% Loss_2: 0.000222  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002643  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003108, Accuracy_2: 92.2% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000001  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000043, Accuracy_2: 85.1% Loss_2: 0.000411  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001650, Accuracy_2: 85.8% Loss_2: 0.002908  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000013, Accuracy_2: 89.4% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.002612  [ 2397/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000394, Accuracy_2: 95.0% Loss_2: 0.000249  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000738, Accuracy_2: 90.1% Loss_2: 0.003365  [ 3525/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000032, Accuracy_2: 93.6% Loss_2: 0.000149  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003483, Accuracy_2: 90.8% Loss_2: 0.001120  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000022, Accuracy_2: 89.4% Loss_2: 0.000006  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.001325  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001821, Accuracy_2: 92.9% Loss_2: 0.000627  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000302, Accuracy_2: 93.6% Loss_2: 0.001443  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001692, Accuracy_2: 88.7% Loss_2: 0.000121  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000593, Accuracy_2: 90.1% Loss_2: 0.004110  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002024, Accuracy_2: 88.7% Loss_2: 0.000130  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000021, Accuracy_2: 90.1% Loss_2: 0.002625  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000387  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000559, Accuracy_2: 89.4% Loss_2: 0.002318  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000334  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000001  [11421/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.001251  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000238, Accuracy_2: 87.2% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003287, Accuracy_2: 92.9% Loss_2: 0.000374  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000958, Accuracy_2: 87.9% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000266, Accuracy_2: 87.2% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000023, Accuracy_2: 83.7% Loss_2: 0.001964  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000972, Accuracy_2: 91.5% Loss_2: 0.000190  [  141/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000712, Accuracy_2: 80.9% Loss_2: 0.002352  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001179, Accuracy_2: 93.6% Loss_2: 0.000002  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000284, Accuracy_2: 93.6% Loss_2: 0.000737  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001252, Accuracy_2: 92.9% Loss_2: 0.000021  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000843, Accuracy_2: 85.8% Loss_2: 0.000195  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000005  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001728, Accuracy_2: 87.2% Loss_2: 0.001388  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001278, Accuracy_2: 89.4% Loss_2: 0.001666  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000002, Accuracy_2: 87.2% Loss_2: 0.003185  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001939, Accuracy_2: 90.8% Loss_2: 0.000651  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000464, Accuracy_2: 88.7% Loss_2: 0.000024  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001702, Accuracy_2: 90.1% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000766, Accuracy_2: 93.6% Loss_2: 0.000002  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000856, Accuracy_2: 90.8% Loss_2: 0.000657  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000010, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001684, Accuracy_2: 89.4% Loss_2: 0.003219  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000565, Accuracy_2: 85.8% Loss_2: 0.003584  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000865, Accuracy_2: 92.9% Loss_2: 0.000038  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000243, Accuracy_2: 86.5% Loss_2: 0.001657  [11421/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000011, Accuracy_2: 93.6% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000013  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001424, Accuracy_2: 90.8% Loss_2: 0.003369  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001664  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001365, Accuracy_2: 89.4% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000007, Accuracy_2: 92.2% Loss_2: 0.001701  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000898, Accuracy_2: 92.9% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001327, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000810, Accuracy_2: 91.5% Loss_2: 0.000380  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000357  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000332, Accuracy_2: 85.1% Loss_2: 0.001094  [ 2961/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.002569, Accuracy_2: 95.7% Loss_2: 0.000010  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000017, Accuracy_2: 88.7% Loss_2: 0.000558  [ 4089/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.001191, Accuracy_2: 95.7% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000994, Accuracy_2: 86.5% Loss_2: 0.000118  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000593  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001018, Accuracy_2: 90.8% Loss_2: 0.001628  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000741, Accuracy_2: 89.4% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001564, Accuracy_2: 88.7% Loss_2: 0.000174  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000711, Accuracy_2: 90.1% Loss_2: 0.000711  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001100, Accuracy_2: 91.5% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000955, Accuracy_2: 85.8% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000037, Accuracy_2: 92.2% Loss_2: 0.000132  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000738, Accuracy_2: 90.8% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000044, Accuracy_2: 90.1% Loss_2: 0.000028  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000017  [11985/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000185, Accuracy_2: 81.6% Loss_2: 0.002616  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000034, Accuracy_2: 91.5% Loss_2: 0.000968  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000462, Accuracy_2: 88.7% Loss_2: 0.000159  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.000008  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000489, Accuracy_2: 87.2% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000013  [  141/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000093, Accuracy_2: 93.6% Loss_2: 0.000150  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000331, Accuracy_2: 90.1% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002624, Accuracy_2: 90.8% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000256, Accuracy_2: 89.4% Loss_2: 0.000395  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000730, Accuracy_2: 87.9% Loss_2: 0.001201  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 85.8% Loss_2: 0.001437  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000005, Accuracy_2: 90.1% Loss_2: 0.000503  [ 4089/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000075, Accuracy_2: 90.8% Loss_2: 0.001522  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000871, Accuracy_2: 87.2% Loss_2: 0.001900  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000777  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.000797  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000208, Accuracy_2: 88.7% Loss_2: 0.001096  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001945, Accuracy_2: 87.2% Loss_2: 0.005308  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000613, Accuracy_2: 92.2% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000189  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000322, Accuracy_2: 89.4% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001824  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000732  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000588, Accuracy_2: 88.7% Loss_2: 0.000624  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000296, Accuracy_2: 91.5% Loss_2: 0.000148  [11421/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000000, Accuracy_2: 84.4% Loss_2: 0.000377  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002373, Accuracy_2: 86.5% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000016  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000008, Accuracy_2: 90.1% Loss_2: 0.000105  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000006, Accuracy_2: 87.9% Loss_2: 0.000091  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001250, Accuracy_2: 89.4% Loss_2: 0.000197  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000521, Accuracy_2: 91.5% Loss_2: 0.002442  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000074, Accuracy_2: 92.2% Loss_2: 0.000219  [ 1269/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000439, Accuracy_2: 85.1% Loss_2: 0.000581  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000173, Accuracy_2: 86.5% Loss_2: 0.001654  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001703, Accuracy_2: 90.8% Loss_2: 0.000299  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000074, Accuracy_2: 92.9% Loss_2: 0.002743  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000226, Accuracy_2: 90.1% Loss_2: 0.000750  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000714  [ 4653/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000015  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.003091, Accuracy_2: 93.6% Loss_2: 0.000489  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000027  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000056, Accuracy_2: 88.7% Loss_2: 0.001442  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000012, Accuracy_2: 90.1% Loss_2: 0.000795  [ 7473/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000118, Accuracy_2: 90.1% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002331, Accuracy_2: 89.4% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000236, Accuracy_2: 90.8% Loss_2: 0.000010  [ 9729/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000014, Accuracy_2: 92.9% Loss_2: 0.004295  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000555  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000753, Accuracy_2: 88.7% Loss_2: 0.000008  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000011, Accuracy_2: 89.4% Loss_2: 0.000122  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000202, Accuracy_2: 90.8% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000874  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001329, Accuracy_2: 92.9% Loss_2: 0.000157  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000012  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000029, Accuracy_2: 90.8% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000017, Accuracy_2: 91.5% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000396, Accuracy_2: 85.1% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000931, Accuracy_2: 86.5% Loss_2: 0.001437  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000205, Accuracy_2: 89.4% Loss_2: 0.000549  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000019, Accuracy_2: 90.8% Loss_2: 0.000042  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000756  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002302, Accuracy_2: 87.9% Loss_2: 0.000013  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000012, Accuracy_2: 87.9% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000449  [ 4653/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000017, Accuracy_2: 91.5% Loss_2: 0.001680  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000339, Accuracy_2: 92.9% Loss_2: 0.000010  [ 5781/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000708, Accuracy_2: 83.0% Loss_2: 0.002357  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000910, Accuracy_2: 89.4% Loss_2: 0.001046  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 87.9% Loss_2: 0.000383  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000999, Accuracy_2: 89.4% Loss_2: 0.000002  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001312, Accuracy_2: 91.5% Loss_2: 0.001263  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000013, Accuracy_2: 92.9% Loss_2: 0.000027  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000401, Accuracy_2: 92.2% Loss_2: 0.000319  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000450, Accuracy_2: 91.5% Loss_2: 0.000667  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000154, Accuracy_2: 92.9% Loss_2: 0.000009  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000003, Accuracy_2: 88.7% Loss_2: 0.002914  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001657, Accuracy_2: 92.9% Loss_2: 0.000039  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001442, Accuracy_2: 92.2% Loss_2: 0.000306  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000936, Accuracy_2: 90.8% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001648, Accuracy_2: 91.5% Loss_2: 0.000656  [13677/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000003, Accuracy_2: 94.3% Loss_2: 0.000049  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000235, Accuracy_2: 87.2% Loss_2: 0.000509  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001149, Accuracy_2: 91.5% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000179, Accuracy_2: 91.5% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001967, Accuracy_2: 87.2% Loss_2: 0.000354  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000702, Accuracy_2: 89.4% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000283, Accuracy_2: 89.4% Loss_2: 0.000533  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000002  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000176  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002535, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000001, Accuracy_2: 95.0% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000311  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000080  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000667, Accuracy_2: 89.4% Loss_2: 0.000001  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000500, Accuracy_2: 90.1% Loss_2: 0.000045  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000992  [ 8037/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001646, Accuracy_2: 86.5% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000261, Accuracy_2: 91.5% Loss_2: 0.003896  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000266, Accuracy_2: 93.6% Loss_2: 0.000016  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001044, Accuracy_2: 92.9% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.000284  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000004, Accuracy_2: 89.4% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002055, Accuracy_2: 91.5% Loss_2: 0.000504  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000633, Accuracy_2: 87.2% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000081  [13113/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.002368  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000042, Accuracy_2: 90.8% Loss_2: 0.000299  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002449, Accuracy_2: 90.8% Loss_2: 0.004028  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.5%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.2%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.003858  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000670  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000540, Accuracy_2: 92.2% Loss_2: 0.001567  [ 1269/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001363, Accuracy_2: 85.8% Loss_2: 0.000065  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000533, Accuracy_2: 90.8% Loss_2: 0.000711  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000634, Accuracy_2: 87.9% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000002  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000499, Accuracy_2: 86.5% Loss_2: 0.003923  [ 4089/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.005620, Accuracy_2: 93.6% Loss_2: 0.000061  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001694, Accuracy_2: 94.3% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001309, Accuracy_2: 91.5% Loss_2: 0.000291  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001604, Accuracy_2: 88.7% Loss_2: 0.000401  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001196, Accuracy_2: 89.4% Loss_2: 0.002941  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001811, Accuracy_2: 92.2% Loss_2: 0.000195  [ 7473/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000029, Accuracy_2: 93.6% Loss_2: 0.001293  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000568, Accuracy_2: 88.7% Loss_2: 0.001686  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002415, Accuracy_2: 88.7% Loss_2: 0.001768  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001517, Accuracy_2: 87.9% Loss_2: 0.000113  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000368, Accuracy_2: 85.8% Loss_2: 0.001258  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000227  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003853, Accuracy_2: 87.2% Loss_2: 0.004118  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000025  [11985/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000133, Accuracy_2: 91.5% Loss_2: 0.000012  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002784, Accuracy_2: 93.6% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000909, Accuracy_2: 85.1% Loss_2: 0.000562  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000007, Accuracy_2: 90.1% Loss_2: 0.003467  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000165, Accuracy_2: 88.7% Loss_2: 0.000008  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001171, Accuracy_2: 90.1% Loss_2: 0.004478  [  705/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000831, Accuracy_2: 92.9% Loss_2: 0.000981  [ 1269/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000258, Accuracy_2: 86.5% Loss_2: 0.000093  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000558, Accuracy_2: 95.0% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002889, Accuracy_2: 90.8% Loss_2: 0.000635  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000331, Accuracy_2: 90.8% Loss_2: 0.001709  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001849, Accuracy_2: 89.4% Loss_2: 0.000204  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001210, Accuracy_2: 90.8% Loss_2: 0.001242  [ 4653/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001072, Accuracy_2: 93.6% Loss_2: 0.000007  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003773, Accuracy_2: 90.8% Loss_2: 0.000884  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000831, Accuracy_2: 90.8% Loss_2: 0.000707  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000299  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001913, Accuracy_2: 94.3% Loss_2: 0.000006  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000548  [ 8037/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002634, Accuracy_2: 84.4% Loss_2: 0.001146  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000420, Accuracy_2: 88.7% Loss_2: 0.001307  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000793, Accuracy_2: 91.5% Loss_2: 0.000005  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000003, Accuracy_2: 91.5% Loss_2: 0.000745  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000335, Accuracy_2: 89.4% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003455, Accuracy_2: 87.9% Loss_2: 0.001422  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000021, Accuracy_2: 87.2% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003280, Accuracy_2: 90.1% Loss_2: 0.002841  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000336, Accuracy_2: 92.9% Loss_2: 0.000707  [13677/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000021, Accuracy_2: 93.6% Loss_2: 0.000679  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000463  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000138, Accuracy_2: 93.6% Loss_2: 0.000004  [  141/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000053, Accuracy_2: 96.5% Loss_2: 0.000003  [  705/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000039, Accuracy_2: 94.3% Loss_2: 0.000395  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000886, Accuracy_2: 92.9% Loss_2: 0.000002  [ 1833/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000042, Accuracy_2: 93.6% Loss_2: 0.000249  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000053, Accuracy_2: 90.8% Loss_2: 0.000477  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000023, Accuracy_2: 90.8% Loss_2: 0.001592  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000043, Accuracy_2: 90.1% Loss_2: 0.000646  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000752, Accuracy_2: 87.2% Loss_2: 0.002012  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000005, Accuracy_2: 87.2% Loss_2: 0.003138  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001263, Accuracy_2: 87.9% Loss_2: 0.001385  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000039, Accuracy_2: 90.8% Loss_2: 0.000019  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000985, Accuracy_2: 92.2% Loss_2: 0.000002  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001917, Accuracy_2: 90.8% Loss_2: 0.001176  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000796, Accuracy_2: 90.8% Loss_2: 0.000036  [ 8601/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002623, Accuracy_2: 85.8% Loss_2: 0.000031  [ 9165/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000505, Accuracy_2: 85.8% Loss_2: 0.000019  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000043, Accuracy_2: 88.7% Loss_2: 0.001494  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000257, Accuracy_2: 92.2% Loss_2: 0.002378  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000729, Accuracy_2: 87.9% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000011, Accuracy_2: 93.6% Loss_2: 0.000009  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000827  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000019, Accuracy_2: 90.8% Loss_2: 0.000687  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003350, Accuracy_2: 90.8% Loss_2: 0.000346  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000173  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001714, Accuracy_2: 89.4% Loss_2: 0.001768  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000448  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000150, Accuracy_2: 89.4% Loss_2: 0.000270  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000023  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000652, Accuracy_2: 90.8% Loss_2: 0.000585  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000087, Accuracy_2: 95.0% Loss_2: 0.000006  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001007, Accuracy_2: 91.5% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.001083, Accuracy_2: 97.9% Loss_2: 0.000032  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000022, Accuracy_2: 90.8% Loss_2: 0.002569  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002439, Accuracy_2: 92.9% Loss_2: 0.000003  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003410, Accuracy_2: 87.9% Loss_2: 0.000213  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000396, Accuracy_2: 89.4% Loss_2: 0.000001  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000355, Accuracy_2: 91.5% Loss_2: 0.002179  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001942, Accuracy_2: 91.5% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000822, Accuracy_2: 90.1% Loss_2: 0.003988  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000243, Accuracy_2: 93.6% Loss_2: 0.000998  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000100  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.001752  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000567  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000616, Accuracy_2: 90.1% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000477, Accuracy_2: 91.5% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000923, Accuracy_2: 92.9% Loss_2: 0.000455  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000367  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000285  [13113/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000004  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000025, Accuracy_2: 91.5% Loss_2: 0.001272  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000218, Accuracy_2: 90.8% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000030  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000003  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000202, Accuracy_2: 92.9% Loss_2: 0.000044  [ 1269/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000171, Accuracy_2: 87.9% Loss_2: 0.000216  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000312  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000660, Accuracy_2: 92.9% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000113, Accuracy_2: 85.8% Loss_2: 0.001236  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000110, Accuracy_2: 90.1% Loss_2: 0.000154  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.005011, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000664  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000229, Accuracy_2: 92.2% Loss_2: 0.000586  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000001  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001170, Accuracy_2: 90.1% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000076, Accuracy_2: 90.8% Loss_2: 0.000271  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000005, Accuracy_2: 89.4% Loss_2: 0.000531  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000124  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001138, Accuracy_2: 87.9% Loss_2: 0.001004  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000084, Accuracy_2: 90.1% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000091  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000006, Accuracy_2: 86.5% Loss_2: 0.000911  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002564, Accuracy_2: 90.1% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000442  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000794  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000149, Accuracy_2: 87.9% Loss_2: 0.001787  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000198  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002327, Accuracy_2: 90.1% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000422, Accuracy_2: 89.4% Loss_2: 0.000004  [ 1269/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000849, Accuracy_2: 87.9% Loss_2: 0.000050  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000023, Accuracy_2: 89.4% Loss_2: 0.000038  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000884, Accuracy_2: 88.7% Loss_2: 0.000436  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000073, Accuracy_2: 92.9% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000001  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000017, Accuracy_2: 88.7% Loss_2: 0.000001  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000389, Accuracy_2: 92.2% Loss_2: 0.000406  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000002  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000081, Accuracy_2: 94.3% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000004, Accuracy_2: 90.1% Loss_2: 0.002433  [ 6909/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 84.4% Loss_2: 0.000744  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000040  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000224, Accuracy_2: 90.8% Loss_2: 0.000559  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000006, Accuracy_2: 90.1% Loss_2: 0.000005  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000001, Accuracy_2: 86.5% Loss_2: 0.001666  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001864  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000329  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001380, Accuracy_2: 90.8% Loss_2: 0.000013  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001723, Accuracy_2: 89.4% Loss_2: 0.000077  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000052  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001914, Accuracy_2: 88.7% Loss_2: 0.003202  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001251, Accuracy_2: 93.6% Loss_2: 0.000453  [14241/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000005  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.5%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003894, Accuracy_2: 90.1% Loss_2: 0.000001  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003212, Accuracy_2: 88.7% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000078, Accuracy_2: 91.5% Loss_2: 0.002531  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.004638, Accuracy_2: 93.6% Loss_2: 0.000002  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002899, Accuracy_2: 92.9% Loss_2: 0.000001  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000136, Accuracy_2: 93.6% Loss_2: 0.000001  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000374, Accuracy_2: 89.4% Loss_2: 0.000989  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001590, Accuracy_2: 85.8% Loss_2: 0.001227  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.001623  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000002, Accuracy_2: 87.2% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000354  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000564  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000499, Accuracy_2: 93.6% Loss_2: 0.000004  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000415  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000812, Accuracy_2: 88.7% Loss_2: 0.000343  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001508, Accuracy_2: 91.5% Loss_2: 0.000828  [10293/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000055, Accuracy_2: 84.4% Loss_2: 0.000579  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000620  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.001099  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000121, Accuracy_2: 90.1% Loss_2: 0.000977  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.001644  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000007, Accuracy_2: 88.7% Loss_2: 0.000026  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000022, Accuracy_2: 89.4% Loss_2: 0.000504  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000024  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000848, Accuracy_2: 89.4% Loss_2: 0.001497  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000281, Accuracy_2: 88.7% Loss_2: 0.001411  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000237, Accuracy_2: 89.4% Loss_2: 0.000089  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000019, Accuracy_2: 89.4% Loss_2: 0.001481  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000118  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.001386  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000620, Accuracy_2: 89.4% Loss_2: 0.000701  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000846, Accuracy_2: 93.6% Loss_2: 0.000401  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000256, Accuracy_2: 90.8% Loss_2: 0.000692  [ 5217/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000617, Accuracy_2: 92.9% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000600  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001642, Accuracy_2: 91.5% Loss_2: 0.002734  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 91.5% Loss_2: 0.003496  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.003477  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001525, Accuracy_2: 86.5% Loss_2: 0.000794  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000264  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000036  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000140, Accuracy_2: 92.2% Loss_2: 0.000002  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002490, Accuracy_2: 92.9% Loss_2: 0.001516  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000650, Accuracy_2: 87.9% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000004, Accuracy_2: 90.1% Loss_2: 0.000011  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000010, Accuracy_2: 90.1% Loss_2: 0.000185  [13677/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.002246, Accuracy_2: 86.5% Loss_2: 0.000001  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.004343  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001464, Accuracy_2: 90.1% Loss_2: 0.000006  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000037, Accuracy_2: 91.5% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002251, Accuracy_2: 89.4% Loss_2: 0.001744  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000071, Accuracy_2: 90.1% Loss_2: 0.001878  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001348, Accuracy_2: 91.5% Loss_2: 0.001866  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000037, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.004470, Accuracy_2: 91.5% Loss_2: 0.000004  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000576  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000083, Accuracy_2: 91.5% Loss_2: 0.000028  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.001307  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000007, Accuracy_2: 87.2% Loss_2: 0.000677  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000003, Accuracy_2: 84.4% Loss_2: 0.004407  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000051, Accuracy_2: 90.8% Loss_2: 0.001845  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000885, Accuracy_2: 90.8% Loss_2: 0.000705  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000012, Accuracy_2: 90.8% Loss_2: 0.000054  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000755, Accuracy_2: 92.2% Loss_2: 0.000070  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000348, Accuracy_2: 92.9% Loss_2: 0.000862  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001350, Accuracy_2: 87.9% Loss_2: 0.003179  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001182, Accuracy_2: 91.5% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003226, Accuracy_2: 91.5% Loss_2: 0.001368  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 91.5% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000527  [13113/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000054, Accuracy_2: 92.9% Loss_2: 0.000002  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000004, Accuracy_2: 87.9% Loss_2: 0.000005  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000687, Accuracy_2: 92.9% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000076, Accuracy_2: 90.1% Loss_2: 0.001276  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000008, Accuracy_2: 90.1% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000145, Accuracy_2: 87.2% Loss_2: 0.000134  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000031  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000672, Accuracy_2: 90.1% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000024  [ 2961/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000826  [ 3525/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000596, Accuracy_2: 84.4% Loss_2: 0.000452  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001475, Accuracy_2: 89.4% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000276, Accuracy_2: 90.8% Loss_2: 0.000202  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001232  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000003, Accuracy_2: 87.9% Loss_2: 0.001190  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000652  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000028  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001005, Accuracy_2: 91.5% Loss_2: 0.000753  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000741, Accuracy_2: 90.8% Loss_2: 0.001628  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000063, Accuracy_2: 89.4% Loss_2: 0.000011  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.002095  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000830, Accuracy_2: 90.1% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002467, Accuracy_2: 90.8% Loss_2: 0.000446  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.004136  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000011, Accuracy_2: 85.8% Loss_2: 0.000308  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000036, Accuracy_2: 85.8% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000983, Accuracy_2: 87.9% Loss_2: 0.000125  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001374, Accuracy_2: 91.5% Loss_2: 0.000413  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000012, Accuracy_2: 87.9% Loss_2: 0.002076  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000002  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.008459, Accuracy_2: 90.1% Loss_2: 0.000088  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 87.9% Loss_2: 0.001448  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000245, Accuracy_2: 92.9% Loss_2: 0.000005  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000338, Accuracy_2: 87.9% Loss_2: 0.001094  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000309, Accuracy_2: 89.4% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002368, Accuracy_2: 86.5% Loss_2: 0.002386  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001322, Accuracy_2: 91.5% Loss_2: 0.000100  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001330, Accuracy_2: 91.5% Loss_2: 0.003775  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000425  [ 4653/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.002413, Accuracy_2: 95.7% Loss_2: 0.000018  [ 5217/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000659, Accuracy_2: 92.9% Loss_2: 0.001531  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001055, Accuracy_2: 88.7% Loss_2: 0.000004  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.004851, Accuracy_2: 90.1% Loss_2: 0.000001  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000007, Accuracy_2: 88.7% Loss_2: 0.000131  [ 7473/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000470, Accuracy_2: 95.0% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000775, Accuracy_2: 89.4% Loss_2: 0.001460  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001201, Accuracy_2: 87.2% Loss_2: 0.000015  [ 9165/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000653, Accuracy_2: 93.6% Loss_2: 0.002714  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000015, Accuracy_2: 92.2% Loss_2: 0.000727  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002032, Accuracy_2: 90.1% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000351, Accuracy_2: 90.8% Loss_2: 0.000265  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000376, Accuracy_2: 87.9% Loss_2: 0.000231  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000302, Accuracy_2: 95.0% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003618, Accuracy_2: 90.1% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.004675, Accuracy_2: 88.7% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000046, Accuracy_2: 87.9% Loss_2: 0.002365  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000067, Accuracy_2: 90.1% Loss_2: 0.000785  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000229, Accuracy_2: 93.6% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000437, Accuracy_2: 85.1% Loss_2: 0.000191  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000008  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000584, Accuracy_2: 90.8% Loss_2: 0.000530  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001679, Accuracy_2: 89.4% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001476, Accuracy_2: 89.4% Loss_2: 0.002045  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000607, Accuracy_2: 87.9% Loss_2: 0.000001  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.004245, Accuracy_2: 92.9% Loss_2: 0.000354  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002421, Accuracy_2: 87.9% Loss_2: 0.001745  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.003403  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001280, Accuracy_2: 90.8% Loss_2: 0.001262  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000063, Accuracy_2: 86.5% Loss_2: 0.002541  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000069, Accuracy_2: 93.6% Loss_2: 0.001443  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000084, Accuracy_2: 87.9% Loss_2: 0.000890  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000016, Accuracy_2: 91.5% Loss_2: 0.000371  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000477, Accuracy_2: 87.9% Loss_2: 0.000002  [ 9729/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000016, Accuracy_2: 91.5% Loss_2: 0.001487  [10293/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002726, Accuracy_2: 86.5% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000120, Accuracy_2: 91.5% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001083, Accuracy_2: 92.2% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001320, Accuracy_2: 91.5% Loss_2: 0.000852  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000006, Accuracy_2: 90.1% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000922  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000492, Accuracy_2: 89.4% Loss_2: 0.000056  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.8%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.004225  [  705/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000059  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000222, Accuracy_2: 92.2% Loss_2: 0.000006  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000114, Accuracy_2: 90.8% Loss_2: 0.002052  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000546, Accuracy_2: 91.5% Loss_2: 0.000004  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000508  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000004, Accuracy_2: 87.9% Loss_2: 0.000679  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000071, Accuracy_2: 91.5% Loss_2: 0.000012  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000075, Accuracy_2: 89.4% Loss_2: 0.002508  [ 5781/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001854, Accuracy_2: 87.9% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000384, Accuracy_2: 92.2% Loss_2: 0.000023  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.000968  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000020, Accuracy_2: 88.7% Loss_2: 0.002059  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000061, Accuracy_2: 89.4% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000776, Accuracy_2: 85.8% Loss_2: 0.000338  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000007, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000094, Accuracy_2: 86.5% Loss_2: 0.000786  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000613  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000715, Accuracy_2: 87.2% Loss_2: 0.002731  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002212, Accuracy_2: 90.8% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001359, Accuracy_2: 87.9% Loss_2: 0.000063  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.003957  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000240  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000055, Accuracy_2: 90.1% Loss_2: 0.000175  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000968, Accuracy_2: 89.4% Loss_2: 0.001212  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000158, Accuracy_2: 87.2% Loss_2: 0.001737  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000212, Accuracy_2: 87.9% Loss_2: 0.000004  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001337, Accuracy_2: 91.5% Loss_2: 0.001135  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.004088, Accuracy_2: 91.5% Loss_2: 0.000001  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000832, Accuracy_2: 87.9% Loss_2: 0.001035  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000169, Accuracy_2: 94.3% Loss_2: 0.000605  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000701, Accuracy_2: 90.1% Loss_2: 0.000043  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001929, Accuracy_2: 90.8% Loss_2: 0.000260  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001528, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000944, Accuracy_2: 86.5% Loss_2: 0.001012  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.002103, Accuracy_2: 95.0% Loss_2: 0.000382  [ 6345/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000001, Accuracy_2: 85.8% Loss_2: 0.000014  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000004, Accuracy_2: 88.7% Loss_2: 0.000002  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002662, Accuracy_2: 88.7% Loss_2: 0.000024  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001032, Accuracy_2: 91.5% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000789, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001874, Accuracy_2: 90.1% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000093, Accuracy_2: 86.5% Loss_2: 0.000345  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000753, Accuracy_2: 90.8% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001108  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000005, Accuracy_2: 92.9% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003044, Accuracy_2: 90.1% Loss_2: 0.000575  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.002370  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000005, Accuracy_2: 91.5% Loss_2: 0.000100  [14241/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001065, Accuracy_2: 87.9% Loss_2: 0.000803  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000443, Accuracy_2: 87.2% Loss_2: 0.001073  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000145, Accuracy_2: 90.1% Loss_2: 0.000175  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000584  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003834, Accuracy_2: 90.1% Loss_2: 0.000001  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000007, Accuracy_2: 92.2% Loss_2: 0.000014  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000010, Accuracy_2: 88.7% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000714, Accuracy_2: 93.6% Loss_2: 0.000468  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003014, Accuracy_2: 90.8% Loss_2: 0.000626  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 91.5% Loss_2: 0.001276  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000326, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000538  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000103, Accuracy_2: 92.2% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003061, Accuracy_2: 87.2% Loss_2: 0.000126  [ 7473/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000004, Accuracy_2: 95.0% Loss_2: 0.000008  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000524, Accuracy_2: 90.1% Loss_2: 0.001307  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000134, Accuracy_2: 87.2% Loss_2: 0.002010  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000578, Accuracy_2: 89.4% Loss_2: 0.000115  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000182, Accuracy_2: 87.9% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000136, Accuracy_2: 88.7% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000008, Accuracy_2: 88.7% Loss_2: 0.000320  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001148, Accuracy_2: 91.5% Loss_2: 0.000292  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001240, Accuracy_2: 87.2% Loss_2: 0.001567  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000553, Accuracy_2: 89.4% Loss_2: 0.001024  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000018, Accuracy_2: 90.8% Loss_2: 0.001753  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.1%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001087, Accuracy_2: 87.9% Loss_2: 0.002457  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002108, Accuracy_2: 91.5% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000314, Accuracy_2: 89.4% Loss_2: 0.000437  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000244, Accuracy_2: 91.5% Loss_2: 0.000442  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001576, Accuracy_2: 91.5% Loss_2: 0.004681  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002101, Accuracy_2: 90.8% Loss_2: 0.000841  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003792, Accuracy_2: 87.2% Loss_2: 0.002366  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000007, Accuracy_2: 92.9% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003451, Accuracy_2: 87.9% Loss_2: 0.000549  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000527, Accuracy_2: 89.4% Loss_2: 0.000008  [ 5217/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000453, Accuracy_2: 85.8% Loss_2: 0.000001  [ 5781/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000643, Accuracy_2: 94.3% Loss_2: 0.000238  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000233, Accuracy_2: 92.2% Loss_2: 0.000007  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.001020  [ 8037/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000003, Accuracy_2: 92.9% Loss_2: 0.000861  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.004871, Accuracy_2: 88.7% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000834, Accuracy_2: 88.7% Loss_2: 0.000324  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000719, Accuracy_2: 88.7% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000036, Accuracy_2: 90.1% Loss_2: 0.001296  [10857/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000000, Accuracy_2: 96.5% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000019, Accuracy_2: 90.8% Loss_2: 0.001418  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001226, Accuracy_2: 87.2% Loss_2: 0.006054  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000947, Accuracy_2: 95.0% Loss_2: 0.000007  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002267, Accuracy_2: 86.5% Loss_2: 0.003744  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000002, Accuracy_2: 86.5% Loss_2: 0.001377  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000836, Accuracy_2: 92.9% Loss_2: 0.000092  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001773, Accuracy_2: 95.0% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001435, Accuracy_2: 87.9% Loss_2: 0.002904  [  705/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001174, Accuracy_2: 85.1% Loss_2: 0.000252  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000207  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000018, Accuracy_2: 91.5% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001243, Accuracy_2: 90.1% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000079, Accuracy_2: 90.1% Loss_2: 0.000256  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000005  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001421, Accuracy_2: 91.5% Loss_2: 0.001357  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002253, Accuracy_2: 87.9% Loss_2: 0.000518  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000506, Accuracy_2: 90.8% Loss_2: 0.000765  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000645, Accuracy_2: 94.3% Loss_2: 0.001074  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000053, Accuracy_2: 89.4% Loss_2: 0.000007  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000674  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000168, Accuracy_2: 88.7% Loss_2: 0.000570  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000128, Accuracy_2: 92.9% Loss_2: 0.002086  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000102, Accuracy_2: 94.3% Loss_2: 0.000001  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001961, Accuracy_2: 88.7% Loss_2: 0.000028  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000002  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000023, Accuracy_2: 84.4% Loss_2: 0.007841  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000500  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000649, Accuracy_2: 91.5% Loss_2: 0.002609  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000005, Accuracy_2: 85.8% Loss_2: 0.000012  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000030, Accuracy_2: 90.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000455, Accuracy_2: 90.8% Loss_2: 0.000002  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000069, Accuracy_2: 94.3% Loss_2: 0.000014  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000237, Accuracy_2: 87.9% Loss_2: 0.001702  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003644, Accuracy_2: 87.9% Loss_2: 0.000203  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000007  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001117, Accuracy_2: 90.1% Loss_2: 0.000358  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000224, Accuracy_2: 90.1% Loss_2: 0.002476  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000716, Accuracy_2: 92.2% Loss_2: 0.000001  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001164, Accuracy_2: 91.5% Loss_2: 0.000822  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 91.5% Loss_2: 0.000702  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000077, Accuracy_2: 90.1% Loss_2: 0.000402  [ 5217/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000157, Accuracy_2: 86.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000352  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000109  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000112, Accuracy_2: 87.9% Loss_2: 0.000288  [ 7473/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000067, Accuracy_2: 94.3% Loss_2: 0.003858  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000470, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000169, Accuracy_2: 90.1% Loss_2: 0.003855  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002372, Accuracy_2: 88.7% Loss_2: 0.000163  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000003  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000013, Accuracy_2: 88.7% Loss_2: 0.000105  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000293, Accuracy_2: 92.9% Loss_2: 0.001562  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000007, Accuracy_2: 90.8% Loss_2: 0.001259  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000604, Accuracy_2: 87.2% Loss_2: 0.000525  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000024, Accuracy_2: 87.2% Loss_2: 0.000299  [13113/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000388, Accuracy_2: 86.5% Loss_2: 0.000104  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.004420, Accuracy_2: 88.7% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002910, Accuracy_2: 92.9% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000516, Accuracy_2: 90.8% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000300, Accuracy_2: 87.2% Loss_2: 0.000351  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.000001  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000047, Accuracy_2: 92.2% Loss_2: 0.000298  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000805, Accuracy_2: 92.9% Loss_2: 0.000004  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000123, Accuracy_2: 92.9% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000131, Accuracy_2: 90.1% Loss_2: 0.001462  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000041, Accuracy_2: 87.2% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000033, Accuracy_2: 89.4% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000132, Accuracy_2: 95.7% Loss_2: 0.000022  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000457, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001761  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000015, Accuracy_2: 87.9% Loss_2: 0.000300  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.008013, Accuracy_2: 90.8% Loss_2: 0.000669  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000890, Accuracy_2: 87.2% Loss_2: 0.000066  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000518, Accuracy_2: 87.2% Loss_2: 0.000755  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000190, Accuracy_2: 91.5% Loss_2: 0.000791  [ 9165/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001241, Accuracy_2: 85.8% Loss_2: 0.000810  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000518, Accuracy_2: 92.2% Loss_2: 0.000064  [10293/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.003261, Accuracy_2: 96.5% Loss_2: 0.000020  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002536, Accuracy_2: 92.9% Loss_2: 0.000001  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000025, Accuracy_2: 88.7% Loss_2: 0.000029  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001803, Accuracy_2: 95.7% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.001144  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003356, Accuracy_2: 89.4% Loss_2: 0.001786  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001033, Accuracy_2: 93.6% Loss_2: 0.000004  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001299, Accuracy_2: 87.9% Loss_2: 0.000566  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.2%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000286, Accuracy_2: 92.9% Loss_2: 0.001354  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001134, Accuracy_2: 87.9% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000295, Accuracy_2: 87.9% Loss_2: 0.000049  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000545  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001691, Accuracy_2: 86.5% Loss_2: 0.000071  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000268, Accuracy_2: 91.5% Loss_2: 0.000006  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.000003  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001214, Accuracy_2: 92.2% Loss_2: 0.000057  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000086  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000970  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000451, Accuracy_2: 87.9% Loss_2: 0.002030  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001784, Accuracy_2: 88.7% Loss_2: 0.000592  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001135, Accuracy_2: 87.2% Loss_2: 0.002882  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000659, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001458, Accuracy_2: 85.8% Loss_2: 0.006173  [ 9729/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000458, Accuracy_2: 95.7% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000061, Accuracy_2: 89.4% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000018, Accuracy_2: 93.6% Loss_2: 0.000015  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.001110  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000550, Accuracy_2: 91.5% Loss_2: 0.000264  [12549/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.002703  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000035  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.001249  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 94.3% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.2%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000518, Accuracy_2: 91.5% Loss_2: 0.000197  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000675  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000071, Accuracy_2: 87.2% Loss_2: 0.001068  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000269, Accuracy_2: 90.8% Loss_2: 0.000230  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001613, Accuracy_2: 88.7% Loss_2: 0.001624  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003913, Accuracy_2: 92.2% Loss_2: 0.000413  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000514, Accuracy_2: 87.9% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000043, Accuracy_2: 86.5% Loss_2: 0.000004  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000391, Accuracy_2: 89.4% Loss_2: 0.001142  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003454, Accuracy_2: 92.2% Loss_2: 0.000448  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000017, Accuracy_2: 90.1% Loss_2: 0.000112  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000091  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000411, Accuracy_2: 92.2% Loss_2: 0.002797  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001258, Accuracy_2: 90.1% Loss_2: 0.000879  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000580, Accuracy_2: 90.1% Loss_2: 0.000032  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.004624, Accuracy_2: 89.4% Loss_2: 0.000016  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003192, Accuracy_2: 87.2% Loss_2: 0.001214  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000423, Accuracy_2: 94.3% Loss_2: 0.000011  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000119  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000021, Accuracy_2: 88.7% Loss_2: 0.000457  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.002097  [11421/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000758  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000022, Accuracy_2: 90.1% Loss_2: 0.003850  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000865, Accuracy_2: 92.9% Loss_2: 0.000035  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001584, Accuracy_2: 90.8% Loss_2: 0.001070  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001177  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002852, Accuracy_2: 91.5% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000008, Accuracy_2: 86.5% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002107  [  705/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.004865, Accuracy_2: 83.0% Loss_2: 0.002017  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001626, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001115, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000049  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000020, Accuracy_2: 88.7% Loss_2: 0.000020  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000078, Accuracy_2: 87.9% Loss_2: 0.000369  [ 4089/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000043, Accuracy_2: 94.3% Loss_2: 0.001486  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000399  [ 5217/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001885, Accuracy_2: 85.8% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000027, Accuracy_2: 90.8% Loss_2: 0.000522  [ 6345/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000001, Accuracy_2: 96.5% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000366, Accuracy_2: 94.3% Loss_2: 0.000001  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003637, Accuracy_2: 92.2% Loss_2: 0.000889  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.001245  [ 8601/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000002, Accuracy_2: 83.7% Loss_2: 0.003196  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000005, Accuracy_2: 87.9% Loss_2: 0.000160  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000042, Accuracy_2: 92.9% Loss_2: 0.000644  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000283, Accuracy_2: 86.5% Loss_2: 0.006394  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001836, Accuracy_2: 88.7% Loss_2: 0.005408  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000179, Accuracy_2: 89.4% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000123, Accuracy_2: 90.1% Loss_2: 0.000031  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.002334  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000119, Accuracy_2: 89.4% Loss_2: 0.000965  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001951, Accuracy_2: 90.1% Loss_2: 0.000902  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001570, Accuracy_2: 94.3% Loss_2: 0.000100  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000306, Accuracy_2: 87.2% Loss_2: 0.000235  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.002319, Accuracy_2: 93.6% Loss_2: 0.000109  [ 1269/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.001193  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001156, Accuracy_2: 92.9% Loss_2: 0.001683  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001184, Accuracy_2: 87.9% Loss_2: 0.005661  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003379, Accuracy_2: 87.9% Loss_2: 0.000004  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000732, Accuracy_2: 92.2% Loss_2: 0.000520  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.004202  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002680, Accuracy_2: 89.4% Loss_2: 0.000004  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000044, Accuracy_2: 90.8% Loss_2: 0.000005  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000051, Accuracy_2: 92.9% Loss_2: 0.000775  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000077, Accuracy_2: 89.4% Loss_2: 0.000642  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002516, Accuracy_2: 90.1% Loss_2: 0.000002  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000230, Accuracy_2: 89.4% Loss_2: 0.000090  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000171  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000527  [ 9165/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000326, Accuracy_2: 96.5% Loss_2: 0.000008  [ 9729/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000006, Accuracy_2: 94.3% Loss_2: 0.001061  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000004  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002012, Accuracy_2: 86.5% Loss_2: 0.005642  [11421/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.001824  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000102, Accuracy_2: 87.9% Loss_2: 0.000685  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000006, Accuracy_2: 90.8% Loss_2: 0.001027  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000202, Accuracy_2: 92.2% Loss_2: 0.000002  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000488, Accuracy_2: 90.1% Loss_2: 0.000335  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000016  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "Accuracy_1: 95.7%, Loss_1: 0.001404, Accuracy_2: 95.7% Loss_2: 0.000020  [  141/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000170, Accuracy_2: 95.0% Loss_2: 0.000039  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000408  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000210, Accuracy_2: 90.8% Loss_2: 0.001025  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001972, Accuracy_2: 91.5% Loss_2: 0.000479  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000206  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000053, Accuracy_2: 87.9% Loss_2: 0.000540  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000025  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001043, Accuracy_2: 92.2% Loss_2: 0.000005  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000312, Accuracy_2: 85.1% Loss_2: 0.001394  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000200, Accuracy_2: 89.4% Loss_2: 0.000001  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000933, Accuracy_2: 89.4% Loss_2: 0.002142  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000046, Accuracy_2: 88.7% Loss_2: 0.002885  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001354, Accuracy_2: 91.5% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000003, Accuracy_2: 89.4% Loss_2: 0.002171  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.002940  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002308, Accuracy_2: 91.5% Loss_2: 0.000154  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000655, Accuracy_2: 92.9% Loss_2: 0.000006  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001074, Accuracy_2: 91.5% Loss_2: 0.000449  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001388, Accuracy_2: 83.7% Loss_2: 0.000265  [11421/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.001615, Accuracy_2: 85.1% Loss_2: 0.000008  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000164  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000578, Accuracy_2: 90.8% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000066  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000694, Accuracy_2: 92.9% Loss_2: 0.000311  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003167, Accuracy_2: 90.8% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002159, Accuracy_2: 94.3% Loss_2: 0.000029  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000008, Accuracy_2: 90.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003219, Accuracy_2: 88.7% Loss_2: 0.001183  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000031  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.004357, Accuracy_2: 90.1% Loss_2: 0.000002  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.001932  [ 2961/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000927, Accuracy_2: 84.4% Loss_2: 0.000320  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002893, Accuracy_2: 89.4% Loss_2: 0.000255  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000767, Accuracy_2: 90.8% Loss_2: 0.000012  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.002023  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001281, Accuracy_2: 87.9% Loss_2: 0.000368  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001004, Accuracy_2: 90.8% Loss_2: 0.002018  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000012, Accuracy_2: 89.4% Loss_2: 0.000148  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000024  [ 7473/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000110, Accuracy_2: 85.1% Loss_2: 0.000456  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000004, Accuracy_2: 94.3% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000778, Accuracy_2: 89.4% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002928, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001223, Accuracy_2: 91.5% Loss_2: 0.000004  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003105, Accuracy_2: 88.7% Loss_2: 0.000811  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000233, Accuracy_2: 87.9% Loss_2: 0.002560  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.000003  [12549/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000003, Accuracy_2: 85.1% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000145, Accuracy_2: 90.8% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000326, Accuracy_2: 92.2% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000008, Accuracy_2: 88.7% Loss_2: 0.001016  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000559, Accuracy_2: 86.5% Loss_2: 0.000681  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000518  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000242  [ 1269/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000254, Accuracy_2: 87.2% Loss_2: 0.000001  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.000007  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000130, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000086, Accuracy_2: 91.5% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001083, Accuracy_2: 94.3% Loss_2: 0.000008  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000352, Accuracy_2: 89.4% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000178, Accuracy_2: 91.5% Loss_2: 0.000348  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000014, Accuracy_2: 90.8% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003032, Accuracy_2: 90.1% Loss_2: 0.000512  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001712  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000042, Accuracy_2: 88.7% Loss_2: 0.000092  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000281, Accuracy_2: 88.7% Loss_2: 0.000974  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000776, Accuracy_2: 92.9% Loss_2: 0.000531  [ 8601/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000008, Accuracy_2: 91.5% Loss_2: 0.002252  [ 9165/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000002, Accuracy_2: 95.0% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000201, Accuracy_2: 85.8% Loss_2: 0.000793  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000710, Accuracy_2: 90.8% Loss_2: 0.001362  [10857/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000898, Accuracy_2: 85.8% Loss_2: 0.000305  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000016, Accuracy_2: 92.2% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002280, Accuracy_2: 88.7% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001447, Accuracy_2: 85.8% Loss_2: 0.000003  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000173, Accuracy_2: 85.8% Loss_2: 0.000002  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002829, Accuracy_2: 92.2% Loss_2: 0.000014  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000018, Accuracy_2: 88.7% Loss_2: 0.001027  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000147  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000005, Accuracy_2: 89.4% Loss_2: 0.000017  [ 2397/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000839, Accuracy_2: 95.0% Loss_2: 0.000813  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000012, Accuracy_2: 90.8% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000001  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000175, Accuracy_2: 86.5% Loss_2: 0.001192  [ 4653/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000031, Accuracy_2: 94.3% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002381, Accuracy_2: 91.5% Loss_2: 0.000001  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000371, Accuracy_2: 88.7% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000058, Accuracy_2: 87.2% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001335, Accuracy_2: 90.1% Loss_2: 0.000575  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000115, Accuracy_2: 92.2% Loss_2: 0.000871  [ 8601/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 83.7% Loss_2: 0.004379  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000205, Accuracy_2: 87.2% Loss_2: 0.000672  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000094, Accuracy_2: 91.5% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.004714, Accuracy_2: 92.9% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000097  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000240, Accuracy_2: 90.1% Loss_2: 0.000812  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000044, Accuracy_2: 94.3% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000245, Accuracy_2: 90.1% Loss_2: 0.006876  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000005, Accuracy_2: 90.1% Loss_2: 0.000025  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000664, Accuracy_2: 85.8% Loss_2: 0.000013  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000003  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000137, Accuracy_2: 85.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000141, Accuracy_2: 89.4% Loss_2: 0.002610  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 88.7% Loss_2: 0.001119  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000051, Accuracy_2: 87.9% Loss_2: 0.000892  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000025, Accuracy_2: 90.8% Loss_2: 0.000001  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000002  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000001  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001992, Accuracy_2: 92.2% Loss_2: 0.000393  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000058, Accuracy_2: 88.7% Loss_2: 0.001177  [ 5781/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000815, Accuracy_2: 84.4% Loss_2: 0.004305  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000121, Accuracy_2: 89.4% Loss_2: 0.000174  [ 7473/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000003  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000027, Accuracy_2: 91.5% Loss_2: 0.001094  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000482, Accuracy_2: 90.1% Loss_2: 0.000448  [ 9729/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003365, Accuracy_2: 85.1% Loss_2: 0.000740  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000034, Accuracy_2: 90.8% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.002012  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000130, Accuracy_2: 93.6% Loss_2: 0.001431  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001268, Accuracy_2: 92.9% Loss_2: 0.000500  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000033, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000757, Accuracy_2: 92.2% Loss_2: 0.000328  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001308  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001202, Accuracy_2: 90.8% Loss_2: 0.000743  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000419, Accuracy_2: 89.4% Loss_2: 0.000459  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001221, Accuracy_2: 92.9% Loss_2: 0.000420  [ 1269/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000001, Accuracy_2: 95.0% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000141, Accuracy_2: 90.1% Loss_2: 0.000465  [ 2397/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000938, Accuracy_2: 95.7% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001213, Accuracy_2: 87.2% Loss_2: 0.001389  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000653, Accuracy_2: 90.1% Loss_2: 0.000005  [ 4089/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001329, Accuracy_2: 91.5% Loss_2: 0.000129  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.004948, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 94.3% Loss_2: 0.000008  [ 5781/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000000, Accuracy_2: 84.4% Loss_2: 0.000398  [ 6345/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000353, Accuracy_2: 85.1% Loss_2: 0.000223  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000510, Accuracy_2: 89.4% Loss_2: 0.000072  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000840, Accuracy_2: 87.9% Loss_2: 0.000057  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001378  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001798  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000015, Accuracy_2: 91.5% Loss_2: 0.000021  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000025  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.003654, Accuracy_2: 86.5% Loss_2: 0.000235  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000017  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000031, Accuracy_2: 91.5% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 94.3% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002311, Accuracy_2: 86.5% Loss_2: 0.000008  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000086, Accuracy_2: 90.1% Loss_2: 0.001319  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000626, Accuracy_2: 87.9% Loss_2: 0.002940  [14241/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002440, Accuracy_2: 85.1% Loss_2: 0.000118  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000003  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000127, Accuracy_2: 87.2% Loss_2: 0.002552  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000025, Accuracy_2: 92.2% Loss_2: 0.000010  [ 1269/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.001935  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003002, Accuracy_2: 88.7% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002243, Accuracy_2: 86.5% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000033, Accuracy_2: 89.4% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000132, Accuracy_2: 93.6% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000562, Accuracy_2: 90.1% Loss_2: 0.000007  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000042, Accuracy_2: 87.2% Loss_2: 0.002543  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000023, Accuracy_2: 94.3% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000777, Accuracy_2: 87.9% Loss_2: 0.000112  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001680, Accuracy_2: 86.5% Loss_2: 0.001637  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.000463  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000383, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000016, Accuracy_2: 94.3% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001016, Accuracy_2: 87.2% Loss_2: 0.001143  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000026, Accuracy_2: 92.9% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000471, Accuracy_2: 88.7% Loss_2: 0.000899  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000591  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000754, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000012, Accuracy_2: 90.8% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 97.2%, Loss_1: 0.000000, Accuracy_2: 96.5% Loss_2: 0.000002  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001514, Accuracy_2: 88.7% Loss_2: 0.000516  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000844, Accuracy_2: 91.5% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000004, Accuracy_2: 90.1% Loss_2: 0.000774  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.001949  [ 1269/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000140, Accuracy_2: 95.0% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000008, Accuracy_2: 91.5% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000940  [ 2961/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003290, Accuracy_2: 88.7% Loss_2: 0.000595  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.002465  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000043, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000029, Accuracy_2: 90.8% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000928, Accuracy_2: 90.8% Loss_2: 0.000051  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000828  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.002230  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001016, Accuracy_2: 87.9% Loss_2: 0.000099  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000040, Accuracy_2: 87.9% Loss_2: 0.000294  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000170, Accuracy_2: 93.6% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000455, Accuracy_2: 88.7% Loss_2: 0.000133  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000002  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000270, Accuracy_2: 91.5% Loss_2: 0.001822  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.002766, Accuracy_2: 95.0% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.003818  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001450, Accuracy_2: 90.1% Loss_2: 0.000248  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002266, Accuracy_2: 87.9% Loss_2: 0.002844  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000441, Accuracy_2: 91.5% Loss_2: 0.000292  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 91.5% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000559, Accuracy_2: 90.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000898, Accuracy_2: 90.8% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.001032  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001444, Accuracy_2: 90.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000645, Accuracy_2: 87.2% Loss_2: 0.002187  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000013, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000690, Accuracy_2: 93.6% Loss_2: 0.001085  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001037, Accuracy_2: 90.1% Loss_2: 0.000002  [ 2961/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000092, Accuracy_2: 95.7% Loss_2: 0.001880  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.000171  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001257, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001932, Accuracy_2: 86.5% Loss_2: 0.001512  [ 5217/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000003, Accuracy_2: 93.6% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000062  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000717, Accuracy_2: 92.2% Loss_2: 0.003377  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001777, Accuracy_2: 92.2% Loss_2: 0.000966  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.001169  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.001985  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000025, Accuracy_2: 91.5% Loss_2: 0.000331  [ 9165/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003972, Accuracy_2: 88.7% Loss_2: 0.000092  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001865, Accuracy_2: 86.5% Loss_2: 0.000402  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000007, Accuracy_2: 90.1% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.001496  [11421/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000011, Accuracy_2: 95.7% Loss_2: 0.000003  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000472  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000153  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000386, Accuracy_2: 92.2% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000582, Accuracy_2: 90.1% Loss_2: 0.001730  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000007, Accuracy_2: 90.1% Loss_2: 0.002942  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000683, Accuracy_2: 88.7% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000012, Accuracy_2: 89.4% Loss_2: 0.000090  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.002037  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000109, Accuracy_2: 92.2% Loss_2: 0.000042  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.004264, Accuracy_2: 87.2% Loss_2: 0.001308  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.006201, Accuracy_2: 91.5% Loss_2: 0.000012  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000585, Accuracy_2: 87.2% Loss_2: 0.000348  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.000003  [ 4089/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000009, Accuracy_2: 92.9% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000001, Accuracy_2: 85.8% Loss_2: 0.001192  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000201, Accuracy_2: 88.7% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000028  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000010, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002983, Accuracy_2: 85.1% Loss_2: 0.000003  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.005893, Accuracy_2: 92.9% Loss_2: 0.000006  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001222, Accuracy_2: 92.2% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000506, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000002  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001760  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001808, Accuracy_2: 89.4% Loss_2: 0.000305  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000071  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000057, Accuracy_2: 92.2% Loss_2: 0.000886  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001766, Accuracy_2: 90.8% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000906, Accuracy_2: 90.8% Loss_2: 0.000698  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002773, Accuracy_2: 88.7% Loss_2: 0.000001  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000161  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002432, Accuracy_2: 93.6% Loss_2: 0.000006  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000480, Accuracy_2: 88.7% Loss_2: 0.000210  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000003, Accuracy_2: 90.1% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000853, Accuracy_2: 91.5% Loss_2: 0.000225  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.001261  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000210  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.002762  [ 3525/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001433, Accuracy_2: 92.9% Loss_2: 0.000623  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000227, Accuracy_2: 86.5% Loss_2: 0.001032  [ 4653/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000515, Accuracy_2: 95.0% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000337, Accuracy_2: 89.4% Loss_2: 0.002868  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000513, Accuracy_2: 90.1% Loss_2: 0.000010  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000796  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.002100  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000108, Accuracy_2: 89.4% Loss_2: 0.000002  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000163, Accuracy_2: 94.3% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.001913  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000284, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.005671, Accuracy_2: 92.2% Loss_2: 0.000002  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000018  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001371, Accuracy_2: 89.4% Loss_2: 0.000709  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000625  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000005  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000063, Accuracy_2: 90.8% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002240, Accuracy_2: 93.6% Loss_2: 0.001057  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003387, Accuracy_2: 92.2% Loss_2: 0.002154  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000475, Accuracy_2: 92.2% Loss_2: 0.000010  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000084, Accuracy_2: 87.9% Loss_2: 0.001105  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001245, Accuracy_2: 90.1% Loss_2: 0.001121  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.005831, Accuracy_2: 91.5% Loss_2: 0.000010  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000091, Accuracy_2: 93.6% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001067  [ 2961/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000008, Accuracy_2: 95.0% Loss_2: 0.001544  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000013, Accuracy_2: 90.8% Loss_2: 0.000001  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000002, Accuracy_2: 87.2% Loss_2: 0.000021  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000714, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000568, Accuracy_2: 94.3% Loss_2: 0.000241  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000012, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000921  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000371, Accuracy_2: 90.8% Loss_2: 0.000004  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.002711  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000932  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000846, Accuracy_2: 90.1% Loss_2: 0.001286  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000016, Accuracy_2: 92.2% Loss_2: 0.000497  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001033, Accuracy_2: 91.5% Loss_2: 0.002256  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000012, Accuracy_2: 86.5% Loss_2: 0.000310  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000072, Accuracy_2: 93.6% Loss_2: 0.000729  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000788, Accuracy_2: 90.8% Loss_2: 0.000193  [13113/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000156  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000360  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 91.5% Loss_2: 0.000017  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000022, Accuracy_2: 90.1% Loss_2: 0.000086  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000035, Accuracy_2: 90.1% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000001  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000106, Accuracy_2: 90.8% Loss_2: 0.001015  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 94.3% Loss_2: 0.000403  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001357, Accuracy_2: 89.4% Loss_2: 0.000949  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001757, Accuracy_2: 89.4% Loss_2: 0.000106  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001507, Accuracy_2: 85.1% Loss_2: 0.001352  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000270, Accuracy_2: 92.2% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000254, Accuracy_2: 90.8% Loss_2: 0.000571  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000388, Accuracy_2: 90.8% Loss_2: 0.002480  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000007  [ 6909/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001229, Accuracy_2: 93.6% Loss_2: 0.001250  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.003608, Accuracy_2: 90.8% Loss_2: 0.002667  [ 8037/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001227, Accuracy_2: 85.8% Loss_2: 0.001159  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000100  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003891, Accuracy_2: 92.2% Loss_2: 0.000062  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000883, Accuracy_2: 91.5% Loss_2: 0.000165  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000277, Accuracy_2: 89.4% Loss_2: 0.000103  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000622, Accuracy_2: 93.6% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000001  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000022, Accuracy_2: 93.6% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000368, Accuracy_2: 91.5% Loss_2: 0.000028  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.001716  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000330, Accuracy_2: 90.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000414  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000234, Accuracy_2: 86.5% Loss_2: 0.000002  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000331, Accuracy_2: 91.5% Loss_2: 0.001701  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000630, Accuracy_2: 88.7% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001240, Accuracy_2: 92.9% Loss_2: 0.000006  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000865  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000852  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000409, Accuracy_2: 89.4% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000559  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001316, Accuracy_2: 91.5% Loss_2: 0.001519  [ 4653/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000001, Accuracy_2: 95.0% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001760, Accuracy_2: 95.0% Loss_2: 0.000050  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000019, Accuracy_2: 92.2% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000447, Accuracy_2: 88.7% Loss_2: 0.003337  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000168, Accuracy_2: 85.8% Loss_2: 0.001863  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000223  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000024, Accuracy_2: 92.9% Loss_2: 0.000083  [ 9165/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000402, Accuracy_2: 86.5% Loss_2: 0.000009  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000106, Accuracy_2: 92.9% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000394, Accuracy_2: 90.8% Loss_2: 0.001458  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000476, Accuracy_2: 90.1% Loss_2: 0.000179  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000003, Accuracy_2: 89.4% Loss_2: 0.003744  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000020  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000226, Accuracy_2: 88.7% Loss_2: 0.000698  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000103, Accuracy_2: 90.8% Loss_2: 0.003827  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000278, Accuracy_2: 92.9% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000233, Accuracy_2: 91.5% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.001360  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000202, Accuracy_2: 89.4% Loss_2: 0.000691  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000130  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000557  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001082, Accuracy_2: 90.1% Loss_2: 0.001018  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000385, Accuracy_2: 92.2% Loss_2: 0.001294  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001773, Accuracy_2: 92.9% Loss_2: 0.003101  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000006, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001065, Accuracy_2: 88.7% Loss_2: 0.001690  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000310, Accuracy_2: 88.7% Loss_2: 0.000017  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000026  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000297  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000028  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000011, Accuracy_2: 89.4% Loss_2: 0.000719  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001813, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000348  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002703, Accuracy_2: 86.5% Loss_2: 0.002378  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000167, Accuracy_2: 89.4% Loss_2: 0.001354  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000178, Accuracy_2: 92.9% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000819  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002326, Accuracy_2: 88.7% Loss_2: 0.002692  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000004, Accuracy_2: 90.8% Loss_2: 0.000036  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000981, Accuracy_2: 91.5% Loss_2: 0.000019  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003224, Accuracy_2: 90.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000356  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000272, Accuracy_2: 92.9% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000236  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000653  [ 1269/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000061, Accuracy_2: 95.7% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000008, Accuracy_2: 91.5% Loss_2: 0.000007  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000090, Accuracy_2: 93.6% Loss_2: 0.002479  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000001  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000004, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000160, Accuracy_2: 92.2% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000314, Accuracy_2: 87.9% Loss_2: 0.000653  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000765  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002168, Accuracy_2: 89.4% Loss_2: 0.000004  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000697, Accuracy_2: 87.9% Loss_2: 0.000384  [ 7473/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000180, Accuracy_2: 96.5% Loss_2: 0.000018  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000016, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002273, Accuracy_2: 89.4% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000641  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.000162  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000597, Accuracy_2: 93.6% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000026, Accuracy_2: 90.1% Loss_2: 0.000001  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000685, Accuracy_2: 86.5% Loss_2: 0.000676  [11985/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.001305, Accuracy_2: 96.5% Loss_2: 0.000002  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000009, Accuracy_2: 93.6% Loss_2: 0.000013  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000023, Accuracy_2: 92.9% Loss_2: 0.000001  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001810, Accuracy_2: 90.1% Loss_2: 0.001497  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000375, Accuracy_2: 86.5% Loss_2: 0.000983  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000459, Accuracy_2: 90.8% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000017, Accuracy_2: 93.6% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000040, Accuracy_2: 90.1% Loss_2: 0.000001  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000287, Accuracy_2: 89.4% Loss_2: 0.004937  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000033, Accuracy_2: 95.0% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.000094  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000075, Accuracy_2: 91.5% Loss_2: 0.001557  [ 4653/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000001, Accuracy_2: 95.7% Loss_2: 0.000013  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000404  [ 5781/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000011, Accuracy_2: 95.0% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002524, Accuracy_2: 90.1% Loss_2: 0.001583  [ 6909/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000002  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002048, Accuracy_2: 87.9% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000385  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000118, Accuracy_2: 92.2% Loss_2: 0.000419  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.002331  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000017, Accuracy_2: 87.9% Loss_2: 0.000009  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000061, Accuracy_2: 89.4% Loss_2: 0.000701  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002257, Accuracy_2: 90.8% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000065, Accuracy_2: 92.2% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000008, Accuracy_2: 91.5% Loss_2: 0.000257  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000087, Accuracy_2: 88.7% Loss_2: 0.000036  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.004271, Accuracy_2: 88.7% Loss_2: 0.000492  [13677/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000023, Accuracy_2: 95.7% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001024, Accuracy_2: 91.5% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "Accuracy_1: 83.7%, Loss_1: 0.003222, Accuracy_2: 87.9% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.001676  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000669, Accuracy_2: 86.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000011, Accuracy_2: 86.5% Loss_2: 0.000205  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000338, Accuracy_2: 92.2% Loss_2: 0.000050  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002088, Accuracy_2: 87.9% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000618, Accuracy_2: 90.8% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000047  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000532, Accuracy_2: 93.6% Loss_2: 0.000007  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000464, Accuracy_2: 88.7% Loss_2: 0.003320  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000527, Accuracy_2: 92.2% Loss_2: 0.000957  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000160  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001487, Accuracy_2: 92.9% Loss_2: 0.000242  [ 8037/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000005, Accuracy_2: 94.3% Loss_2: 0.000066  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000697, Accuracy_2: 89.4% Loss_2: 0.000044  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000879, Accuracy_2: 90.1% Loss_2: 0.000047  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001894, Accuracy_2: 93.6% Loss_2: 0.002029  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000385  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001564, Accuracy_2: 91.5% Loss_2: 0.000002  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000362, Accuracy_2: 88.7% Loss_2: 0.000141  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.002780  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.002280, Accuracy_2: 85.1% Loss_2: 0.000123  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.007503, Accuracy_2: 92.2% Loss_2: 0.000001  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.001506  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 84.4% Loss_2: 0.000419  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000029  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000936, Accuracy_2: 90.8% Loss_2: 0.000589  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000056  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000016  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002446, Accuracy_2: 88.7% Loss_2: 0.001121  [ 2961/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000010  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000053, Accuracy_2: 91.5% Loss_2: 0.000001  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000375, Accuracy_2: 91.5% Loss_2: 0.000533  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001359, Accuracy_2: 92.9% Loss_2: 0.000915  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000971, Accuracy_2: 92.9% Loss_2: 0.001842  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000012, Accuracy_2: 90.8% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002133, Accuracy_2: 92.2% Loss_2: 0.000001  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000259  [ 8037/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000000, Accuracy_2: 84.4% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001546, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003754, Accuracy_2: 90.8% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 90.1% Loss_2: 0.002997  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000403, Accuracy_2: 90.8% Loss_2: 0.002515  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000569, Accuracy_2: 92.9% Loss_2: 0.000490  [12549/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000823, Accuracy_2: 93.6% Loss_2: 0.000868  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000923, Accuracy_2: 91.5% Loss_2: 0.000600  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002846  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000108, Accuracy_2: 95.0% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.1%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000013, Accuracy_2: 92.9% Loss_2: 0.002430  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001858, Accuracy_2: 87.2% Loss_2: 0.000316  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000042, Accuracy_2: 87.2% Loss_2: 0.003531  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000075, Accuracy_2: 90.8% Loss_2: 0.000212  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000167, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000283, Accuracy_2: 92.9% Loss_2: 0.000223  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000265  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000285, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001256, Accuracy_2: 92.9% Loss_2: 0.000002  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001077, Accuracy_2: 91.5% Loss_2: 0.000097  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000065, Accuracy_2: 92.2% Loss_2: 0.000075  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.001864  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001133, Accuracy_2: 92.2% Loss_2: 0.001473  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000021, Accuracy_2: 91.5% Loss_2: 0.003119  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000205, Accuracy_2: 89.4% Loss_2: 0.000233  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000471, Accuracy_2: 91.5% Loss_2: 0.000007  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000987, Accuracy_2: 89.4% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.001002  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.002463  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000023, Accuracy_2: 88.7% Loss_2: 0.000572  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000589, Accuracy_2: 89.4% Loss_2: 0.000385  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000077, Accuracy_2: 95.0% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002136, Accuracy_2: 93.6% Loss_2: 0.000002  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000452, Accuracy_2: 87.9% Loss_2: 0.002646  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002250, Accuracy_2: 92.9% Loss_2: 0.000136  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.9%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000443, Accuracy_2: 88.7% Loss_2: 0.008219  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000802, Accuracy_2: 89.4% Loss_2: 0.000395  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000203  [ 1269/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000417  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.006868  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000262, Accuracy_2: 91.5% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000264, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000197, Accuracy_2: 89.4% Loss_2: 0.002489  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 91.5% Loss_2: 0.000636  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002514, Accuracy_2: 90.8% Loss_2: 0.000004  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001093, Accuracy_2: 92.2% Loss_2: 0.000041  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000861  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001197, Accuracy_2: 90.8% Loss_2: 0.000019  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000005  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000309, Accuracy_2: 92.2% Loss_2: 0.001015  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000447, Accuracy_2: 92.9% Loss_2: 0.000451  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000180, Accuracy_2: 90.1% Loss_2: 0.001414  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000001  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000003  [10857/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000253, Accuracy_2: 95.0% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000002, Accuracy_2: 91.5% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000366, Accuracy_2: 87.2% Loss_2: 0.001328  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000616  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001794, Accuracy_2: 89.4% Loss_2: 0.002052  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000108, Accuracy_2: 91.5% Loss_2: 0.000020  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000764, Accuracy_2: 91.5% Loss_2: 0.000001  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000002  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001135, Accuracy_2: 92.9% Loss_2: 0.000105  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002248, Accuracy_2: 90.8% Loss_2: 0.000001  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000055  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000095, Accuracy_2: 87.2% Loss_2: 0.002048  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000064, Accuracy_2: 87.2% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002627, Accuracy_2: 91.5% Loss_2: 0.002472  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000001  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000835, Accuracy_2: 87.9% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000024, Accuracy_2: 92.2% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000439, Accuracy_2: 90.8% Loss_2: 0.000003  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.003393  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000124, Accuracy_2: 90.8% Loss_2: 0.001173  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000123, Accuracy_2: 90.8% Loss_2: 0.001474  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000321, Accuracy_2: 90.1% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000001, Accuracy_2: 85.1% Loss_2: 0.000359  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.001367  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000148, Accuracy_2: 92.2% Loss_2: 0.006089  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000488, Accuracy_2: 90.8% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000007, Accuracy_2: 87.9% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000884, Accuracy_2: 91.5% Loss_2: 0.001055  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001960, Accuracy_2: 90.8% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000265  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001898, Accuracy_2: 93.6% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000443, Accuracy_2: 92.9% Loss_2: 0.001083  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000252, Accuracy_2: 92.2% Loss_2: 0.001499  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.000221  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000670, Accuracy_2: 90.1% Loss_2: 0.000348  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000017, Accuracy_2: 89.4% Loss_2: 0.002541  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001541, Accuracy_2: 87.2% Loss_2: 0.000007  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000957, Accuracy_2: 92.9% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002683, Accuracy_2: 88.7% Loss_2: 0.000002  [ 3525/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000012, Accuracy_2: 86.5% Loss_2: 0.000029  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001038  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000002  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000992, Accuracy_2: 92.9% Loss_2: 0.000008  [ 5781/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000107, Accuracy_2: 95.7% Loss_2: 0.000013  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000013, Accuracy_2: 86.5% Loss_2: 0.000407  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001770, Accuracy_2: 90.8% Loss_2: 0.000003  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002642, Accuracy_2: 89.4% Loss_2: 0.003253  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000004, Accuracy_2: 94.3% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000058, Accuracy_2: 90.8% Loss_2: 0.000036  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000149  [10293/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000441  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000219, Accuracy_2: 92.2% Loss_2: 0.000028  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000382  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000778, Accuracy_2: 91.5% Loss_2: 0.001423  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000057, Accuracy_2: 91.5% Loss_2: 0.000001  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000004  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000005, Accuracy_2: 83.7% Loss_2: 0.001183  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000079, Accuracy_2: 88.7% Loss_2: 0.000642  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000199  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001892, Accuracy_2: 89.4% Loss_2: 0.000328  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000361  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001968, Accuracy_2: 91.5% Loss_2: 0.000081  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000022  [ 4089/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001273, Accuracy_2: 93.6% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003395, Accuracy_2: 92.2% Loss_2: 0.005947  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001694, Accuracy_2: 86.5% Loss_2: 0.001032  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000006, Accuracy_2: 92.2% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000013, Accuracy_2: 92.2% Loss_2: 0.000008  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000054, Accuracy_2: 87.9% Loss_2: 0.001125  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.001243  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.004368, Accuracy_2: 92.2% Loss_2: 0.000031  [ 9165/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000281, Accuracy_2: 86.5% Loss_2: 0.000001  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000022, Accuracy_2: 90.8% Loss_2: 0.000865  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002035, Accuracy_2: 90.8% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000001  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000160, Accuracy_2: 90.8% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.004259, Accuracy_2: 96.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002902, Accuracy_2: 92.9% Loss_2: 0.000011  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001012, Accuracy_2: 91.5% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000838  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000326, Accuracy_2: 92.9% Loss_2: 0.001826  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000558, Accuracy_2: 87.2% Loss_2: 0.000094  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002576, Accuracy_2: 94.3% Loss_2: 0.000010  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001621, Accuracy_2: 91.5% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000008, Accuracy_2: 86.5% Loss_2: 0.000397  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.002735  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003568, Accuracy_2: 92.9% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000093, Accuracy_2: 93.6% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000033, Accuracy_2: 87.2% Loss_2: 0.001793  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000003, Accuracy_2: 93.6% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001592, Accuracy_2: 90.8% Loss_2: 0.000119  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002108  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000059, Accuracy_2: 89.4% Loss_2: 0.000002  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000388  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000031  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001255, Accuracy_2: 89.4% Loss_2: 0.006204  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001546, Accuracy_2: 88.7% Loss_2: 0.001971  [11985/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002132, Accuracy_2: 92.2% Loss_2: 0.000005  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000585, Accuracy_2: 90.1% Loss_2: 0.000178  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000003, Accuracy_2: 85.8% Loss_2: 0.002102  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000347  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000041, Accuracy_2: 92.2% Loss_2: 0.000002  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000009, Accuracy_2: 93.6% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000111, Accuracy_2: 91.5% Loss_2: 0.000002  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000005, Accuracy_2: 92.9% Loss_2: 0.000607  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001092, Accuracy_2: 89.4% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.001787  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000129, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.002599  [ 4653/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001750, Accuracy_2: 85.8% Loss_2: 0.000749  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001365, Accuracy_2: 92.2% Loss_2: 0.000759  [ 5781/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000064  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001741, Accuracy_2: 90.1% Loss_2: 0.000078  [ 7473/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.001150  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.003888, Accuracy_2: 88.7% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003018, Accuracy_2: 91.5% Loss_2: 0.000013  [10293/15250]\n",
      "Accuracy_1: 97.2%, Loss_1: 0.000000, Accuracy_2: 96.5% Loss_2: 0.000134  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000001  [11421/15250]\n",
      "Accuracy_1: 97.9%, Loss_1: 0.000063, Accuracy_2: 98.6% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000040, Accuracy_2: 90.8% Loss_2: 0.000636  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000542, Accuracy_2: 92.2% Loss_2: 0.000044  [13113/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000007, Accuracy_2: 93.6% Loss_2: 0.000183  [13677/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000307, Accuracy_2: 87.9% Loss_2: 0.000773  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001545, Accuracy_2: 89.4% Loss_2: 0.003307  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002029, Accuracy_2: 91.5% Loss_2: 0.001740  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000003, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001751, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001276  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001204, Accuracy_2: 90.8% Loss_2: 0.000014  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.005322, Accuracy_2: 89.4% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000143  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000557, Accuracy_2: 91.5% Loss_2: 0.000001  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000001, Accuracy_2: 86.5% Loss_2: 0.000009  [ 5781/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001393, Accuracy_2: 86.5% Loss_2: 0.000110  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000398, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000035, Accuracy_2: 92.9% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000004, Accuracy_2: 90.1% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000040  [ 8601/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000063, Accuracy_2: 84.4% Loss_2: 0.000136  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001167, Accuracy_2: 88.7% Loss_2: 0.001061  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000005  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.004094  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000003, Accuracy_2: 88.7% Loss_2: 0.001795  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.003246  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000660, Accuracy_2: 91.5% Loss_2: 0.000012  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001421, Accuracy_2: 86.5% Loss_2: 0.001216  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000009, Accuracy_2: 90.8% Loss_2: 0.001507  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000014, Accuracy_2: 87.9% Loss_2: 0.001573  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000869  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000115, Accuracy_2: 94.3% Loss_2: 0.000255  [  705/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.002504  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000067, Accuracy_2: 90.1% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000868  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000469  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000024, Accuracy_2: 90.8% Loss_2: 0.000120  [ 3525/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000424, Accuracy_2: 93.6% Loss_2: 0.000484  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000637, Accuracy_2: 87.2% Loss_2: 0.000017  [ 4653/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.003811, Accuracy_2: 86.5% Loss_2: 0.000662  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000475, Accuracy_2: 90.8% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000023, Accuracy_2: 88.7% Loss_2: 0.000390  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001765, Accuracy_2: 89.4% Loss_2: 0.000076  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.000620  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001524, Accuracy_2: 92.2% Loss_2: 0.000710  [ 8037/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000735, Accuracy_2: 83.7% Loss_2: 0.003158  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.004216, Accuracy_2: 87.9% Loss_2: 0.000002  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003297, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.002521, Accuracy_2: 94.3% Loss_2: 0.000654  [10293/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.001269, Accuracy_2: 93.6% Loss_2: 0.003331  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000025, Accuracy_2: 89.4% Loss_2: 0.000063  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001112, Accuracy_2: 90.1% Loss_2: 0.001355  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000029, Accuracy_2: 87.9% Loss_2: 0.002901  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001517, Accuracy_2: 92.2% Loss_2: 0.000535  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001954, Accuracy_2: 90.1% Loss_2: 0.000459  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000882, Accuracy_2: 88.7% Loss_2: 0.000003  [ 1269/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001153, Accuracy_2: 87.2% Loss_2: 0.000004  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002709  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001143, Accuracy_2: 86.5% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.001133, Accuracy_2: 95.0% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000002, Accuracy_2: 91.5% Loss_2: 0.003919  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000006, Accuracy_2: 89.4% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.001632  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002820, Accuracy_2: 91.5% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002715, Accuracy_2: 91.5% Loss_2: 0.001267  [ 8037/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000429  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000991, Accuracy_2: 90.1% Loss_2: 0.000188  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000058, Accuracy_2: 92.2% Loss_2: 0.001209  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001570, Accuracy_2: 87.9% Loss_2: 0.001087  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000026, Accuracy_2: 88.7% Loss_2: 0.000785  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001504, Accuracy_2: 91.5% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000080  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000811, Accuracy_2: 86.5% Loss_2: 0.000281  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000304, Accuracy_2: 89.4% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001118, Accuracy_2: 89.4% Loss_2: 0.000473  [13677/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000007, Accuracy_2: 95.7% Loss_2: 0.000042  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000578  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000031, Accuracy_2: 95.7% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000414  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001687, Accuracy_2: 90.1% Loss_2: 0.000229  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001736, Accuracy_2: 92.9% Loss_2: 0.000036  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000411, Accuracy_2: 90.1% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001292, Accuracy_2: 91.5% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000118  [ 4089/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000016, Accuracy_2: 95.0% Loss_2: 0.004614  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001115, Accuracy_2: 90.8% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000821, Accuracy_2: 93.6% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000742  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000011  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000010, Accuracy_2: 91.5% Loss_2: 0.000092  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001777, Accuracy_2: 93.6% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000483, Accuracy_2: 89.4% Loss_2: 0.000075  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000032, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000198, Accuracy_2: 90.1% Loss_2: 0.000006  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000523  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000845, Accuracy_2: 88.7% Loss_2: 0.000615  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001425, Accuracy_2: 92.9% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001338, Accuracy_2: 93.6% Loss_2: 0.001553  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000099  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000690, Accuracy_2: 92.2% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000259, Accuracy_2: 93.6% Loss_2: 0.000234  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001310, Accuracy_2: 90.1% Loss_2: 0.000834  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000041, Accuracy_2: 93.6% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000128, Accuracy_2: 93.6% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000685, Accuracy_2: 85.8% Loss_2: 0.000652  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000128, Accuracy_2: 88.7% Loss_2: 0.001020  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000488, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000496, Accuracy_2: 88.7% Loss_2: 0.000689  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000222, Accuracy_2: 91.5% Loss_2: 0.000946  [ 5217/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000146, Accuracy_2: 95.0% Loss_2: 0.000001  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000022, Accuracy_2: 88.7% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000001, Accuracy_2: 95.0% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000013, Accuracy_2: 90.1% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002513, Accuracy_2: 89.4% Loss_2: 0.006178  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000863, Accuracy_2: 90.8% Loss_2: 0.000046  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000001, Accuracy_2: 95.7% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003498, Accuracy_2: 91.5% Loss_2: 0.000041  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000005, Accuracy_2: 92.9% Loss_2: 0.000274  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000017, Accuracy_2: 88.7% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000538, Accuracy_2: 90.8% Loss_2: 0.002127  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000006  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000291, Accuracy_2: 92.9% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003012, Accuracy_2: 89.4% Loss_2: 0.000128  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.003119, Accuracy_2: 95.0% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001544, Accuracy_2: 90.1% Loss_2: 0.001008  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000285, Accuracy_2: 87.2% Loss_2: 0.002125  [  705/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000007, Accuracy_2: 95.7% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001928, Accuracy_2: 90.8% Loss_2: 0.001518  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000873, Accuracy_2: 92.2% Loss_2: 0.001856  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000438, Accuracy_2: 87.2% Loss_2: 0.002637  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000001  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000158, Accuracy_2: 87.2% Loss_2: 0.001079  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.003546  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000357, Accuracy_2: 90.1% Loss_2: 0.000279  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000625, Accuracy_2: 87.2% Loss_2: 0.000433  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001372, Accuracy_2: 88.7% Loss_2: 0.001153  [ 7473/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000001, Accuracy_2: 95.7% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001075, Accuracy_2: 90.1% Loss_2: 0.001123  [ 8601/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000173, Accuracy_2: 97.2% Loss_2: 0.000010  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001225, Accuracy_2: 89.4% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000928  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000184, Accuracy_2: 87.9% Loss_2: 0.000889  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000084, Accuracy_2: 89.4% Loss_2: 0.000816  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000014  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000050, Accuracy_2: 90.1% Loss_2: 0.001108  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000015  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000490, Accuracy_2: 93.6% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.003721  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.5%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000044, Accuracy_2: 91.5% Loss_2: 0.000005  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000841, Accuracy_2: 90.8% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001100, Accuracy_2: 92.9% Loss_2: 0.001156  [ 1269/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.003356  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000998, Accuracy_2: 89.4% Loss_2: 0.000118  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000009, Accuracy_2: 87.9% Loss_2: 0.000189  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000053, Accuracy_2: 92.9% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001928, Accuracy_2: 95.0% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000384, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001527, Accuracy_2: 90.8% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000001, Accuracy_2: 80.9% Loss_2: 0.001687  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000277, Accuracy_2: 90.8% Loss_2: 0.000018  [ 6909/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000059, Accuracy_2: 87.9% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002693, Accuracy_2: 88.7% Loss_2: 0.001177  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003413, Accuracy_2: 90.1% Loss_2: 0.001674  [ 8601/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000009, Accuracy_2: 94.3% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000009, Accuracy_2: 91.5% Loss_2: 0.000006  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001758, Accuracy_2: 93.6% Loss_2: 0.000754  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000350, Accuracy_2: 87.9% Loss_2: 0.000894  [10857/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000000, Accuracy_2: 96.5% Loss_2: 0.000705  [11421/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000006, Accuracy_2: 91.5% Loss_2: 0.000032  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001043  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000593  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 92.2% Loss_2: 0.000045  [14241/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000032, Accuracy_2: 95.7% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000172  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000083, Accuracy_2: 93.6% Loss_2: 0.002183  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000005, Accuracy_2: 89.4% Loss_2: 0.000037  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000573  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000406  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000016, Accuracy_2: 88.7% Loss_2: 0.000630  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000010, Accuracy_2: 87.9% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000110, Accuracy_2: 89.4% Loss_2: 0.000507  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000630, Accuracy_2: 92.2% Loss_2: 0.000001  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000388, Accuracy_2: 89.4% Loss_2: 0.000081  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000118, Accuracy_2: 92.2% Loss_2: 0.001258  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000526, Accuracy_2: 92.2% Loss_2: 0.000001  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000085  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000685, Accuracy_2: 89.4% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000003  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000362, Accuracy_2: 88.7% Loss_2: 0.000232  [ 9165/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.003744  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000306  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000077, Accuracy_2: 92.2% Loss_2: 0.000014  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000012, Accuracy_2: 90.8% Loss_2: 0.000097  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000010, Accuracy_2: 90.8% Loss_2: 0.000009  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000005  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 92.2% Loss_2: 0.000127  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000005, Accuracy_2: 92.2% Loss_2: 0.000004  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001809, Accuracy_2: 89.4% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000027, Accuracy_2: 93.6% Loss_2: 0.000045  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000014, Accuracy_2: 91.5% Loss_2: 0.000010  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002874, Accuracy_2: 89.4% Loss_2: 0.000586  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002758, Accuracy_2: 90.1% Loss_2: 0.005665  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000031  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000005, Accuracy_2: 90.1% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000069, Accuracy_2: 91.5% Loss_2: 0.001436  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000002, Accuracy_2: 87.9% Loss_2: 0.000115  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000085, Accuracy_2: 89.4% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000723, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000037, Accuracy_2: 88.7% Loss_2: 0.000516  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003050, Accuracy_2: 92.9% Loss_2: 0.000001  [ 5781/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 94.3% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003247, Accuracy_2: 92.2% Loss_2: 0.000003  [ 7473/15250]\n",
      "Accuracy_1: 97.2%, Loss_1: 0.000003, Accuracy_2: 96.5% Loss_2: 0.002501  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002640, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000872, Accuracy_2: 92.9% Loss_2: 0.000920  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001797, Accuracy_2: 91.5% Loss_2: 0.001338  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000041, Accuracy_2: 91.5% Loss_2: 0.000003  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003821, Accuracy_2: 87.9% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 90.1% Loss_2: 0.000431  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000909, Accuracy_2: 87.2% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001441, Accuracy_2: 85.1% Loss_2: 0.000419  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000202, Accuracy_2: 94.3% Loss_2: 0.000258  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001738  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000929  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001043, Accuracy_2: 90.8% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000016, Accuracy_2: 93.6% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.001033  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000002  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000112, Accuracy_2: 92.2% Loss_2: 0.000010  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000416, Accuracy_2: 90.1% Loss_2: 0.000006  [ 2961/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.001286  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000007  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000009  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001621, Accuracy_2: 90.8% Loss_2: 0.000515  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000014, Accuracy_2: 92.9% Loss_2: 0.000481  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000715, Accuracy_2: 90.1% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000195  [ 8601/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002520, Accuracy_2: 90.1% Loss_2: 0.001629  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.004457, Accuracy_2: 92.9% Loss_2: 0.000011  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002641, Accuracy_2: 89.4% Loss_2: 0.000685  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000001  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000133, Accuracy_2: 92.9% Loss_2: 0.000926  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001162, Accuracy_2: 93.6% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000630, Accuracy_2: 89.4% Loss_2: 0.000673  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000418, Accuracy_2: 87.9% Loss_2: 0.000364  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000007, Accuracy_2: 87.2% Loss_2: 0.000437  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.4%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000271, Accuracy_2: 87.9% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000230  [  705/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000861, Accuracy_2: 96.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000181, Accuracy_2: 87.9% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001500, Accuracy_2: 95.0% Loss_2: 0.000002  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000826  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000103, Accuracy_2: 89.4% Loss_2: 0.000001  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001199, Accuracy_2: 90.8% Loss_2: 0.001722  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000015, Accuracy_2: 90.1% Loss_2: 0.000220  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000844, Accuracy_2: 90.8% Loss_2: 0.004936  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000179, Accuracy_2: 87.2% Loss_2: 0.001167  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.003975  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000782  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000578, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000062, Accuracy_2: 91.5% Loss_2: 0.000507  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000929  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000065, Accuracy_2: 89.4% Loss_2: 0.001227  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003770, Accuracy_2: 94.3% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000120, Accuracy_2: 96.5% Loss_2: 0.000390  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000379, Accuracy_2: 91.5% Loss_2: 0.003608  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002158  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000035  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.002652  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.1%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000438  [  141/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.001303, Accuracy_2: 96.5% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000657, Accuracy_2: 87.9% Loss_2: 0.003851  [ 1269/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000452, Accuracy_2: 85.1% Loss_2: 0.000692  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002207, Accuracy_2: 89.4% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002563, Accuracy_2: 91.5% Loss_2: 0.000184  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000090, Accuracy_2: 91.5% Loss_2: 0.000019  [ 3525/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000009, Accuracy_2: 90.8% Loss_2: 0.003774  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001066, Accuracy_2: 89.4% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000006, Accuracy_2: 92.9% Loss_2: 0.001361  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000668, Accuracy_2: 90.1% Loss_2: 0.000682  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001103  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000109, Accuracy_2: 89.4% Loss_2: 0.000507  [ 6909/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002063, Accuracy_2: 85.1% Loss_2: 0.002393  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000694  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001688  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001162, Accuracy_2: 88.7% Loss_2: 0.001340  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002212, Accuracy_2: 93.6% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001999, Accuracy_2: 92.9% Loss_2: 0.001073  [10857/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000002, Accuracy_2: 94.3% Loss_2: 0.005026  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000234, Accuracy_2: 86.5% Loss_2: 0.001263  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000472  [12549/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000483, Accuracy_2: 86.5% Loss_2: 0.000056  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001107  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.004714, Accuracy_2: 94.3% Loss_2: 0.000001  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000004, Accuracy_2: 87.2% Loss_2: 0.000452  [  141/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.003360, Accuracy_2: 97.2% Loss_2: 0.000809  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000286, Accuracy_2: 90.8% Loss_2: 0.000452  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000008  [ 2397/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.001056, Accuracy_2: 95.7% Loss_2: 0.000027  [ 2961/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000000, Accuracy_2: 84.4% Loss_2: 0.002042  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000012, Accuracy_2: 90.1% Loss_2: 0.000809  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000328, Accuracy_2: 90.8% Loss_2: 0.000001  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000357, Accuracy_2: 92.9% Loss_2: 0.001044  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001680, Accuracy_2: 88.7% Loss_2: 0.000087  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003980, Accuracy_2: 90.8% Loss_2: 0.000011  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000476, Accuracy_2: 93.6% Loss_2: 0.001839  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000018, Accuracy_2: 89.4% Loss_2: 0.000003  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000322, Accuracy_2: 87.2% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000703, Accuracy_2: 92.2% Loss_2: 0.000684  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000960, Accuracy_2: 90.1% Loss_2: 0.001368  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000499, Accuracy_2: 91.5% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001227, Accuracy_2: 92.9% Loss_2: 0.000048  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002461, Accuracy_2: 90.1% Loss_2: 0.001947  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000122  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000048, Accuracy_2: 88.7% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000970, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000021  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001543, Accuracy_2: 92.2% Loss_2: 0.000073  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000354  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000323, Accuracy_2: 89.4% Loss_2: 0.002727  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000003  [ 1269/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000163, Accuracy_2: 96.5% Loss_2: 0.000004  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001415  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003446, Accuracy_2: 90.8% Loss_2: 0.000471  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000020, Accuracy_2: 93.6% Loss_2: 0.000008  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000157, Accuracy_2: 85.1% Loss_2: 0.001588  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002391, Accuracy_2: 87.9% Loss_2: 0.002268  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000965  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001303, Accuracy_2: 87.2% Loss_2: 0.000001  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.005231, Accuracy_2: 91.5% Loss_2: 0.000008  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000319, Accuracy_2: 87.9% Loss_2: 0.000745  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000003, Accuracy_2: 89.4% Loss_2: 0.002104  [ 8037/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000001, Accuracy_2: 95.0% Loss_2: 0.000004  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001913, Accuracy_2: 90.8% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002061, Accuracy_2: 92.2% Loss_2: 0.001744  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001292  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000968, Accuracy_2: 90.1% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.008015, Accuracy_2: 89.4% Loss_2: 0.000653  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000782, Accuracy_2: 89.4% Loss_2: 0.003584  [11985/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.001045  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000170  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.000607  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000875, Accuracy_2: 92.9% Loss_2: 0.002231  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000004, Accuracy_2: 93.6% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000875  [  141/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.002351, Accuracy_2: 94.3% Loss_2: 0.000269  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000233, Accuracy_2: 86.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.002835  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002751, Accuracy_2: 92.2% Loss_2: 0.000047  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000087  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000048, Accuracy_2: 90.8% Loss_2: 0.000622  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000007, Accuracy_2: 90.8% Loss_2: 0.002051  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000915, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.000003  [ 5217/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000065, Accuracy_2: 87.2% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000471, Accuracy_2: 88.7% Loss_2: 0.002542  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000485, Accuracy_2: 88.7% Loss_2: 0.005080  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000063  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000001  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000497, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000002  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000164  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000026  [10293/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000031, Accuracy_2: 92.2% Loss_2: 0.001016  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001364  [11421/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000671  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001263, Accuracy_2: 92.2% Loss_2: 0.000835  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000367  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000107, Accuracy_2: 90.1% Loss_2: 0.000171  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000481, Accuracy_2: 94.3% Loss_2: 0.000003  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000480, Accuracy_2: 90.1% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000621, Accuracy_2: 89.4% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001073, Accuracy_2: 92.2% Loss_2: 0.001373  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000167, Accuracy_2: 88.7% Loss_2: 0.000028  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001566, Accuracy_2: 92.2% Loss_2: 0.000086  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000174, Accuracy_2: 91.5% Loss_2: 0.001246  [ 4653/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000002, Accuracy_2: 86.5% Loss_2: 0.000420  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000911, Accuracy_2: 91.5% Loss_2: 0.000980  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.001345  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001096, Accuracy_2: 92.2% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001766, Accuracy_2: 89.4% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001945, Accuracy_2: 90.1% Loss_2: 0.000138  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001187, Accuracy_2: 90.8% Loss_2: 0.000703  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000242, Accuracy_2: 92.2% Loss_2: 0.000825  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001694, Accuracy_2: 94.3% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000569, Accuracy_2: 90.1% Loss_2: 0.000259  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.001372  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000879, Accuracy_2: 87.9% Loss_2: 0.000835  [13677/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.000000, Accuracy_2: 81.6% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000132  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000349, Accuracy_2: 88.7% Loss_2: 0.000006  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000155, Accuracy_2: 92.2% Loss_2: 0.000007  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001700, Accuracy_2: 90.8% Loss_2: 0.002539  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000013, Accuracy_2: 88.7% Loss_2: 0.000279  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000557, Accuracy_2: 94.3% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000609, Accuracy_2: 90.1% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.004956  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000214, Accuracy_2: 93.6% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001448  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000984, Accuracy_2: 90.1% Loss_2: 0.000440  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000929, Accuracy_2: 91.5% Loss_2: 0.001448  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001086, Accuracy_2: 88.7% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000276, Accuracy_2: 93.6% Loss_2: 0.000002  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000855, Accuracy_2: 90.1% Loss_2: 0.003616  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.007786, Accuracy_2: 92.9% Loss_2: 0.001354  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000071  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000024, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000079, Accuracy_2: 93.6% Loss_2: 0.000380  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000269, Accuracy_2: 91.5% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000037  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000658, Accuracy_2: 90.8% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000111, Accuracy_2: 87.9% Loss_2: 0.000156  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000979  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000998, Accuracy_2: 91.5% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000003, Accuracy_2: 90.1% Loss_2: 0.000013  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000332, Accuracy_2: 95.7% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000034, Accuracy_2: 92.9% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.004811  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000032, Accuracy_2: 91.5% Loss_2: 0.000142  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000002  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000002  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000178, Accuracy_2: 87.9% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.001865  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.000033  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 90.1% Loss_2: 0.001553  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000027, Accuracy_2: 91.5% Loss_2: 0.002288  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000204, Accuracy_2: 89.4% Loss_2: 0.000045  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000177  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000010, Accuracy_2: 90.1% Loss_2: 0.004207  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000488, Accuracy_2: 92.2% Loss_2: 0.000156  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001060, Accuracy_2: 88.7% Loss_2: 0.000003  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002826, Accuracy_2: 90.1% Loss_2: 0.000098  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.002987  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000415, Accuracy_2: 92.2% Loss_2: 0.000005  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000765, Accuracy_2: 90.8% Loss_2: 0.004044  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000875  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001333, Accuracy_2: 89.4% Loss_2: 0.001343  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000054  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000104, Accuracy_2: 91.5% Loss_2: 0.000058  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002173, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000003, Accuracy_2: 92.9% Loss_2: 0.002291  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001213, Accuracy_2: 87.2% Loss_2: 0.000231  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000619, Accuracy_2: 90.1% Loss_2: 0.000001  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000361, Accuracy_2: 90.1% Loss_2: 0.003096  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000988  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.000091  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000194, Accuracy_2: 89.4% Loss_2: 0.002263  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000377, Accuracy_2: 90.1% Loss_2: 0.000424  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000815, Accuracy_2: 94.3% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000015, Accuracy_2: 90.8% Loss_2: 0.000091  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000703, Accuracy_2: 89.4% Loss_2: 0.000010  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000026, Accuracy_2: 87.9% Loss_2: 0.000919  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001753, Accuracy_2: 89.4% Loss_2: 0.000826  [ 9729/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000000, Accuracy_2: 83.7% Loss_2: 0.000471  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002725, Accuracy_2: 95.0% Loss_2: 0.000118  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002633, Accuracy_2: 88.7% Loss_2: 0.000382  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000054, Accuracy_2: 92.2% Loss_2: 0.000062  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000031, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000229, Accuracy_2: 90.8% Loss_2: 0.000132  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000644, Accuracy_2: 90.1% Loss_2: 0.000003  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.2%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000047, Accuracy_2: 89.4% Loss_2: 0.000001  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000169, Accuracy_2: 91.5% Loss_2: 0.000473  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002054  [ 1269/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001555, Accuracy_2: 86.5% Loss_2: 0.000055  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000001  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000881, Accuracy_2: 90.8% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000794, Accuracy_2: 90.1% Loss_2: 0.000086  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000674  [ 4653/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.001611  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002091, Accuracy_2: 85.1% Loss_2: 0.003893  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001943, Accuracy_2: 93.6% Loss_2: 0.000002  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000362, Accuracy_2: 87.2% Loss_2: 0.002120  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.004412, Accuracy_2: 91.5% Loss_2: 0.000004  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001291, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000053, Accuracy_2: 90.8% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000173, Accuracy_2: 91.5% Loss_2: 0.000880  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000228, Accuracy_2: 88.7% Loss_2: 0.002644  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000005  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000025, Accuracy_2: 88.7% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000464, Accuracy_2: 89.4% Loss_2: 0.000668  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000110, Accuracy_2: 90.8% Loss_2: 0.003075  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000027, Accuracy_2: 85.1% Loss_2: 0.002446  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000002  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.001504  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000008, Accuracy_2: 90.1% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.1%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001204, Accuracy_2: 91.5% Loss_2: 0.000697  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.005147, Accuracy_2: 87.2% Loss_2: 0.000557  [  705/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000005, Accuracy_2: 94.3% Loss_2: 0.000020  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000676, Accuracy_2: 93.6% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000008, Accuracy_2: 93.6% Loss_2: 0.000413  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000077  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.002836, Accuracy_2: 86.5% Loss_2: 0.001276  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000047, Accuracy_2: 88.7% Loss_2: 0.000847  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000030  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000221  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000042  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001879, Accuracy_2: 88.7% Loss_2: 0.000003  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000561  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000302, Accuracy_2: 90.8% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001267, Accuracy_2: 89.4% Loss_2: 0.000001  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000040, Accuracy_2: 91.5% Loss_2: 0.000626  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001587  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000026  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000298  [11985/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000084, Accuracy_2: 95.0% Loss_2: 0.002560  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002431  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000320, Accuracy_2: 87.9% Loss_2: 0.001709  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000206, Accuracy_2: 92.2% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.002379  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000028  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000094, Accuracy_2: 89.4% Loss_2: 0.001781  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000012  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000478, Accuracy_2: 90.1% Loss_2: 0.000028  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.001095  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000219  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000739  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000234, Accuracy_2: 92.2% Loss_2: 0.001062  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000075, Accuracy_2: 91.5% Loss_2: 0.000408  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000130, Accuracy_2: 89.4% Loss_2: 0.002817  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000172  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000062  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000317, Accuracy_2: 92.2% Loss_2: 0.000104  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001889, Accuracy_2: 93.6% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000212, Accuracy_2: 93.6% Loss_2: 0.000008  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000050  [10293/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000044  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000002, Accuracy_2: 92.9% Loss_2: 0.002813  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000674  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 91.5% Loss_2: 0.000309  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000083  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000014, Accuracy_2: 90.1% Loss_2: 0.000087  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000877, Accuracy_2: 91.5% Loss_2: 0.001285  [  141/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002389, Accuracy_2: 92.9% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000001  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000062, Accuracy_2: 90.8% Loss_2: 0.000057  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.001144  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001541, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002346, Accuracy_2: 87.9% Loss_2: 0.001563  [ 3525/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.002779  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001008, Accuracy_2: 87.9% Loss_2: 0.000100  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000175  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000069, Accuracy_2: 88.7% Loss_2: 0.001628  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002486, Accuracy_2: 91.5% Loss_2: 0.000162  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000033, Accuracy_2: 92.2% Loss_2: 0.000033  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000039, Accuracy_2: 92.9% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 86.5% Loss_2: 0.000900  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001066, Accuracy_2: 87.9% Loss_2: 0.002082  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.000155  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002213, Accuracy_2: 94.3% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000280, Accuracy_2: 92.2% Loss_2: 0.000122  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000127  [11421/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000005, Accuracy_2: 94.3% Loss_2: 0.000232  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.005220, Accuracy_2: 92.2% Loss_2: 0.000100  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001357, Accuracy_2: 90.1% Loss_2: 0.000341  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000072  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000542, Accuracy_2: 92.2% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.2%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000797, Accuracy_2: 85.8% Loss_2: 0.001716  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000021, Accuracy_2: 87.9% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000524, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000390, Accuracy_2: 93.6% Loss_2: 0.000980  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000098, Accuracy_2: 90.1% Loss_2: 0.000002  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001100, Accuracy_2: 87.9% Loss_2: 0.000419  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000034, Accuracy_2: 90.8% Loss_2: 0.001384  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001112  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000006, Accuracy_2: 88.7% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000554, Accuracy_2: 86.5% Loss_2: 0.003387  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000485, Accuracy_2: 87.2% Loss_2: 0.000001  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002966, Accuracy_2: 90.8% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000053, Accuracy_2: 92.2% Loss_2: 0.001055  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001341, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000327, Accuracy_2: 90.8% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000010, Accuracy_2: 91.5% Loss_2: 0.000280  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000200, Accuracy_2: 93.6% Loss_2: 0.000002  [ 9729/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000042, Accuracy_2: 87.2% Loss_2: 0.001692  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000784, Accuracy_2: 92.9% Loss_2: 0.001380  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000614, Accuracy_2: 87.2% Loss_2: 0.001071  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000031, Accuracy_2: 89.4% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001002, Accuracy_2: 90.1% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000065  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000327, Accuracy_2: 92.9% Loss_2: 0.000479  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000155, Accuracy_2: 92.2% Loss_2: 0.000969  [  141/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000437, Accuracy_2: 95.7% Loss_2: 0.000039  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000012, Accuracy_2: 92.9% Loss_2: 0.000556  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000008  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000026, Accuracy_2: 89.4% Loss_2: 0.000154  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000010, Accuracy_2: 91.5% Loss_2: 0.000747  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000035  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.004762, Accuracy_2: 87.9% Loss_2: 0.000083  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002500, Accuracy_2: 86.5% Loss_2: 0.000579  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001093, Accuracy_2: 92.9% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000141  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000286, Accuracy_2: 92.9% Loss_2: 0.000184  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000289, Accuracy_2: 89.4% Loss_2: 0.001191  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000553, Accuracy_2: 91.5% Loss_2: 0.000947  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002559, Accuracy_2: 92.9% Loss_2: 0.001148  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000027, Accuracy_2: 86.5% Loss_2: 0.000096  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000511, Accuracy_2: 90.1% Loss_2: 0.001920  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000863  [ 9729/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.001279, Accuracy_2: 82.3% Loss_2: 0.000291  [10293/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000004, Accuracy_2: 94.3% Loss_2: 0.000458  [10857/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000709, Accuracy_2: 83.7% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000029, Accuracy_2: 95.0% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000001, Accuracy_2: 94.3% Loss_2: 0.000210  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000006, Accuracy_2: 92.2% Loss_2: 0.000004  [13113/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001119, Accuracy_2: 92.9% Loss_2: 0.000086  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000006  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003785, Accuracy_2: 89.4% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.003182  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000005, Accuracy_2: 91.5% Loss_2: 0.000003  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.005826, Accuracy_2: 87.9% Loss_2: 0.001728  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000063  [ 1833/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.001700  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000819, Accuracy_2: 88.7% Loss_2: 0.000506  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000897, Accuracy_2: 88.7% Loss_2: 0.002357  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000103, Accuracy_2: 93.6% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.008380, Accuracy_2: 95.0% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000195, Accuracy_2: 89.4% Loss_2: 0.000002  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000840, Accuracy_2: 88.7% Loss_2: 0.000455  [ 5781/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000292, Accuracy_2: 85.8% Loss_2: 0.000322  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000005  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.003263  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000371, Accuracy_2: 92.2% Loss_2: 0.000061  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002127, Accuracy_2: 87.9% Loss_2: 0.001577  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000292, Accuracy_2: 91.5% Loss_2: 0.000157  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.004793, Accuracy_2: 90.1% Loss_2: 0.001298  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000384, Accuracy_2: 91.5% Loss_2: 0.000002  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000135, Accuracy_2: 92.2% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000748, Accuracy_2: 92.2% Loss_2: 0.000033  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000004, Accuracy_2: 90.8% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000520, Accuracy_2: 83.0% Loss_2: 0.002375  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000521, Accuracy_2: 93.6% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000081, Accuracy_2: 92.2% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.003016, Accuracy_2: 96.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001692, Accuracy_2: 95.0% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003602, Accuracy_2: 93.6% Loss_2: 0.000133  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003037, Accuracy_2: 91.5% Loss_2: 0.002856  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000633, Accuracy_2: 89.4% Loss_2: 0.000244  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.003340  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000127, Accuracy_2: 90.1% Loss_2: 0.000328  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001036, Accuracy_2: 92.9% Loss_2: 0.000002  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000261, Accuracy_2: 87.9% Loss_2: 0.002664  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000278, Accuracy_2: 90.8% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000003, Accuracy_2: 93.6% Loss_2: 0.000670  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000137  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000031, Accuracy_2: 88.7% Loss_2: 0.002146  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001353, Accuracy_2: 91.5% Loss_2: 0.000496  [10293/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000336  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000019, Accuracy_2: 89.4% Loss_2: 0.001495  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000450, Accuracy_2: 90.8% Loss_2: 0.001599  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000576  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000031  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001163, Accuracy_2: 89.4% Loss_2: 0.000057  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000413, Accuracy_2: 92.9% Loss_2: 0.001143  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000007, Accuracy_2: 91.5% Loss_2: 0.000005  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.2%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001330, Accuracy_2: 92.2% Loss_2: 0.000639  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000012, Accuracy_2: 86.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000195, Accuracy_2: 91.5% Loss_2: 0.000002  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000093  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000036, Accuracy_2: 90.1% Loss_2: 0.000570  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000642, Accuracy_2: 86.5% Loss_2: 0.000082  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000225, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000154  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003170, Accuracy_2: 90.8% Loss_2: 0.000425  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000014, Accuracy_2: 92.2% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000582, Accuracy_2: 88.7% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000262, Accuracy_2: 92.2% Loss_2: 0.000016  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000416, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002277, Accuracy_2: 90.1% Loss_2: 0.000866  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000470, Accuracy_2: 89.4% Loss_2: 0.000214  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000376  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001255, Accuracy_2: 91.5% Loss_2: 0.001857  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000002  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002528, Accuracy_2: 88.7% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 94.3% Loss_2: 0.000047  [11985/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000512, Accuracy_2: 86.5% Loss_2: 0.000028  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.004608, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000727, Accuracy_2: 91.5% Loss_2: 0.000417  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001058, Accuracy_2: 91.5% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000696, Accuracy_2: 90.8% Loss_2: 0.000001  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000001  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003591, Accuracy_2: 93.6% Loss_2: 0.000015  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000022, Accuracy_2: 90.1% Loss_2: 0.000003  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000203, Accuracy_2: 88.7% Loss_2: 0.000005  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000283, Accuracy_2: 91.5% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000032  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003737, Accuracy_2: 91.5% Loss_2: 0.000020  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001021, Accuracy_2: 90.8% Loss_2: 0.001340  [ 4653/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000003, Accuracy_2: 93.6% Loss_2: 0.000643  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000059, Accuracy_2: 94.3% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000876, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000498, Accuracy_2: 87.9% Loss_2: 0.000022  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000218, Accuracy_2: 93.6% Loss_2: 0.000354  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000033, Accuracy_2: 89.4% Loss_2: 0.000298  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000452, Accuracy_2: 92.9% Loss_2: 0.000033  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000365, Accuracy_2: 90.1% Loss_2: 0.000001  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000380, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000234, Accuracy_2: 92.9% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000288  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000852, Accuracy_2: 92.2% Loss_2: 0.000013  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000270, Accuracy_2: 89.4% Loss_2: 0.000034  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000167, Accuracy_2: 93.6% Loss_2: 0.000145  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000491, Accuracy_2: 87.2% Loss_2: 0.000062  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000224, Accuracy_2: 92.2% Loss_2: 0.000001  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.001200  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000013, Accuracy_2: 87.2% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000006, Accuracy_2: 95.0% Loss_2: 0.000001  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.001151  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.005348, Accuracy_2: 88.7% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000257, Accuracy_2: 86.5% Loss_2: 0.000019  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000005, Accuracy_2: 92.9% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000010, Accuracy_2: 88.7% Loss_2: 0.000364  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000760, Accuracy_2: 90.8% Loss_2: 0.000708  [ 5781/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003754, Accuracy_2: 86.5% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000167, Accuracy_2: 90.1% Loss_2: 0.000185  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000002  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.003702  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000219, Accuracy_2: 92.2% Loss_2: 0.000276  [ 8601/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000444, Accuracy_2: 84.4% Loss_2: 0.007071  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000181  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000756, Accuracy_2: 94.3% Loss_2: 0.000014  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.002468  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001300, Accuracy_2: 89.4% Loss_2: 0.001053  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000039, Accuracy_2: 90.8% Loss_2: 0.000439  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000854, Accuracy_2: 90.8% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000641  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000112  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000019, Accuracy_2: 92.2% Loss_2: 0.000026  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.5%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000331  [  141/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001620  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000485, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002596, Accuracy_2: 92.9% Loss_2: 0.000310  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000986, Accuracy_2: 89.4% Loss_2: 0.000123  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000275  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000268, Accuracy_2: 89.4% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000165  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001877, Accuracy_2: 87.9% Loss_2: 0.003742  [ 5217/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000801, Accuracy_2: 94.3% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.003283, Accuracy_2: 87.2% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000075, Accuracy_2: 90.8% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001548, Accuracy_2: 90.1% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001509, Accuracy_2: 89.4% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003020, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.003824, Accuracy_2: 95.0% Loss_2: 0.000002  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000197, Accuracy_2: 93.6% Loss_2: 0.000178  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.004554, Accuracy_2: 87.9% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000157, Accuracy_2: 85.8% Loss_2: 0.002178  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001248, Accuracy_2: 89.4% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.001692  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000020, Accuracy_2: 88.7% Loss_2: 0.003631  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001991, Accuracy_2: 90.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000055, Accuracy_2: 90.8% Loss_2: 0.000005  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000153, Accuracy_2: 92.9% Loss_2: 0.000279  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000185  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002321, Accuracy_2: 93.6% Loss_2: 0.000036  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002608, Accuracy_2: 90.8% Loss_2: 0.001091  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001713, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000080, Accuracy_2: 90.8% Loss_2: 0.000331  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002370, Accuracy_2: 90.1% Loss_2: 0.000327  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002232, Accuracy_2: 90.1% Loss_2: 0.000041  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000003, Accuracy_2: 92.9% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000002  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000863, Accuracy_2: 88.7% Loss_2: 0.000236  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000624, Accuracy_2: 92.2% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000055, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000128, Accuracy_2: 92.2% Loss_2: 0.000003  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000046  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001664, Accuracy_2: 90.8% Loss_2: 0.001635  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000466, Accuracy_2: 86.5% Loss_2: 0.000017  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001063, Accuracy_2: 88.7% Loss_2: 0.000346  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000746, Accuracy_2: 92.2% Loss_2: 0.000896  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000002, Accuracy_2: 87.9% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000119  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001741, Accuracy_2: 94.3% Loss_2: 0.000016  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000092, Accuracy_2: 89.4% Loss_2: 0.000181  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000022, Accuracy_2: 83.7% Loss_2: 0.001183  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001149, Accuracy_2: 87.9% Loss_2: 0.000375  [  705/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000227  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000514, Accuracy_2: 93.6% Loss_2: 0.000005  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000485, Accuracy_2: 88.7% Loss_2: 0.000100  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000047, Accuracy_2: 90.8% Loss_2: 0.000203  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000005, Accuracy_2: 88.7% Loss_2: 0.000107  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000049, Accuracy_2: 87.2% Loss_2: 0.001116  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001540, Accuracy_2: 87.2% Loss_2: 0.001550  [ 5217/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000834, Accuracy_2: 93.6% Loss_2: 0.002635  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.003322  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000405  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000660  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000578, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000007, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000118, Accuracy_2: 87.2% Loss_2: 0.003194  [ 9729/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000000, Accuracy_2: 83.0% Loss_2: 0.000292  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000048  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000003, Accuracy_2: 87.2% Loss_2: 0.000907  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000028  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.001364  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000994, Accuracy_2: 89.4% Loss_2: 0.000107  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002559, Accuracy_2: 87.9% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001960, Accuracy_2: 94.3% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002573, Accuracy_2: 90.8% Loss_2: 0.000001  [  141/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000054, Accuracy_2: 92.2% Loss_2: 0.000872  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.004411, Accuracy_2: 90.8% Loss_2: 0.000540  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002628, Accuracy_2: 92.9% Loss_2: 0.000455  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000008, Accuracy_2: 90.8% Loss_2: 0.000002  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001003, Accuracy_2: 90.8% Loss_2: 0.000718  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001058  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001477, Accuracy_2: 88.7% Loss_2: 0.000547  [ 4089/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000136  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000024  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000568, Accuracy_2: 92.9% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000185, Accuracy_2: 87.9% Loss_2: 0.000143  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000242, Accuracy_2: 90.1% Loss_2: 0.000001  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000241, Accuracy_2: 85.1% Loss_2: 0.001888  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000128, Accuracy_2: 95.0% Loss_2: 0.000024  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000002  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000017  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000012, Accuracy_2: 90.8% Loss_2: 0.001221  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001316, Accuracy_2: 93.6% Loss_2: 0.000001  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002021, Accuracy_2: 90.8% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000241, Accuracy_2: 85.1% Loss_2: 0.000002  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000520, Accuracy_2: 89.4% Loss_2: 0.000027  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.002156  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000001, Accuracy_2: 95.7% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002649, Accuracy_2: 92.2% Loss_2: 0.000229  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000205, Accuracy_2: 92.2% Loss_2: 0.000471  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001878, Accuracy_2: 88.7% Loss_2: 0.001320  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000005, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001640, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000089, Accuracy_2: 92.9% Loss_2: 0.000357  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002260, Accuracy_2: 91.5% Loss_2: 0.001125  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000583, Accuracy_2: 88.7% Loss_2: 0.001919  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.004630, Accuracy_2: 88.7% Loss_2: 0.000598  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000240  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000609, Accuracy_2: 88.7% Loss_2: 0.000602  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001995, Accuracy_2: 92.9% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000341, Accuracy_2: 89.4% Loss_2: 0.000021  [ 8037/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000644  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000021, Accuracy_2: 89.4% Loss_2: 0.002548  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000232  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000599, Accuracy_2: 91.5% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001839, Accuracy_2: 90.8% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.001980  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002445, Accuracy_2: 88.7% Loss_2: 0.000028  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.1%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000021, Accuracy_2: 90.8% Loss_2: 0.000862  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000583, Accuracy_2: 88.7% Loss_2: 0.004728  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000648, Accuracy_2: 92.2% Loss_2: 0.004280  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.004127, Accuracy_2: 92.9% Loss_2: 0.000393  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001656, Accuracy_2: 90.8% Loss_2: 0.000304  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000956, Accuracy_2: 93.6% Loss_2: 0.000591  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001875, Accuracy_2: 87.2% Loss_2: 0.003310  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000563, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001804, Accuracy_2: 94.3% Loss_2: 0.000019  [ 4653/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001416, Accuracy_2: 86.5% Loss_2: 0.000046  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000001  [ 5781/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000519  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000017, Accuracy_2: 92.2% Loss_2: 0.000847  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002773, Accuracy_2: 87.9% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003928, Accuracy_2: 86.5% Loss_2: 0.004880  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000335  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001395  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000328, Accuracy_2: 87.2% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000983  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000008  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001083, Accuracy_2: 90.1% Loss_2: 0.001173  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000134, Accuracy_2: 91.5% Loss_2: 0.001773  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001297, Accuracy_2: 89.4% Loss_2: 0.002416  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000460  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000001  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002645  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000054, Accuracy_2: 91.5% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000956  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001357, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001454, Accuracy_2: 88.7% Loss_2: 0.001147  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000616, Accuracy_2: 87.2% Loss_2: 0.000038  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000065, Accuracy_2: 87.9% Loss_2: 0.003507  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001498  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.003239  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000018  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000629, Accuracy_2: 89.4% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000096, Accuracy_2: 86.5% Loss_2: 0.001016  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.004247, Accuracy_2: 89.4% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000702, Accuracy_2: 90.1% Loss_2: 0.003488  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000009, Accuracy_2: 88.7% Loss_2: 0.002233  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001285, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000007, Accuracy_2: 91.5% Loss_2: 0.000001  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000287, Accuracy_2: 90.1% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000004, Accuracy_2: 90.8% Loss_2: 0.002953  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000074  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003832, Accuracy_2: 90.8% Loss_2: 0.000006  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000018, Accuracy_2: 90.1% Loss_2: 0.001274  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001252, Accuracy_2: 88.7% Loss_2: 0.000065  [13677/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000019  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000006, Accuracy_2: 87.9% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000003, Accuracy_2: 89.4% Loss_2: 0.000005  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000346, Accuracy_2: 89.4% Loss_2: 0.000039  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000127, Accuracy_2: 86.5% Loss_2: 0.000183  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000083, Accuracy_2: 92.9% Loss_2: 0.001055  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001364, Accuracy_2: 87.2% Loss_2: 0.000635  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000474, Accuracy_2: 90.8% Loss_2: 0.000001  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000039, Accuracy_2: 90.8% Loss_2: 0.000025  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000639, Accuracy_2: 87.9% Loss_2: 0.000358  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000301  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003315, Accuracy_2: 91.5% Loss_2: 0.002016  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.002401  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000009, Accuracy_2: 93.6% Loss_2: 0.000019  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 92.2% Loss_2: 0.000001  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002135, Accuracy_2: 87.2% Loss_2: 0.002834  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000267  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000267  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000306  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000222  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001781, Accuracy_2: 91.5% Loss_2: 0.000035  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.004970, Accuracy_2: 90.1% Loss_2: 0.002830  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000209, Accuracy_2: 88.7% Loss_2: 0.000275  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000162  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001077, Accuracy_2: 90.1% Loss_2: 0.000104  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000351  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000820, Accuracy_2: 91.5% Loss_2: 0.002708  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000056, Accuracy_2: 92.9% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.001199  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000817, Accuracy_2: 90.8% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001547, Accuracy_2: 92.2% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000012  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000745, Accuracy_2: 88.7% Loss_2: 0.000032  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000778, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000009, Accuracy_2: 93.6% Loss_2: 0.000006  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000379, Accuracy_2: 92.9% Loss_2: 0.000009  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000012, Accuracy_2: 88.7% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000179  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000037  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000747  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.005285, Accuracy_2: 90.1% Loss_2: 0.001879  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001192, Accuracy_2: 92.9% Loss_2: 0.001462  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.003311, Accuracy_2: 93.6% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000988, Accuracy_2: 88.7% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000362, Accuracy_2: 95.0% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000227, Accuracy_2: 89.4% Loss_2: 0.000722  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000615  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001475  [ 2961/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000001, Accuracy_2: 94.3% Loss_2: 0.008004  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000509, Accuracy_2: 92.9% Loss_2: 0.000002  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000707  [ 4653/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.000114, Accuracy_2: 85.1% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000781, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000296, Accuracy_2: 95.0% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000045  [ 6909/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000009  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001558, Accuracy_2: 89.4% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.002349, Accuracy_2: 95.0% Loss_2: 0.000005  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000011  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000120, Accuracy_2: 92.2% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000132  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000379, Accuracy_2: 92.9% Loss_2: 0.000472  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003851, Accuracy_2: 90.1% Loss_2: 0.001717  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000006  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000223  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000872, Accuracy_2: 91.5% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000019, Accuracy_2: 91.5% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000082, Accuracy_2: 90.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.001526  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001642, Accuracy_2: 95.7% Loss_2: 0.000002  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000005, Accuracy_2: 90.8% Loss_2: 0.000004  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.001376  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000655, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000032, Accuracy_2: 92.2% Loss_2: 0.000438  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000003, Accuracy_2: 90.1% Loss_2: 0.000112  [ 5781/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000638, Accuracy_2: 87.2% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000083, Accuracy_2: 92.9% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000385, Accuracy_2: 92.2% Loss_2: 0.000072  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002096, Accuracy_2: 92.9% Loss_2: 0.000032  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000009, Accuracy_2: 92.9% Loss_2: 0.001245  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000147, Accuracy_2: 87.2% Loss_2: 0.000979  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000003, Accuracy_2: 87.9% Loss_2: 0.000545  [10857/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000037, Accuracy_2: 95.0% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000961, Accuracy_2: 90.1% Loss_2: 0.000404  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.001439  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000097, Accuracy_2: 90.8% Loss_2: 0.001273  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000733, Accuracy_2: 89.4% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000054, Accuracy_2: 90.1% Loss_2: 0.000008  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000337, Accuracy_2: 87.2% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000878  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000080, Accuracy_2: 89.4% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002597, Accuracy_2: 89.4% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001139  [ 4089/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000007, Accuracy_2: 91.5% Loss_2: 0.002236  [ 4653/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000037, Accuracy_2: 91.5% Loss_2: 0.002997  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000004  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000004  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 86.5% Loss_2: 0.003314  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000074, Accuracy_2: 90.1% Loss_2: 0.000018  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000006, Accuracy_2: 88.7% Loss_2: 0.000004  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003424, Accuracy_2: 90.8% Loss_2: 0.000563  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000762, Accuracy_2: 91.5% Loss_2: 0.000026  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000663  [10857/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000054, Accuracy_2: 93.6% Loss_2: 0.001235  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000547, Accuracy_2: 92.2% Loss_2: 0.000881  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001919, Accuracy_2: 90.1% Loss_2: 0.000459  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001027, Accuracy_2: 92.2% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000000, Accuracy_2: 83.0% Loss_2: 0.000001  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000138, Accuracy_2: 92.9% Loss_2: 0.000025  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001154  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000019, Accuracy_2: 90.1% Loss_2: 0.000307  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001519, Accuracy_2: 90.1% Loss_2: 0.000983  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.003538  [ 1833/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000002, Accuracy_2: 87.2% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000419  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003406, Accuracy_2: 89.4% Loss_2: 0.000003  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.001477  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002414, Accuracy_2: 90.8% Loss_2: 0.001570  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000102, Accuracy_2: 88.7% Loss_2: 0.000989  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000295, Accuracy_2: 88.7% Loss_2: 0.002431  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001485, Accuracy_2: 90.1% Loss_2: 0.001587  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000012, Accuracy_2: 89.4% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001552, Accuracy_2: 93.6% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000017, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000914, Accuracy_2: 90.1% Loss_2: 0.000061  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000165, Accuracy_2: 90.1% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001098, Accuracy_2: 88.7% Loss_2: 0.000117  [10857/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000489, Accuracy_2: 88.7% Loss_2: 0.000046  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000963, Accuracy_2: 90.8% Loss_2: 0.000005  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001591, Accuracy_2: 93.6% Loss_2: 0.000004  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001101, Accuracy_2: 90.8% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000759  [13677/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000001, Accuracy_2: 85.1% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000043  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.005769  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.004045, Accuracy_2: 92.2% Loss_2: 0.000029  [ 2397/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002773  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001966, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000249, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001137, Accuracy_2: 87.2% Loss_2: 0.000004  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000009  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002877, Accuracy_2: 87.2% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000012  [ 8037/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000500, Accuracy_2: 95.0% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000332, Accuracy_2: 90.8% Loss_2: 0.000353  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001038, Accuracy_2: 87.2% Loss_2: 0.000135  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 84.4% Loss_2: 0.000393  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000069  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000046, Accuracy_2: 90.1% Loss_2: 0.000068  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000225  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000037, Accuracy_2: 90.1% Loss_2: 0.000006  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000004  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002952, Accuracy_2: 89.4% Loss_2: 0.000315  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000005  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.2%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001616  [  141/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000679, Accuracy_2: 94.3% Loss_2: 0.000117  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000048, Accuracy_2: 92.2% Loss_2: 0.000109  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000001  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000660, Accuracy_2: 91.5% Loss_2: 0.000001  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000008, Accuracy_2: 92.2% Loss_2: 0.000235  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001079, Accuracy_2: 88.7% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000072, Accuracy_2: 89.4% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000185  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000019  [ 5217/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000337, Accuracy_2: 90.8% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000312, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000059, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000151, Accuracy_2: 91.5% Loss_2: 0.001071  [ 9729/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.001359  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000717, Accuracy_2: 93.6% Loss_2: 0.000013  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000123, Accuracy_2: 90.1% Loss_2: 0.000401  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000222, Accuracy_2: 90.8% Loss_2: 0.000551  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003496, Accuracy_2: 92.2% Loss_2: 0.000561  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000567  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001714, Accuracy_2: 91.5% Loss_2: 0.000002  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000009, Accuracy_2: 90.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000416, Accuracy_2: 90.1% Loss_2: 0.000604  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.001636  [ 1833/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000065, Accuracy_2: 95.0% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000827, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000819, Accuracy_2: 89.4% Loss_2: 0.000014  [ 3525/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.005598, Accuracy_2: 85.8% Loss_2: 0.000980  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000597, Accuracy_2: 92.9% Loss_2: 0.000011  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000016, Accuracy_2: 90.1% Loss_2: 0.000772  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000014, Accuracy_2: 90.1% Loss_2: 0.000028  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000256, Accuracy_2: 92.2% Loss_2: 0.000101  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000588, Accuracy_2: 90.1% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001037, Accuracy_2: 91.5% Loss_2: 0.001166  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001267, Accuracy_2: 87.9% Loss_2: 0.001059  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000038  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001484, Accuracy_2: 90.1% Loss_2: 0.001400  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000042, Accuracy_2: 90.1% Loss_2: 0.002360  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000003, Accuracy_2: 90.1% Loss_2: 0.000033  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.001419  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000327, Accuracy_2: 91.5% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000060, Accuracy_2: 88.7% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000636, Accuracy_2: 93.6% Loss_2: 0.001217  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000032, Accuracy_2: 91.5% Loss_2: 0.001116  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000008, Accuracy_2: 90.1% Loss_2: 0.001318  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000165, Accuracy_2: 92.9% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.000154  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000008, Accuracy_2: 88.7% Loss_2: 0.000002  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.004242  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000004, Accuracy_2: 89.4% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.002106, Accuracy_2: 96.5% Loss_2: 0.000876  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000288, Accuracy_2: 88.7% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.001437  [ 5217/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000383  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000041, Accuracy_2: 92.2% Loss_2: 0.001123  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001074, Accuracy_2: 90.1% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000329, Accuracy_2: 90.1% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000101, Accuracy_2: 92.9% Loss_2: 0.002149  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001563, Accuracy_2: 90.8% Loss_2: 0.000122  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.002731  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002066, Accuracy_2: 91.5% Loss_2: 0.000009  [10293/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000011, Accuracy_2: 89.4% Loss_2: 0.000570  [11421/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000771, Accuracy_2: 85.8% Loss_2: 0.000349  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.003046  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000705, Accuracy_2: 87.2% Loss_2: 0.001593  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.002848  [13677/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000316  [14241/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.001101  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000398, Accuracy_2: 92.2% Loss_2: 0.000031  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000067, Accuracy_2: 87.9% Loss_2: 0.000603  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000185  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.002466, Accuracy_2: 92.9% Loss_2: 0.001252  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001496, Accuracy_2: 93.6% Loss_2: 0.000703  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000432, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.001848  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000196, Accuracy_2: 92.9% Loss_2: 0.000065  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001101, Accuracy_2: 92.9% Loss_2: 0.000003  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000775, Accuracy_2: 92.2% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001547, Accuracy_2: 91.5% Loss_2: 0.000712  [ 6909/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.002729  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000086, Accuracy_2: 91.5% Loss_2: 0.000791  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002447, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.001701, Accuracy_2: 96.5% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000187, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000007, Accuracy_2: 87.9% Loss_2: 0.000102  [10857/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.001066  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001066  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.004783, Accuracy_2: 93.6% Loss_2: 0.000094  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000089, Accuracy_2: 88.7% Loss_2: 0.001892  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000830  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002980, Accuracy_2: 89.4% Loss_2: 0.000480  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001169, Accuracy_2: 86.5% Loss_2: 0.000436  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000362, Accuracy_2: 91.5% Loss_2: 0.000643  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001144, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003831, Accuracy_2: 89.4% Loss_2: 0.000718  [ 2961/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000005, Accuracy_2: 92.2% Loss_2: 0.001877  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002056, Accuracy_2: 89.4% Loss_2: 0.000500  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002551, Accuracy_2: 90.1% Loss_2: 0.000002  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000979  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.006981, Accuracy_2: 87.2% Loss_2: 0.001356  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000055, Accuracy_2: 90.8% Loss_2: 0.000001  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000567, Accuracy_2: 92.2% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001930, Accuracy_2: 85.8% Loss_2: 0.002662  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001725, Accuracy_2: 88.7% Loss_2: 0.001323  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000400, Accuracy_2: 89.4% Loss_2: 0.000732  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000030  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001814, Accuracy_2: 90.1% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000033, Accuracy_2: 93.6% Loss_2: 0.001336  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000756, Accuracy_2: 88.7% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000029, Accuracy_2: 93.6% Loss_2: 0.001311  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000285, Accuracy_2: 91.5% Loss_2: 0.000031  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.1%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000037, Accuracy_2: 92.2% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001446, Accuracy_2: 85.1% Loss_2: 0.005194  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000186, Accuracy_2: 92.2% Loss_2: 0.000938  [ 1269/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.003730, Accuracy_2: 87.2% Loss_2: 0.000193  [ 2397/15250]\n",
      "Accuracy_1: 97.2%, Loss_1: 0.000000, Accuracy_2: 96.5% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.001659  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001262, Accuracy_2: 90.8% Loss_2: 0.000107  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002780, Accuracy_2: 92.2% Loss_2: 0.000002  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000834  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.001035  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002678, Accuracy_2: 91.5% Loss_2: 0.000359  [ 7473/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.003378, Accuracy_2: 86.5% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002787  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002251  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.002833, Accuracy_2: 94.3% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001520, Accuracy_2: 87.9% Loss_2: 0.001437  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000013, Accuracy_2: 90.8% Loss_2: 0.000446  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001083, Accuracy_2: 89.4% Loss_2: 0.000092  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001071, Accuracy_2: 93.6% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000014  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001363, Accuracy_2: 90.8% Loss_2: 0.001330  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000990, Accuracy_2: 90.8% Loss_2: 0.000002  [14241/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000302, Accuracy_2: 83.7% Loss_2: 0.003010  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.4%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000195  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.001478  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000947, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002533  [ 2961/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000200, Accuracy_2: 94.3% Loss_2: 0.003459  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001108  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000640, Accuracy_2: 90.1% Loss_2: 0.001418  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000003  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000037, Accuracy_2: 92.2% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000767, Accuracy_2: 95.0% Loss_2: 0.000472  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000818  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000035  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001505, Accuracy_2: 90.8% Loss_2: 0.000002  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000010, Accuracy_2: 91.5% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000002, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000112  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000742, Accuracy_2: 92.2% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000004, Accuracy_2: 92.2% Loss_2: 0.000028  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001277  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000538  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000313  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000255, Accuracy_2: 93.6% Loss_2: 0.002045  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000585  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001590, Accuracy_2: 89.4% Loss_2: 0.002719  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001216  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000737, Accuracy_2: 91.5% Loss_2: 0.000089  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.003036  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000044, Accuracy_2: 93.6% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.005238  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001826, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003514, Accuracy_2: 87.9% Loss_2: 0.001176  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.001804  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000038  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.005233, Accuracy_2: 93.6% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.001716  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000025  [ 8037/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000083  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000049  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000192, Accuracy_2: 89.4% Loss_2: 0.000445  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000091, Accuracy_2: 92.2% Loss_2: 0.002373  [12549/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000007  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000087, Accuracy_2: 92.2% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000822, Accuracy_2: 88.7% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001638, Accuracy_2: 92.2% Loss_2: 0.000001  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000128, Accuracy_2: 89.4% Loss_2: 0.000501  [  141/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000002  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000075  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002194, Accuracy_2: 89.4% Loss_2: 0.000091  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000825, Accuracy_2: 93.6% Loss_2: 0.000006  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000011, Accuracy_2: 90.1% Loss_2: 0.002657  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000000, Accuracy_2: 96.5% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000373, Accuracy_2: 90.8% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001050, Accuracy_2: 93.6% Loss_2: 0.001729  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000006, Accuracy_2: 90.8% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000708, Accuracy_2: 85.8% Loss_2: 0.002933  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000304  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000327  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000103, Accuracy_2: 88.7% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000013  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000947, Accuracy_2: 89.4% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000622  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.001466  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000009  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003278, Accuracy_2: 90.8% Loss_2: 0.001397  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000238, Accuracy_2: 90.1% Loss_2: 0.000076  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000086, Accuracy_2: 90.8% Loss_2: 0.000892  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000860, Accuracy_2: 91.5% Loss_2: 0.000033  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000007, Accuracy_2: 88.7% Loss_2: 0.002275  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003172, Accuracy_2: 91.5% Loss_2: 0.000961  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002658, Accuracy_2: 91.5% Loss_2: 0.000002  [ 1269/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000019  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002956, Accuracy_2: 92.2% Loss_2: 0.000520  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000103, Accuracy_2: 90.8% Loss_2: 0.000575  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000014, Accuracy_2: 90.8% Loss_2: 0.000736  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000032, Accuracy_2: 89.4% Loss_2: 0.002849  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000009  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.004875, Accuracy_2: 90.8% Loss_2: 0.003944  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000208, Accuracy_2: 90.8% Loss_2: 0.000001  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000230, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001346, Accuracy_2: 92.9% Loss_2: 0.000612  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000499  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000024, Accuracy_2: 89.4% Loss_2: 0.000011  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.003114  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000005, Accuracy_2: 93.6% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000034, Accuracy_2: 91.5% Loss_2: 0.001510  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001529, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.004380, Accuracy_2: 92.9% Loss_2: 0.000006  [13677/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.006466, Accuracy_2: 86.5% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000085, Accuracy_2: 93.6% Loss_2: 0.000556  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000020, Accuracy_2: 90.1% Loss_2: 0.000005  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001826, Accuracy_2: 91.5% Loss_2: 0.000080  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000568, Accuracy_2: 90.8% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000001  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000423  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000399, Accuracy_2: 92.9% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.001039, Accuracy_2: 96.5% Loss_2: 0.000001  [ 4089/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000834, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000016, Accuracy_2: 89.4% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000525, Accuracy_2: 96.5% Loss_2: 0.000711  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.001016  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001852, Accuracy_2: 88.7% Loss_2: 0.000319  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000005  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000003, Accuracy_2: 86.5% Loss_2: 0.001989  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001304, Accuracy_2: 92.2% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 92.2% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001877, Accuracy_2: 90.8% Loss_2: 0.001500  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000004  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000015  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000218, Accuracy_2: 86.5% Loss_2: 0.001146  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000081, Accuracy_2: 89.4% Loss_2: 0.000014  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000887  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.6%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.1%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000902, Accuracy_2: 92.9% Loss_2: 0.000108  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000098, Accuracy_2: 92.2% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000000, Accuracy_2: 96.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.001492  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000040  [ 2961/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.003839  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000518, Accuracy_2: 89.4% Loss_2: 0.001516  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001185, Accuracy_2: 89.4% Loss_2: 0.001197  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000143  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000006, Accuracy_2: 91.5% Loss_2: 0.000001  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000080  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.004691  [ 8601/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.002732  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001611, Accuracy_2: 91.5% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.001331, Accuracy_2: 96.5% Loss_2: 0.001464  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000996, Accuracy_2: 85.8% Loss_2: 0.004344  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000072, Accuracy_2: 91.5% Loss_2: 0.000551  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000939, Accuracy_2: 91.5% Loss_2: 0.000046  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000757, Accuracy_2: 92.9% Loss_2: 0.000006  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000129, Accuracy_2: 87.2% Loss_2: 0.001386  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000038  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001294, Accuracy_2: 90.1% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000003, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000002, Accuracy_2: 94.3% Loss_2: 0.000919  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000793, Accuracy_2: 93.6% Loss_2: 0.002843  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000004, Accuracy_2: 92.2% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000006, Accuracy_2: 92.2% Loss_2: 0.001354  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000051  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001324, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 83.7%, Loss_1: 0.000009, Accuracy_2: 83.7% Loss_2: 0.000014  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000128, Accuracy_2: 92.2% Loss_2: 0.000023  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000085, Accuracy_2: 94.3% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000023, Accuracy_2: 87.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000327  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.004261, Accuracy_2: 90.8% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002512, Accuracy_2: 91.5% Loss_2: 0.002586  [10857/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000034, Accuracy_2: 94.3% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000006, Accuracy_2: 89.4% Loss_2: 0.000009  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000210, Accuracy_2: 88.7% Loss_2: 0.001579  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000001, Accuracy_2: 95.7% Loss_2: 0.001057  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000082  [14241/15250]\n",
      "Accuracy_1: 97.2%, Loss_1: 0.000000, Accuracy_2: 97.2% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000049, Accuracy_2: 86.5% Loss_2: 0.000135  [ 1833/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.001700, Accuracy_2: 95.0% Loss_2: 0.000027  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000137, Accuracy_2: 92.2% Loss_2: 0.000011  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.004299, Accuracy_2: 91.5% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000017, Accuracy_2: 86.5% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000046  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000053, Accuracy_2: 91.5% Loss_2: 0.000407  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000075, Accuracy_2: 92.2% Loss_2: 0.000579  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000146, Accuracy_2: 90.8% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000017  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000003, Accuracy_2: 92.9% Loss_2: 0.000017  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000113, Accuracy_2: 92.2% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000174, Accuracy_2: 95.0% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001014, Accuracy_2: 90.8% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002001, Accuracy_2: 92.2% Loss_2: 0.000017  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002229  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.001868  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003725, Accuracy_2: 89.4% Loss_2: 0.000481  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000460  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.001424  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000504, Accuracy_2: 93.6% Loss_2: 0.005411  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000619, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002585, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002164  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.001017  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.001451  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001576, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000158, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001608  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000378, Accuracy_2: 89.4% Loss_2: 0.000001  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000417  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000307, Accuracy_2: 91.5% Loss_2: 0.002868  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000097, Accuracy_2: 90.8% Loss_2: 0.000003  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000003, Accuracy_2: 91.5% Loss_2: 0.001118  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000005, Accuracy_2: 92.2% Loss_2: 0.002347  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000040, Accuracy_2: 92.2% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000026  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000479, Accuracy_2: 90.8% Loss_2: 0.000187  [11421/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000493, Accuracy_2: 93.6% Loss_2: 0.000364  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000083, Accuracy_2: 86.5% Loss_2: 0.002538  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001506, Accuracy_2: 90.8% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000004  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000634, Accuracy_2: 89.4% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000457, Accuracy_2: 92.9% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000643  [ 1269/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000805, Accuracy_2: 95.0% Loss_2: 0.000004  [ 2961/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000107  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000006, Accuracy_2: 87.9% Loss_2: 0.005257  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000005, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000031, Accuracy_2: 93.6% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002928  [ 6345/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000038, Accuracy_2: 94.3% Loss_2: 0.000002  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.002000, Accuracy_2: 94.3% Loss_2: 0.000183  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000002  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.003946  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000556, Accuracy_2: 91.5% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000452, Accuracy_2: 92.9% Loss_2: 0.000475  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000558  [10857/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000025, Accuracy_2: 93.6% Loss_2: 0.000521  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000429, Accuracy_2: 91.5% Loss_2: 0.000078  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001277, Accuracy_2: 91.5% Loss_2: 0.000036  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000008, Accuracy_2: 90.1% Loss_2: 0.000256  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000285, Accuracy_2: 90.8% Loss_2: 0.002699  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000292, Accuracy_2: 92.2% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000492  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003126, Accuracy_2: 92.2% Loss_2: 0.000025  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000157, Accuracy_2: 93.6% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000019, Accuracy_2: 94.3% Loss_2: 0.000002  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001957  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000064  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000104, Accuracy_2: 89.4% Loss_2: 0.000227  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000002, Accuracy_2: 87.9% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000769  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000403, Accuracy_2: 91.5% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000156, Accuracy_2: 92.2% Loss_2: 0.000004  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.006387, Accuracy_2: 91.5% Loss_2: 0.001318  [ 8601/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000000, Accuracy_2: 84.4% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.000002  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000535, Accuracy_2: 93.6% Loss_2: 0.000014  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000006, Accuracy_2: 88.7% Loss_2: 0.000007  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001426, Accuracy_2: 89.4% Loss_2: 0.000242  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002513, Accuracy_2: 89.4% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.003295  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 92.9% Loss_2: 0.000671  [13677/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.004198, Accuracy_2: 94.3% Loss_2: 0.000002  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001338, Accuracy_2: 92.2% Loss_2: 0.002150  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000838, Accuracy_2: 94.3% Loss_2: 0.000972  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000235, Accuracy_2: 90.1% Loss_2: 0.000001  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000024, Accuracy_2: 90.8% Loss_2: 0.000008  [ 1833/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001724, Accuracy_2: 85.8% Loss_2: 0.000004  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002106, Accuracy_2: 92.2% Loss_2: 0.003737  [ 2961/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001301, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000004  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.004825, Accuracy_2: 91.5% Loss_2: 0.000004  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000003, Accuracy_2: 93.6% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000001, Accuracy_2: 95.7% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.001296  [ 8037/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000039, Accuracy_2: 95.0% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000015, Accuracy_2: 87.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000016, Accuracy_2: 90.8% Loss_2: 0.000066  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000038, Accuracy_2: 89.4% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000087, Accuracy_2: 87.9% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000099, Accuracy_2: 96.5% Loss_2: 0.000002  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002068, Accuracy_2: 90.8% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000804, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000122, Accuracy_2: 87.9% Loss_2: 0.000790  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000039, Accuracy_2: 92.2% Loss_2: 0.000513  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000011, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001511, Accuracy_2: 93.6% Loss_2: 0.000001  [ 1833/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000449, Accuracy_2: 91.5% Loss_2: 0.000002  [ 2961/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000001, Accuracy_2: 95.7% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000296, Accuracy_2: 95.7% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000115, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000570, Accuracy_2: 86.5% Loss_2: 0.000207  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001094, Accuracy_2: 90.1% Loss_2: 0.000004  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000022, Accuracy_2: 91.5% Loss_2: 0.001080  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000479  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.001541  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000153, Accuracy_2: 92.2% Loss_2: 0.000037  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001460, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000808  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000001  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.005604, Accuracy_2: 87.9% Loss_2: 0.000001  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000776, Accuracy_2: 90.1% Loss_2: 0.000023  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000045, Accuracy_2: 90.8% Loss_2: 0.000024  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000202, Accuracy_2: 92.9% Loss_2: 0.000116  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.001629  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000024, Accuracy_2: 88.7% Loss_2: 0.000892  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001078, Accuracy_2: 87.9% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000311, Accuracy_2: 86.5% Loss_2: 0.001193  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.001444  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000455, Accuracy_2: 92.9% Loss_2: 0.000010  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000556  [ 2397/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.003537, Accuracy_2: 97.2% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000946  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.004166, Accuracy_2: 92.9% Loss_2: 0.000187  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000043, Accuracy_2: 90.1% Loss_2: 0.000003  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000073  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000172, Accuracy_2: 87.9% Loss_2: 0.004449  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000371  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000058  [ 6909/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000257, Accuracy_2: 95.7% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000829  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000933  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.001218  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000031, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.001984  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003679, Accuracy_2: 91.5% Loss_2: 0.002854  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000665, Accuracy_2: 92.2% Loss_2: 0.000002  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000075  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000045, Accuracy_2: 92.2% Loss_2: 0.000987  [14241/15250]\n",
      "Accuracy_1: 81.6%, Loss_1: 0.000000, Accuracy_2: 83.0% Loss_2: 0.000073  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000202, Accuracy_2: 91.5% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000035  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000627, Accuracy_2: 92.9% Loss_2: 0.000519  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002371, Accuracy_2: 92.9% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000132, Accuracy_2: 90.8% Loss_2: 0.000006  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000012, Accuracy_2: 89.4% Loss_2: 0.000486  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000024  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001564, Accuracy_2: 94.3% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000009  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000888, Accuracy_2: 88.7% Loss_2: 0.000687  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000475  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.003087  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000406  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000899  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000388, Accuracy_2: 87.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000042  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000652, Accuracy_2: 92.9% Loss_2: 0.000001  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.004386  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000016, Accuracy_2: 87.9% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003552, Accuracy_2: 88.7% Loss_2: 0.000750  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000030, Accuracy_2: 87.2% Loss_2: 0.000004  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000009, Accuracy_2: 89.4% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.001374, Accuracy_2: 95.7% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001536, Accuracy_2: 90.8% Loss_2: 0.000381  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000307, Accuracy_2: 94.3% Loss_2: 0.000871  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.7%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000545, Accuracy_2: 92.9% Loss_2: 0.001768  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000805, Accuracy_2: 89.4% Loss_2: 0.000352  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000016  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000045  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000085, Accuracy_2: 90.8% Loss_2: 0.002970  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000745, Accuracy_2: 90.8% Loss_2: 0.000008  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000356, Accuracy_2: 91.5% Loss_2: 0.000939  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000012, Accuracy_2: 92.2% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000252  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000098, Accuracy_2: 87.2% Loss_2: 0.001594  [ 6909/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000224, Accuracy_2: 94.3% Loss_2: 0.000126  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000519, Accuracy_2: 90.1% Loss_2: 0.004127  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000016  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000796, Accuracy_2: 93.6% Loss_2: 0.001195  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000015  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000002, Accuracy_2: 92.9% Loss_2: 0.000066  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000005, Accuracy_2: 90.8% Loss_2: 0.002467  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000012, Accuracy_2: 88.7% Loss_2: 0.000070  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002308, Accuracy_2: 92.2% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001690, Accuracy_2: 89.4% Loss_2: 0.000217  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.004225, Accuracy_2: 92.9% Loss_2: 0.002773  [13113/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000024, Accuracy_2: 95.7% Loss_2: 0.000011  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000005, Accuracy_2: 89.4% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000137, Accuracy_2: 92.9% Loss_2: 0.002016  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000441, Accuracy_2: 87.9% Loss_2: 0.001469  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000493, Accuracy_2: 91.5% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000369  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002536, Accuracy_2: 93.6% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000023, Accuracy_2: 87.2% Loss_2: 0.000132  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001976, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000837, Accuracy_2: 91.5% Loss_2: 0.000555  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002631  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000277, Accuracy_2: 90.8% Loss_2: 0.001958  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000008, Accuracy_2: 89.4% Loss_2: 0.001059  [ 6909/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002716, Accuracy_2: 85.1% Loss_2: 0.003381  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000112, Accuracy_2: 92.9% Loss_2: 0.000870  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001430, Accuracy_2: 90.1% Loss_2: 0.000263  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001166, Accuracy_2: 90.8% Loss_2: 0.000288  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003603, Accuracy_2: 91.5% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000233  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000745, Accuracy_2: 87.9% Loss_2: 0.000001  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.004574  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001382, Accuracy_2: 93.6% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001404, Accuracy_2: 93.6% Loss_2: 0.000521  [13677/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001008, Accuracy_2: 92.2% Loss_2: 0.000016  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.4%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.5%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.004815  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000843, Accuracy_2: 91.5% Loss_2: 0.000004  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000007, Accuracy_2: 85.8% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000845, Accuracy_2: 93.6% Loss_2: 0.000003  [ 2397/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000378  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000926, Accuracy_2: 94.3% Loss_2: 0.000013  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000554  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001100  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000501, Accuracy_2: 88.7% Loss_2: 0.001206  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000751, Accuracy_2: 93.6% Loss_2: 0.000004  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000003, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001990, Accuracy_2: 86.5% Loss_2: 0.000216  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000051, Accuracy_2: 92.2% Loss_2: 0.001715  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000425  [ 9165/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.002407, Accuracy_2: 94.3% Loss_2: 0.001100  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000029, Accuracy_2: 92.2% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001175, Accuracy_2: 87.9% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001602, Accuracy_2: 92.2% Loss_2: 0.000893  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000011, Accuracy_2: 89.4% Loss_2: 0.004974  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.003368  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000414, Accuracy_2: 92.2% Loss_2: 0.001527  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000984  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.5%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001620, Accuracy_2: 93.6% Loss_2: 0.000009  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000622, Accuracy_2: 87.2% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000159, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002857, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000022, Accuracy_2: 91.5% Loss_2: 0.000585  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000234, Accuracy_2: 87.9% Loss_2: 0.003436  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001600, Accuracy_2: 92.9% Loss_2: 0.000314  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001634  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000596, Accuracy_2: 86.5% Loss_2: 0.001484  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000585, Accuracy_2: 90.8% Loss_2: 0.001395  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000001  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001325, Accuracy_2: 94.3% Loss_2: 0.000503  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000055, Accuracy_2: 87.2% Loss_2: 0.001063  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002636, Accuracy_2: 92.2% Loss_2: 0.000717  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000360, Accuracy_2: 88.7% Loss_2: 0.000510  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.004353, Accuracy_2: 93.6% Loss_2: 0.003743  [ 8601/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000002, Accuracy_2: 93.6% Loss_2: 0.000327  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000012, Accuracy_2: 85.8% Loss_2: 0.001196  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000047  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000272, Accuracy_2: 94.3% Loss_2: 0.000502  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000074, Accuracy_2: 92.9% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001239, Accuracy_2: 92.2% Loss_2: 0.000575  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000082, Accuracy_2: 92.9% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000023  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.004415, Accuracy_2: 89.4% Loss_2: 0.003707  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000645  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000020, Accuracy_2: 90.1% Loss_2: 0.000002  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000082, Accuracy_2: 85.8% Loss_2: 0.001445  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000834, Accuracy_2: 87.9% Loss_2: 0.001443  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001278, Accuracy_2: 88.7% Loss_2: 0.000586  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000064, Accuracy_2: 95.7% Loss_2: 0.000795  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000800, Accuracy_2: 92.2% Loss_2: 0.000002  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000155, Accuracy_2: 90.1% Loss_2: 0.001063  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000698, Accuracy_2: 90.1% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000189, Accuracy_2: 94.3% Loss_2: 0.000052  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.002170  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.003113, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001374  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.002495, Accuracy_2: 94.3% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001641, Accuracy_2: 92.2% Loss_2: 0.000023  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000450, Accuracy_2: 87.9% Loss_2: 0.000009  [10857/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000231, Accuracy_2: 95.0% Loss_2: 0.000001  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000225, Accuracy_2: 90.8% Loss_2: 0.001140  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001422, Accuracy_2: 92.2% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000926, Accuracy_2: 90.1% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000917, Accuracy_2: 92.9% Loss_2: 0.000004  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000004  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.001618  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001232, Accuracy_2: 92.2% Loss_2: 0.000076  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.001627  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000167, Accuracy_2: 92.2% Loss_2: 0.000011  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001408  [ 4089/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.003772  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000157, Accuracy_2: 93.6% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000007, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.004558  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002473, Accuracy_2: 92.9% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001014, Accuracy_2: 90.1% Loss_2: 0.000006  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.003936  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001173, Accuracy_2: 90.8% Loss_2: 0.001526  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000010, Accuracy_2: 91.5% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000156, Accuracy_2: 92.9% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000073, Accuracy_2: 90.8% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000289, Accuracy_2: 86.5% Loss_2: 0.000220  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000122  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000995  [13113/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000001, Accuracy_2: 95.0% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000887, Accuracy_2: 88.7% Loss_2: 0.000249  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000050  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000211, Accuracy_2: 92.9% Loss_2: 0.000094  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000833, Accuracy_2: 89.4% Loss_2: 0.001043  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000029, Accuracy_2: 91.5% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000210, Accuracy_2: 91.5% Loss_2: 0.000039  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000378, Accuracy_2: 89.4% Loss_2: 0.001959  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000233, Accuracy_2: 92.2% Loss_2: 0.001676  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000272, Accuracy_2: 92.9% Loss_2: 0.000012  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.004637, Accuracy_2: 92.2% Loss_2: 0.000001  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000083, Accuracy_2: 90.8% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000139  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000299, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002232, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000515, Accuracy_2: 89.4% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002263, Accuracy_2: 90.8% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001589, Accuracy_2: 95.7% Loss_2: 0.000004  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000282, Accuracy_2: 92.2% Loss_2: 0.000165  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000025, Accuracy_2: 90.8% Loss_2: 0.000314  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000022, Accuracy_2: 92.2% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.003367  [13113/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000060  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000092, Accuracy_2: 90.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001104, Accuracy_2: 91.5% Loss_2: 0.000734  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.1%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000004, Accuracy_2: 90.8% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000030, Accuracy_2: 90.8% Loss_2: 0.000105  [ 1269/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000016, Accuracy_2: 87.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000046, Accuracy_2: 89.4% Loss_2: 0.000085  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000009  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000027, Accuracy_2: 92.9% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000818, Accuracy_2: 89.4% Loss_2: 0.000464  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000001  [ 5217/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000601, Accuracy_2: 92.9% Loss_2: 0.000771  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.002615  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000057  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.002647  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000031, Accuracy_2: 90.8% Loss_2: 0.000004  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000012, Accuracy_2: 92.9% Loss_2: 0.003732  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000715, Accuracy_2: 94.3% Loss_2: 0.000695  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001237, Accuracy_2: 90.8% Loss_2: 0.000507  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.003660  [10857/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000781, Accuracy_2: 87.2% Loss_2: 0.000008  [11421/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000017  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000732, Accuracy_2: 87.9% Loss_2: 0.000627  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000164  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002131, Accuracy_2: 89.4% Loss_2: 0.000522  [14241/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001469, Accuracy_2: 87.9% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.1%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001274, Accuracy_2: 90.8% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002135, Accuracy_2: 85.1% Loss_2: 0.000656  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000863, Accuracy_2: 92.2% Loss_2: 0.000010  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000232  [ 1833/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.004237, Accuracy_2: 86.5% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000282, Accuracy_2: 89.4% Loss_2: 0.000048  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000001  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000470, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001770, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 98.6%, Loss_1: 0.000000, Accuracy_2: 98.6% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000531, Accuracy_2: 95.7% Loss_2: 0.000001  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.009642  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001563, Accuracy_2: 88.7% Loss_2: 0.000010  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.006498  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000034  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000972  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000010, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001080, Accuracy_2: 93.6% Loss_2: 0.000020  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002961, Accuracy_2: 91.5% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000077, Accuracy_2: 91.5% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000440  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000041, Accuracy_2: 89.4% Loss_2: 0.001813  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000503  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000040, Accuracy_2: 92.9% Loss_2: 0.000779  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000085  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000353, Accuracy_2: 87.2% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 96.5% Loss_2: 0.000002  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.5%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002209, Accuracy_2: 90.1% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000058, Accuracy_2: 88.7% Loss_2: 0.006374  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000845, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000010, Accuracy_2: 94.3% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000392, Accuracy_2: 87.9% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001585, Accuracy_2: 86.5% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000020, Accuracy_2: 95.7% Loss_2: 0.000633  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000003, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001373, Accuracy_2: 95.0% Loss_2: 0.000003  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.004602  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000005  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000005  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.004905  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000501, Accuracy_2: 89.4% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000496, Accuracy_2: 87.2% Loss_2: 0.001490  [ 8601/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000001, Accuracy_2: 95.0% Loss_2: 0.000107  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000038, Accuracy_2: 87.9% Loss_2: 0.000001  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.001646  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000771, Accuracy_2: 90.8% Loss_2: 0.000894  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000002  [11985/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.001969  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000259, Accuracy_2: 93.6% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000543, Accuracy_2: 96.5% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000003  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000049, Accuracy_2: 88.7% Loss_2: 0.000790  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000231, Accuracy_2: 92.2% Loss_2: 0.000002  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000187, Accuracy_2: 88.7% Loss_2: 0.001031  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.002116  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000089, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002718, Accuracy_2: 91.5% Loss_2: 0.001426  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002459, Accuracy_2: 93.6% Loss_2: 0.000001  [ 3525/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000462, Accuracy_2: 87.2% Loss_2: 0.001084  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001026, Accuracy_2: 90.8% Loss_2: 0.000171  [ 4653/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001157, Accuracy_2: 93.6% Loss_2: 0.002387  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.001000  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.005066, Accuracy_2: 90.1% Loss_2: 0.001031  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000295  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000822, Accuracy_2: 93.6% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000158, Accuracy_2: 95.0% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000182, Accuracy_2: 92.9% Loss_2: 0.000328  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000019  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000001  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000405, Accuracy_2: 92.9% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000389  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.003914  [13113/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000003, Accuracy_2: 94.3% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000001  [14241/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000009, Accuracy_2: 94.3% Loss_2: 0.001444  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.5%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000032, Accuracy_2: 93.6% Loss_2: 0.000801  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000481  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.001113  [ 2961/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000326, Accuracy_2: 94.3% Loss_2: 0.001270  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000751, Accuracy_2: 92.2% Loss_2: 0.000008  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.000009  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000558, Accuracy_2: 92.2% Loss_2: 0.002017  [ 5217/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000261, Accuracy_2: 87.9% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000971, Accuracy_2: 90.1% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000171, Accuracy_2: 87.9% Loss_2: 0.000138  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.001924  [ 7473/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002151, Accuracy_2: 86.5% Loss_2: 0.000091  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000009, Accuracy_2: 92.9% Loss_2: 0.000038  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001447, Accuracy_2: 89.4% Loss_2: 0.000570  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000006  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000338  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002848, Accuracy_2: 90.1% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000184  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000004  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001481, Accuracy_2: 92.2% Loss_2: 0.001052  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002217, Accuracy_2: 90.1% Loss_2: 0.000003  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000354, Accuracy_2: 95.0% Loss_2: 0.000004  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000112, Accuracy_2: 88.7% Loss_2: 0.000182  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000916, Accuracy_2: 89.4% Loss_2: 0.000494  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.004850, Accuracy_2: 89.4% Loss_2: 0.003421  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000052, Accuracy_2: 89.4% Loss_2: 0.001114  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000231, Accuracy_2: 87.2% Loss_2: 0.000116  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.002517  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000122, Accuracy_2: 93.6% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000375, Accuracy_2: 88.7% Loss_2: 0.000798  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001442, Accuracy_2: 94.3% Loss_2: 0.000082  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003383, Accuracy_2: 90.1% Loss_2: 0.000126  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000212, Accuracy_2: 87.2% Loss_2: 0.000154  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000230, Accuracy_2: 87.2% Loss_2: 0.001042  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000188  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000828, Accuracy_2: 91.5% Loss_2: 0.000726  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.004196, Accuracy_2: 90.1% Loss_2: 0.006217  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001271, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.006031, Accuracy_2: 90.1% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000804, Accuracy_2: 92.2% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000690  [11421/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.002006, Accuracy_2: 96.5% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001893, Accuracy_2: 90.8% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003447, Accuracy_2: 92.2% Loss_2: 0.003155  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001276  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000226, Accuracy_2: 93.6% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000338, Accuracy_2: 92.2% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000148, Accuracy_2: 87.9% Loss_2: 0.000055  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000760, Accuracy_2: 90.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000798  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000697  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000843  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000301  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000001  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001790, Accuracy_2: 85.8% Loss_2: 0.001247  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002506, Accuracy_2: 90.8% Loss_2: 0.000145  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000093, Accuracy_2: 91.5% Loss_2: 0.003761  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000010, Accuracy_2: 92.9% Loss_2: 0.000002  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003754, Accuracy_2: 92.9% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001051, Accuracy_2: 89.4% Loss_2: 0.000032  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001352, Accuracy_2: 90.1% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000036  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002616, Accuracy_2: 92.2% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000007, Accuracy_2: 92.2% Loss_2: 0.000424  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000009, Accuracy_2: 86.5% Loss_2: 0.000220  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000577, Accuracy_2: 89.4% Loss_2: 0.000500  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.002573  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000013, Accuracy_2: 90.1% Loss_2: 0.000136  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000174, Accuracy_2: 90.8% Loss_2: 0.000192  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.001472  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.9%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000225, Accuracy_2: 92.9% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000011, Accuracy_2: 90.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000291, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000170  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000913, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000622, Accuracy_2: 95.0% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000408, Accuracy_2: 92.2% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000033, Accuracy_2: 88.7% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003401, Accuracy_2: 89.4% Loss_2: 0.000807  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001184, Accuracy_2: 92.9% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.005377, Accuracy_2: 92.9% Loss_2: 0.000279  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.002393  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003744, Accuracy_2: 90.1% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002257, Accuracy_2: 88.7% Loss_2: 0.000595  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000513, Accuracy_2: 92.2% Loss_2: 0.000035  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000003, Accuracy_2: 88.7% Loss_2: 0.000003  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000085, Accuracy_2: 90.8% Loss_2: 0.001166  [ 9165/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000259  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000005, Accuracy_2: 92.2% Loss_2: 0.001933  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000903  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000005, Accuracy_2: 92.2% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000228, Accuracy_2: 92.9% Loss_2: 0.002702  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.000718  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000011, Accuracy_2: 90.1% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.001242  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.004913  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000463  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.003889, Accuracy_2: 91.5% Loss_2: 0.001304  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000284, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000006, Accuracy_2: 85.1% Loss_2: 0.001812  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000001  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001472, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000016, Accuracy_2: 92.9% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000010, Accuracy_2: 91.5% Loss_2: 0.000029  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000030, Accuracy_2: 90.8% Loss_2: 0.000027  [ 5781/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000233, Accuracy_2: 95.0% Loss_2: 0.001376  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000001, Accuracy_2: 95.7% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001575, Accuracy_2: 90.8% Loss_2: 0.000753  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.005332, Accuracy_2: 89.4% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000004, Accuracy_2: 92.2% Loss_2: 0.000002  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.009942  [ 9729/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000008, Accuracy_2: 93.6% Loss_2: 0.002208  [10293/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000012, Accuracy_2: 92.9% Loss_2: 0.000544  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000529, Accuracy_2: 90.8% Loss_2: 0.000093  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000012  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000245  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001294, Accuracy_2: 91.5% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000026  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000258, Accuracy_2: 92.2% Loss_2: 0.001402  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000434  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000089, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000517, Accuracy_2: 87.9% Loss_2: 0.000014  [ 1833/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001358, Accuracy_2: 87.9% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000016  [ 3525/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000002  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000340  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.003900, Accuracy_2: 96.5% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000190, Accuracy_2: 86.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000841  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002293, Accuracy_2: 93.6% Loss_2: 0.000008  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001331, Accuracy_2: 92.2% Loss_2: 0.000528  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002076, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000736, Accuracy_2: 90.8% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000011, Accuracy_2: 88.7% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000026, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.000124  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000012, Accuracy_2: 89.4% Loss_2: 0.005427  [11421/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.002244  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.006180, Accuracy_2: 92.2% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000002, Accuracy_2: 93.6% Loss_2: 0.000007  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001035, Accuracy_2: 90.8% Loss_2: 0.000276  [13677/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001662, Accuracy_2: 87.9% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.002300  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.9%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000729  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000566, Accuracy_2: 87.9% Loss_2: 0.000622  [ 1269/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000012  [ 1833/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000437, Accuracy_2: 86.5% Loss_2: 0.000751  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000495, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.000014  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000007, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000018, Accuracy_2: 87.9% Loss_2: 0.001787  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000043  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000002  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.002759  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.003713  [ 7473/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001097, Accuracy_2: 95.0% Loss_2: 0.001659  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000029, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000009, Accuracy_2: 93.6% Loss_2: 0.000353  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000071, Accuracy_2: 91.5% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001160, Accuracy_2: 87.9% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000088  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000074  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.007257, Accuracy_2: 92.2% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.002889  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000364, Accuracy_2: 91.5% Loss_2: 0.000747  [13113/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000592, Accuracy_2: 95.0% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000897  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000067, Accuracy_2: 92.2% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000003  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000418, Accuracy_2: 93.6% Loss_2: 0.000015  [ 1269/15250]\n",
      "Accuracy_1: 97.2%, Loss_1: 0.000001, Accuracy_2: 96.5% Loss_2: 0.001004  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000001, Accuracy_2: 85.1% Loss_2: 0.003339  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.002004  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000071, Accuracy_2: 93.6% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000018, Accuracy_2: 87.9% Loss_2: 0.001140  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000106, Accuracy_2: 92.9% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000149  [ 5781/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000004  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000448, Accuracy_2: 93.6% Loss_2: 0.000084  [ 6909/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000561, Accuracy_2: 86.5% Loss_2: 0.000103  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000003, Accuracy_2: 92.2% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000631, Accuracy_2: 87.9% Loss_2: 0.005006  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000008, Accuracy_2: 90.8% Loss_2: 0.000001  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000002  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000169, Accuracy_2: 94.3% Loss_2: 0.000166  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000039, Accuracy_2: 89.4% Loss_2: 0.000176  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000016, Accuracy_2: 90.8% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000434, Accuracy_2: 90.8% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000026, Accuracy_2: 90.1% Loss_2: 0.001631  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000485  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000713, Accuracy_2: 90.1% Loss_2: 0.000084  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002128, Accuracy_2: 90.8% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000685, Accuracy_2: 95.0% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000541, Accuracy_2: 89.4% Loss_2: 0.000918  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000246, Accuracy_2: 90.1% Loss_2: 0.001296  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000144  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000071  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000571, Accuracy_2: 92.9% Loss_2: 0.003798  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.003427  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000779  [ 4653/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.002307, Accuracy_2: 95.0% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000466, Accuracy_2: 93.6% Loss_2: 0.000128  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000005, Accuracy_2: 90.8% Loss_2: 0.000079  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000068, Accuracy_2: 89.4% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001500, Accuracy_2: 90.1% Loss_2: 0.000259  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000638, Accuracy_2: 94.3% Loss_2: 0.008058  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001555, Accuracy_2: 93.6% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001201, Accuracy_2: 88.7% Loss_2: 0.001713  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000042  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000274, Accuracy_2: 93.6% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000867, Accuracy_2: 88.7% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000127, Accuracy_2: 92.2% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000671, Accuracy_2: 89.4% Loss_2: 0.000002  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000036, Accuracy_2: 90.8% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001576, Accuracy_2: 88.7% Loss_2: 0.000727  [13677/15250]\n",
      "Accuracy_1: 97.9%, Loss_1: 0.000040, Accuracy_2: 96.5% Loss_2: 0.000144  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000006, Accuracy_2: 90.8% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002252, Accuracy_2: 89.4% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000006, Accuracy_2: 92.9% Loss_2: 0.005627  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000008, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000001  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002002, Accuracy_2: 84.4% Loss_2: 0.000325  [ 3525/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000000, Accuracy_2: 84.4% Loss_2: 0.000519  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000458, Accuracy_2: 85.1% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000016, Accuracy_2: 92.2% Loss_2: 0.000001  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002632, Accuracy_2: 91.5% Loss_2: 0.000137  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000005  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000005  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000005, Accuracy_2: 87.9% Loss_2: 0.000001  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000004, Accuracy_2: 90.8% Loss_2: 0.002383  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.003235, Accuracy_2: 94.3% Loss_2: 0.001917  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000658, Accuracy_2: 90.1% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000629, Accuracy_2: 89.4% Loss_2: 0.000012  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.001066  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000266, Accuracy_2: 94.3% Loss_2: 0.000012  [12549/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.000362, Accuracy_2: 83.0% Loss_2: 0.002220  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000204, Accuracy_2: 88.7% Loss_2: 0.000002  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000011  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001172, Accuracy_2: 94.3% Loss_2: 0.001501  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.006206, Accuracy_2: 95.0% Loss_2: 0.000020  [  705/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.002331  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000035, Accuracy_2: 90.1% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000657, Accuracy_2: 89.4% Loss_2: 0.001086  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001040, Accuracy_2: 92.9% Loss_2: 0.002041  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000006  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000002  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.004325  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000359, Accuracy_2: 92.2% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000441  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000077, Accuracy_2: 92.9% Loss_2: 0.000006  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000014  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001954, Accuracy_2: 89.4% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000116, Accuracy_2: 90.8% Loss_2: 0.000583  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.001251  [ 8601/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000543, Accuracy_2: 85.8% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000105, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000331  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000214, Accuracy_2: 93.6% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000005, Accuracy_2: 93.6% Loss_2: 0.000036  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000690, Accuracy_2: 89.4% Loss_2: 0.000009  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002151, Accuracy_2: 90.8% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000115  [13677/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.003910, Accuracy_2: 97.9% Loss_2: 0.000032  [14241/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000353, Accuracy_2: 92.2% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001883, Accuracy_2: 89.4% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000879, Accuracy_2: 91.5% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000411  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.001459  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001971, Accuracy_2: 92.9% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000031, Accuracy_2: 88.7% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000026, Accuracy_2: 92.9% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000002, Accuracy_2: 93.6% Loss_2: 0.002929  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.000076  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000013, Accuracy_2: 92.2% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000020, Accuracy_2: 91.5% Loss_2: 0.001626  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001229, Accuracy_2: 92.2% Loss_2: 0.000001  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000010, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000008  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000010, Accuracy_2: 90.1% Loss_2: 0.003430  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000007, Accuracy_2: 90.8% Loss_2: 0.003447  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001336  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000004  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000912, Accuracy_2: 91.5% Loss_2: 0.001309  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000010, Accuracy_2: 93.6% Loss_2: 0.000078  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000122, Accuracy_2: 92.9% Loss_2: 0.000225  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.5%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000232, Accuracy_2: 96.5% Loss_2: 0.000001  [  141/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000283  [  705/15250]\n",
      "Accuracy_1: 98.6%, Loss_1: 0.000041, Accuracy_2: 97.9% Loss_2: 0.001155  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000124, Accuracy_2: 91.5% Loss_2: 0.002429  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001002, Accuracy_2: 92.9% Loss_2: 0.000015  [ 2397/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002076, Accuracy_2: 92.2% Loss_2: 0.000919  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000748, Accuracy_2: 92.2% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000334  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.002823  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000896, Accuracy_2: 92.2% Loss_2: 0.001587  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000713  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002318, Accuracy_2: 91.5% Loss_2: 0.000047  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000021, Accuracy_2: 90.1% Loss_2: 0.008489  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000050, Accuracy_2: 90.1% Loss_2: 0.002770  [ 7473/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000107, Accuracy_2: 95.0% Loss_2: 0.000535  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000496, Accuracy_2: 94.3% Loss_2: 0.000046  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000248, Accuracy_2: 92.2% Loss_2: 0.000085  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003077, Accuracy_2: 90.8% Loss_2: 0.000001  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000404  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000256  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000038, Accuracy_2: 95.0% Loss_2: 0.000002  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000832, Accuracy_2: 92.9% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000026, Accuracy_2: 95.7% Loss_2: 0.002907  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000169  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000097, Accuracy_2: 90.1% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000003\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.8%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001043, Accuracy_2: 92.9% Loss_2: 0.001775  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000493, Accuracy_2: 90.1% Loss_2: 0.000525  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001489, Accuracy_2: 87.9% Loss_2: 0.000101  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000054, Accuracy_2: 92.2% Loss_2: 0.000003  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000092  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000581, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002555, Accuracy_2: 92.9% Loss_2: 0.000001  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000802, Accuracy_2: 90.1% Loss_2: 0.000017  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000330, Accuracy_2: 89.4% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000136, Accuracy_2: 87.2% Loss_2: 0.001898  [ 5217/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000661  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.002327, Accuracy_2: 96.5% Loss_2: 0.000017  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001052, Accuracy_2: 90.8% Loss_2: 0.000001  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000151, Accuracy_2: 93.6% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000042, Accuracy_2: 92.2% Loss_2: 0.000022  [ 8037/15250]\n",
      "Accuracy_1: 97.2%, Loss_1: 0.000000, Accuracy_2: 96.5% Loss_2: 0.001288  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001971  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001591, Accuracy_2: 89.4% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000013, Accuracy_2: 89.4% Loss_2: 0.000180  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000533, Accuracy_2: 89.4% Loss_2: 0.003731  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000723, Accuracy_2: 95.0% Loss_2: 0.000016  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000584, Accuracy_2: 87.2% Loss_2: 0.002136  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000070, Accuracy_2: 90.1% Loss_2: 0.002045  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000071  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.001179  [  141/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.001045  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000398, Accuracy_2: 94.3% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000001, Accuracy_2: 94.3% Loss_2: 0.000964  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000591, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000947  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000165  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000738, Accuracy_2: 88.7% Loss_2: 0.007630  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000045, Accuracy_2: 90.1% Loss_2: 0.002883  [ 5217/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000516, Accuracy_2: 95.7% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000143, Accuracy_2: 90.8% Loss_2: 0.000180  [ 6345/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000036  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001157, Accuracy_2: 92.2% Loss_2: 0.000041  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001433, Accuracy_2: 92.2% Loss_2: 0.001030  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.005266, Accuracy_2: 93.6% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000181, Accuracy_2: 96.5% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000557  [ 9729/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000986  [10293/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000063  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000012, Accuracy_2: 92.2% Loss_2: 0.000002  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002715  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000942, Accuracy_2: 90.8% Loss_2: 0.000010  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000023, Accuracy_2: 87.9% Loss_2: 0.001425  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000003, Accuracy_2: 87.2% Loss_2: 0.001505  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001048, Accuracy_2: 90.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000689, Accuracy_2: 88.7% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001954, Accuracy_2: 92.9% Loss_2: 0.001355  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000980, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002676  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000373, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.001666  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000347, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000957  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000571  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001139  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000015, Accuracy_2: 92.2% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000049, Accuracy_2: 88.7% Loss_2: 0.000197  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.001929  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000992, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000005  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000579  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000958, Accuracy_2: 90.1% Loss_2: 0.000480  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000006, Accuracy_2: 92.9% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000001  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 84.4%, Loss_1: 0.001218, Accuracy_2: 85.8% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000066  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000028  [14241/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000002, Accuracy_2: 85.1% Loss_2: 0.001719  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.5%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000614, Accuracy_2: 84.4% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000049  [ 1269/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000002  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002037, Accuracy_2: 90.8% Loss_2: 0.000020  [ 2397/15250]\n",
      "Accuracy_1: 97.2%, Loss_1: 0.000015, Accuracy_2: 96.5% Loss_2: 0.000157  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000183  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000040  [ 4089/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000002, Accuracy_2: 92.2% Loss_2: 0.000288  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000003, Accuracy_2: 94.3% Loss_2: 0.000070  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000011  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.001746  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000850, Accuracy_2: 89.4% Loss_2: 0.000324  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000521  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000504, Accuracy_2: 90.1% Loss_2: 0.004087  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.003048, Accuracy_2: 95.0% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000055, Accuracy_2: 89.4% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000425, Accuracy_2: 89.4% Loss_2: 0.003556  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000319, Accuracy_2: 90.8% Loss_2: 0.000503  [11985/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000007  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000044  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003551, Accuracy_2: 90.1% Loss_2: 0.000007  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002961, Accuracy_2: 92.2% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.5%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000250, Accuracy_2: 87.9% Loss_2: 0.000349  [  141/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000326, Accuracy_2: 95.0% Loss_2: 0.000003  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001379, Accuracy_2: 91.5% Loss_2: 0.007189  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000227, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000013  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000083, Accuracy_2: 87.9% Loss_2: 0.000393  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000811, Accuracy_2: 93.6% Loss_2: 0.000976  [ 3525/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000574, Accuracy_2: 93.6% Loss_2: 0.000409  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000001  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000024, Accuracy_2: 92.2% Loss_2: 0.001179  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001152, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000313, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.005205, Accuracy_2: 95.7% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000763, Accuracy_2: 92.2% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000005, Accuracy_2: 91.5% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 91.5% Loss_2: 0.000248  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000130, Accuracy_2: 91.5% Loss_2: 0.000697  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "Accuracy_1: 85.1%, Loss_1: 0.004621, Accuracy_2: 86.5% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.005032  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000003, Accuracy_2: 88.7% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000776, Accuracy_2: 96.5% Loss_2: 0.000221  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000193  [ 3525/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.002080, Accuracy_2: 95.7% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.004612, Accuracy_2: 87.2% Loss_2: 0.000230  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000418, Accuracy_2: 92.2% Loss_2: 0.000022  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003943, Accuracy_2: 92.9% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000136, Accuracy_2: 89.4% Loss_2: 0.000051  [ 6345/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000001, Accuracy_2: 85.1% Loss_2: 0.002137  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001729, Accuracy_2: 93.6% Loss_2: 0.000684  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000027, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000259, Accuracy_2: 94.3% Loss_2: 0.000003  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001295, Accuracy_2: 94.3% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000118  [ 9729/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000921, Accuracy_2: 89.4% Loss_2: 0.000323  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001424, Accuracy_2: 93.6% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000616, Accuracy_2: 88.7% Loss_2: 0.001451  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001797, Accuracy_2: 87.9% Loss_2: 0.000348  [13113/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000033, Accuracy_2: 88.7% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000243  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000701, Accuracy_2: 90.1% Loss_2: 0.000078  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.6%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "Accuracy_1: 97.2%, Loss_1: 0.000000, Accuracy_2: 97.2% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001157, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000090, Accuracy_2: 88.7% Loss_2: 0.000878  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000006, Accuracy_2: 87.2% Loss_2: 0.001616  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.002413  [ 4089/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001338, Accuracy_2: 84.4% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000297, Accuracy_2: 93.6% Loss_2: 0.000190  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000767, Accuracy_2: 92.9% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003434, Accuracy_2: 87.2% Loss_2: 0.000144  [ 6909/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.002670  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000229  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000823, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000007  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000015, Accuracy_2: 91.5% Loss_2: 0.000010  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.005606  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001447, Accuracy_2: 88.7% Loss_2: 0.000077  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001299, Accuracy_2: 90.8% Loss_2: 0.002368  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000017, Accuracy_2: 90.1% Loss_2: 0.000011  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000056  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000006  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.5%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003319, Accuracy_2: 91.5% Loss_2: 0.000279  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001367, Accuracy_2: 87.9% Loss_2: 0.001308  [  705/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.003970, Accuracy_2: 87.9% Loss_2: 0.000064  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001386, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000834  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001542, Accuracy_2: 87.9% Loss_2: 0.000400  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001604, Accuracy_2: 87.9% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000744, Accuracy_2: 92.9% Loss_2: 0.000019  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001540, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000227  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000001  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000055, Accuracy_2: 90.1% Loss_2: 0.000604  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000031, Accuracy_2: 90.1% Loss_2: 0.000110  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003629, Accuracy_2: 95.0% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000687, Accuracy_2: 90.1% Loss_2: 0.000044  [ 9729/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000286, Accuracy_2: 87.9% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.009132, Accuracy_2: 88.7% Loss_2: 0.001943  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002599, Accuracy_2: 93.6% Loss_2: 0.000314  [11421/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.004528  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000124  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.002250, Accuracy_2: 90.1% Loss_2: 0.000006  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000007, Accuracy_2: 90.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000606, Accuracy_2: 88.7% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.4%, Avg loss: 0.000003\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001685, Accuracy_2: 90.1% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000792  [ 1269/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000253, Accuracy_2: 90.1% Loss_2: 0.000082  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000830  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001105, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000599, Accuracy_2: 92.9% Loss_2: 0.001654  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001738, Accuracy_2: 92.9% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000006, Accuracy_2: 92.2% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000072, Accuracy_2: 91.5% Loss_2: 0.000002  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000429  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000696, Accuracy_2: 90.8% Loss_2: 0.000038  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000892, Accuracy_2: 91.5% Loss_2: 0.000144  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001186, Accuracy_2: 90.8% Loss_2: 0.000247  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000011, Accuracy_2: 90.8% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000002, Accuracy_2: 92.9% Loss_2: 0.000040  [11421/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000053, Accuracy_2: 95.0% Loss_2: 0.000001  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000544, Accuracy_2: 94.3% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000010, Accuracy_2: 90.1% Loss_2: 0.000515  [13677/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000042, Accuracy_2: 85.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000993, Accuracy_2: 92.2% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001207, Accuracy_2: 92.2% Loss_2: 0.000420  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000010, Accuracy_2: 86.5% Loss_2: 0.000727  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000012  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.002476, Accuracy_2: 95.7% Loss_2: 0.001183  [ 5217/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000013  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000005, Accuracy_2: 88.7% Loss_2: 0.000223  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000016, Accuracy_2: 87.2% Loss_2: 0.000891  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001434, Accuracy_2: 92.9% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000347, Accuracy_2: 91.5% Loss_2: 0.001490  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001011, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000243, Accuracy_2: 92.9% Loss_2: 0.000175  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000859, Accuracy_2: 92.9% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000014, Accuracy_2: 91.5% Loss_2: 0.000889  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000153  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001014, Accuracy_2: 90.8% Loss_2: 0.001510  [11985/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000184, Accuracy_2: 96.5% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003745, Accuracy_2: 92.9% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000013, Accuracy_2: 85.8% Loss_2: 0.002524  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.001432  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002186, Accuracy_2: 90.1% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 81.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.6%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000036  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.005868  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.004563, Accuracy_2: 92.9% Loss_2: 0.001484  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000901, Accuracy_2: 93.6% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000741  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000002  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000386, Accuracy_2: 90.8% Loss_2: 0.001758  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000454  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.002816  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000008, Accuracy_2: 90.8% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000420, Accuracy_2: 87.2% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000573, Accuracy_2: 89.4% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000093, Accuracy_2: 92.9% Loss_2: 0.000012  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000498, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.001540, Accuracy_2: 97.2% Loss_2: 0.000022  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002676, Accuracy_2: 92.2% Loss_2: 0.002247  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001044, Accuracy_2: 92.2% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000876  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000077, Accuracy_2: 92.9% Loss_2: 0.000463  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000134, Accuracy_2: 92.9% Loss_2: 0.001101  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000795, Accuracy_2: 91.5% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.002212  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.1%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000879, Accuracy_2: 96.5% Loss_2: 0.000001  [  141/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002750, Accuracy_2: 92.9% Loss_2: 0.001140  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000277  [ 1269/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000001  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000819, Accuracy_2: 91.5% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.001187  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000001  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003521, Accuracy_2: 92.2% Loss_2: 0.000071  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000039, Accuracy_2: 89.4% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000041, Accuracy_2: 93.6% Loss_2: 0.000015  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000596  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000087, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000324  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000492, Accuracy_2: 86.5% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001054, Accuracy_2: 92.9% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000109, Accuracy_2: 92.2% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002349  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001654  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.002499  [14241/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000015, Accuracy_2: 85.8% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.003275  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000216, Accuracy_2: 91.5% Loss_2: 0.007261  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000972, Accuracy_2: 90.1% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.001616  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000137, Accuracy_2: 92.2% Loss_2: 0.000019  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.002482  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002656, Accuracy_2: 92.9% Loss_2: 0.001861  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000256, Accuracy_2: 86.5% Loss_2: 0.000001  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000006  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000037, Accuracy_2: 90.1% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000960, Accuracy_2: 91.5% Loss_2: 0.000029  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000578  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000609  [ 9165/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000230, Accuracy_2: 95.0% Loss_2: 0.000002  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002240, Accuracy_2: 88.7% Loss_2: 0.000666  [10293/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000053, Accuracy_2: 95.7% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000826  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000101, Accuracy_2: 86.5% Loss_2: 0.000428  [12549/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000643  [13677/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000003, Accuracy_2: 95.7% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000018, Accuracy_2: 95.0% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003256, Accuracy_2: 89.4% Loss_2: 0.000142  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000142, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000042  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001966, Accuracy_2: 92.9% Loss_2: 0.001577  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001365, Accuracy_2: 93.6% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001381, Accuracy_2: 93.6% Loss_2: 0.000056  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000757, Accuracy_2: 90.1% Loss_2: 0.000011  [ 4653/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000593, Accuracy_2: 86.5% Loss_2: 0.000222  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001832, Accuracy_2: 91.5% Loss_2: 0.001559  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000004  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001453, Accuracy_2: 89.4% Loss_2: 0.000017  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000824, Accuracy_2: 89.4% Loss_2: 0.000001  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000371, Accuracy_2: 93.6% Loss_2: 0.000005  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000617, Accuracy_2: 88.7% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000370  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000505, Accuracy_2: 92.2% Loss_2: 0.000009  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000162, Accuracy_2: 92.2% Loss_2: 0.000018  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001238, Accuracy_2: 92.9% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001558  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000450, Accuracy_2: 90.1% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000323  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000004  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000660, Accuracy_2: 88.7% Loss_2: 0.000341  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000033  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001470, Accuracy_2: 89.4% Loss_2: 0.002543  [  141/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.001031, Accuracy_2: 95.0% Loss_2: 0.000943  [  705/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000007, Accuracy_2: 90.8% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001016, Accuracy_2: 92.2% Loss_2: 0.000271  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000481, Accuracy_2: 94.3% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000132  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000938  [ 3525/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000539  [ 4089/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.005238  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001540, Accuracy_2: 90.8% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000185, Accuracy_2: 88.7% Loss_2: 0.000014  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000022, Accuracy_2: 93.6% Loss_2: 0.000027  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.004267, Accuracy_2: 94.3% Loss_2: 0.000044  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000021  [ 7473/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000365, Accuracy_2: 87.2% Loss_2: 0.000624  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000095  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.005375, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000439, Accuracy_2: 90.1% Loss_2: 0.000594  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.004471  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000001  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000339  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001056, Accuracy_2: 92.2% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000411  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000183, Accuracy_2: 91.5% Loss_2: 0.000001  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000010  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000052, Accuracy_2: 91.5% Loss_2: 0.000951  [ 1269/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000036, Accuracy_2: 94.3% Loss_2: 0.000007  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000289, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000057  [ 3525/15250]\n",
      "Accuracy_1: 97.2%, Loss_1: 0.005145, Accuracy_2: 97.2% Loss_2: 0.000075  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000329, Accuracy_2: 90.1% Loss_2: 0.000101  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000444, Accuracy_2: 92.2% Loss_2: 0.000298  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000172, Accuracy_2: 90.8% Loss_2: 0.000001  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000510, Accuracy_2: 91.5% Loss_2: 0.000009  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000115, Accuracy_2: 89.4% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000041, Accuracy_2: 88.7% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000290, Accuracy_2: 90.8% Loss_2: 0.000022  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001525, Accuracy_2: 91.5% Loss_2: 0.000003  [ 8601/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002312, Accuracy_2: 92.9% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001330, Accuracy_2: 90.8% Loss_2: 0.000002  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001003, Accuracy_2: 91.5% Loss_2: 0.000399  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000012, Accuracy_2: 85.1% Loss_2: 0.000315  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000375  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "Accuracy_1: 85.8%, Loss_1: 0.013376, Accuracy_2: 87.2% Loss_2: 0.007974  [  141/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000694, Accuracy_2: 94.3% Loss_2: 0.001668  [  705/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001690, Accuracy_2: 86.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000004, Accuracy_2: 90.1% Loss_2: 0.000004  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000623  [ 3525/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000519, Accuracy_2: 96.5% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001236, Accuracy_2: 95.0% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000077  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000529, Accuracy_2: 90.1% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.001035, Accuracy_2: 95.7% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000006, Accuracy_2: 87.9% Loss_2: 0.001301  [ 8037/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000678, Accuracy_2: 86.5% Loss_2: 0.000010  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000489, Accuracy_2: 92.9% Loss_2: 0.001429  [ 9165/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001713, Accuracy_2: 88.7% Loss_2: 0.000510  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000262  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001337, Accuracy_2: 90.1% Loss_2: 0.000206  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002540, Accuracy_2: 89.4% Loss_2: 0.000002  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.001118  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001318, Accuracy_2: 91.5% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000006, Accuracy_2: 90.8% Loss_2: 0.001619  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000332, Accuracy_2: 90.1% Loss_2: 0.000445  [14241/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000030, Accuracy_2: 93.6% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000008, Accuracy_2: 90.1% Loss_2: 0.000033  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000006  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000004, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000283  [ 2961/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001460, Accuracy_2: 95.0% Loss_2: 0.000927  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003527, Accuracy_2: 90.8% Loss_2: 0.000007  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.003334  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.004036  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001060, Accuracy_2: 94.3% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000001  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002779, Accuracy_2: 88.7% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.003019, Accuracy_2: 88.7% Loss_2: 0.000759  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000003, Accuracy_2: 90.1% Loss_2: 0.000621  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000234, Accuracy_2: 94.3% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000139, Accuracy_2: 83.7% Loss_2: 0.003291  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000015, Accuracy_2: 93.6% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000363, Accuracy_2: 92.2% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000002, Accuracy_2: 92.9% Loss_2: 0.000237  [11421/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000041, Accuracy_2: 92.9% Loss_2: 0.000902  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000003  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002654, Accuracy_2: 93.6% Loss_2: 0.000018  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000701, Accuracy_2: 92.9% Loss_2: 0.001003  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002744, Accuracy_2: 93.6% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000738, Accuracy_2: 92.2% Loss_2: 0.000007  [  141/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000385, Accuracy_2: 92.2% Loss_2: 0.000350  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.003639  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000002, Accuracy_2: 91.5% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000028, Accuracy_2: 91.5% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.001813  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000051  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000619  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000242, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.002327  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003398, Accuracy_2: 87.9% Loss_2: 0.000277  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000412, Accuracy_2: 90.1% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001901, Accuracy_2: 87.9% Loss_2: 0.000131  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000008  [ 9165/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000257, Accuracy_2: 87.2% Loss_2: 0.000432  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000177  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001168, Accuracy_2: 93.6% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001796, Accuracy_2: 89.4% Loss_2: 0.001108  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000056, Accuracy_2: 93.6% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001727, Accuracy_2: 91.5% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000730, Accuracy_2: 87.9% Loss_2: 0.000306  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000004, Accuracy_2: 88.7% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.5%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000050, Accuracy_2: 90.8% Loss_2: 0.000265  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.002005  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001623  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000255, Accuracy_2: 93.6% Loss_2: 0.000011  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000013  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000029, Accuracy_2: 93.6% Loss_2: 0.000002  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000192, Accuracy_2: 90.1% Loss_2: 0.000506  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000002, Accuracy_2: 87.9% Loss_2: 0.000001  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000002  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000001  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000105, Accuracy_2: 90.8% Loss_2: 0.000001  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000077  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000261, Accuracy_2: 92.9% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000367  [ 7473/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.004400, Accuracy_2: 95.7% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000003, Accuracy_2: 92.2% Loss_2: 0.000011  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002114, Accuracy_2: 90.1% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000597, Accuracy_2: 89.4% Loss_2: 0.000631  [10293/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001221, Accuracy_2: 95.0% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.005356, Accuracy_2: 92.9% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000295, Accuracy_2: 92.9% Loss_2: 0.000171  [11985/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002379, Accuracy_2: 88.7% Loss_2: 0.004658  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.006793, Accuracy_2: 93.6% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000938, Accuracy_2: 92.2% Loss_2: 0.000370  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001402, Accuracy_2: 88.7% Loss_2: 0.001739  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001217, Accuracy_2: 89.4% Loss_2: 0.001311  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000003\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.002465, Accuracy_2: 90.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000927, Accuracy_2: 92.9% Loss_2: 0.002891  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000464, Accuracy_2: 91.5% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000149  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000007  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000001  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000503, Accuracy_2: 90.8% Loss_2: 0.000020  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.011469, Accuracy_2: 92.2% Loss_2: 0.000918  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002008, Accuracy_2: 90.8% Loss_2: 0.003114  [ 7473/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000774  [ 8037/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000361  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.002709  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000048  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.003292  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000886  [12549/15250]\n",
      "Accuracy_1: 97.2%, Loss_1: 0.000000, Accuracy_2: 97.2% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000283, Accuracy_2: 92.2% Loss_2: 0.000088  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000584, Accuracy_2: 90.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000275, Accuracy_2: 91.5% Loss_2: 0.000142  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.2%, Avg loss: 0.000003\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000129  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000972, Accuracy_2: 89.4% Loss_2: 0.000904  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.003153, Accuracy_2: 91.5% Loss_2: 0.001063  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001518, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.001088  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.002574  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000419, Accuracy_2: 91.5% Loss_2: 0.000944  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000094, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001795  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002413, Accuracy_2: 90.8% Loss_2: 0.000949  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000706  [ 6345/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000373  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.003669  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000581  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000934, Accuracy_2: 87.9% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000212  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000055  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001247, Accuracy_2: 90.1% Loss_2: 0.000679  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000426, Accuracy_2: 91.5% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000003  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000754  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.002129  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000987  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000314, Accuracy_2: 87.9% Loss_2: 0.000101  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001992, Accuracy_2: 92.2% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.1%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001856, Accuracy_2: 93.6% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000504, Accuracy_2: 87.2% Loss_2: 0.000035  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.003254, Accuracy_2: 94.3% Loss_2: 0.000041  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000222, Accuracy_2: 90.1% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000231  [ 3525/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000001  [ 5217/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001060, Accuracy_2: 89.4% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000082, Accuracy_2: 90.1% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000497  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 93.6% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000051  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.003885, Accuracy_2: 93.6% Loss_2: 0.002264  [ 8601/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001289, Accuracy_2: 90.8% Loss_2: 0.000002  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000027, Accuracy_2: 91.5% Loss_2: 0.000011  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001198, Accuracy_2: 89.4% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001121  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000018  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000002  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002293  [14241/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.002114, Accuracy_2: 87.9% Loss_2: 0.004532  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.7%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000120  [  141/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000241, Accuracy_2: 93.6% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000195, Accuracy_2: 90.8% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000177, Accuracy_2: 88.7% Loss_2: 0.005786  [ 1833/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000060, Accuracy_2: 90.1% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001276, Accuracy_2: 92.9% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000569, Accuracy_2: 93.6% Loss_2: 0.001235  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.001961  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000210, Accuracy_2: 92.9% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000008  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000109, Accuracy_2: 89.4% Loss_2: 0.000001  [ 7473/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000388  [ 8037/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000038  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000124  [ 9729/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002033  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000018, Accuracy_2: 87.2% Loss_2: 0.000119  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000029  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000400, Accuracy_2: 89.4% Loss_2: 0.000212  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001452  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000069, Accuracy_2: 89.4% Loss_2: 0.000856  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000010, Accuracy_2: 90.8% Loss_2: 0.000007  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000007, Accuracy_2: 92.2% Loss_2: 0.000002  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000002, Accuracy_2: 88.7% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000722, Accuracy_2: 91.5% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000340, Accuracy_2: 89.4% Loss_2: 0.003513  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000955, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 96.5% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000378, Accuracy_2: 90.8% Loss_2: 0.000720  [ 4653/15250]\n",
      "Accuracy_1: 99.3%, Loss_1: 0.000000, Accuracy_2: 97.9% Loss_2: 0.002371  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.001192  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.004258  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000004  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000067, Accuracy_2: 94.3% Loss_2: 0.000013  [ 7473/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.002182  [ 8037/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.001188  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000003, Accuracy_2: 88.7% Loss_2: 0.000100  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000032, Accuracy_2: 88.7% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000012  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002708, Accuracy_2: 91.5% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000727, Accuracy_2: 92.2% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000163, Accuracy_2: 91.5% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001557, Accuracy_2: 87.9% Loss_2: 0.000798  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000093, Accuracy_2: 90.1% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000408  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000003\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001199, Accuracy_2: 90.8% Loss_2: 0.000958  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000436, Accuracy_2: 93.6% Loss_2: 0.000049  [  705/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.002085  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001312, Accuracy_2: 92.2% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000599, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000041  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000478, Accuracy_2: 92.9% Loss_2: 0.000353  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 90.1% Loss_2: 0.000001  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000249  [ 4653/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002124, Accuracy_2: 93.6% Loss_2: 0.000003  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000065, Accuracy_2: 90.8% Loss_2: 0.003532  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000117, Accuracy_2: 89.4% Loss_2: 0.000640  [ 7473/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000806, Accuracy_2: 95.0% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001465, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000466  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001504, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000512  [10857/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000340, Accuracy_2: 97.2% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000286, Accuracy_2: 89.4% Loss_2: 0.001303  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000002  [12549/15250]\n",
      "Accuracy_1: 97.9%, Loss_1: 0.000000, Accuracy_2: 96.5% Loss_2: 0.000777  [13113/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000125  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000949, Accuracy_2: 92.2% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000171  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.5%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001569, Accuracy_2: 90.8% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000082  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000015  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001252, Accuracy_2: 87.9% Loss_2: 0.002224  [ 2961/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000042, Accuracy_2: 89.4% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001187  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002573, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.002273  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000069  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000211  [ 6345/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000912, Accuracy_2: 90.1% Loss_2: 0.000343  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001891, Accuracy_2: 92.2% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001143, Accuracy_2: 95.0% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002718  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001149, Accuracy_2: 92.2% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000402, Accuracy_2: 93.6% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000417, Accuracy_2: 92.9% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000030  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000007  [13677/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001069, Accuracy_2: 91.5% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000003, Accuracy_2: 94.3% Loss_2: 0.000002  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.5%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 81.9%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000010  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000461  [ 1269/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000414, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000396, Accuracy_2: 92.9% Loss_2: 0.000513  [ 2397/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000021, Accuracy_2: 94.3% Loss_2: 0.000065  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000001, Accuracy_2: 94.3% Loss_2: 0.000550  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000930  [ 4653/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.003321  [ 5217/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000001, Accuracy_2: 94.3% Loss_2: 0.000179  [ 5781/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000301, Accuracy_2: 92.9% Loss_2: 0.000312  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000519, Accuracy_2: 92.9% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000422, Accuracy_2: 89.4% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000381  [ 8601/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000144, Accuracy_2: 89.4% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000004, Accuracy_2: 95.0% Loss_2: 0.000405  [11421/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001811  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001269, Accuracy_2: 93.6% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000459, Accuracy_2: 92.2% Loss_2: 0.000137  [13677/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000521  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000297  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000034, Accuracy_2: 92.2% Loss_2: 0.001217  [  141/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.001016, Accuracy_2: 86.5% Loss_2: 0.002539  [  705/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.002478, Accuracy_2: 88.7% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000175, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000406, Accuracy_2: 92.9% Loss_2: 0.003525  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000180, Accuracy_2: 95.0% Loss_2: 0.000001  [ 2961/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.003302, Accuracy_2: 89.4% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000956  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000011, Accuracy_2: 89.4% Loss_2: 0.000008  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000012, Accuracy_2: 90.8% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.001800  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000200, Accuracy_2: 89.4% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.006160, Accuracy_2: 92.2% Loss_2: 0.001674  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000005, Accuracy_2: 90.8% Loss_2: 0.001516  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001839, Accuracy_2: 92.9% Loss_2: 0.002684  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000008, Accuracy_2: 90.1% Loss_2: 0.000004  [ 9729/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000003, Accuracy_2: 90.8% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001164, Accuracy_2: 87.2% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000009, Accuracy_2: 91.5% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000983  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000023, Accuracy_2: 89.4% Loss_2: 0.000406  [12549/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.6%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.001610  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000113, Accuracy_2: 90.1% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000002  [ 1269/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000032, Accuracy_2: 93.6% Loss_2: 0.000006  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000094, Accuracy_2: 91.5% Loss_2: 0.000263  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000022, Accuracy_2: 90.1% Loss_2: 0.000016  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000816, Accuracy_2: 91.5% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000009, Accuracy_2: 91.5% Loss_2: 0.000855  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000530, Accuracy_2: 92.9% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000010  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000034, Accuracy_2: 92.2% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003933, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.006943  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.001034, Accuracy_2: 85.8% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001333, Accuracy_2: 90.1% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 97.2%, Loss_1: 0.000000, Accuracy_2: 97.2% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000399, Accuracy_2: 92.2% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000458, Accuracy_2: 92.2% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000012, Accuracy_2: 93.6% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.002854  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000007, Accuracy_2: 87.9% Loss_2: 0.000939  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.3%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.1%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002820, Accuracy_2: 93.6% Loss_2: 0.002987  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000003, Accuracy_2: 93.6% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000675, Accuracy_2: 92.2% Loss_2: 0.004353  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000099  [ 1833/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000056, Accuracy_2: 87.9% Loss_2: 0.000001  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002066, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000253, Accuracy_2: 93.6% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.001445, Accuracy_2: 95.0% Loss_2: 0.000690  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.002176  [ 4653/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000260, Accuracy_2: 92.2% Loss_2: 0.002661  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000045, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000298, Accuracy_2: 89.4% Loss_2: 0.000612  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000030  [ 6909/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.001713  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000002  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000002, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000226, Accuracy_2: 92.9% Loss_2: 0.006520  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000026, Accuracy_2: 87.9% Loss_2: 0.000122  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001482, Accuracy_2: 92.9% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.000000, Accuracy_2: 83.0% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000835  [11985/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000003  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000235  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000005, Accuracy_2: 88.7% Loss_2: 0.000632  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000001\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.004879  [  705/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.003940, Accuracy_2: 86.5% Loss_2: 0.000414  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000619, Accuracy_2: 92.9% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000024, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.000309  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000025, Accuracy_2: 92.9% Loss_2: 0.003105  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000131, Accuracy_2: 89.4% Loss_2: 0.000436  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003158, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000033, Accuracy_2: 94.3% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001898, Accuracy_2: 95.0% Loss_2: 0.000007  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000041, Accuracy_2: 91.5% Loss_2: 0.000002  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000011, Accuracy_2: 90.1% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000554, Accuracy_2: 94.3% Loss_2: 0.000188  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001536, Accuracy_2: 92.9% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001244  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000035, Accuracy_2: 87.9% Loss_2: 0.000905  [10857/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000010, Accuracy_2: 87.9% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000239  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000065, Accuracy_2: 92.9% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000042  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000388  [14241/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000409, Accuracy_2: 94.3% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.1%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000002  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000439, Accuracy_2: 92.2% Loss_2: 0.000059  [  705/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000430, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000617, Accuracy_2: 94.3% Loss_2: 0.002869  [ 1833/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000519, Accuracy_2: 93.6% Loss_2: 0.007762  [ 2397/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000022  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001298, Accuracy_2: 91.5% Loss_2: 0.000001  [ 3525/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.001060  [ 4089/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000002  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002077, Accuracy_2: 94.3% Loss_2: 0.000003  [ 5781/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.004451, Accuracy_2: 95.7% Loss_2: 0.000010  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003192, Accuracy_2: 90.8% Loss_2: 0.000824  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000434, Accuracy_2: 91.5% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 85.1% Loss_2: 0.000120  [ 8037/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.005198, Accuracy_2: 87.9% Loss_2: 0.002927  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001847  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000152, Accuracy_2: 90.8% Loss_2: 0.000002  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001417  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001823, Accuracy_2: 89.4% Loss_2: 0.000003  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 85.8% Loss_2: 0.000268  [12549/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000001  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000049, Accuracy_2: 90.1% Loss_2: 0.000004  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.002807  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000004, Accuracy_2: 91.5% Loss_2: 0.000604  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000159, Accuracy_2: 90.8% Loss_2: 0.001617  [  141/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002211, Accuracy_2: 89.4% Loss_2: 0.002975  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000874, Accuracy_2: 88.7% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000256, Accuracy_2: 94.3% Loss_2: 0.000003  [ 2961/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000394, Accuracy_2: 90.1% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000401, Accuracy_2: 85.8% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000114, Accuracy_2: 90.8% Loss_2: 0.000695  [ 6345/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.002416, Accuracy_2: 89.4% Loss_2: 0.001644  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000039, Accuracy_2: 89.4% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000005, Accuracy_2: 92.9% Loss_2: 0.000006  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000014  [ 8601/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.001244  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000170, Accuracy_2: 91.5% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000498, Accuracy_2: 91.5% Loss_2: 0.005312  [10293/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001248, Accuracy_2: 95.0% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000741, Accuracy_2: 89.4% Loss_2: 0.000059  [11421/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000007, Accuracy_2: 89.4% Loss_2: 0.001520  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000449  [12549/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000005  [13113/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000319, Accuracy_2: 90.1% Loss_2: 0.001139  [13677/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000504, Accuracy_2: 87.9% Loss_2: 0.001787  [14241/15250]\n",
      "Accuracy_1: 83.0%, Loss_1: 0.001934, Accuracy_2: 84.4% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.4%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.7%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000885, Accuracy_2: 90.8% Loss_2: 0.004927  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000073, Accuracy_2: 91.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 82.3%, Loss_1: 0.000000, Accuracy_2: 81.6% Loss_2: 0.000057  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000302, Accuracy_2: 92.2% Loss_2: 0.002576  [ 2397/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000001, Accuracy_2: 94.3% Loss_2: 0.000004  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.001954, Accuracy_2: 91.5% Loss_2: 0.000995  [ 4653/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000577, Accuracy_2: 95.7% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000646, Accuracy_2: 90.8% Loss_2: 0.000460  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000006  [ 6345/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000014, Accuracy_2: 90.1% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000700, Accuracy_2: 90.1% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001494  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000002  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000002, Accuracy_2: 89.4% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.001643  [10293/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001837, Accuracy_2: 90.8% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.003665, Accuracy_2: 92.2% Loss_2: 0.000565  [12549/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000457  [13113/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.002982  [13677/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000072  [14241/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002154  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.4%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.1%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000253, Accuracy_2: 92.9% Loss_2: 0.000042  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000006, Accuracy_2: 89.4% Loss_2: 0.001091  [  705/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000114, Accuracy_2: 88.7% Loss_2: 0.000134  [ 1269/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000295, Accuracy_2: 92.9% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000050, Accuracy_2: 89.4% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000147  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000014  [ 4089/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.001429, Accuracy_2: 92.9% Loss_2: 0.000001  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.003813, Accuracy_2: 90.8% Loss_2: 0.000239  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000010, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000018, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000012, Accuracy_2: 90.1% Loss_2: 0.001056  [ 6909/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000336, Accuracy_2: 88.7% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000633, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000005  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000001, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001357, Accuracy_2: 90.1% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.002451, Accuracy_2: 86.5% Loss_2: 0.000003  [10857/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000041, Accuracy_2: 92.2% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.002975  [13113/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000791  [13677/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000247, Accuracy_2: 86.5% Loss_2: 0.000969  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.001453  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 84.2%, Avg loss: 0.000001 \n",
      "\n",
      "[+] Saving Model...\n",
      "[!] Models Saved.\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000538, Accuracy_2: 88.7% Loss_2: 0.002189  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000084, Accuracy_2: 89.4% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000135  [ 1269/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000065  [ 1833/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.001048, Accuracy_2: 89.4% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000003, Accuracy_2: 94.3% Loss_2: 0.001063  [ 4089/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.000475, Accuracy_2: 86.5% Loss_2: 0.000688  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000073, Accuracy_2: 89.4% Loss_2: 0.000711  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.003636, Accuracy_2: 90.8% Loss_2: 0.000449  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000121, Accuracy_2: 92.2% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000009, Accuracy_2: 87.2% Loss_2: 0.000258  [ 7473/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000021, Accuracy_2: 87.9% Loss_2: 0.000947  [ 8037/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000020, Accuracy_2: 92.9% Loss_2: 0.000167  [ 8601/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000780, Accuracy_2: 87.9% Loss_2: 0.002150  [ 9165/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.001064, Accuracy_2: 87.9% Loss_2: 0.000001  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000015  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000066, Accuracy_2: 90.8% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000025  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.003192, Accuracy_2: 89.4% Loss_2: 0.002538  [11985/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000009, Accuracy_2: 91.5% Loss_2: 0.000023  [12549/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000249, Accuracy_2: 87.2% Loss_2: 0.000784  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.003703, Accuracy_2: 92.2% Loss_2: 0.001092  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.002855  [14241/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000019, Accuracy_2: 88.7% Loss_2: 0.000003  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.7%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000061, Accuracy_2: 95.0% Loss_2: 0.000510  [  141/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000505, Accuracy_2: 90.1% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000348, Accuracy_2: 96.5% Loss_2: 0.000001  [ 1833/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001772, Accuracy_2: 92.2% Loss_2: 0.000004  [ 2397/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000386, Accuracy_2: 90.1% Loss_2: 0.002244  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000005, Accuracy_2: 88.7% Loss_2: 0.001158  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000800, Accuracy_2: 88.7% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000401  [ 4653/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000286, Accuracy_2: 92.2% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000087, Accuracy_2: 96.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000331, Accuracy_2: 94.3% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000553, Accuracy_2: 92.9% Loss_2: 0.000075  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000132, Accuracy_2: 95.0% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002662, Accuracy_2: 92.9% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000014  [11421/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000580, Accuracy_2: 89.4% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000107, Accuracy_2: 92.2% Loss_2: 0.000006  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000922, Accuracy_2: 94.3% Loss_2: 0.000027  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.003231  [13677/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.001307, Accuracy_2: 92.9% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000059, Accuracy_2: 93.6% Loss_2: 0.000005  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000018  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000936, Accuracy_2: 90.1% Loss_2: 0.000038  [  705/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000852  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001202, Accuracy_2: 93.6% Loss_2: 0.000000  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000302, Accuracy_2: 92.2% Loss_2: 0.002099  [ 2397/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000025  [ 2961/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000979  [ 4089/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000001, Accuracy_2: 92.2% Loss_2: 0.000123  [ 4653/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000003, Accuracy_2: 95.0% Loss_2: 0.001826  [ 5781/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000259  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.9% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000031  [ 7473/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000398, Accuracy_2: 92.2% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000006, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000629, Accuracy_2: 90.1% Loss_2: 0.004621  [ 9729/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002432, Accuracy_2: 91.5% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000512, Accuracy_2: 92.9% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 87.2%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000002  [11985/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000001, Accuracy_2: 87.2% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000039, Accuracy_2: 90.1% Loss_2: 0.000818  [13113/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [13677/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000003, Accuracy_2: 95.0% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000467, Accuracy_2: 89.4% Loss_2: 0.001499  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.5%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.3%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000109, Accuracy_2: 90.8% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000323, Accuracy_2: 92.9% Loss_2: 0.000024  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000005, Accuracy_2: 91.5% Loss_2: 0.000005  [ 1269/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.002055  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.002131, Accuracy_2: 92.2% Loss_2: 0.000012  [ 2397/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.004873, Accuracy_2: 87.2% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000044, Accuracy_2: 89.4% Loss_2: 0.000436  [ 3525/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000891, Accuracy_2: 88.7% Loss_2: 0.001208  [ 4089/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000144  [ 4653/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000045, Accuracy_2: 95.0% Loss_2: 0.001065  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000059, Accuracy_2: 92.2% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001850  [ 6345/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000273, Accuracy_2: 89.4% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000081, Accuracy_2: 95.0% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000925, Accuracy_2: 92.2% Loss_2: 0.001638  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000045, Accuracy_2: 89.4% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000404, Accuracy_2: 87.2% Loss_2: 0.002132  [10293/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.002007, Accuracy_2: 91.5% Loss_2: 0.000233  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.002922, Accuracy_2: 90.8% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000721  [13677/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000052, Accuracy_2: 89.4% Loss_2: 0.000690  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.0%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000001, Accuracy_2: 92.9% Loss_2: 0.000000  [  141/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000001  [  705/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000312, Accuracy_2: 90.8% Loss_2: 0.000014  [ 1833/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000474  [ 2961/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000350, Accuracy_2: 94.3% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.001158, Accuracy_2: 87.9% Loss_2: 0.000065  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.008122, Accuracy_2: 92.2% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000008, Accuracy_2: 95.7% Loss_2: 0.000001  [ 5781/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.003608  [ 6345/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000000, Accuracy_2: 95.7% Loss_2: 0.000069  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000200, Accuracy_2: 87.2% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000760, Accuracy_2: 92.2% Loss_2: 0.000503  [ 8601/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.000360  [ 9165/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000007, Accuracy_2: 89.4% Loss_2: 0.000531  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.001380, Accuracy_2: 94.3% Loss_2: 0.000001  [10293/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000013, Accuracy_2: 92.2% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000370, Accuracy_2: 90.8% Loss_2: 0.003250  [11985/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000196, Accuracy_2: 91.5% Loss_2: 0.000014  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [13113/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001434  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 89.4% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 82.9%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 84.1%, Avg loss: 0.000001 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000468, Accuracy_2: 89.4% Loss_2: 0.009170  [  141/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 95.7%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.001261  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000575, Accuracy_2: 91.5% Loss_2: 0.000422  [ 1833/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000007, Accuracy_2: 88.7% Loss_2: 0.000504  [ 3525/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.001270  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000587, Accuracy_2: 92.9% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.004637, Accuracy_2: 90.8% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 85.1%, Loss_1: 0.000391, Accuracy_2: 85.1% Loss_2: 0.000876  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000004, Accuracy_2: 90.8% Loss_2: 0.001907  [ 7473/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000001  [ 8601/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001092, Accuracy_2: 90.8% Loss_2: 0.001639  [ 9729/15250]\n",
      "Accuracy_1: 85.8%, Loss_1: 0.001067, Accuracy_2: 88.7% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 87.9% Loss_2: 0.000021  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000006, Accuracy_2: 92.2% Loss_2: 0.000548  [11421/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.001047  [11985/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.004924, Accuracy_2: 90.1% Loss_2: 0.000001  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000401  [13113/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000261, Accuracy_2: 92.9% Loss_2: 0.002422  [13677/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [14241/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000010, Accuracy_2: 94.3% Loss_2: 0.000000  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.2%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.2%, Avg loss: 0.000003 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000191  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000126, Accuracy_2: 92.9% Loss_2: 0.000009  [  705/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000691  [ 1269/15250]\n",
      "Accuracy_1: 95.0%, Loss_1: 0.000000, Accuracy_2: 95.0% Loss_2: 0.000001  [ 1833/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000292  [ 2397/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000270, Accuracy_2: 89.4% Loss_2: 0.000005  [ 2961/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000013, Accuracy_2: 92.9% Loss_2: 0.003469  [ 3525/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000362, Accuracy_2: 92.2% Loss_2: 0.000822  [ 4089/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000095, Accuracy_2: 89.4% Loss_2: 0.000774  [ 4653/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000004, Accuracy_2: 92.9% Loss_2: 0.000009  [ 5781/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000443, Accuracy_2: 88.7% Loss_2: 0.000010  [ 6345/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.001205, Accuracy_2: 90.1% Loss_2: 0.000002  [ 6909/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000264, Accuracy_2: 92.9% Loss_2: 0.000899  [ 7473/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000028, Accuracy_2: 91.5% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000227  [ 9165/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000015, Accuracy_2: 94.3% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000001  [10293/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000000, Accuracy_2: 94.3% Loss_2: 0.000000  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.003685, Accuracy_2: 93.6% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000389, Accuracy_2: 90.8% Loss_2: 0.000003  [13113/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000071  [13677/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.001716, Accuracy_2: 95.0% Loss_2: 0.000160  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000002  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.1%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 82.8%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000744, Accuracy_2: 91.5% Loss_2: 0.000003  [  141/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000771, Accuracy_2: 93.6% Loss_2: 0.000000  [  705/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000000  [ 1269/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001527, Accuracy_2: 92.2% Loss_2: 0.000789  [ 1833/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000001, Accuracy_2: 88.7% Loss_2: 0.000000  [ 2397/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000639, Accuracy_2: 88.7% Loss_2: 0.000000  [ 2961/15250]\n",
      "Accuracy_1: 96.5%, Loss_1: 0.000452, Accuracy_2: 97.2% Loss_2: 0.000000  [ 3525/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.002607  [ 4089/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000085  [ 4653/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000421, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.001674, Accuracy_2: 91.5% Loss_2: 0.000000  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.001211, Accuracy_2: 91.5% Loss_2: 0.001502  [ 6345/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 91.5% Loss_2: 0.000001  [ 6909/15250]\n",
      "Accuracy_1: 94.3%, Loss_1: 0.000030, Accuracy_2: 93.6% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000605, Accuracy_2: 93.6% Loss_2: 0.000000  [ 8037/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000863, Accuracy_2: 90.1% Loss_2: 0.000000  [ 8601/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000190, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9165/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000002, Accuracy_2: 93.6% Loss_2: 0.000000  [ 9729/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000001, Accuracy_2: 91.5% Loss_2: 0.000055  [10293/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002453  [10857/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.001784  [11421/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000256, Accuracy_2: 90.8% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.002320, Accuracy_2: 92.2% Loss_2: 0.001246  [13113/15250]\n",
      "Accuracy_1: 87.9%, Loss_1: 0.000000, Accuracy_2: 87.2% Loss_2: 0.003231  [13677/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000265  [14241/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.001314  [14805/15250]\n",
      "Finished training\n",
      "Validation Error (Model 1): \n",
      " Accuracy: 83.8%, Avg loss: 0.000002\n",
      "Validation Error (Model 2): \n",
      " Accuracy: 83.4%, Avg loss: 0.000002 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.002939  [  141/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000000, Accuracy_2: 89.4% Loss_2: 0.001600  [  705/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000033, Accuracy_2: 85.8% Loss_2: 0.000382  [ 1269/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000006, Accuracy_2: 92.9% Loss_2: 0.000974  [ 1833/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000145, Accuracy_2: 92.9% Loss_2: 0.000266  [ 2397/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000330, Accuracy_2: 89.4% Loss_2: 0.000002  [ 2961/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000000, Accuracy_2: 90.8% Loss_2: 0.000261  [ 3525/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000000  [ 4089/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [ 4653/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000040, Accuracy_2: 89.4% Loss_2: 0.000000  [ 5217/15250]\n",
      "Accuracy_1: 89.4%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.000237  [ 5781/15250]\n",
      "Accuracy_1: 90.1%, Loss_1: 0.000001, Accuracy_2: 90.1% Loss_2: 0.000000  [ 6345/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.000000, Accuracy_2: 90.1% Loss_2: 0.000000  [ 6909/15250]\n",
      "Accuracy_1: 92.2%, Loss_1: 0.000000, Accuracy_2: 92.2% Loss_2: 0.000000  [ 7473/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000107, Accuracy_2: 87.2% Loss_2: 0.001608  [ 8037/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000039, Accuracy_2: 92.2% Loss_2: 0.002762  [ 8601/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 93.6% Loss_2: 0.000003  [ 9165/15250]\n",
      "Accuracy_1: 88.7%, Loss_1: 0.000000, Accuracy_2: 88.7% Loss_2: 0.006227  [ 9729/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000000  [10293/15250]\n",
      "Accuracy_1: 92.9%, Loss_1: 0.000000, Accuracy_2: 92.9% Loss_2: 0.000001  [10857/15250]\n",
      "Accuracy_1: 91.5%, Loss_1: 0.000599, Accuracy_2: 90.8% Loss_2: 0.001005  [11421/15250]\n",
      "Accuracy_1: 93.6%, Loss_1: 0.000278, Accuracy_2: 94.3% Loss_2: 0.000000  [11985/15250]\n",
      "Accuracy_1: 86.5%, Loss_1: 0.000000, Accuracy_2: 86.5% Loss_2: 0.000000  [12549/15250]\n",
      "Accuracy_1: 90.8%, Loss_1: 0.002410, Accuracy_2: 90.1% Loss_2: 0.000083  [13113/15250]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m     accuracy_1, accuracy_2, loss_1, loss_2 \u001b[38;5;241m=\u001b[39m validate_model(model_1, model_2, X_val, y_val, criterion)\n",
      "Cell \u001b[1;32mIn[18], line 18\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model_1, model_2, X_train, y_train, criterion, optimizer_1, optimizer_2)\u001b[0m\n\u001b[0;32m     15\u001b[0m X \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mfrom_numpy(X_train[indices[start:end]])\u001b[38;5;241m.\u001b[39mto(T\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m y_true \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mTensor(y_train[indices[start:end]])\u001b[38;5;241m.\u001b[39mto(T\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 18\u001b[0m logits_1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m logits_2 \u001b[38;5;241m=\u001b[39m model_2\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[0;32m     21\u001b[0m loss_1, loss_2 \u001b[38;5;241m=\u001b[39m criterion(logits_1, logits_2, y_true, \u001b[38;5;241m0.2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 41\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m---> 41\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:287\u001b[0m, in \u001b[0;36mGroupNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:2561\u001b[0m, in \u001b[0;36mgroup_norm\u001b[1;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected at least 2 dimensions for input tensor but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2560\u001b[0m _verify_batch_size([\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_groups, num_groups] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m2\u001b[39m:]))\n\u001b[1;32m-> 2561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Global Variables\n",
    "epochs = 1000\n",
    "learning_rate = 1e-2\n",
    "\n",
    "# Load Pre-Trained Models\n",
    "# model_1.load(\"Conv-NeuralNetwork-GN-Image Dataset-1_acc-78.86_loss-0.000002\")\n",
    "# model_2.load(\"Conv-NeuralNetwork-GN-Image Dataset-2_acc-80.67_loss-0.000002\")\n",
    "\n",
    "criterion = loss_coteaching # Co-teaching loss function\n",
    "optimizer_1 = optim.Adam(model_1.parameters(), lr=learning_rate)\n",
    "optimizer_2 = optim.Adam(model_2.parameters(), lr=learning_rate)\n",
    "\n",
    "best_accuracy = 0.80 # ???\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "\n",
    "    train_model(model_1, model_2, X_train, y_train, criterion, optimizer_1, optimizer_2)\n",
    "    print('Finished training')\n",
    "    \n",
    "    accuracy_1, accuracy_2, loss_1, loss_2 = validate_model(model_1, model_2, X_val, y_val, criterion)\n",
    "\n",
    "    if max(accuracy_1, accuracy_2) > best_accuracy:\n",
    "        print(f\"[+] Saving Model...\")\n",
    "\n",
    "        model_1.save(f\"Conv-NeuralNetwork-GN-Image Dataset-1_acc-{accuracy_1 * 100:.2f}_loss-{loss_1:>8f}\")\n",
    "        model_2.save(f\"Conv-NeuralNetwork-GN-Image Dataset-2_acc-{accuracy_2 * 100:.2f}_loss-{loss_2:>8f}\")\n",
    "        best_accuracy = max(accuracy_1, accuracy_2)\n",
    "\n",
    "        print(f\"[!] Models Saved.\")\n",
    "\n",
    "    epoch += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = loss_coteaching\n",
    "\n",
    "def test_model(model_1, model_2, X_test, y_test, criterion):\n",
    "    size = len(y_test)\n",
    "\n",
    "    model_1.eval()\n",
    "    model_2.eval()\n",
    "    with T.no_grad():\n",
    "        X = T.from_numpy(X_test).to(T.float32).to(device)\n",
    "        y_true = T.Tensor(y_test).to(T.float).to(device)\n",
    "\n",
    "        logits_1 = model_1.forward(X)\n",
    "        logits_2 = model_2.forward(X)\n",
    "\n",
    "        loss_1, loss_2 = criterion(logits_1, logits_2, y_true, 0.2)\n",
    "\n",
    "        correct_1 = (logits_1.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "        correct_2 = (logits_2.argmax(1) == y_true.argmax(1)).type(T.float).sum().item()\n",
    "        \n",
    "        loss_1 /= size\n",
    "        loss_2 /= size\n",
    "        accuracy_1 = correct_1/size\n",
    "        accuracy_2 = correct_2/size\n",
    "        \n",
    "        print(f\"Test Error (Model 1): \\n Accuracy: {(100 * (accuracy_1)):>0.1f}%, Avg loss: {loss_1:>8f}\")\n",
    "        print(f\"Test Error (Model 2): \\n Accuracy: {(100 * (accuracy_2)):>0.1f}%, Avg loss: {loss_2:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error (Model 1): \n",
      " Accuracy: 83.3%, Avg loss: 0.000001\n",
      "Test Error (Model 2): \n",
      " Accuracy: 82.9%, Avg loss: 0.000001 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1.load(\"Conv-NeuralNetwork-GN-Image Dataset-1_acc-83.24_loss-0.000001\")\n",
    "model_2.load(\"Conv-NeuralNetwork-GN-Image Dataset-2_acc-83.05_loss-0.000001\")\n",
    "test_model(model_1, model_2, X_test, y_test, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
